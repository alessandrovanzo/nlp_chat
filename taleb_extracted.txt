
================================================================================
CHAPTER/SECTION 1 (Item 2)
================================================================================

Antifragile, The Black Swan, Fooled by Randomness
, and
The Bed of Procrustes
are works of fiction. Names, places, and incidents either are products of the author’s imagination or are used fictitiously.
A Random House Ebook Omnibus Edition
Antifragile
copyright © 2012 by Nassim Nicholas Taleb
The Black Swan
copyright © 2007 by Nassim Nicholas Taleb
Fooled by Randomness
copyright © 2005 by Nassim Nicholas Taleb
The Bed of Procrustes
copyright © 2010 by Nassim Nicholas Taleb
All rights reserved.
Published in the United States by Random House, an imprint of Random House, a division of Penguin Random House LLC, New York.
R
ANDOM
H
OUSE
and the H
OUSE
colophon are registered trademarks of Penguin Random House LLC.
Antifragile, The Black Swan, Fooled by Randomness
, and
The Bed of Procrustes
were each published separately by Random House, an imprint of The Random House Publishing Group, a division of Penguin Random House LLC, New York, in 2012, 2007, 2005, and 2010.
ebook ISBN 9780812997699
Cover design: Joseph Perez
randomhousebooks.com
v3.1_r1


================================================================================
CHAPTER/SECTION 2 (Item 3)
================================================================================

CONTENTS
Cover
Title Page
Copyright
Antifragile
The Black Swan
Fooled by Randomness
The Bed of Procrustes
Other Books by This Author
About the Author


================================================================================
CHAPTER/SECTION 3 (Item 6)
================================================================================

Copyright © 2012 by Nassim Nicholas Taleb
All rights reserved.
Published in the United States by Random House, an imprint of The Random House Publishing Group, a division of Random House LLC, a Penguin Random House Company, New York
R
ANDOM
H
OUSE
and colophon are registered trademarks of Random House LLC.
LIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA
Taleb, Nassim.
Antifragile : things that gain from disorder / Nassim Nicholas Taleb.
p.   cm.
Includes bibliographical references and index.
ISBN 978-1-4000-6782-4
eISBN: 978-0-679-64527-6
1. Uncertainty (Information theory)—Social aspects.   2. Forecasting.   3. Complexity (Philosophy)   I. Title.
Q375.T348 2012
155.2’4—dc23 2012028697
Cover design: Keenan
Cover Illustration: based on a photograph
© Malerapaso/iStockphoto
www.atrandom.com
v3.1_r6


================================================================================
CHAPTER/SECTION 4 (Item 7)
================================================================================

CONTENTS
Master - Table of Contents
Antifragile
Title Page
Copyright
Chapter Summaries and Map
Prologue
APPENDIX
:      The Triad, or A Map of the World and Things Along the Three Properties
BOOK I: THE ANTIFRAGILE: AN INTRODUCTION
Chapter 1:   Between Damocles and Hydra
Half of Life Has No Name
Please Behead Me
On the Necessity of Naming
Proto-Antifragility
Domain Independence Is Domain Dependent
Chapter 2:   Overcompensation and Overreaction Everywhere
How to Win a Horse Race
Antifragile Responses as Redundancy
On the Antifragility of Riots, Love, and Other Unexpected Beneficiaries of Stress
Please Ban My Book: The Antifragility of Information
Get Another Job
Chapter 3:   The Cat and the Washing Machine
The Complex
Stressors Are Information
Equilibrium, Not Again
Crimes Against Children
Punished by Translation
Touristification
The Secret Thirst for Chance
Chapter 4:   What Kills Me Makes Others Stronger
Antifragility by Layers
Evolution and Unpredictability
Organisms Are Populations and Populations Are Organisms
Thank You, Errors
Learning from the Mistakes of Others
How to Become Mother Teresa
Why the Aggregate Hates the Individual
What Does Not Kill Me Kills Others
Me and Us
National Entrepreneur Day
BOOK II: MODERNITY AND THE DENIAL OF ANTIFRAGILITY
Chapter 5:   The Souk and the Office Building
Two Types of Professions
Lenin in Zurich
Bottom-up Variations
Away from Extremistan
The Great Turkey Problem
Twelve Thousand Years
War, Prison, or Both
Pax Romana
War or No War
Chapter 6:   Tell Them I Love (Some) Randomness
Hungry Donkeys
Political Annealing
That Time Bomb Called Stability
The Second Step: Do (Small) Wars Save Lives?
What to Tell the Foreign Policy Makers
What Do We Call Here Modernity?
Chapter 7:   Naive Intervention
Intervention and Iatrogenics
First, Do No Harm
The Opposite of Iatrogenics
Iatrogenics in High Places
Can a Whale Fly Like an Eagle?
Not Doing Nothing
Non-Naive Interventionism
In Praise of Procrastination—the Fabian Kind
Neuroticism in Industrial Proportions
A Legal Way to Kill People
Media-Driven Neuroticism
The State Can Help—When Incompetent
France Is Messier than You Think
Sweden and the Large State
Catalyst-as-Cause Confusion
Chapter 8:   Prediction as a Child of Modernity
Ms.   Bré Has Competitors
The Predictive
Plus or Minus Bad Teeth
The Idea of Becoming a Non-Turkey
No More Black Swans
BOOK III: A NONPREDICTIVE VIEW OF THE WORLD
Chapter 9:   Fat Tony and the Fragilistas
Indolent Fellow Travelers
The Importance of Lunch
The Antifragility of Libraries
On Suckers and Nonsuckers
Loneliness
What the Nonpredictor Can Predict
Chapter 10:   Seneca’s Upside and Downside
Is This Really Serious?
Less Downside from Life
Stoicism’s Emotional Robustification
The Domestication of Emotions
How to Become the Master
The Foundational Asymmetry
Chapter 11:   Never Marry the Rock Star
On the Irreversibility of Broken Packages
Seneca’s Barbell
The Accountant and the Rock Star
Away from the Golden Middle
The Domestication of Uncertainty
BOOK IV: OPTIONALITY, TECHNOLOGY, AND THE INTELLIGENCE OF ANTIFRAGILITY
Do You Really Know Where You Are Going?
The Teleological Fallacy
America’s Principal Asset
Chapter 12:   Thales’ Sweet Grapes
Option and Asymmetry
The Options of Sweet Grapes
Saturday Evening in London
Your Rent
Asymmetry
Things That Like Dispersion
The Thalesian and the Aristotelian
How to Be Stupid
Nature and Options
The Rationality
Life Is Long Gamma
Roman Politics Likes Optionality
Next
Chapter 13:   Lecturing Birds on How to Fly
Once More, Less Is More
Mind the Gaps
Search and How Errors Can Be Investments
Creative and Uncreative Destructions
The Soviet-Harvard Department of Ornithology
Epiphenomena
Greed as a Cause
Debunking Epiphenomena
Cherry-picking (or the Fallacy of Confirmation)
Chapter 14:   When Two Things Are Not the “Same Thing”
Where Are the Stressors?
L’Art pour l’Art, to Learn for Learning’s Sake
Polished Dinner Partners
The Green Lumber Fallacy
How Fat Tony Got Rich (and Fat)
Conflation
Prometheus and Epimetheus
Chapter 15:   History Written by the Losers
The Evidence Staring at Us
Is It Like Cooking?
The Industrial Revolution
Governments Should Spend on Nonteleological Tinkering, Not Research
The Case in Medicine
Matt Ridley’s Anti-Teleological Argument
Corporate Teleology
The Inverse Turkey Problem
To Fail Seven Times, Plus or Minus Two
The Charlatan, the Academic, and the Showman
Chapter 16:   A Lesson in Disorder
The Ecological and the Ludic
The Touristification of the Soccer Mom
An Antifragile (Barbell) Education
Chapter 17:   Fat Tony Debates Socrates
Euthyphro
Fat Tony Versus Socrates
Primacy of Definitional Knowledge
Mistaking the Unintelligible for the Unintelligent
Tradition
The Sucker-Nonsucker Distinction
Fragility, Not Probability
Conflation of Events and Exposure
Conclusion to Book IV
What Will Happen Next?
BOOK V: THE NONLINEAR AND THE NONLINEAR
On the Importance of Attics
Chapter 18:   On the Difference Between a Large Stone and a Thousand Pebbles
A Simple Rule to Detect the Fragile
Why Is Fragility Nonlinear?
When to Smile and When to Frown
Why Is the Concave Hurt by Black Swan Events?
Traffic in New York
Someone Call New York City Officials
Where More Is Different
A “Balanced Meal”
Run, Don’t Walk
Small May Be Ugly, It Is Certainly Less Fragile
How to Be Squeezed
Kerviel and Micro-Kerviel
How to Exit a Movie Theater
Projects and Prediction
Why Planes Don’t Arrive Early
Wars, Deficits, and Deficits
Where the “Efficient” Is Not Efficient
Pollution and Harm to the Planet
The Nonlinearity of Wealth
Conclusion
Chapter 19:   The Philosopher’s Stone and Its Inverse
How to Detect Who Will Go Bust
The Idea of Positive and Negative Model Error
How to Lose a Grandmother
Now the Philosopher’s Stone
How to Transform Gold into Mud: The Inverse Philosopher’s Stone
BOOK VI: VIA NEGATIVA
Where Is the Charlatan?
Subtractive Knowledge
Barbells, Again
Less Is More
Chapter 20:   Time and Fragility
From Simonides to Jensen
Learning to Subtract
Technology at Its Best
To Age in Reverse: The Lindy Effect
A Few Mental Biases
Neomania and Treadmill Effects
Architecture and the Irreversible Neomania
Wall to Wall Windows
Metrification
Turning Science into Journalism
What Should Break
Prophets and the Present
Empedocles’ Dog
What Does Not Make Sense
Chapter 21:   Medicine, Convexity, and Opacity
How to Argue in an Emergency Room
First Principle of Iatrogenics (Empiricism)
Second Principle of Iatrogenics (Nonlinearity in Response)
Jensen’s Inequality in Medicine
Burying the Evidence
The Never-ending History of Turkey Situations
Nature’s Opaque Logic
Guilty or Innocent
Plead Ignorance of Biology: Phenomenology
The Ancients Were More Caustic
How to Medicate Half the Population
The “Rigor of Mathematics” in Medicine
Next
Chapter 22:   To Live Long, but Not Too Long
Life Expectancy and Convexity
Subtraction Adds to Your Life
The Iatrogenics of Money
Religion and Naive Interventionism
If It’s Wednesday, I Must Be Vegan
Convexity Effects and Random Nutrition
How to Eat Yourself
Walk-Deprived
I Want to Live Forever
BOOK VII: THE ETHICS OF FRAGILITY AND ANTIFRAGILITY
Chapter 23:   Skin in the Game: Antifragility and Optionality at the Expense of Others
Hammurabi
The Talker’s Free Option
Postdicting
The Stiglitz Syndrome
The Problem of Frequency, or How to Lose Arguments
The Right Decision for the Wrong Reason
The Ancients and the Stiglitz Syndrome
To Burn One’s Vessels
How Poetry Can Kill You
The Problem of Insulation
Champagne Socialism
Soul in the Game
Options, Antifragility, and Social Fairness
The Robert Rubin Free Option
Which Adam Smith?
The Antifragility and Ethics of (Large) Corporations
Artisans, Marketing, and the Cheapest to Deliver
Lawrence of Arabia or Meyer Lansky
Next
Chapter 24:   Fitting Ethics to a Profession
Wealth Without Independence
The Professionals and the Collective
The Ethical and the Legal
Casuistry as Optionality
Big Data and the Researcher’s Option
The Tyranny of the Collective
Chapter 25:   Conclusion
Epilogue
Glossary
Appendix I
Appendix II
Dedication
Acknowledgments
Additional Notes, Afterthoughts, and Further Reading
Bibliography


================================================================================
CHAPTER/SECTION 5 (Item 8)
================================================================================

CHAPTER SUMMARIES AND MAP
Boldface terms are in the
Glossary
.
BOOK I:  THE ANTIFRAGILE: AN INTRODUCTION
CHAPTER 1
. Explains how we missed the word “antifragility” in classrooms. Fragile-Robust-Antifragile as Damocles-Phoenix-Hydra. Domain dependence.
CHAPTER 2
. Where we find overcompensation. Obsessive love is the most antifragile thing outside of economics.
CHAPTER 3
. The difference between the organic and the engineered.
Touristification
and attempts to suck volatility out of life.
CHAPTER 4
. The antifragility of the whole often depends on the fragility of the parts. Why death is a necessity for life. The benefits of errors for the collective. Why we need risk takers. A few remarks about modernity missing the point. A salute to the entrepreneur and risk taker.
BOOK II:  MODERNITY AND THE DENIAL OF ANTIFRAGILITY
THE PROCRUSTEAN BED
CHAPTER 5
. Two different randomness categories, seen through the profiles of two brothers. How Switzerland is not controlled from above. The difference between
Mediocristan
and
Extremistan.
The virtues of city-states, bottom-up political systems, and the stabilizing effect of municipal noise.
CHAPTER 6
. Systems that like randomness. Annealing inside and outside physics. Explains the effect of overstabilizing organisms and complex systems (political, economic, etc.). The defects of intellectualism. U.S. foreign policy, and pseudostabilization.
CHAPTER 7
. An introduction to
naive intervention
and
iatrogenics,
the most neglected product of modernity. Noise and signal and overintervening from noise.
CHAPTER 8
. Prediction as the child of modernity.
BOOK III:  A NONPREDICTIVE VIEW OF THE WORLD
CHAPTER 9
. Fat Tony, the smeller of fragility, Nero, long lunches, and squeezing the
fragilistas.
CHAPTER 10
. In which Professor Triffat refuses his own medicine and we use Seneca and stoicism as a back door to explain why everything antifragile has to have more upside than downside and hence benefits from volatility, error, and stressors—the
fundamental asymmetry.
CHAPTER 11
. What to mix and not to mix. The
barbell strategy
in life and things as the transformation of anything from fragile to antifragile.
BOOK IV:  OPTIONALITY, TECHNOLOGY, AND THE INTELLIGENCE OF ANTIFRAGILITY
(The tension between education, which loves order, and innovation, which loves disorder.)
CHAPTER 12
. Thales versus Aristotle, and the notion of
optionality,
which allows you not to know what’s going on—why it has been misunderstood owing to the conflation. How Aristotle missed the point. Optionality in private life. Conditions under which tinkering outperforms design.
Rational
flâneur.
CHAPTER 13
. Asymmetric payoffs behind growth, little else. The
Soviet-Harvard illusion,
or the lecturing-birds-how-to-fly effect. Epiphenomena.
CHAPTER 14
.
The green lumber fallacy.
Tension between episteme and trial and error, and the role through history. Does knowledge generate wealth, and if so, which knowledge? When two things are not the same thing.
CHAPTER 15
. Rewriting the history of technology. How, in science, history is rewritten by the losers and how I saw it in my own business and how we can generalize. Does knowledge of biology hurt medicine? Hiding the role of luck. What makes a good entrepreneur?
CHAPTER 16
. How to deal with Soccer Moms. The education of a
flâneur.
CHAPTER 17
. Fat Tony argues with Socrates. Why can’t we do things we can’t explain, and why do we have to explain things we do? The
Dionysian.
The sucker-nonsucker approach to things.
BOOK V:  THE NONLINEAR AND THE NONLINEAR
CHAPTER 18
.
Convexity, concavity,
and convexity effects. Why size fragilizes.
CHAPTER 19
.
The Philosopher’s Stone.
Deeper into convexity. How Fannie Mae went bust. Nonlinearity. The heuristic to detect fragility and antifragility. Convexity biases,
Jensen’s inequality,
and their impact on ignorance.
BOOK VI:  VIA NEGATIVA
CHAPTER 20
.
Neomania.
Looking at the future by
via negativa.
The
Lindy effect:
the old outlives the new in proportion to its age.
Empedocles’ Tile.
Why the irrational has an edge over the perceived-to-be-rational.
CHAPTER 21
. Medicine and asymmetry. Decision rules in medical problems: why the very ill has a convex payoff and the healthy has concave exposures.
CHAPTER 22
. Medicine by subtraction. Introduces the match between individuals and the type of randomness in the environment. Why I don’t want to live forever.
BOOK VII:  THE ETHICS OF FRAGILITY AND ANTIFRAGILITY
CHAPTER 23
. The
agency problem
as transfer of fragility.
Skin in the game. Doxastic commitment,
or
soul in the game.
The
Robert Rubin problem,
the
Joseph Stiglitz problem,
and the
Alan Blinder problem,
all three about agency, and one about
cherry-picking.
CHAPTER 24
.
Ethical
inversion.
The collective can be wrong while individuals know it. How people are trapped into an opinion, and how to set them free.
CHAPTER 25
. Conclusion.
EPILOGUE
. What happens when Nero leaves to go to the Levant to observe the rite of Adonis.


================================================================================
CHAPTER/SECTION 6 (Item 9)
================================================================================

PROLOGUE


================================================================================
CHAPTER/SECTION 7 (Item 10)
================================================================================

I. HOW TO LOVE THE WIND
Wind extinguishes a candle and energizes fire.
Likewise with randomness, uncertainty, chaos: you want to use them, not hide from them. You want to be the fire and wish for the wind. This summarizes this author’s nonmeek attitude to randomness and uncertainty.
We just don’t want to just survive uncertainty, to just about make it. We want to survive uncertainty and, in addition—like a certain class of aggressive Roman Stoics—have the last word. The mission is how to domesticate, even dominate, even conquer, the unseen, the opaque, and the inexplicable.
How?


================================================================================
CHAPTER/SECTION 8 (Item 11)
================================================================================

II. THE ANTIFRAGILE
Some things benefit from shocks; they thrive and grow when exposed to volatility, randomness, disorder, and stressors and love adventure, risk, and uncertainty. Yet, in spite of the ubiquity of the phenomenon, there is no word for the exact opposite of fragile. Let us call it antifragile.
Antifragility is beyond resilience or robustness. The resilient resists shocks and stays the same; the antifragile gets better. This property is behind everything that has changed with time: evolution, culture, ideas,
revolutions, political systems, technological innovation, cultural and economic success, corporate survival, good recipes (say, chicken soup or steak tartare with a drop of cognac), the rise of cities, cultures, legal systems, equatorial forests, bacterial resistance … even our own existence as a species on this planet. And antifragility determines the boundary between what is living and organic (or complex), say, the human body, and what is inert, say, a physical object like the stapler on your desk.
The antifragile loves randomness and uncertainty, which also means—crucially—a love of errors, a certain class of errors. Antifragility has a singular property of allowing us to deal with the unknown, to do things without understanding them—and do them well. Let me be more aggressive: we are largely better at doing than we are at thinking, thanks to antifragility. I’d rather be dumb and antifragile than extremely smart and fragile, any time.
It is easy to see things around us that like a measure of stressors and volatility: economic systems, your body, your nutrition (diabetes and many similar modern ailments seem to be associated with a lack of randomness in feeding and the absence of the stressor of occasional starvation), your psyche. There are even financial contracts that are antifragile: they are explicitly designed to benefit from market volatility.
Antifragility makes us understand fragility better. Just as we cannot improve health without reducing disease, or increase wealth without first decreasing losses, antifragility and fragility are degrees on a spectrum.
Nonprediction
By grasping the mechanisms of antifragility we can build a systematic and broad guide to
nonpredictive
decision making under uncertainty in business, politics, medicine, and life in general—anywhere the unknown preponderates, any situation in which there is randomness, unpredictability, opacity, or incomplete understanding of things.
It is far easier to figure out if something is fragile than to predict the occurrence of an event that may harm it. Fragility can be measured; risk is not measurable (outside of casinos or the minds of people who call themselves “risk experts”). This provides a solution to what I’ve called the Black Swan problem—the impossibility of calculating the risks of consequential rare events and predicting their occurrence. Sensitivity to harm from volatility is tractable, more so than forecasting the event that
would cause the harm. So we propose to stand our current approaches to prediction, prognostication, and risk management on their heads.
In every domain or area of application, we propose rules for moving from the fragile toward the antifragile, through reduction of fragility or harnessing antifragility. And we can almost always detect antifragility (and fragility) using a simple test of asymmetry: anything that has more upside than downside from random events (or certain shocks) is antifragile; the reverse is fragile.
Deprivation of Antifragility
Crucially, if antifragility is the property of all those natural (and complex) systems that have survived, depriving these systems of volatility, randomness, and stressors will harm them. They will weaken, die, or blow up. We have been fragilizing the economy, our health, political life, education, almost everything … by suppressing randomness and volatility. Just as spending a month in bed (preferably with an unabridged version of
War and Peace
and access to
The Sopranos
’ entire eighty-six episodes) leads to muscle atrophy, complex systems are weakened, even killed, when deprived of stressors. Much of our modern, structured, world has been harming us with top-down policies and contraptions (dubbed “Soviet-Harvard delusions” in the book) which do precisely this: an insult to the antifragility of systems.
This is the tragedy of modernity: as with neurotically overprotective parents, those trying to help are often hurting us the most.
If about everything top-down fragilizes and blocks antifragility and growth, everything bottom-up thrives under the right amount of stress and disorder. The process of discovery (or innovation, or technological progress) itself depends on antifragile tinkering, aggressive risk bearing rather than formal education.
Upside at the Expense of Others
Which brings us to the largest fragilizer of society, and greatest generator of crises, absence of “skin in the game.” Some become antifragile at the expense of others by getting the upside (or gains) from volatility, variations, and disorder and exposing others to the downside risks of losses or harm. And such
antifragility-at-the-cost-of-fragility-of-others
is hidden—given the blindness to antifragility by the Soviet-Harvard intellectual
circles, this asymmetry is rarely identified and (so far) never taught. Further, as we discovered during the financial crisis that started in 2008, these blowup risks-to-others are easily concealed owing to the growing complexity of modern institutions and political affairs. While in the past people of rank or status were those and only those who took risks, who had the downside for their actions, and heroes were those who did so for the sake of others, today the exact reverse is taking place. We are witnessing the rise of a new class of inverse heroes, that is, bureaucrats, bankers, Davos-attending members of the I.A.N.D. (International Association of Name Droppers), and academics with too much power and no real downside and/or accountability. They game the system while citizens pay the price.
At no point in history have so many non-risk-takers, that is, those with no personal exposure, exerted so much control.
The chief ethical rule is the following: Thou shalt not have antifragility at the expense of the fragility of others.


================================================================================
CHAPTER/SECTION 9 (Item 12)
================================================================================

III. THE ANTIDOTE TO THE BLACK SWAN
I want to live happily in a world I don’t understand.
Black Swans (capitalized) are large-scale unpredictable and irregular events of massive consequence—unpredicted by a certain observer, and such unpredictor is generally called the “turkey” when he is both surprised and harmed by these events. I have made the claim that most of history comes from Black Swan events, while we worry about fine-tuning our understanding of the ordinary, and hence develop models, theories, or representations that cannot possibly track them or measure the possibility of these shocks.
Black Swans hijack our brains, making us feel we “sort of” or “almost” predicted them, because they are retrospectively explainable. We don’t realize the role of these Swans in life because of this illusion of predictability. Life is more, a lot more, labyrinthine than shown in our memory—our minds are in the business of turning history into something smooth and linear, which makes us underestimate randomness. But when we see it, we fear it and overreact. Because of this fear and thirst for order, some human systems, by disrupting the invisible or not so visible logic of things, tend to be exposed to harm from Black Swans and almost never get any benefit. You get pseudo-order when you seek
order; you only get a measure of order and control when you embrace randomness.
Complex systems are full of interdependencies—hard to detect—and nonlinear responses. “Nonlinear” means that when you double the dose of, say, a medication, or when you double the number of employees in a factory, you don’t get twice the initial effect, but rather a lot more or a lot less. Two weekends in Philadelphia are not twice as pleasant as a single one—I’ve tried. When the response is plotted on a graph, it does not show as a straight line (“linear”), rather as a curve. In such environments, simple causal associations are misplaced; it is hard to see how things work by looking at single parts.
Man-made complex systems tend to develop cascades and runaway chains of reactions that decrease, even eliminate, predictability and cause outsized events. So the modern world may be increasing in technological knowledge, but, paradoxically, it is making things a lot more unpredictable. Now for reasons that have to do with the increase of the artificial, the move away from ancestral and natural models, and the loss in robustness owing to complications in the design of everything, the role of Black Swans is increasing. Further, we are victims to a new disease, called in this book
neomania,
that makes us build Black Swan–vulnerable systems—“progress.”
An annoying aspect of the Black Swan problem—in fact the central, and largely missed, point—is that the odds of rare events are simply not computable. We know a lot less about hundred-year floods than five-year floods—model error swells when it comes to small probabilities.
The rarer the event, the less tractable, and the less we know about how frequent its occurrence
—yet the rarer the event, the more confident these “scientists” involved in predicting, modeling, and using PowerPoint in conferences with equations in multicolor background have become.
It is of great help that Mother Nature—thanks to its antifragility—is the best expert at rare events, and the best manager of Black Swans; in its billions of years it succeeded in getting here without much command-and-control instruction from an Ivy League–educated director nominated by a search committee. Antifragility is not just the antidote to the Black Swan; understanding it makes us less intellectually fearful in accepting the role of these events as necessary for history, technology, knowledge, everything.
Robust Is Not Robust Enough
Consider that Mother Nature is not just “safe.” It is aggressive in destroying and replacing, in selecting and reshuffling. When it comes to random events, “robust” is certainly not good enough. In the long run everything with the most minute vulnerability breaks, given the ruthlessness of time—yet our planet has been around for perhaps four billion years and, convincingly, robustness can’t just be it: you need perfect robustness for a crack not to end up crashing the system. Given the unattainability of perfect robustness, we need a mechanism by which the system regenerates itself continuously by using, rather than suffering from, random events, unpredictable shocks, stressors, and volatility.
The antifragile gains from prediction errors, in the long run. If you follow this idea to its conclusion, then many things that gain from randomness should be dominating the world today—and things that are hurt by it should be gone. Well, this turns out to be the case. We have the illusion that the world functions thanks to programmed design, university research, and bureaucratic funding, but there is compelling—very compelling—evidence to show that this is an illusion, the illusion I call
lecturing birds how to fly.
Technology is the result of antifragility, exploited by risk-takers in the form of tinkering and trial and error, with nerd-driven design confined to the backstage. Engineers and tinkerers develop things while history books are written by academics; we will have to refine historical interpretations of growth, innovation, and many such things.
On the Measurability of (Some) Things
Fragility is quite measurable, risk not so at all, particularly risk associated with rare events.
1
I said that we can estimate, even measure, fragility and antifragility, while we cannot calculate risks and probabilities of shocks and rare events, no matter how sophisticated we get. Risk management as practiced is the study of an event taking place in the future, and only some economists and other lunatics can claim—against experience—to “measure” the future incidence of these rare events, with suckers listening
to them—against experience and the track record of such claims. But fragility and antifragility are part of the current property of an object, a coffee table, a company, an industry, a country, a political system. We can detect fragility, see it, even in many cases measure it, or at least measure comparative fragility with a small error while comparisons of risk have been (so far) unreliable. You cannot say with any reliability that a certain remote event or shock is more likely than another (unless you enjoy deceiving yourself), but you can state with a lot more confidence that an object or a structure is more fragile than another should a certain event happen. You can easily tell that your grandmother is more fragile to abrupt changes in temperature than you, that some military dictatorship is more fragile than Switzerland should political change happen, that a bank is more fragile than another should a crisis occur, or that a poorly built modern building is more fragile than the Cathedral of Chartres should an earthquake happen. And—centrally—you can even make the prediction of which one will last longer.
Instead of a discussion of risk (which is both predictive and sissy) I advocate the notion of fragility, which is not predictive—and, unlike risk, has an interesting word that can describe its functional opposite, the nonsissy concept of antifragility.
To measure antifragility, there is a philosopher’s-stone-like recipe using a compact and simplified rule that allows us to identify it across domains, from health to the construction of societies.
We have been unconsciously exploiting antifragility in practical life and, consciously, rejecting it—particularly in intellectual life.
The Fragilista
Our idea is to avoid interference with things we don’t understand. Well, some people are prone to the opposite. The fragilista belongs to that category of persons who are usually in suit and tie, often on Fridays; he faces your jokes with icy solemnity, and tends to develop back problems early in life from sitting at a desk, riding airplanes, and studying newspapers. He is often involved in a strange ritual, something commonly called “a meeting.” Now, in addition to these traits, he defaults to thinking that what he doesn’t see is not there, or what he does not understand does not exist. At the core, he tends to mistake the unknown for the nonexistent.
The fragilista falls for the
Soviet-Harvard delusion
, the (unscientific)
overestimation of the reach of scientific knowledge. Because of such delusion, he is what is called a
naive rationalist,
a
rationalizer,
or sometimes just a
rationalist,
in the sense that he believes that the
reasons
behind things are automatically accessible to him. And let us not confuse rationalizing with rational—the two are almost always exact opposites. Outside of physics, and generally in complex domains, the reasons behind things have had a tendency to make themselves less obvious to us, and even less to the fragilista. This property of natural things not to advertise themselves in a user’s manual is, alas, not much of a hindrance: some fragilistas will get together to write the user’s manual themselves, thanks to their definition of “science.”
So thanks to the fragilista, modern culture has been increasingly building blindness to the mysterious, the impenetrable, what Nietzsche called the Dionysian, in life.
Or to translate Nietzsche into the less poetic but no less insightful Brooklyn vernacular, this is what our character Fat Tony calls a “sucker game.”
In short, the fragilista (medical, economic, social planning) is one who makes you engage in policies and actions, all artificial, in which
the benefits are small and visible, and the side effects potentially severe and invisible
.
There is the medical fragilista who overintervenes in denying the body’s natural ability to heal and gives you medications with potentially very severe side effects; the policy fragilista (the interventionist social planner) who mistakes the economy for a washing machine that continuously needs fixing (by him) and blows it up; the psychiatric fragilista who medicates children to “improve” their intellectual and emotional life; the soccer-mom fragilista; the financial fragilista who makes people use “risk” models that destroy the banking system (then uses them again); the military fragilista who disturbs complex systems; the predictor fragilista who encourages you to take more risks; and many more.
2
Indeed, the political discourse is lacking a concept. Politicians in their speeches, goals, and promises aim at the timid concepts of “resilience,” “solidity,” not antifragility, and in the process are stifling the mechanisms of growth and evolution. We didn’t get where we are thanks to the sissy
notion of resilience. And, what’s worse, we didn’t get where we are today thanks to policy makers—but thanks to the appetite for risks and errors of a certain class of people we need to encourage, protect, and respect.
Where Simple Is More Sophisticated
A complex system, contrary to what people believe, does not require complicated systems and regulations and intricate policies. The simpler, the better. Complications lead to multiplicative chains of unanticipated effects. Because of opacity, an intervention leads to unforeseen consequences, followed by apologies about the “unforeseen” aspect of the consequences, then to another intervention to correct the secondary effects, leading to an explosive series of branching “unforeseen” responses, each one worse than the preceding one.
Yet simplicity has been difficult to implement in modern life because it is against the spirit of a certain brand of people who seek sophistication so they can justify their profession.
Less is more and usually more effective
. Thus I will produce a small number of tricks, directives, and interdicts—how to live in a world we don’t understand, or, rather, how to
not be afraid
to work with things we patently don’t understand, and, more principally, in what manner we should work with these. Or, even better, how to dare to look our ignorance in the face and not be ashamed of being human—be aggressively and proudly human. But that may require some structural changes.
What I propose is a road map to modify our man-made systems to let the simple—and natural—take their course.
But simplicity is not so simple to attain. Steve Jobs figured out that “you have to work hard to get your thinking clean to make it simple.” The Arabs have an expression for trenchant prose:
no skill to understand it, mastery to write it
.
Heuristics are simplified rules of thumb that make things simple and easy to implement. But their main advantage is that the user knows that they are not perfect, just expedient, and is therefore less fooled by their powers. They become dangerous when we forget that.


================================================================================
CHAPTER/SECTION 10 (Item 13)
================================================================================

IV. THIS BOOK
The journey to this idea of antifragility was, if anything, nonlinear.
I suddenly realized one day that fragility—which had been lacking a
technical definition—could be expressed as
what does not like volatility,
and that
what does not like volatility
does not like randomness, uncertainty, disorder, errors, stressors, etc. Think of anything fragile, say, objects in your living room such as the glass frame, the television set, or, even better, the china in the cupboards. If you label them “fragile,” then you necessarily want them to be left alone in peace, quiet, order, and predictability. A fragile object would not possibly benefit from an earthquake or the visit of your hyperactive nephew. Further, everything that does not like volatility does not like stressors, harm, chaos, events, disorder, “unforeseen” consequences, uncertainty, and, critically, time.
And antifragility flows—sort of—from this explicit definition of fragility. It likes volatility et al. It also likes time. And there is a powerful and helpful link to nonlinearity: everything nonlinear in response is either fragile or antifragile to a certain source of randomness.
The strangest thing is that this obvious property that
anything fragile hates volatility,
and vice versa, has been sitting completely outside the scientific and philosophical discourse. Completely. And the study of the sensitivity of things to volatility is the strange business specialty in which I spent most of my adult life, two decades—I know it is a strange specialty, I promise to explain later. My focus in that profession has been on identifying items that “love volatility” or “hate volatility”; so all I had to do was expand the ideas from the financial domain in which I had been focused to the broader notion of decision making under uncertainty across various fields, from political science to medicine to dinner plans.
3
And in that strange profession of people who work with volatility, there were two types. First category, academics, report-writers, and commentators who study future events and write books and papers; and, second category, practitioners who, instead of studying future events, try to understand how things react to volatility (but practitioners are usually too busy practitioning to write books, articles, papers, speeches, equations, theories and get honored by Highly Constipated and Honorable Members of Academies). The difference between the two categories is central: as we saw, it is much easier to understand if
something is harmed by volatility—hence fragile—than try to forecast harmful events, such as these oversized Black Swans. But only practitioners (or people who do things) tend to spontaneously get the point.
The (Rather Happy) Disorder Family
One technical comment. We keep saying that fragility and antifragility mean potential gain or harm from exposure to
something
related to volatility. What is that something? Simply, membership in the extended disorder family.
The Extended Disorder Family (or Cluster): (i) uncertainty, (ii) variability, (iii) imperfect, incomplete knowledge, (iv) chance, (v) chaos, (vi) volatility, (vii) disorder, (viii) entropy, (ix) time, (x) the unknown, (xi) randomness, (xii) turmoil, (xiii) stressor, (xiv) error, (xv) dispersion of outcomes, (xvi) unknowledge.
It happens that uncertainty, disorder, and the unknown are completely equivalent in their effect: antifragile systems benefit (to some degree) from, and the fragile is penalized by, almost all of them—even if you have to find them in separate buildings of the university campuses and some philosophaster who has never taken real risks in his life, or, worse, never had a life, would inform you that “they are
clearly
not the same thing.”
Why item (ix), time? Time is functionally similar to volatility: the more time, the more events, the more disorder. Consider that if you can suffer limited harm and are antifragile to small errors, time brings the kind of errors or reverse errors that end up benefiting you. This is simply what your grandmother calls experience. The fragile breaks with time.
Only One Book
This makes this book my central work. I’ve had only one master idea, each time taken to its next step, the last step—this book—being more like a big jump. I am reconnected to my “practical self,” my soul of a practitioner, as this is a merger of my entire history as practitioner and “volatility specialist” combined with my intellectual and philosophical interests in randomness and uncertainty, which had previously taken separate paths.
My writings are not stand-alone essays on specific topics, with beginnings, ends, and expiration dates; rather, they are nonoverlapping chapters from that central idea, a main corpus focused on uncertainty, randomness, probability, disorder, and what to do in a world we don’t understand, a world with unseen elements and properties, the random and the complex; that is, decision making under opacity. The corpus is called
Incerto
and is constituted (so far) of a trilogy plus philosophical and technical addenda. The rule is that the distance between a random chapter of one book, say,
Antifragile,
and another random chapter of another, say,
Fooled by Randomness,
should be similar to the one between chapters of a long book. The rule allows the corpus to cross domains (by shifting across science, philosophy, business, psychology, literature, and autobiographical segments) without lapsing into promiscuity.
So the relationship of this book to
The Black Swan
would be as follows: in spite of the chronology (and the fact that this book takes the Black Swan idea to its natural and prescriptive conclusion),
Antifragile
would be the main volume and
The Black Swan
its backup of sorts, and a theoretical one, perhaps even its junior appendix. Why? Because
The Black Swan
(and its predecessor,
Fooled by Randomness
) were written to convince us of a dire situation, and worked hard at it; this one starts from the position that one does not need convincing that (a) Black Swans dominate society and history (and people, because of ex post rationalization, think themselves capable of understanding them); (b) as a consequence, we don’t quite know what’s going on, particularly under severe nonlinearities; so we can get to practical business right away.
No Guts, No Belief
To accord with the practitioner’s ethos, the rule in this book is as follows: I eat my own cooking.
I have only written, in every line I have composed in my professional life, about things I have done, and the risks I have recommended that others take or avoid were risks I have been taking or avoiding myself. I will be the first to be hurt if I am wrong. When I warned about the fragility of the banking system in
The Black Swan,
I was betting on its collapse (particularly when my message went unheeded); otherwise I felt it would not have been ethical to write about it. That personal stricture applies to every domain, including medicine, technical innovation, and simple matters in life. It does not mean that one’s personal experiences
constitute a sufficient sample to derive a conclusion about an idea; it is just that one’s personal experience gives the stamp of authenticity and sincerity of opinion. Experience is devoid of the cherry-picking that we find in studies, particularly those called “observational,” ones in which the researcher finds past patterns, and, thanks to the sheer amount of data, can therefore fall into the trap of an invented narrative.
Further, in writing, I feel corrupt and unethical if I have to look up a subject in a library as part of the writing itself. This acts as a filter—it is the only filter. If the subject is not interesting enough for me to look it up
independently,
for my own curiosity or purposes, and I have not done so before, then I should not be writing about it at all, period. It does not mean that libraries (physical and virtual) are not acceptable; it means that they should not be the
source
of any idea. Students pay to write essays on topics for which they have to derive knowledge from a library as a self-enhancement exercise; a professional who is compensated to write and is taken seriously by others should use a more potent filter. Only distilled ideas, ones that sit in us for a long time, are acceptable—and those that come from reality.
It is time to revive the not well-known philosophical notion of
doxastic commitment,
a class of beliefs that go beyond talk, and to which we are committed enough to take personal risks.
If You See Something
Modernity has replaced ethics with legalese, and the law can be gamed with a good lawyer.
So I will expose the transfer of fragility, or rather the theft of antifragility, by people “arbitraging” the system. These people will be named by name. Poets and painters are free,
liberi poetae et pictores,
and there are severe moral imperatives that come with such freedom. First ethical rule:
If you see fraud and do not say fraud, you are a fraud.
Just as being nice to the arrogant is no better than being arrogant toward the nice, being accommodating toward anyone committing a nefarious action condones it.
Further, many writers and scholars speak in private, say, after half a bottle of wine, differently from the way they do in print. Their writing is certifiably fake, fake. And many of the problems of society come from
the argument “other people are doing it.” So if I call someone a dangerous ethically challenged fragilista in private after the third glass of Lebanese wine (white), I will be obligated to do so here.
Calling people and institutions fraudulent in print when they are not (yet) called so by others carries a cost, but is too small to be a deterrent. After the mathematical scientist Benoît Mandelbrot read the galleys of
The Black Swan,
a book dedicated to him, he called me and quietly said: “In what language should I say ‘good luck’ to you?” I did not need any luck, it turned out; I was antifragile to all manner of attacks: the more attacks I got from the Central Fragilista Delegation, the more my message spread as it drove people to examine my arguments. I am now ashamed of not having gone further in calling a spade a spade.
Compromising is condoning. The only modern dictum I follow is one by George Santayana:
A man is morally free when … he judges the world, and judges other men, with uncompromising sincerity
. This is not just an aim but an obligation.
Defossilizing Things
Second ethical point.
I am obligated to submit myself to the scientific process simply because I require it from others, but no more than that. When I read empirical claims in medicine or other sciences, I like these claims to go through the peer-review mechanism, a fact-checking of sorts, an examination of the rigor of the approach. Logical statements, or those backed by mathematical reasoning, on the other hand, do not require such a mechanism: they can and must stand on their own legs. So I publish technical footnotes for these books in specialized and academic outlets, and nothing more (and limit them to statements that require proofs or more elaborate technical arguments). But for the sake of authenticity and to avoid careerism (the debasing of knowledge by turning it into a competitive sport), I ban myself from publishing anything outside of these footnotes.
After more than twenty years as a transactional trader and businessman in what I called the “strange profession,” I tried what one calls an academic career. And I have something to report—actually that was the driver behind this idea of antifragility in life and the dichotomy between the
natural
and the alienation of the
unnatural
. Commerce is fun, thrilling, lively, and natural; academia as currently professionalized is none of
these. And for those who think that academia is “quieter” and an emotionally relaxing transition after the volatile and risk-taking business life, a surprise: when in action, new problems and scares emerge every day to displace and eliminate the previous day’s headaches, resentments, and conflicts. A nail displaces another nail, with astonishing variety. But academics (particularly in social science) seem to distrust each other; they live in petty obsessions, envy, and icy-cold hatreds, with small snubs developing into grudges, fossilized over time in the loneliness of the transaction with a computer screen and the immutability of their environment. Not to mention a level of envy I have almost never seen in business.… My experience is that money and transactions purify relations; ideas and abstract matters like “recognition” and “credit” warp them, creating an atmosphere of perpetual rivalry. I grew to find people greedy for credentials nauseating, repulsive, and untrustworthy.
Commerce, business, Levantine souks (though not large-scale markets and corporations) are activities and places that bring out the best in people, making most of them forgiving, honest, loving, trusting, and open-minded. As a member of the Christian minority in the Near East, I can vouch that commerce, particularly small commerce, is the door to tolerance—the only door, in my opinion, to any form of tolerance. It beats rationalizations and lectures. Like antifragile tinkering, mistakes are small and rapidly forgotten.
I want to be happy to be human and be in an environment in which other people are in love with their fate—and never, until my brush with academia, did I think that that environment was a certain form of commerce (combined with solitary scholarship). The biologist-writer and libertarian economist Matt Ridley made me feel that it was truly the Phoenician trader in me (or, more exactly, the Canaanite) that was the intellectual.
4


================================================================================
CHAPTER/SECTION 11 (Item 14)
================================================================================

V. ORGANIZATION
Antifragile
is composed of seven books and a notes section.
Why “books”? The novelist and essayist Rolf Dobelli’s first reaction upon reading my ethics and
via negativa
chapters, which I supplied separately, was that each should be a separate book and published as a short or medium-length essay. Someone in the business of “summarizing” books would have to write four or five separate descriptions. But I saw that they were not stand-alone essays at all; each deals with the applications of a central idea, going either deeper or into different territories: evolution, politics, business innovation, scientific discovery, economics, ethics, epistemology, and general philosophy. So I call them books rather than sections or parts. Books to me are not expanded journal articles, but reading experiences; and the academics who tend to read in order to cite in their writing—rather than read for enjoyment, curiosity, or simply because they like to read—tend to be frustrated when they can’t rapidly scan the text and summarize it in one sentence that connects it to some existing discourse in which they have been involved. Further, the essay is the polar opposite of the textbook—mixing autobiographical musings and parables with more philosophical and scientific investigations. I write about probability with my entire soul and my entire experiences in the risk-taking business; I write with my scars, hence my thought is inseparable from autobiography. The personal essay form is ideal for the topic of incertitude.
The sequence is as follows.
The Appendix to this prologue presents the Triad as a table, a comprehensive map of the world along the fragility spectrum.
Book I,
The Antifragile: An Introduction
, presents the new property and discusses evolution and the organic as the typical antifragile system. It also looks at the tradeoff between the antifragility of the collective and the fragility of the individual.
Book II,
Modernity and the Denial of Antifragility
, describes what happens when we starve systems—mostly political systems—of volatility. It discusses this invention called the nation-state, as well as the idea of harm done by the healer, someone who tries to help you and ends up harming you very badly.
Book III,
A Nonpredictive View of the World
, introduces Fat Tony and his intuitive detection of fragility and presents the foundational
asymmetry of things grounded in the writings of Seneca, the Roman philosopher and doer.
Book IV,
Optionality, Technology, and the Intelligence of Antifragility
, presents the mysterious property of the world, by which a certain asymmetry is behind things, rather than human “intelligence,” and how optionality drove us here. It is opposed to what I call the Soviet-Harvard method. And Fat Tony argues with Socrates about how we do things one cannot quite explain.
Book V,
The Nonlinear and the Nonlinear
(
sic
), is about the philosopher’s stone and its opposite: how to turn lead into gold, and gold into lead. Two chapters constitute the central technical section—the plumbing of the book—mapping fragility (as nonlinearity, more specifically, convexity effects) and showing the edge coming from a certain class of convex strategies.
Book VI,
Via Negativa
, shows the wisdom and effectiveness of subtraction over addition (acts of omission over acts of commission). This section introduces the notion of convexity effects. Of course the first application is to medicine. I look at medicine only from an epistemological, risk-management approach—and it looks different from there.
Book VII,
The Ethics of Fragility and Antifragility
, grounds ethics in transfers of fragility, with one party getting the benefits and the other one the harm, and points out problems arising from absence of skin in the game.
The end of the book consists of graphs, notes, and a technical appendix.
The book is written at three levels.
First, the literary and philosophical, with parables and illustrations but minimal if any technical arguments, except in
Book V
(the philosopher’s stone), which presents the convexity arguments. (The enlightened reader is invited to skip
Book V
, as the ideas are distilled elsewhere.)
Second, the appendix, with graphs and more technical discussion, but no elaborate derivations.
Third, the backup material with more elaborate arguments, all in the form of technical papers and notes (don’t mistake my illustrations and parables for proof; remember, a personal essay is not a scientific document, but a scientific document is a scientific document). All these backup documents are gathered as a freely available electronic technical companion.
1
Outside of casinos and some narrowly defined areas such as man-made situations and constructions.
2
Hayek did not take his idea about organic price formation into risk and fragility. For Hayek, bureaucrats were inefficient, not fragilistas. This discussion starts with fragility and antifragility, and gets us as a side discussion into organic price formation.
3
The technical term I used for “hates volatility” was “short vega” or “short gamma,” meaning “harmed should volatility increase,” and “long vega” or “long gamma” for things that benefit. In the rest of the book we will use “short” and “long” to describe negative and positive exposures, respectively. It is critical that I never believed in our ability to forecast volatility, as I just focused on how things react to it.
4
Once again, please, no,
itisnotresilience
. I am used to facing, at the end of a conference lecture, the question “So what is the difference between robust and antifragile?” or the more unenlightened and even more irritating “Antifragile is resilient, no?” The reaction to my answer is usually “Ah,” with the look “Why didn’t you say that before?” (of course I had said that before). Even the initial referee of the scientific article I wrote on defining and detecting antifragility entirely missed the point, conflating antifragility and robustness—and that was the scientist who pored over my definitions. It is worth re-explaining the following: the robust or resilient is neither harmed nor helped by volatility and disorder, while the antifragile benefits from them. But it takes some effort for the concept to sink in. A lot of things people call robust or resilient are just robust or resilient, the other half are antifragile.


================================================================================
CHAPTER/SECTION 12 (Item 15)
================================================================================

APPENDIX: THE TRIAD, OR A MAP OF THE WORLD AND THINGS ALONG THE THREE PROPERTIES
Now we aim—after some work—to connect in the reader’s mind, with a single thread, elements seemingly far apart, such as Cato the Elder, Nietzsche, Thales of Miletus, the potency of the system of city-states, the sustainability of artisans, the process of discovery, the onesidedness of opacity, financial derivatives, antibiotic resistance, bottom-up systems, Socrates’ invitation to overrationalize, how to lecture birds, obsessive love, Darwinian evolution, the mathematical concept of Jensen’s inequality, optionality and option theory, the idea of ancestral heuristics, the works of Joseph de Maistre and Edmund Burke, Wittgenstein’s antirationalism, the fraudulent theories of the economics establishment, tinkering and bricolage, terrorism exacerbated by death of its members, an apologia for artisanal societies, the ethical flaws of the middle class, Paleo-style workouts (and nutrition), the idea of medical iatrogenics, the glorious notion of the magnificent (
megalopsychon
), my obsession with the idea of convexity (and my phobia of concavity), the late-2000s banking and economic crisis, the misunderstanding of redundancy, the difference between tourist and flâneur, etc. All in one single—and, I am certain, simple—thread.
How? We can begin by seeing how things—just about anything that matters—can be mapped or classified into three categories, what I call the Triad.
Things Come in Triples
In the Prologue, we saw that the idea is to focus on fragility rather than predicting and calculating future probabilities, and that fragility and antifragility come on a spectrum of varying degrees. The task here is to build a map of exposures. (This is what is called “real-world solution,” though only academics and other non-real-world operators use the expression “real-world solution” instead of simply “solution.”)
The Triad classifies items in three columns along the designation
FRAGILE    ROBUST    ANTIFRAGILE
Recall that the fragile wants tranquility, the antifragile grows from disorder, and the robust doesn’t care too much. The reader is invited
to navigate the Triad to see how the ideas of the book apply across domains. Simply, in a given subject, when you discuss an item or a policy, the task is to find in which category of the Triad one should put it and what to do in order to improve its condition. For example: the centralized nation-state is on the far left of the Triad, squarely in the fragile category, and a decentralized system of city-states on the far right, in the antifragile one. By getting the characteristics of the latter, we can move away from the undesirable fragility of the large state. Or look at errors. On the left, in the fragile category, the mistakes are rare and large when they occur, hence irreversible; to the right the mistakes are small and benign, even reversible and quickly overcome. They are also rich in information. So a certain system of tinkering and trial and error would have the attributes of antifragility. If you want to become antifragile, put yourself in the situation “loves mistakes”—to the right of “hates mistakes”—by making these numerous and small in harm. We will call this process and approach the “barbell” strategy.
Or take the health category. Adding is on the left, removing to the right.
Removing
medication, or some other unnatural stressor—say, gluten, fructose, tranquilizers, nail polish, or some such substance—by trial and error is more robust than
adding
medication, with unknown side effects, unknown in spite of the statements about “evidence” and shmevidence.
As the reader can see, the map uninhibitedly spreads across domains and human pursuits, such as culture, health, biology, political systems, technology, urban organization, socioeconomic life, and other matters of more or less direct interest to the reader. I have even managed to merge decision making and
flâneur
in the same breath. So a simple method would lead us to both a risk-based political philosophy and medical decision-making.
The Triad in Action
Note that fragile and antifragile here are relative terms, not quite absolute properties: one item to the right of the Triad is more antifragile than another to the left. For instance, artisans are more antifragile than small businesses, but a rock star will be more antifragile than any artisan. Debt always puts you on the left, fragilizes economic systems. And things are antifragile up to a certain level of stress. Your body benefits from
some amount of mishandling, but up to a point—it would not benefit too much from being thrown down from the top of the Tower of Babel.
The Golden Robust:
Further, the
robust
here in the middle column is not equivalent to Aristotle’s “golden middle” (commonly mislabeled the “golden mean”), in the way that, say, generosity is the middle between profligacy and stinginess—it can be, but it is not necessarily so. Antifragility is desirable in general, but not always, as there are cases in which antifragility will be costly, extremely so. Further, it is hard to consider robustness as always desirable—to quote Nietzsche, one can die from being immortal.
Finally, by now the reader, grappling with a new word, might ask too much from it. If the designation
antifragile
is rather vague and limited to specific sources of harm or volatility, and up to a certain range of exposure, it is no more and no less so than the designation
fragile
. Antifragility is relative to a given situation. A boxer might be robust, hale when it comes to his physical condition, and might improve from fight to fight, but he can easily be emotionally fragile and break into tears when dumped by his girlfriend. Your grandmother might have opposite qualities, fragile in build but equipped with a strong personality. I remember the following vivid image from the Lebanese civil war: A diminutive old lady, a widow (she was dressed in black), was chastising militiamen from the enemy side for having caused the shattering of the glass in her window during a battle. They were pointing their guns at her; a single bullet would have terminated her but they were visibly having a bad moment, intimidated and scared by her. She was the opposite of the boxer: physically fragile, but not fragile in character.
Now the Triad.
Click
here
for a larger image of this table.


================================================================================
CHAPTER/SECTION 13 (Item 16)
================================================================================

BOOK I
The Antifragile: An Introduction
T
he first two chapters introduce and illustrate antifragility.
Chapter 3
introduces a distinction between the organic and the mechanical, say, between your cat and a washing machine.
Chapter 4
is about how the antifragility of some comes from the fragility of others, how errors benefit some, not others—the sort of things people tend to call evolution and write a lot, a lot about.


================================================================================
CHAPTER/SECTION 14 (Item 17)
================================================================================

CHAPTER 1
Between Damocles and Hydra
Please cut my head off—How by some magic, colors become colors—How to lift weight in Dubai


================================================================================
CHAPTER/SECTION 15 (Item 18)
================================================================================

HALF OF LIFE HAS NO NAME
You are in the post office about to send a gift, a package full of champagne glasses, to a cousin in Central Siberia. As the package can be damaged during transportation, you would stamp “fragile,” “breakable,” or “handle with care” on it (in red). Now what is the exact opposite of such situation, the exact opposite of “fragile”?
Almost all people answer that the opposite of “fragile” is “robust,” “resilient,” “solid,” or something of the sort. But the resilient, robust (and company) are items that neither break nor improve, so you would not need to write anything on them—have you ever seen a package with “robust” in thick green letters stamped on it? Logically, the exact opposite of a “fragile” parcel would be a package on which one has written “please mishandle” or “please handle carelessly.” Its contents would not just be unbreakable, but would benefit from shocks and a wide array of trauma. The fragile is the package that would be
at best
unharmed, the robust would be
at best
and
at worst
unharmed. And the opposite of fragile is therefore what is
at worst
unharmed.
We gave the appellation “antifragile” to such a package; a neologism was necessary as there is no simple, noncompound word in the
Oxford
English Dictionary
that expresses the point of reverse fragility. For the idea of antifragility is not part of our consciousness—but, luckily, it is part of our ancestral behavior, our biological apparatus, and a ubiquitous property of every system that has survived.
FIGURE 1
. A package begging for stressors and disorder. Credit: Giotto Enterprise and George Nasr.
To see how alien the concept is to our minds, repeat the experiment and ask around at the next gathering, picnic, or pre-riot congregation what’s the antonym of fragile (and specify insistently that you mean the
exact reverse,
something that has opposite properties and payoff). The likely answers will be, aside from robust: unbreakable, solid, well-built, resilient, strong, something-proof (say, waterproof, windproof, rustproof)—unless they’ve heard of this book. Wrong—and it is not just individuals but branches of knowledge that are confused by it; this is a mistake made in every dictionary of synonyms and antonyms I’ve found.
Another way to view it: since the opposite of
positive
is
negative,
not
neutral,
the opposite of positive fragility should be negative fragility (hence my appellation “antifragility”), not neutral, which would just convey robustness, strength, and unbreakability. Indeed, when one writes things down mathematically, antifragility is fragility with a negative sign in front of it.
1
This blind spot seems universal. There is no word for “antifragility”
in the main known languages, modern, ancient, colloquial, or slang. Even Russian (Soviet version) and Standard Brooklyn English don’t seem to have a designation for antifragility, conflating it with robustness.
2
Half of life—the interesting half of life—we don’t have a name for.


================================================================================
CHAPTER/SECTION 16 (Item 19)
================================================================================

PLEASE BEHEAD ME
If we have no common name for antifragility, we can find a mythological equivalence, the expression of historical intelligence through potent metaphors. In a Roman recycled version of a Greek myth, the Sicilian tyrant Dionysius II has the fawning courtier Damocles enjoy the luxury of a fancy banquet, but with a sword hanging over his head, tied to the ceiling with a single hair from a horse’s tail. A horse’s hair is the kind of thing that eventually breaks under pressure, followed by a scene of blood, high-pitched screams, and the equivalent of ancient ambulances. Damocles is fragile—it is only a matter of time before the sword strikes him down.
In another ancient legend, this time the Greek recycling of an ancient Semitic and Egyptian legend, we find Phoenix, the bird with splendid colors. Whenever it is destroyed, it is reborn from it own ashes. It always returns to its initial state. Phoenix happens to be the ancient symbol of Beirut, the city where I grew up. According to legend, Berytus (Beirut’s historical name) has been destroyed seven times in its close to five-thousand-year history, and has come back seven times. The story seems cogent, as I myself saw the eighth episode; central Beirut (the ancient part of the city) was completely destroyed for the eighth time during my late childhood, thanks to the brutal civil war. I also saw its eighth rebuilding.
But Beirut was, in its latest version, rebuilt in even better shape than the previous incarnation—and with an interesting irony: the earthquake of
A.D.
551 had buried the Roman law school, which was discovered, like a bonus from history, during the reconstruction (with archeologists
and real estate developers trading public insults). That’s not Phoenix, but something else beyond the robust. Which brings us to the third mythological metaphor: Hydra.
Hydra, in Greek mythology, is a serpent-like creature that dwells in the lake of Lerna, near Argos, and has numerous heads. Each time one is cut off, two grow back. So harm is what it likes. Hydra represents antifragility.
The sword of Damocles represents the side effect of power and success: you cannot rise and rule without facing this continuous danger—someone out there will be actively working to topple you. And like the sword, the danger will be silent, inexorable, and discontinuous. It will fall abruptly after long periods of quiet, perhaps at the very moment one has gotten used to it and forgotten about its existence. Black Swans will be out there to get you as you now have much more to lose, a cost of success (and growth), perhaps an unavoidable penalty of excessive success. At the end, what matters is the strength of the string—not the wealth and power of the dining party. But, luckily, this is an identifiable, measurable, and tractable vulnerability, for those who want to listen. The entire point of the Triad is that in many situations we can measure the strength of the string.
Further, consider how toxic such growth-followed-by-a-fall can be to society, as the fall of the dining guest, in response to the fall of the sword of Damocles, will bring what we now call collateral damage, harming others. For instance, the collapse of a large institution will have effects on society.
Sophistication, a certain brand of sophistication, also brings fragility to Black Swans: as societies gain in complexity, with more and more “cutting edge” sophistication in them, and more and more specialization, they become increasingly vulnerable to collapse. This idea has been brilliantly—and convincingly—adumbrated by the archeologist Joseph Tainter. But it does not have to be so: it is so only for those unwilling to go the extra step and understand the matrix of reality. To counter success, you need a high offsetting dose of robustness, even high doses of antifragility. You want to be Phoenix, or possibly Hydra. Otherwise the sword of Damocles will get you.
On the Necessity of Naming
We know more than we think we do, a lot more than we can articulate. If our formal systems of thought denigrate the natural, and in fact we don’t have a name for antifragility, and fight the concept whenever we use our brains, it does not mean that our actions neglect it. Our perceptions and intuitions, as expressed in deeds, can be superior to what we know and tabulate, discuss in words, and teach in a classroom. We will have ample discussions of the point particularly with the potent notion of the
apophatic
(what cannot be explicitly said, or directly described, in our current vocabulary); so for now, take this curious phenomenon.
In
Through the Language Glass,
the linguist Guy Deutscher reports that many primitive populations, without being color-blind, have verbal designations for only two or three colors. But when given a simple test, they can successfully match strings to their corresponding colors. They are capable of detecting the differences between the various nuances of the rainbow, but they do not express these in their vocabularies. These populations are culturally, though not biologically, color-blind.
Just as we are intellectually, not organically, antifragility-blind. To see the difference just consider that you need the name “blue” for the construction of a narrative, but not when you engage in action.
It is not well known that many colors we take for granted had no name for a long time, and had no names in the central texts in Western culture. Ancient Mediterranean texts, both Greek and Semitic, also had a reduced vocabulary of a small number of colors polarized around the dark and the light—Homer and his contemporaries were limited to about three or four main colors: black, white, and some indeterminate part of the rainbow, often subsumed as red, or yellow.
I contacted Guy Deutscher. He was extremely generous with his help and pointed out to me that the ancients even lacked words for something as elementary as blue. This absence of the word “blue” in ancient Greek explains the recurring reference by Homer to the “wine-dark sea” (
oinopa ponton
), which has been quite puzzling to readers (including this one).
Interestingly, it was the British Prime Minister William Gladstone who first made this discovery in the 1850s (and was unfairly and thoughtlessly reviled for it by the usual journalists). Gladstone, quite an erudite, wrote, during his interregnum between political positions, an
impressive seventeen-hundred-page treatise on Homer. In the last section, Gladstone announced this limitation of color vocabulary, attributing our modern sensitization to many more nuances of color to a cross-generational training of the eye. But regardless of these variations of color in the culture of the time, people were shown to be able to identify the nuances—unless physically color-blind.
Gladstone was impressive in many respects. Aside from his erudition, force of character, respect for the weak, and high level of energy, four very attractive attributes (respect for the weak being, after intellectual courage, the second most attractive quality to this author), he showed remarkable prescience. He figured out what few in his day dared to propose: that the
Iliad
corresponds to a true story (the city of Troy had not been discovered yet). In addition, even more prescient and of great relevance to this book, he was insistent upon a balanced fiscal budget: fiscal deficits have proven to be a prime source of fragility in social and economic systems.


================================================================================
CHAPTER/SECTION 17 (Item 20)
================================================================================

PROTO-ANTIFRAGILITY
There have been names for two starter-antifragility concepts, with two precursor applications that cover some special cases of it. These are mild aspects of antifragility and limited to the medical field. But they are a good way to start.
According to legend, Mithridates IV, king of Pontus in Asia Minor, while hiding after his father’s assassination, got himself some protection against poisoning by ingesting sub-lethal doses of toxic material in progressively larger quantities. He later incorporated the process into a complicated religious ritual. But this immunity got him in trouble a bit later as his attempt to take his own life by poisoning failed, “having fortified himself against the drugs of others.” So he had to ask for the services of an ally military commander to give him a blow with a sword.
The method named
Antidotum Mithridatium,
celebrated by Celsus, the ancient world’s famous doctor, had to be rather fashionable in Rome, since about a century later it brought some complication to the emperor Nero’s attempts at matricide. Nero had been obsessed with the idea of killing his mother, Agrippina, who, to make things more colorful, was Caligula’s sister (and, even more colorful, was the alleged lover of the philosopher Seneca, more on whom later). But a mother tends to know her son rather well and predict his actions, particularly when he is her
only child—and Agrippina knew something about poison, as she might have used the method to kill at least one of her husbands (I said things were quite colorful). So, suspecting that Nero had a contract on her, she got herself Mithridatized against the poisons that would have been available to her son’s underlings. Like Mithridates, Agrippina eventually died by more mechanical methods as her son (supposedly) had assassins slay her, thus providing us with the small but meaningful lesson that one cannot be robust against everything. And, two thousand years later, nobody has found a method for us to get “fortified” against swords.
Let us call Mithridatization the result of an exposure to a small dose of a substance that, over time, makes one immune to additional, larger quantities of it. It is the sort of approach used in vaccination and allergy medicine. It is not quite antifragility, still at the more modest level of robustness, but we are on our way. And we already have a hint that perhaps being deprived of poison makes us fragile and that the road to robustification starts with a modicum of harm.
Now consider a case when the poisonous substance, in some dose, makes you better off overall, one step up from robustness. Hormesis, a word coined by pharmacologists, is when a small dose of a harmful substance is actually beneficial for the organism, acting as medicine. A little bit of an otherwise offending substance, not too much, acts to benefit the organism and make it better overall as it triggers some overreaction. This was not interpreted at the time in the sense of “gains from harm” so much as “harm is dose dependent” or “medicine is dose dependent.” The interest to scientists has been in the nonlinearity of the dose-response.
Hormesis was well known by the ancients (and like the color blue was known but not expressed). But it was only in 1888 that it was first “scientifically” described (though still not given a name) by a German toxicologist, Hugo Schulz, who observed that small doses of poison stimulate the growth of yeast while larger doses cause harm. Some researchers hold that the benefits of vegetables may not be so much in what we call the “vitamins” or some other rationalizing theories (that is, ideas that seem to make sense in narrative form but have not been subjected to rigorous empirical testing), but in the following: plants protect themselves from harm and fend off predators with poisonous substances that, ingested by us in the right quantities, may stimulate our organisms—or so goes the story. Again, limited, low-dose poisoning triggers healthy benefits.
Many claim that caloric restriction (permanent or episodic) activates
healthy reactions and switches that, among other benefits, lengthen life expectancy in laboratory animals. We humans live too long for researchers to test if such restriction increases our life expectancy (if the hypothesis is true, then the subjects of the test would outlive the researchers). But it looks like such restriction makes humans healthier (and may also improve their sense of humor). But since abundance would bring the opposite effect, this episodic caloric restriction can be also interpreted as follows: too much regular food is bad for you, and depriving humans of the stressor of hunger may make them live less than their full potential; so all hormesis seems to be doing is reestablishing the natural dosage for food and hunger in humans. In other words, hormesis is the norm, and its absence is what hurts us.
Hormesis lost some scientific respect, interest, and practice after the 1930s because some people mistakenly associated it with homeopathy. The association was unfair, as the mechanisms are extremely different. Homeopathy is based on other principles, such as the one that minute, highly diluted parts of the agents of a disease (so small they can hardly be perceptible, hence cannot cause hormesis) can help cure us of the disease itself. Homeopathy has shown little empirical backing and because of its testing methodologies belongs today to alternative medicine, while hormesis, as a phenomenon, has ample scientific evidence to back it up.
But the larger point is that we can now see that depriving systems of stressors, vital stressors, is not necessarily a good thing, and can be downright harmful.


================================================================================
CHAPTER/SECTION 18 (Item 21)
================================================================================

DOMAIN INDEPENDENCE IS DOMAIN DEPENDENT
This idea that systems may need some stress and agitation has been missed by those who grasp it in one area and not in another. So we can now also see the
domain dependence
of our minds, a “domain” being an area or category of activity. Some people can understand an idea in one domain, say, medicine, and fail to recognize it in another, say, socioeconomic life. Or they get it in the classroom, but not in the more complicated texture of the street. Humans somehow fail to recognize situations outside the contexts in which they usually learn about them.
I had a vivid illustration of domain dependence in the driveway of a hotel in the pseudocity of Dubai. A fellow who looked like a banker had a uniformed porter carry his luggage (I can instantly tell if someone is a
certain type of banker with minimal cues as I have physical allergies to them, even affecting my breathing). About fifteen minutes later I saw the banker lifting free weights at the gym, trying to replicate natural exercises using kettlebells as if he were swinging a suitcase. Domain dependence is pervasive.
Further, the problem is not just that Mithridatization and hormesis can be known in (some) medical circles and missed in other applications such as socioeconomic life. Even within medicine, some get it here and miss it there. The same doctor might recommend exercise so you “get tougher,” and a few minutes later write a prescription for antibiotics in response to a trivial infection so you “don’t get sick.”
Another expression of domain dependence: ask a U.S. citizen if some semi-governmental agency with a great deal of independence (and no interference from Congress) should control the price of cars, morning newspapers, and Malbec wine, as its domain of specialty. He would jump in anger, as it appears to violate every principle the country stands for, and call you a Communist post-Soviet mole for even suggesting it. OK. Then ask him if that same government agency should control foreign exchange, mainly the rate of the dollar against the euro and the Mongolian tugrit. Same reaction: this is not France. Then very gently point out to him that the Federal Reserve Bank of the United States is in the business of controlling and managing the price of another good, another price, called the lending rate, the interest rate in the economy (and has proved to be good at it). The libertarian presidential candidate Ron Paul was called a crank for suggesting the abolition of the Federal Reserve, or even restricting its role. But he would also have been called a crank for suggesting the creation of an agency to control other prices.
Imagine someone gifted in learning languages but unable to transfer concepts from one tongue to another, so he would need to relearn “chair” or “love” or “apple pie” every time he acquires a new language. He would not recognize “house” (English) or “casa” (Spanish) or “byt” (Semitic). We are all, in a way, similarly handicapped, unable to recognize the same idea when it is presented in a different context. It is as if we are doomed to be deceived by the most superficial part of things, the packaging, the gift wrapping. This is why we don’t see antifragility in places that are obvious, too obvious. It is not part of the accepted way of thinking about success, economic growth, or innovation that these may result only from overcompensation against stressors. Nor do we see this overcompensation at work elsewhere. (And domain dependence is
also why it has been difficult for many researchers to realize that uncertainty, incomplete understanding, disorder, and volatility are members of the same close family.)
This lack of translation is a mental handicap that comes with being a human; and we will only start to attain wisdom or rationality when we make an effort to overcome and break through it.
Let us get deeper into overcompensation.
1
Just as concavity is convexity with a negative sign in front of it and is sometimes called anticonvexity.
2
I checked in addition to Brooklyn English most Indo-European languages, both ancient (Latin, Greek) and modern branches: Romance (Italian, French, Spanish, Portuguese), Slavic (Russian, Polish, Serbian, Croatian), Germanic (German, Dutch, Afrikaans), and Indo-Iranian (Hindi, Urdu, Farsi). It is also absent from non-Indo-European families such as Semitic (Arabic, Hebrew, Aramaic) and Turkic (Turkish).


================================================================================
CHAPTER/SECTION 19 (Item 22)
================================================================================

CHAPTER 2
Overcompensation and Overreaction Everywhere
Is it easy to write on a Heathrow runway?—Try to get the Pope to ban your work—How to beat up an economist (but not too hard, just enough to go to jail)
My own domain dependence was revealed to me one day as I was sitting in the office of David Halpern, a U.K. government advisor and policy maker. He informed me—in response to the idea of antifragility—of a phenomenon called post-traumatic growth, the opposite of post-traumatic stress syndrome, by which people harmed by past events surpass themselves. I had never heard about it before, and, to my great shame, had never made the effort to think of its existence: there is a small literature but it is not advertised outside a narrow discipline. We hear about the more lurid post-traumatic disorder, not post-traumatic growth, in the intellectual and so-called learned vocabulary. But popular culture has an awareness of its equivalent, revealed in the expression “it builds character.” So do the ancient Mediterranean classics, along with grandmothers.
Intellectuals tend to focus on negative responses from randomness (fragility) rather than the positive ones (antifragility). This is not just in psychology: it prevails across the board.
How do you innovate? First, try to get in trouble. I mean serious, but not terminal, trouble. I hold—it is beyond speculation, rather a conviction—that
innovation and sophistication spark from initial situations of necessity, in ways that go far beyond the satisfaction of such necessity (from the unintended side effects of, say, an initial invention or attempt at invention). Naturally, there are classical thoughts on the subject, with a Latin saying that sophistication is born out of hunger (
artificia docuit fames
). The idea pervades classical literature: in Ovid, difficulty is what wakes up the genius (
ingenium mala saepe movent
), which translates in Brooklyn English into “When life gives you a lemon …”
The excess energy released from overreaction to setbacks is what innovates!
This message from the ancients is vastly deeper than it seems. It contradicts modern methods and ideas of innovation and progress on many levels, as we tend to think that innovation comes from bureaucratic funding, through planning, or by putting people through a Harvard Business School class by one Highly Decorated Professor of Innovation and Entrepreneurship (who never innovated anything) or hiring a consultant (who never innovated anything). This is a fallacy—note for now the disproportionate contribution of
uneducated
technicians and entrepreneurs to various technological leaps, from the Industrial Revolution to the emergence of Silicon Valley, and you will see what I mean.
Yet in spite of the visibility of the counterevidence, and the wisdom you can pick up free of charge from the ancients (or grandmothers), moderns try today to create inventions from situations of comfort, safety, and predictability instead of accepting the notion that “necessity really is the mother of invention.”
Many, like the great Roman statesman Cato the Censor, looked at comfort, almost any form of comfort, as a road to waste.
1
He did not like it when we had it too easy, as he worried about the weakening of the will. And the softening he feared was not just at the personal level: an entire society can fall ill. Consider that as I am writing these lines, we are living in a debt crisis. The world as a whole has never been richer, and it has never been more heavily in debt, living off borrowed money. The record shows that, for society, the richer we become, the harder it gets to live within our means. Abundance is harder for us to handle than scarcity.
Cato would have smiled hearing about the recently observed effect in aeronautics that the automation of airplanes is underchallenging pilots, making flying too comfortable for them, dangerously comfortable. The dulling of the pilot’s attention and skills from too
little
challenge is indeed causing deaths from flying accidents. Part of the problem is a Federal Aviation Administration (FAA) regulation that forced the industry to increase its reliance on automated flying. But, thankfully, the same FAA finally figured out the problem; it has recently found that pilots often “abdicate too much responsibility to automated systems.”


================================================================================
CHAPTER/SECTION 20 (Item 23)
================================================================================

HOW TO WIN A HORSE RACE
It is said that the best horses lose when they compete with slower ones, and win against better rivals. Undercompensation from the absence of a stressor, inverse hormesis, absence of challenge, degrades the best of the best. In Baudelaire’s poem, “The albatross’s giant wings prevent him from walking”—many do better in Calculus 103 than Calculus 101.
This mechanism of overcompensation hides in the most unlikely places. If tired after an intercontinental flight, go to the gym for some exertion instead of resting. Also, it is a well-known trick that if you need something urgently done, give the task to the busiest (or second busiest) person in the office. Most humans manage to squander their free time, as free time makes them dysfunctional, lazy, and unmotivated—the busier they get, the more active they are at other tasks. Overcompensation, here again.
I’ve discovered a trick when giving lectures. I have been told by conference organizers that one needs to be clear, to speak with the fake articulation of TV announcers, maybe even dance on the stage to get the attention of the crowd. Some try sending authors to “speech school”—the first time it was suggested to me I walked out, resolved to change publishers on the spot. I find it better to whisper, not shout. Better to be slightly inaudible, less clear. When I was a pit trader (one of those crazy people who stand in a crowded arena shouting and screaming in a continuous auction), I learned that the noise produced by the person is inverse to the pecking order: as with mafia dons, the most powerful traders were the least audible. One should have enough self-control to make the audience work hard to listen, which causes them to switch into intellectual overdrive. This paradox of attention has been a little bit investigated:
there is empirical evidence of the effect of “disfluency.” Mental effort moves us into higher gear, activating more vigorous and more analytical brain machinery.
2
The management guru Peter Drucker and the psychoanalyst Jacques Lacan, two persons who mesmerized the crowds the most in their respective areas, were the antithesis of the polished-swanky speaker or the consonant-trained television announcer.
The same or a similar mechanism of overcompensation makes us concentrate better in the presence of a modicum of background random noise, as if the act of countering such noise helps us hone our mental focus. Consider this remarkable ability humans have to filter out noise at happy hour and distinguish the signal among so many other loud conversations. So not only are we made to overcompensate, but we sometimes
need
the noise. Like many writers, I like to sit in cafés, working, as they say, against resistance. Consider our bedtime predilection for the rustle of tree leaves or the sound of the ocean: there are even electric contraptions that produce “white noise”
3
that helps people sleep better. Now these small distractions, like hormetic responses, act up to a point. I haven’t tried it yet, but I am certain that it would be hard to write an essay on the runway of Heathrow airport.
Antifragile Responses as Redundancy
Something flashed when I heard “post-traumatic” during that London visit. It hit me right there and then that these antifragile hormetic responses were just a form of redundancy, and all the ideas of Mother Nature converged in my mind. It is all about redundancy. Nature likes to overinsure itself.
Layers of redundancy are the central risk management property of natural systems. We humans have two kidneys (this may even include accountants), extra spare parts, and extra capacity in many, many things (say, lungs, neural system, arterial apparatus), while human design tends to be spare and inversely redundant, so to speak—we have a historical track record of engaging in debt, which is the opposite of redundancy (fifty thousand in extra cash in the bank or, better, under the mattress, is
redundancy; owing the bank an equivalent amount, that is, debt, is the opposite of redundancy). Redundancy is ambiguous because it seems like a waste if nothing unusual happens. Except that something unusual happens—usually.
Further, redundancy is not necessarily wussy; it can be extremely aggressive. For instance, if you have extra inventory of, say, fertilizers in the warehouse, just to be safe, and there happens to be a shortage because of disruptions in China, you can sell the excess inventory at a huge premium. Or if you have extra oil reserves, you may sell them at a large profit during a squeeze.
Now, it turns out, the same, very same logic applies to overcompensation: it is just a form of redundancy. An additional head for Hydra is no different from an extra—that is, seemingly redundant—kidney for humans, and no different from the additional capacity to withstand an extra stressor. If you ingest, say, fifteen milligrams of a poisonous substance, your body may prepare for twenty or more, and as a side effect will get stronger overall. These extra five milligrams of poison that you can withstand are no different from additional stockpiles of vital or necessary goods, say extra cash in the bank or more food in the basement. And to return to the drivers of innovation: the additional
quantities
of motivation and willpower, so to speak, stemming from setbacks can be also seen as extra capacity, no different from extra boxes of victuals.
A system that overcompensates is necessarily in overshooting mode, building extra capacity and strength in anticipation of a worse outcome and in response to information about the possibility of a hazard. And of course such extra capacity or strength may become useful by itself, opportunistically. We saw that redundancy is opportunistic, so such extra strength can be used to some benefit even in the absence of the hazard. Tell the next MBA analyst or business school professor you run into that redundancy is not defensive; it is more like investment than insurance. And tell them that what they call “inefficient” is often very efficient.
Indeed, our bodies discover probabilities in a very sophisticated manner and assess risks much better than our intellects do. To take one example, risk management professionals look in the past for information on the so-called
worst-case scenario
and use it to estimate future risks—this method is called “stress testing.” They take the worst historical recession, the worst war, the worst historical move in interest rates, or the worst point in unemployment as an exact estimate for the worst future outcome. But they never notice the following inconsistency:
this so-called worst-case event, when it happened, exceeded the worst case at the time.
I have called this mental defect
the Lucretius problem,
after the Latin poetic philosopher who wrote that the fool believes that the tallest mountain in the world will be equal to the tallest one he has observed. We consider the biggest object of any kind that we have seen in our lives or hear about as the largest item that can possibly exist. And we have been doing this for millennia. In Pharaonic Egypt, which happens to be the first complete top-down nation-state managed by bureaucrats, scribes tracked the high-water mark of the Nile and used it as an estimate for a future worst-case scenario.
The same can be seen in the Fukushima nuclear reactor, which experienced a catastrophic failure in 2011 when a tsunami struck. It had been built to withstand the worst past historical earthquake, with the builders not imagining much worse—and not thinking that the worst past event had to be a surprise, as it had no precedent. Likewise, the former chairman of the Federal Reserve, Fragilista Doctor Alan Greenspan, in his apology to Congress offered the classic “It never happened before.” Well, nature, unlike Fragilista Greenspan, prepares for what has not happened before,
assuming worse harm is possible
.
4
If humans fight the last war, nature fights the next one. Your body is more imaginative about the future than you are. Consider how people train in weightlifting: the body overshoots in response to exposures and overprepares (up to the point of biological limit, of course). This is how bodies get stronger.
In the aftermath of the banking crisis, I received all manner of threats, and
The Wall Street Journal
suggested that I “stock up on bodyguards.” I tried to tell myself no worries, stay calm, these threats were coming from disgruntled bankers; anyway, people get whacked first, then you read about it in the newspapers, not in the reverse sequence. But the argument did not register in my mind, and, when in New York or London, I could not relax, even after chamomile tea. I started feeling paranoia in public places, scrutinizing people to ascertain that I was not being followed. I started taking the bodyguard suggestion seriously, and I found it more appealing (and considerably more economical) to become one,
or, better, to look like one. I found Lenny “Cake,” a trainer, weighing around two hundred and eighty pounds (one hundred and thirty kilograms), who moonlighted as a security person. His nickname and weight both came from his predilection for cakes. Lenny Cake was the most physically intimidating person within five zip codes, and he was sixty. So, rather than taking lessons, I watched him train. He was into the “maximum lifts” type of training and swore by it, as he found it the most effective and least time-consuming. This method consisted of short episodes in the gym in which one focused solely on improving one’s past maximum in a single lift, the heaviest weight one could haul, sort of the high-water mark. The workout was limited to trying to exceed that mark once or twice, rather than spending time on un-entertaining time-consuming repetitions. The exercise got me into a naturalistic form of weightlifting, and one that accords with the evidence-based literature: work on the maximum, spend the rest of the time resting and splurging on mafia-sized steaks. I have been trying to push my limit for four years now; it is amazing to see how something in my biology anticipates a higher level than the past maximum—until it reaches its ceiling. When I deadlift (i.e., mimic lifting a stone to waist level) using a bar with three hundred and thirty pounds, then rest, I can safely expect that I will build a certain amount of additional strength as my body
predicts
that next time I may need to lift three hundred and thirty-five pounds. The benefits, beyond the fading of my paranoia and my newfound calm in public places, includes small unexpected conveniences. When I am harassed by limo drivers in the arrival hall at Kennedy airport insistently offering me a ride and I calmly tell them to “f*** off,” they go away immediately. But there are severe drawbacks: some of the readers I meet at conferences have a rough time dealing with an intellectual who has the appearance of a bodyguard—intellectuals can be svelte or flabby and out of shape (when they wear a tweed jacket), but they are not supposed to look like butchers.
Something that will give the Darwinists some work, an observation made to me by the risk analyst, my favorite intellectual opponent (and personal friend) Aaron Brown: the term “fitness” itself may be quite imprecise and even ambiguous, which is why the notion of antifragility as something exceeding mere fitness can elucidate the confusion. What does “fitness” mean? Being exactly tuned to a given past history of a specific environment, or extrapolating to an environment with stressors of higher intensity? Many seem to point to the first kind of adaptation,
missing the notion of antifragility. But if one were to write down mathematically a standard model of selection, one would get overcompensation rather than mere “fitness.”
5
Even the psychologists who studied the antifragile response of post-traumatic growth, and show the data for it, don’t quite get the full concept, as they lapse, when using words, into the concept of “resilience.”


================================================================================
CHAPTER/SECTION 21 (Item 24)
================================================================================

ON THE ANTIFRAGILITY OF RIOTS, LOVE, AND OTHER UNEXPECTED BENEFICIARIES OF STRESS
Once one makes an effort to overcome domain dependence, the phenomenon of overcompensation appears ubiquitous.
Those who understand bacterial resistance in the biological domain completely fail to grasp the dictum by Seneca in
De clemencia
about the inverse effect of punishments. He wrote: “Repeated punishment, while it crushes the hatred of a few, stirs the hatred of all … just as trees that have been trimmed throw out again countless branches.” For revolutions feed on repression, growing heads faster and faster as one
literally
cuts a few off by killing demonstrators. There is an Irish revolutionary song that encapsulates the effect:
The higher you build your barricades, the stronger we become.
The crowds, at some point, mutate, blinded by anger and a sense of outrage, fueled by the heroism of a few willing to sacrifice their lives for the cause (although they don’t quite see it as sacrifice) and hungry for the privilege to become martyrs. It is that political movements and rebellions can be highly antifragile, and the sucker game is to try to repress them using brute force rather than manipulate them, give in, or find more astute ruses, as Heracles did with Hydra.
If antifragility is what wakes up and overreacts and overcompensates to stressors and damage, then one of the most antifragile things you will find outside economic life is a certain brand of refractory love (or hate),
one that seems to overreact and overcompensate for impediments such as distance, family incompatibilities, and every conscious attempt to kill it. Literature is rife with characters trapped in a form of antifragile passion, seemingly against their will. In Proust’s long novel
La recherche,
Swann, a socially sophisticated Jewish art dealer, falls for Odette, a demimondaine, a “kept” woman of sorts, a semi- or perhaps just a quarter-prostitute; she treats him badly. Her elusive behavior fuels his obsession, causing him to demean himself for the reward of a bit more time with her. He exhibits overt clinginess, follows her on her trysts with other men, hiding shamelessly in staircases, which of course causes her to treat him even more elusively. Supposedly, the story was a fictionalization of Proust’s own entanglement with his (male) driver. Or take Dino Buzzati’s semiautobiographical novel
Un amore,
the story of a middle-aged Milanese man who falls—accidentally, of course—for a dancer at the Scala who moonlights as a prostitute. She of course mistreats him, exploits him, takes advantage of him, milks him; and the more she mistreats him, the more he exposes himself to abuse to satisfy the antifragile thirst of a few moments with her. But some form of happy ending there: from his biography, Buzzati himself ended up marrying, at sixty, a twenty-five year old, Almerina, a former dancer, seemingly the character of the story; when he died shortly after that, she became a good caretaker of his literary legacy.
Even when authors such as Lucretius (the same of the high mountains earlier in this chapter) rant against the dependence, imprisonment, and alienation of love, treating it as a (preventable) disease, they end up lying to us or themselves. Legend perhaps: Lucretius the priest of anti-romance might have been himself involved in uncontrollable—antifragile—infatuation.
Like tormenting love, some thoughts are so antifragile that you feed them by trying to get rid of them, turning them into obsessions. Psychologists have shown the irony of the process of thought control: the more energy you put into trying to control your ideas and what you think about, the more your ideas end up controlling you.
Please Ban My Book: The Antifragility of Information
Information is antifragile; it feeds more on attempts to harm it than it does on efforts to promote it. For instance, many wreck their reputations merely by trying to defend them.
The wily Venetians knew how to spread information by disguising it as a secret. Try it out with the following experiment in spreading gossip: tell someone a secret and qualify it by insisting that it is a secret, begging your listener “not to tell anyone”; the more you insist that it remain a secret, the more it will spread.
We all learn early on in life that books and ideas are antifragile and get nourishment from attacks—to borrow from the Roman emperor Marcus Aurelius (one of the doer-Stoic authors), “fire feeds on obstacles.” There is the attraction of banned books, their antifragility to interdicts. The first book I read, during my childhood, of Graham Greene’s was
The Power and the Glory,
selected for no other reason than its having been put on the
Index
(that is, banned) by the Vatican. Likewise, as a teenager, I gorged on the books of the American expatriate Henry Miller—his major book sold a million copies in one year thanks to having been banned in twenty-three states. The same with
Madame Bovary
or
Lady Chatterley’s Lover.
Criticism, for a book, is a truthful, unfaked badge of attention, signaling that it is not boring; and boring is the only very bad thing for a book. Consider the Ayn Rand phenomenon: her books
Atlas Shrugged
and
The Fountainhead
have been read for more than half a century by millions of people, in spite of, or most likely thanks to, brutally nasty reviews and attempts to discredit her. The first-order information is the intensity: what matters is the effort the critic puts into trying to prevent others from reading the book, or, more generally in life, it is the effort in badmouthing someone that matters, not so much what is said. So if you really want people to read a book, tell them it is “overrated,” with a sense of outrage (and use the attribute “underrated” for the opposite effect).
Balzac recounts how actresses paid journalists (often in kind) to write favorable accounts—but the wiliest got them to write unfavorable comments, knowing that it made them more interesting.
I have just bought Tom Holland’s book on the rise of Islam for the sole reason that he was attacked by Glen Bowersock, considered to be the most prominent living scholar on the Roman Levant. Until then I had thought that Tom Holland was just a popularizer, and I would not have taken him seriously otherwise. I didn’t even attempt to read Bowersock’s review. So here is a simple rule of thumb (a heuristic): to estimate the quality of research, take the caliber of the highest detractor,
or the caliber of the lowest detractor whom the author answers in print—whichever is lower.
Criticism itself can be antifragile to repression, when the fault finder wants to be attacked in return in order to get some validation. Jean Fréron, said to be a very envious thinker, with the mediocrity of envious thinkers, managed to play a role in intellectual history solely by irritating the otherwise brilliant Voltaire to the point of bringing him to write satirical poems against him. Voltaire, himself a gadfly and expert at ticking off people to benefit from their reactions, forgot how things worked when it came to himself. Perhaps Voltaire’s charm was in that he did not know how to save his wit. So the same hidden antifragilities apply to attacks on our ideas and persons: we fear them and dislike negative publicity, but smear campaigns, if you can survive them, help enormously, conditional on the person appearing to be extremely motivated and adequately angry—just as when you hear a woman badmouthing another in front of a man (or vice versa). There is a visible selection bias: why did he attack
you
instead of someone else, one of the millions of persons deserving but not worthy of attack? It is his energy in attacking or badmouthing that will, antifragile style, put you on the map.
My great-grandfather Nicolas Ghosn was a wily politician who managed to stay permanently in power and hold government positions in spite of his numerous enemies (most notably his archenemy, my great-great-grandfather on the Taleb side of the family). As my grandfather, his eldest son, was starting his administrative and hopefully political career, his father summoned him to his deathbed. “My son, I am very disappointed in you,” he said. “I never hear anything wrong said about you. You have proven yourself incapable of generating envy.”
Get Another Job
As we saw with the Voltaire story, it is not possible to stamp out criticism; if it harms you, get out. It is easier to change jobs than control your reputation or public perception.
Some jobs and professions are fragile to reputational harm, something that in the age of the Internet cannot possibly be controlled—these jobs aren’t worth having. You do not want to “control” your reputation; you won’t be able to do it by controlling information flow. Instead, focus on altering your exposure, say, by putting yourself in a position
impervious to reputational damage. Or even put yourself in a situation to benefit from the antifragility of information. In that sense, a writer is antifragile, but we will see later most modernistic professions are usually not.
I was in Milan trying to explain antifragility to Luca Formenton, my Italian publisher (with great aid from body language and hand gestures). I was there partly for the Moscato dessert wines, partly for a convention in which the other main speaker was a famous fragilista economist. So, suddenly remembering that I was an author, I presented Luca with the following thought experiment: if I beat up the economist publicly, what would happen to me (other than a publicized trial causing great interest in the new notions of
fragilita
and
antifragilita
)? You know, this economist had what is called a
tête à baffe,
a face that invites you to slap it, just like a cannoli invites you to bite into it. Luca thought for a second … well, it’s not like he would like me to do it, but, you know, it wouldn’t hurt book sales. Nothing I can do as an author that makes it to the front page of
Corriere della Sera
would be detrimental for my book. Almost no scandal would hurt an artist or writer.
6
Now let’s say I were a midlevel executive employee of some corporation listed on the London Stock Exchange, the sort who never take chances by dressing down, always wearing a suit and tie (even on the beach). What would happen to me if I attack the fragilista? My firing and arrest record would plague me forever. I would be the total victim of informational antifragility. But someone earning close to minimum wage, say, a construction worker or a taxi driver, does not overly depend on his reputation and is free to have his own opinions. He would be merely robust compared to the artist, who is antifragile. A midlevel bank employee with a mortgage would be fragile to the extreme. In fact he would be completely a prisoner of the value system that invites him to be corrupt to the core—because of his dependence on the annual vacation in Barbados. The same with a civil servant in Washington. Take this easy-to-use heuristic (which is, to repeat the definition, a simple compressed rule of thumb) to detect the independence and robustness of someone’s reputation. With few exceptions, those who dress outrageously are robust or even antifragile in reputation; those clean-shaven types who dress in suits and ties are fragile to information about them.
Large corporations and governments do not seem to understand this rebound power of information and its ability to control those who try to control it. When you hear a corporation or a debt-laden government trying to “reinstill confidence” you know they are fragile, hence doomed. Information is merciless: one press conference “to tranquilize” and the investors will run away, causing a death spiral or a run on the bank. Which explains why I have an obsessive stance against government indebtedness, as a staunch proponent of what is called fiscal conservatism. When you don’t have debt you don’t care about your reputation in economics circles—and somehow it is only when you don’t care about your reputation that you tend to have a good one. Just as in matters of seduction, people lend the most to those who need them the least.
And we are blind to this antifragility of information in even more domains. If I physically beat up a rival in an ancestral environment, I injure him, weaken him, perhaps eliminate him forever—and get some exercise in the process. If I use the mob to put a contract on his head, he is gone. But if I stage a barrage of informational attacks on websites and in journals, I may be just helping him and hurting myself.
So I end this section with a thought. It is quite perplexing that those from whom we have benefited the most aren’t those who have tried to help us (say with “advice”) but rather those who have actively tried—but eventually failed—to harm us.
Next we turn to a central distinction between the things that like stress and other things that don’t.
1
Cato was the statesman who, three books ago (
Fooled by Randomness
), expelled all philosophers from Rome.
2
This little bit of effort seems to activate the switch between two distinct mental systems, one intuitive and the other analytical, what psychologists call “system 1” and “system 2.”
3
There is nothing particularly “white” in white noise; it is simply random noise that follows a Normal Distribution.
4
The obvious has not been tested empirically: Can the occurrence of extreme events be predicted from past history? Alas, according to a simple test: no, sorry.
5
Set a simple filtering rule: all members of a species need to have a neck forty centimeters long in order to survive. After a few generations, the surviving population would have, on average, a neck
longer
than forty centimeters. (More technically, a stochastic process subjected to an absorbing barrier will have an observed mean higher than the barrier.)
6
The French have a long series of authors who owe part of their status to their criminal record—which includes the poet Ronsard, the writer Jean Genet, and many others.


================================================================================
CHAPTER/SECTION 22 (Item 25)
================================================================================

CHAPTER 3
The Cat and the Washing Machine
Stress is knowledge (and knowledge is stress)—The organic and the mechanical—No translator needed, for now—Waking up the animal in us, after two hundred years of modernity
The bold conjecture made here is that everything that has life in it is to some extent antifragile (but not the reverse). It looks like the secret of life is antifragility.
Typically, the natural—the biological—is both antifragile and fragile, depending on the source (and the range) of variation. A human body can benefit from stressors (to get stronger), but only to a point. For instance, your bones will get denser when episodic stress is applied to them, a mechanism formalized under the name Wolff’s Law after an 1892 article by a German surgeon. But a dish, a car, an inanimate object will not—these may be robust but cannot be intrinsically antifragile.
Inanimate—that is, nonliving—material, typically, when subjected to stress, either undergoes material fatigue or breaks. One of the rare exceptions I’ve seen is in the report of a 2011 experiment by Brent Carey, a graduate student, in which he shows that composite material of carbon nanotubes arranged in a certain manner produces a self-strengthening response previously unseen in synthetic materials, “similar to the localized self-strengthening that occurs in biological structures.” This crosses the boundary between the living and the inanimate, as it can lead to the development of adaptable load-bearing material.
We can use the distinction as a marker between living and nonliving. The fact that the artificial needs to be antifragile for us to be able to use it as tissue is quite a telling difference between the biological and the synthetic. Your house, your food processor, and your computer desk eventually wear down and don’t self-repair. They may look better with age (when artisanal), just as your jeans will look more fashionable with use, but eventually time will catch up with them and the hardest material will end up looking like Roman ruins. Your jeans may look improved and more fashionable when worn out, but their material did not get stronger, nor do they self-repair. But think of a material that would make them stronger, self-heal, and improve with time.
1
True, while humans self-repair, they eventually wear out (hopefully leaving their genes, books, or some other information behind—another discussion). But the phenomenon of aging is misunderstood, largely fraught with mental biases and logical flaws. We observe old people and see them age, so we associate aging with their loss of muscle mass, bone weakness, loss of mental function, taste for Frank Sinatra music, and similar degenerative effects. But these failures to self-repair come largely from maladjustment—either too few stressors or too little time for recovery between them—and maladjustment for this author is the mismatch between one’s design and the structure of the randomness of the environment (what I call more technically its “distributional or statistical properties”). What we observe in “aging” is a combination of maladjustment and senescence, and it appears that the two are separable—senescence might not be avoidable, and should not be avoided (it would contradict the logic of life, as we will see in the next chapter); maladjustment is avoidable. Much of aging comes from a misunderstanding of the effect of comfort—a disease of civilization: make life longer and longer, while people are more and more sick. In a natural environment, people die without aging—or after a very short period of aging. For instance, some markers, such as blood pressure, that tend to worsen over time for moderns do not change over the life of hunter-gatherers until the very end.
And this artificial aging comes from stifling internal antifragility.
The Complex
This organic-mechanical dichotomy is a good starter distinction to build intuitions about the difference between two kinds of phenomena, but we can do better. Many things such as society, economic activities and markets, and cultural behavior are apparently man-made but grow on their own to reach some kind of self-organization. They may not be strictly biological, but they resemble the biological in that, in a way, they multiply and replicate—think of rumors, ideas, technologies, and businesses. They are closer to the cat than to the washing machine but tend to be mistaken for washing machines. Accordingly we can generalize our distinction beyond the biological-nonbiological. More effective is the distinction between noncomplex and complex systems.
Artificial, man-made mechanical and engineering contraptions with simple responses are complicated, but not “complex,” as they don’t have interdependencies. You push a button, say, a light switch, and get an exact response, with no possible ambiguity in the consequences, even in Russia. But with complex systems, interdependencies are severe. You need to think in terms of ecology: if you remove a specific animal you disrupt a food chain: its predators will starve and its prey will grow unchecked, causing complications and series of cascading side effects. Lions are exterminated by the Canaanites, Phoenicians, Romans, and later inhabitants of Mount Lebanon, leading to the proliferation of goats who crave tree roots, contributing to the deforestation of mountain areas, consequences that were hard to see ahead of time. Likewise, if you shut down a bank in New York, it will cause ripple effects from Iceland to Mongolia.
In the complex world, the notion of “cause” itself is suspect; it is either nearly impossible to detect or not really defined—another reason to ignore newspapers, with their constant supply of causes for things.


================================================================================
CHAPTER/SECTION 23 (Item 26)
================================================================================

STRESSORS ARE INFORMATION
Now the crux of complex systems, those with interacting parts, is that they convey information to these component parts through stressors, or thanks to these stressors: your body gets information about the environment not through your logical apparatus, your intelligence and ability to reason, compute, and calculate, but through stress, via hormones or other messengers we haven’t discovered yet. As we saw, your bones will
get stronger when subjected to gravity, say, after your (short) employment with a piano moving company. They will become weaker after you spend the next Christmas vacation in a space station with zero gravity or (as few people realize) if you spend a lot of time riding a bicycle. The skin on the palms of your hands will get calloused if you spend a summer on a Soviet-style cooperative farm. Your skin lightens in the winter and tans in the summer (especially if you have Mediterranean origins, less so if you are of Irish or African descent or from other places with more uniform weather throughout the year).
Further, errors and their consequences are information; for small children, pain is the only risk management information, as their logical faculties are not very developed. For complex systems are, well, all about information. And there are many more conveyors of information around us than meet the eye. This is what we will call
causal opacity:
it is hard to see the arrow from cause to consequence, making much of conventional methods of analysis, in addition to standard logic, inapplicable. As I said, the predictability of specific events is low, and it is such opacity that makes it low. Not only that, but because of nonlinearities, one needs higher visibility than with regular systems—instead what we have is opacity.
FIGURE 2
. This illustrates why I have a thing for bones. You see identical situations of head-loading water or grain in traditional societies in India, Africa, and the Americas. There is even a Levantine love song about an attractive woman with an amphora on her head. The health benefits could beat bone density medication—but such forms of therapy would not benefit pharma’s bottom line. Credit: Creative Commons
Let us consider bones again. I have a thing for bones, and the idea I will discuss next made me focus on lifting heavy objects rather than using gym machines. This obsession with the skeleton got started when I found a paper published in the journal
Nature
in 2003 by Gerard Karsenty and colleagues. The tradition has been to think that aging
causes
bone weakness (bones lose density, become more brittle), as if there was a one-way relationship possibly brought about by hormones (females start experiencing osteoporosis after menopause). It turns out, as shown by Karsenty and others who have since embarked on the line of research, that the reverse is also largely true: loss of bone density and degradation of the health of the bones also
causes
aging, diabetes, and, for males, loss of fertility and sexual function. We just cannot isolate any causal relationship in a complex system. Further, the story of the bones and the associated misunderstanding of interconnectedness illustrates how lack of stress (here, bones under a weight-bearing load) can cause aging, and how depriving stress-hungry antifragile systems of stressors brings a great deal of fragility which we will transport to political systems in
Book II
. Lenny’s exercise method, the one I watched and tried to imitate in the last chapter, seemed to be as much about stressing and strengthening the bones as it was about strengthening the muscles—he didn’t know much about the mechanism but had discovered, heuristically, that weight bearing did something to his system. The lady in
Figure 2
, thanks to a lifetime of head-loading water jugs, has outstanding health and excellent posture.
Our antifragilities have conditions. The frequency of stressors matters a bit. Humans tend to do better with acute than with chronic stressors, particularly when the former are followed by ample time for recovery, which allows the stressors to do their jobs as messengers. For instance, having an intense emotional shock from seeing a snake coming out of my keyboard or a vampire entering my room, followed by a period of soothing safety (with chamomile tea and baroque music) long enough for me to regain control of my emotions, would be beneficial for my health, provided of course that I manage to overcome the snake or vampire after an arduous, hopefully heroic fight and have a picture taken next to the dead predator. Such a stressor would be certainly better than the mild but continuous stress of a boss, mortgage, tax problems, guilt over procrastinating with one’s tax return, exam pressures, chores, emails to answer, forms to complete, daily commutes—things that make you feel trapped in life. In other words, the pressures brought
about by civilization. In fact, neurobiologists show that the former type of stressor is necessary, the second harmful, for one’s health. For an idea of how harmful a low-level stressor without recovery can be, consider the so-called Chinese water torture: a drop continuously hitting the same spot on your head, never letting you recover.
Indeed, the way Heracles managed to control Hydra was by cauterizing the wounds on the stumps of the heads that he had just severed. He thus prevented the regrowth of the heads and the exercise of antifragility. In other words, he disrupted the recovery.
Table 2
shows the difference between the two types. Note that there may be intermediate steps between engineered and organic, though things tend to cluster in one bucket or the other.
The reader can get a hint of the central problem we face with top-down tampering with political systems (or similar complex systems), the subject of
Book II
. The fragilista mistakes the economy for a washing machine that needs monthly maintenance, or misconstrues the properties of your body for those of a compact disc player. Adam Smith himself made the analogy of the economy as a watch or a clock that once set in motion continues on its own. But I am certain that he did not quite think
of matters in these terms, that he looked at the economy in terms of organisms but lacked a framework to express it. For Smith understood the opacity of complex systems as well as the interdependencies, since he developed the notion of the “invisible hand.”
Click
here
for a larger image of this table.
But alas, unlike Adam Smith, Plato did not quite get it. Promoting the well-known metaphor of the
ship of state,
he likens a state to a naval vessel, which, of course, requires the monitoring of a captain. He ultimately argues that the only men fit to be captain of this ship are philosopher kings, benevolent men with absolute power who have access to the Form of the Good. And once in a while one hears shouts of “who is governing us?” as if the world needs someone to govern it.
Equilibrium, Not Again
Social scientists use the term “equilibrium” to describe balance between opposing forces, say, supply and demand, so small disturbances or deviations in one direction, like those of a pendulum, would be countered with an adjustment in the opposite direction that would bring things back to stability. In short, this is thought to be the goal for an economy.
Looking deeper into what these social scientists want us to get into, such a goal can be death. For the complexity theorist Stuart Kaufman uses the idea of equilibrium to separate the two different worlds of
Table 2
.
For the nonorganic, noncomplex, say, an object on the table, equilibrium
(as traditionally defined)
happens in a state of inertia. So for something organic, equilibrium
(in that sense)
only happens with death.
Consider an example used by Kaufman: in your bathtub, a vortex starts forming and will keep going after that. Such type of situation is permanently “far from equilibrium”—and it looks like organisms and dynamic systems exist in such a state.
2
For them, a state of normalcy requires a certain degree of volatility, randomness, the continuous swapping of information, and stress, which explains the harm they may be subjected to when deprived of volatility.


================================================================================
CHAPTER/SECTION 24 (Item 27)
================================================================================

CRIMES AGAINST CHILDREN
Not only are we averse to stressors, and don’t understand them, but we are committing crimes against life, the living, science, and wisdom, for the sake of eliminating volatility and variation.
I feel anger and frustration when I think that one in ten Americans beyond the age of high school is on some kind of antidepressant, such as Prozac. Indeed, when you go through mood swings, you now have to justify why you
are not
on some medication. There may be a few good reasons to be on medication, in severely pathological cases, but my mood, my sadness, my bouts of anxiety, are a second source of intelligence—perhaps even the first source. I get mellow and lose physical energy when it rains, become more meditative, and tend to write more and more slowly then, with the raindrops hitting the window, what Verlaine called autumnal “sobs” (
sanglots
). Some days I enter poetic melancholic states, what the Portuguese call
saudade
or the Turks
hüzün
(from the Arabic word for sadness). Other days I am more aggressive, have more energy—and will write less, walk more, do other things, argue with researchers, answer emails, draw graphs on blackboards. Should I be turned into a vegetable or a happy imbecile?
Had Prozac been available last century, Baudelaire’s “spleen,” Edgar Allan Poe’s moods, the poetry of Sylvia Plath, the lamentations of so many other poets, everything with a soul would have been silenced.
3
…
If large pharmaceutical companies were able to eliminate the seasons, they would probably do so—for a profit, of course.
There is another danger: in addition to harming children, we are harming society and our future. Measures that aim at reducing variability and swings in the lives of children are also reducing variability and differences within our said to be Great Culturally Globalized Society.
Punished by Translation
Another forgotten property of stressors is in language acquisition—I don’t know anyone who ever learned to speak his mother tongue in a textbook, starting with grammar and, checked by biquarterly exams, systematically fitting words to the acquired rules. You pick up a language best thanks to situational difficulty, from error to error, when you need to communicate under more or less straining circumstances, particularly
to express urgent needs (say, physical ones, such those arising in the aftermath of dinner in a tropical location).
One learns new words without making a nerd-effort, but rather another type of effort: to communicate, mostly by being forced to read the mind of the other person—suspending one’s fear of making mistakes. Success, wealth, and technology, alas, make this mode of acquisition much more difficult. A few years ago, when I was of no interest to anyone, foreign conference organizers did not assign to me the fawning “travel assistant” fluent in Facebook English, so I used to be forced to fend for myself, hence picking up vocabulary by finger pointing and trial and error (just as children do)—no handheld devices, no dictionary, nothing. Now I am punished by privilege and comfort—and I can’t resist comfort. The punishment is in the form of a person, fluent in English, greeting me by displaying my misspelled name at the airport, no stress, no ambiguity, and no exposure to Russian, Turkish, Croatian, or Polish outside of ugly (and organized) textbooks. What is worse, the person is unctuous; obsequious verbosity is something rather painful under the condition of jet lag.
Yet the best way to learn a language may be an episode of jail in a foreign country. My friend Chad Gracia improved his Russian thanks to an involuntary stay in the quarantine section of a hospital in Moscow for an imagined disease. It was a cunning brand of medical kidnapping, as during the mess after the end of the Soviet rule, hospitals were able to extort travelers with forced hospital stays unless they paid large sums of money to have their papers cleared. Chad, then barely fluent in the language, was forced to read Tolstoy in the original, and picked up quite a bit of vocabulary.
Touristification
My friend Chad benefited from the kind of disorder that is less and less prevalent thanks to the modern disease of
touristification
. This is my term for an aspect of modern life that treats humans as washing machines, with simplified mechanical responses—and a detailed user’s manual. It is the systematic removal of uncertainty and randomness from things, trying to make matters highly predictable in their smallest details. All that for the sake of comfort, convenience, and efficiency.
What a tourist is in relation to an adventurer, or a flâneur, touristification is to life; it consists in converting activities, and not just travel,
into the equivalent of a script like those followed by actors. We will see how touristification castrates systems and organisms that like uncertainty by sucking randomness out of them to the last drop—while providing them with the illusion of benefit. The guilty parties are the education system, planning the funding of teleological scientific research, the French baccalaureate, gym machines, etc.
And the electronic calendar.
But the worse touristification is the life we moderns have to lead in captivity, during our leisure hours: Friday night opera, scheduled parties, scheduled laughs. Again, golden jail.
This “goal-driven” attitude hurts deeply inside my existential self.
The Secret Thirst for Chance
Which brings us to the existential aspect of randomness. If you are not a washing machine or a cuckoo clock—in other words, if you are alive—something deep in your soul likes a certain measure of randomness and disorder.
There is a titillating feeling associated with randomness. We like the moderate (and highly domesticated) world of games, from spectator sports to having our breathing suspended between crap shoots during the next visit to Las Vegas. I myself, while writing these lines, try to avoid the tyranny of a precise and explicit plan, drawing from an opaque source inside me that gives me surprises. Writing is only worth it when it provides us with the tingling effect of adventure, which is why I enjoy the composition of books and dislike the straitjacket of the 750-word op-ed, which, even without the philistinism of the editor, bores me to tears. And, remarkably, what the author is bored writing bores the reader.
If I could predict what my day would exactly look like, I would feel a little bit dead.
Further, this randomness is necessary for true life. Consider that all the wealth of the world can’t buy a liquid more pleasurable than water after intense thirst. Few objects bring more thrill than a recovered wallet (or laptop) lost on a train. Further, in an ancestral habitat we humans were prompted by natural stimuli—fear, hunger, desire—that made us work out and become fit for our environment. Consider how easy it is to find the energy to lift a car if a crying child is under it, or to run for your life if you see a wild animal crossing the street. Compare this to the
heaviness of the obligation to visit the gym at the planned 6
P.M
. and be bullied there by some personal trainer—unless of course you are under the imperative to look like a bodyguard. Also consider how easy it is to skip a meal when the randomness in the environment causes us to do so, because of lack of food—as compared to the “discipline” of sticking to some eighteen-day diet plan.
There exist the kind of people for whom life is some kind of project. After talking to them, you stop feeling good for a few hours; life starts tasting like food cooked without salt. I, a thrill-seeking human, have a b***t detector that seems to match my boredom detector, as if we were equipped with a naturalistic filter, dullness-aversion. Ancestral life had no homework, no boss, no civil servants, no academic grades, no conversation with the dean, no consultant with an MBA, no table of procedure, no application form, no trip to New Jersey, no grammatical stickler, no conversation with someone boring you: all life was random stimuli and nothing, good or bad, ever felt like work.
4
Dangerous, yes, but boring, never.
Finally, an environment with variability (hence randomness) does not expose us to chronic stress injury, unlike human-designed systems. If you walk on uneven, not man-made terrain, no two steps will ever be identical—compare that to the randomness-free gym machine offering the exact opposite: forcing you into endless repetitions of the very same movement.
Much of modern life is preventable chronic stress injury.
Next, let us examine a wrinkle of evolution, that great expert on antifragility.
1
Another way to see it: machines are harmed by low-level stressors (material fatigue), organisms are harmed by the
absence
of low-level stressors (hormesis).
2
These are the so-called dissipative structures, after the works of the physicist Ilya Prigogine, that have a quite different status from simple equilibrium structures: they are formed and maintained through the effect of exchange of energy and matter in permanent nonequilibrium conditions.
3
This does not mean that Sylvia Plath should not have been medicated at all. The point is that pathologies should be medicated when there is a risk of suicide, not mood swings.
4
Neither Rousseau nor Hobbes. True, life then was perhaps “brutal and short,” but it is a severe logical mistake to present a tradeoff, to use unsavory aspects of early humanity as a necessary cost of avoiding modern tortures. There is no reason to not want advantages from both eras.


================================================================================
CHAPTER/SECTION 25 (Item 28)
================================================================================

CHAPTER 4
What Kills Me Makes Others Stronger
Antifragility for one is fragility for someone else—Where we introduce the idea that we think too much, do very little—Fail for others to succeed—One day you may get a thank-you note


================================================================================
CHAPTER/SECTION 26 (Item 29)
================================================================================

ANTIFRAGILITY BY LAYERS
This chapter is about error, evolution, and antifragility, with a hitch: it is largely about the errors of others—the antifragility of some comes necessarily at the expense of the fragility of others. In a system, the sacrifices of some units—fragile units, that is, or people—are often necessary for the well-being of other units or the whole. The fragility of every startup is necessary for the economy to be antifragile, and that’s what makes, among other things, entrepreneurship work: the fragility of individual entrepreneurs and their necessarily high failure rate.
So antifragility gets a bit more intricate—and more interesting—in the presence of layers and hierarchies. A natural organism is not a single, final unit; it is composed of subunits and itself may be the subunit of some larger collective. These subunits may be contending with each other. Take another business example. Restaurants are fragile; they compete with each other, but the collective of local restaurants is antifragile for that very reason. Had restaurants been individually robust, hence immortal, the overall business would be either stagnant or weak, and would deliver nothing better than cafeteria food—and I mean Soviet-style
cafeteria food. Further, it would be marred with systemic shortages, with, once in a while, a complete crisis and government bailout. All that quality, stability, and reliability are owed to the fragility of the restaurant itself.
So some parts
on the inside
of a system may be required to be fragile in order to make the system antifragile as a result. Or the organism itself might be fragile, but the information encoded in the genes reproducing it will be antifragile. The point is not trivial, as it is behind the logic of evolution. This applies equally to entrepreneurs and individual scientific researchers.
Further, we mentioned “sacrifice” a few paragraphs ago. Sadly, the benefits of errors are often conferred on others, the collective—as if individuals were designed to make errors for the greater good, not their own. Alas, we tend to discuss mistakes without taking into consideration this layering and transfer of fragility.
Evolution and Unpredictability
I said that the notions of Mithridatization and hormesis were “proto”-antifragility, introductory concepts: they are even a bit naive, and we will need to refine, even transcend them, in order to look at a complex system as a whole. Hormesis is a metaphor; antifragility is a phenomenon.
Primo,
Mithridatization and hormesis are just very weak forms of antifragility, with limited gains from volatility, accident, or harm and a certain reversal of the protective or beneficial effect beyond a certain dosage. Hormesis likes only a little bit of disorder, or, rather,
needs
a little bit of it. They are mostly interesting insofar as their deprivation is harmful, something we don’t get intuitively—our minds cannot easily understand the complicated responses (we think linearly, and these dose-dependent responses are nonlinear). Our linear minds do not like nuances and reduce the information to the binary “harmful” or “helpful.”
Secundo,
and that’s the central weakness, they see the organism from the outside and consider it as a whole, a single unit, when things can be a bit more nuanced.
There is a different, stronger variety of antifragility linked to evolution that is beyond hormesis—actually very different from hormesis; it is even its opposite. It can be described as hormesis—getting stronger
under harm—if we look from the outside, not from the inside. This other variety of antifragility is evolutionary, and operates at the informational level—genes are information. Unlike with hormesis, the unit does not get stronger in response to stress; it dies. But it accomplishes a transfer of benefits; other units survive—and those that survive have attributes that improve the collective of units, leading to modifications commonly assigned the vague term “evolution” in textbooks and in the
New York Times
Tuesday science section. So the antifragility of concern here is not so much that of the organisms, inherently weak, but rather that of their genetic code, which can survive them. The code doesn’t really care about the welfare of the unit itself—quite the contrary, since it destroys many things around it. Robert Trivers figured out the presence of competition between gene and organism in his idea of the “selfish gene.”
In fact, the most interesting aspect of evolution is that it only works because of its
antifragility;
it is in love with stressors, randomness, uncertainty, and disorder—while individual organisms are relatively fragile, the gene pool takes advantage of shocks to enhance its fitness.
So from this we can see that there is a tension between nature and individual organisms.
Everything alive or organic in nature has a finite life and dies eventually—even Methuselah lived less than a thousand years. But it usually dies after reproducing offspring with a genetic code in one way or another different from that of the parents, with their information modified. Methuselah’s genetic information is still present in Damascus, Jerusalem, and, of course, Brooklyn, New York. Nature does not find its members very helpful after their reproductive abilities are depleted (except perhaps special situations in which animals live in groups, such as the need for grandmothers in the human and elephant domains to assist others in preparing offspring to take charge). Nature prefers to let the game continue at the informational level, the genetic code. So organisms need to die for nature to be antifragile—nature is opportunistic, ruthless, and selfish.
Consider, as a thought experiment, the situation of an immortal organism, one that is built without an expiration date. To survive, it would need to be completely fit for all possible random events that can take place in the environment, all
future
random events. By some nasty property, a random event is, well, random. It does not advertise its arrival ahead of time, allowing the organism to prepare and make adjustments to sustain shocks. For an immortal organism, pre-adaptation for all such
events would be a necessity. When a random event happens, it is already too late to react, so the organism should be prepared to withstand the shock, or say goodbye. We saw that our bodies overshoot a bit in response to stressors, but this remains highly insufficient; they still can’t see the future. They can prepare for the next war, but not win it. Post-event adaptation, no matter how fast, would always be a bit late.
1
To satisfy the conditions for such immortality, the organisms need to predict the future with perfection—near perfection is not enough. But by letting the organisms go one lifespan at a time, with modifications between successive generations, nature does not need to predict future conditions beyond the extremely vague idea of which direction things should be heading. Actually, even a vague direction is not necessary. Every random event will bring its own antidote in the form of ecological variation. It is as if nature changed itself at every step and modified its strategy every instant.
Consider this in terms of economic and institutional life. If nature ran the economy, it would not continuously bail out its living members to make them live forever. Nor would it have permanent administrations and forecasting departments that try to outsmart the future—it would not let the scam artists of the United States Office of Management and Budget make such mistakes of epistemic arrogance.
If one looks at history as a complex system similar to nature, then, like nature, it won’t let a single empire dominate the planet forever—even if every superpower from the Babylonians to the Egyptians to the Persians to the Romans to modern America has believed in the permanence of its domination and managed to produce historians to theorize to that effect. Systems subjected to randomness—and unpredictability—build a mechanism beyond the robust to opportunistically reinvent themselves each generation, with a continuous change of population and species.
Black Swan Management 101: nature (and nature-like systems) likes
diversity
between
organisms rather than diversity
within
an immortal organism, unless you consider nature itself the immortal organism, as in the pantheism of Spinoza or that present in Asian religions, or the Stoicism of Chrisippus or Epictetus. If you run into a historian of civilizations, try to explain it to him.
Let us look at how evolution benefits from randomness and volatility (in some dose, of course). The more noise and disturbances in the system, up to a point, barring those extreme shocks that lead to extinction of a species, the more the effect of the reproduction of the fittest and that of random mutations will play a role in defining the properties of the next generation. Say an organism produces ten offspring. If the environment is perfectly stable, all ten will be able to reproduce. But if there is instability, pushing aside five of these descendants (likely to be on average weaker than their surviving siblings), then those that evolution considers (on balance) the better ones will reproduce, making the gene undergo some fitness. Likewise, if there is variability among the offspring, thanks to occasional random spontaneous mutation, a sort of copying mistake in the genetic code, then the best should reproduce, increasing the fitness of the species. So evolution benefits from randomness by two different routes: randomness in the mutations, and randomness in the environment—both act in a similar way to cause changes in the traits of the surviving next generations.
Even when there is extinction of an entire species after some extreme event, no big deal, it is part of the game. This is still evolution at work, as those species that survive are fittest and take over from the lost dinosaurs—evolution is not about a species, but at the service of the whole of nature.
But note that evolution likes randomness only up to some limit.
2
If a calamity completely kills life on the entire planet, the fittest will not survive. Likewise, if random mutations occur at too high a rate, then the fitness gain might not stick, might perhaps even reverse thanks to a new mutation: as I will keep repeating, nature is antifragile
up to a point
but such point is quite high—it can take a lot, a lot of shocks. Should a nuclear event eradicate most of life on earth, but not all life, some rat or bacteria will emerge out of nowhere, perhaps the bottom of the oceans,
and the story will start again, without us, and without the members of the Office of Management and Budget, of course.
So, in a way, while hormesis corresponds to situations by which the individual organism benefits from direct harm to itself, evolution occurs when harm makes the individual organism perish and the benefits are transferred to others, the surviving ones, and future generations.
For an illustration of how families of organisms like
harm
in order to evolve (again, up to a point), though not the organisms themselves, consider the phenomenon of antibiotic resistance. The harder you try to harm bacteria, the stronger the survivors will be—unless you can manage to eradicate them completely. The same with cancer therapy: quite often cancer cells that manage to survive the toxicity of chemotherapy and radiation reproduce faster and take over the void made by the weaker cells.
Organisms Are Populations and Populations Are Organisms
The idea of viewing things in terms of populations, not individuals, with benefits to the latter stemming from harm to the former, came to me from the works on antifragility by the physicist turned geneticist Antoine Danchin.
3
For him, analysis needs to accommodate the fact that an organism is not something isolated and stand-alone: there are layerings and hierarchies. If you view things in terms of populations, you must transcend the terms “hormesis” and “Mithridatization” as a characterization of antifragility. Why? To rephrase the argument made earlier, hormesis is a metaphor for direct antifragility, when an organism directly benefits from harm; with evolution, something hierarchically superior to that organism benefits from the damage. From the outside, it looks like there is hormesis, but from the inside, there are winners and losers.
How does this layering operate? A tree has many branches, and these look like small trees; further, these large branches have many more smaller branches that sort of look like even smaller trees. This is a manifestation of what is called
fractal self-similarity,
a vision by the
mathematician Benoît Mandelbrot. There is a similar hierarchy in things and we just see the top layer from the outside. The cell has a population of intercellular molecules; in turn the organism has a population of cells, and the species has a population of organisms. A strengthening mechanism for the species comes at the expense of some organisms; in turn the organism strengthens at the expense of some cells, all the way down and all the way up as well.
For instance, if you drink a poisonous substance in small amounts, the mechanism by which your organism gets better is, according to Danchin, evolutionary
within
your system, with bad (and weak) proteins in the cells replaced by stronger—and younger—ones and the stronger ones being spared (or some similar operation). When you starve yourself of food, it is the bad proteins that are broken down first and recycled by your own body—a process called
autophagy
. This is a purely evolutionary process, one that selects and
kills
the weakest for fitness. But one does not need to accept the specific biological theory (like aging proteins and autophagy) to buy the general idea that survival pressures within the organism play a role in its overall improvement under external stress.


================================================================================
CHAPTER/SECTION 27 (Item 30)
================================================================================

THANK YOU, ERRORS
Now we get into errors and how the errors of some people carry benefits for others.
We can simplify the relationships between fragility, errors, and antifragility as follows. When you are fragile, you depend on things following the exact planned course, with as little deviation as possible—for deviations are more harmful than helpful. This is why the fragile
needs
to be very predictive in its approach, and, conversely, predictive systems cause fragility. When you want deviations, and you don’t care about the possible dispersion of outcomes that the future can bring, since most will be helpful, you are antifragile.
Further, the random element in trial and error is not quite random, if it is carried out rationally, using error as a source of information. If every trial provides you with information about what
does not
work, you start zooming in on a solution—so every attempt becomes more valuable, more like an expense than an error. And of course you make discoveries along the way.
Learning from the Mistakes of Others
But recall that this chapter is about layering, units, hierarchies, fractal structure, and the difference between the interest of a unit and those of its subunits. So it is often the mistakes of others that benefit the rest of us—and, sadly, not them. We saw that stressors are information, in the right context. For the antifragile, harm from errors should be less than the benefits. We are talking about some, not all, errors, of course; those that do not destroy a system help prevent larger calamities. The engineer and historian of engineering Henry Petroski presents a very elegant point. Had the
Titanic
not had that famous accident, as fatal as it was, we would have kept building larger and larger ocean liners and the next disaster would have been even more tragic. So the people who perished were sacrificed for the greater good; they unarguably saved more lives than were lost. The story of the
Titanic
illustrates the difference between gains for the system and harm to some of its individual parts.
The same can be said of the debacle of Fukushima: one can safely say that it made us aware of the problem with nuclear reactors (and small probabilities) and prevented larger catastrophes. (Note that the errors of naive stress testing and reliance on risk models were quite obvious at the time; as with the economic crisis, nobody wanted to listen.)
Every plane crash brings us closer to safety, improves the system, and makes the next flight safer—those who perish contribute to the overall safety of others. Swiss flight 111, TWA flight 800, and Air France flight 447 allowed the improvement of the system. But these systems learn because they are antifragile and set up to exploit small errors; the same cannot be said of economic crashes, since the economic system is not antifragile the way it is presently built. Why? There are hundreds of thousands of plane flights every year, and a crash in one plane does not involve others, so errors remain confined and highly epistemic—whereas globalized economic systems operate as one: errors spread and compound.
Again, crucially, we are talking of partial, not general, mistakes, small, not severe and terminal ones. This creates a separation between good and bad systems. Good systems such as airlines are set up to have small errors, independent from each other—or, in effect, negatively correlated to each other, since mistakes lower the odds of future mistakes. This is one way to see how one environment can be antifragile (aviation)
and the other fragile (modern economic life with “earth is flat” style interconnectedness).
If every plane crash makes the next one less likely, every bank crash makes the next one more likely. We need to eliminate the second type of error—the one that produces contagion—in our construction of an ideal socioeconomic system. Let us examine Mother Nature once again.
The natural was built from nonsystemic mistake to nonsystemic mistake: my errors lifting stones, when I am well calibrated, translate into small injuries that guide me the next time, as I try to avoid pain—after all, that’s the purpose of pain. Leopards, who move like a true symphony of nature, are not instructed by personal trainers on the “proper form” to lift a deer up a tree. Human advice might work with artificial sports, like, say, tennis, bowling, or gun shooting, not with natural movements.
Some businesses love their
own
mistakes. Reinsurance companies, who focus on insuring catastrophic risks (and are used by insurance companies to “re-insure” such non-diversifiable risks), manage to do well
after
a calamity or tail event that causes them to take a hit. If they are still in business and “have their powder dry” (few manage to have plans for such contingency), they make it up by disproportionately raising premia—customers overreact and pay up for insurance. They claim to have no idea about fair value, that is, proper pricing, for reinsurance, but they certainly know that it is overpriced at times of stress, which is sufficient to them to make a long-term shekel. All they need is to keep their mistakes small enough so they can survive them.
How to Become Mother Teresa
Variability causes mistakes and adaptations; it also allows you to know who your friends are. Both your failures and your successes will give you information. But, and this is one of the good things in life, sometimes you only know about someone’s character after you harm them with an error for which you are solely responsible—I have been astonished at the generosity of some persons in the way they forgave me for my mistakes.
And of course you learn from the errors of others. You may never know what type of person someone is unless they are given opportunities to violate moral or ethical codes. I remember a classmate, a girl in high school who seemed nice and honest and part of my childhood
group of anti-materialistic utopists. I learned that against my expectations (and her innocent looks) she didn’t turn out to be Mother Teresa or Rosa Luxemburg, as she dumped her first (rich) husband for another, richer person, whom she dumped upon his first financial difficulties for yet another richer and more powerful (and generous) lover. In a nonvolatile environment I (and most probably she, too) would have mistaken her for a utopist and a saint. Some members of society—those who did not marry her—got valuable information while others, her victims, paid the price.
Further, my characterization of a loser is someone who, after making a mistake, doesn’t introspect, doesn’t exploit it, feels embarrassed and defensive rather than enriched with a new piece of information, and tries to explain why he made the mistake rather than moving on. These types often consider themselves the “victims” of some large plot, a bad boss, or bad weather.
Finally, a thought. He who has never sinned is less reliable than he who has only sinned once. And someone who has made plenty of errors—though never the same error more than once—is more reliable than someone who has never made any.


================================================================================
CHAPTER/SECTION 28 (Item 31)
================================================================================

WHY THE AGGREGATE HATES THE INDIVIDUAL
We saw that antifragility in biology works thanks to layers. This rivalry between suborganisms contributes to evolution: cells within our bodies compete; within the cells, proteins compete, all the way through. Let us translate the point into human endeavors. The economy has an equivalent layering: individuals, artisans, small firms, departments within corporations, corporations, industries, the regional economy, and, finally, on top, the general economy—one can even have thinner slicing with a larger number of layers.
For the economy to be antifragile and undergo what is called evolution, every single individual business must
necessarily
be fragile, exposed to breaking—evolution needs organisms (or their genes) to die when supplanted by others, in order to achieve improvement, or to avoid reproduction when they are not as fit as someone else. Accordingly, the antifragility of the higher level may require the fragility—and sacrifice—of the lower one. Every time you use a coffeemaker for your morning cappuccino, you are benefiting from the fragility of the coffeemaking
entrepreneur who failed. He failed in order to help put the superior merchandise on your kitchen counter.
Also consider traditional societies. There, too, we have a similar layering: individuals, immediate families, extended families, tribes, people using the same dialects, ethnicities, groups.
While sacrifice as a modus is obvious in the case of ant colonies, I am certain that individual businessmen are not overly interested in hara-kiri for the greater good of the economy; they are therefore necessarily concerned in seeking antifragility or at least some level of robustness for themselves. That’s not necessarily compatible with the interest of the collective—that is, the economy. So there is a problem in which the property of the sum (the aggregate) varies from that of each one of the parts—in fact, it wants harm to the parts.
It is painful to think about ruthlessness as an engine of improvement.
Now what is the solution? There is none, alas, that can please everyone—but there are ways to mitigate the harm to the very weak.
The problem is graver than you think. People go to business school to learn how to do well while ensuring their survival—but what the economy, as a collective, wants them to do is to
not
survive, rather to take a lot, a lot of imprudent risks themselves and be blinded by the odds. Their respective industries improve from failure to failure. Natural and naturelike systems want some overconfidence on the part of individual economic agents, i.e., the overestimation of their chances of success and underestimation of the risks of failure in their businesses, provided their failure does not impact others. In other words, they want local, but not global, overconfidence.
We saw that the restaurant business is wonderfully efficient precisely because restaurants, being vulnerable, go bankrupt every minute, and entrepreneurs ignore such a possibility, as they think that they will beat the odds. In other words, some class of rash, even suicidal, risk taking is healthy for the economy—under the condition that not all people take the same risks and that these risks remain small and localized.
Now, by disrupting the model, as we will see, with bailouts, governments typically favor a certain class of firms that are large enough to require being saved in order to avoid contagion to other business. This is the opposite of healthy risk-taking; it is
transferring fragility from the collective to the unfit
. People have difficulty realizing that the solution is building a system in which nobody’s fall can drag others down—for
continuous failures work to preserve the system. Paradoxically, many government interventions and social policies end up hurting the weak and consolidating the established.


================================================================================
CHAPTER/SECTION 29 (Item 32)
================================================================================

WHAT DOES NOT KILL ME KILLS OTHERS
Time to debunk a myth.
As an advocate of antifragility I need to warn about the illusion of seeing it when it is not really there. We can mistake the antifragility of the system for that of the individual, when in fact it takes place
at the expense
of the individual (the difference between hormesis and selection).
Nietzsche’s famous expression “what does not kill me makes me stronger” can be easily misinterpreted as meaning Mithridatization or hormesis. It may be one of these two phenomena, very possible, but it could as well mean “what did not kill me
did not
make me stronger, but spared me
because
I am stronger than others; but it killed others and the average population is now stronger because the weak are gone.” In other words, I passed an exit exam. I’ve discussed the problem in earlier writings of the false illusion of causality, with a newspaper article saying that the new mafia members, former Soviet exiles, had been “hardened by a visit to the Gulag” (the Soviet concentration camps). Since the sojourn in the Gulag killed the weakest, one had the illusion of strengthening. Sometimes we see people having survived trials and imagine, given that the surviving population is sturdier than the original one, that these trials are good for them. In other words, the trial can just be a ruthless exam that kills those who fail. All we may be witnessing is that transfer of fragility (rather, antifragility) from the individual to the system that I discussed earlier. Let me present it in a different way. The surviving cohort, clearly, is stronger than the initial one—but not quite the individuals, since the weaker ones died.
Someone paid a price for the system to improve.
Me and Us
This visible tension between individual and collective interests is new in history: in the past it was dealt with by the near irrelevance of individuals. Sacrifice for the sake of the group is behind the notion of heroism: it is good for the tribe, bad for those who perish under the fever of war. This instinct for heroism and the fading of individual interests in favor
of the communal has become aberrant with suicide bombers. These pre-death terrorists get into a mood similar to an ecstatic trance in which their emotions drive them to become indifferent to their own mortality. It is a fallacy that suicide bombers are driven by the promise of a reward of some Islamic paradise with virgins and other entertainment, for, as the anthropologist Scott Atran has pointed out, the first suicide bombers in the Levant were revolutionaries of Greek Orthodox background—my tribe—not Islamists.
There is something like a switch in us that kills the individual in favor of the collective when people engage in communal dances, mass riots, or war. Your mood is now that of the herd. You are part of what Elias Canetti calls the
rhythmic and throbbing crowd
. You can also feel a different variety of crowd experience during your next street riot, when fear of authorities vanishes completely under group fever.
Let us now generalize the point. Looking at the world from a certain distance, I see a total tension between man and nature—a tension in the trade-off of fragilities. We saw how nature wants herself, the aggregate, to survive—not every species—just as, in turn, every single species wants its individuals to be fragile (particularly after reproduction), for evolutionary selection to take place. We saw how such transfer of fragility from individuals to species is necessary for its overall survival: species are potentially antifragile, given that DNA is information, but members of the species are perishable, hence ready to sacrifice and in reality designed to do so for the benefit of the collective.
Antifragility shmantifragility. Some of the ideas about fitness and selection here are not very comfortable to this author, which makes the writing of some sections rather painful—I detest the ruthlessness of selection, the inexorable disloyalty of Mother Nature. I detest the notion of improvement thanks to harm to others. As a humanist, I stand against the antifragility of systems at the expense of individuals, for if you follow the reasoning, this makes us humans individually irrelevant.
The great benefit of the Enlightenment has been to bring the individual to the fore, with his rights, his freedom, his independence, his “pursuit of happiness” (whatever that “happiness” means), and, most of all, his privacy. In spite of its denial of antifragility, the Enlightenment and the political systems that emerged from it freed us (somewhat) from the domination of society, the tribe, and the family that had prevailed throughout history.
The unit in traditional cultures is the collective; and it could be perceived
to be harmed by the behavior of an individual—the honor of the family is sullied when, say, a daughter becomes pregnant, or a member of the family engages in large-scale financial swindles and Ponzi schemes, or, worst, may even teach a college course in the charlatanic subject of financial economics. And these mores persist. Even as recently as the late nineteenth century or early twentieth, it was common in, say, rural France for someone to spend all his savings to erase the debts of a remote cousin (a practice called
passer l’éponge,
literally, to use a sponge to erase the liability from the chalkboard), and to do so in order to preserve the dignity and good name of the extended family. It was perceived as a duty. (I confess having done some of that myself in the twenty-first century!)
Clearly the system needs to be there for the individual to survive. So one needs to be careful in glorifying one interest against others in the presence of interdependence and complexity.
4
In the Cosa Nostra, the Sicilian mafia, the designation “man of honor” (
uomo d’onore
) implies that the person caught by the police would remain silent and not rat on his friends, regardless of benefits, and that life in prison is preferable to a plea that entails hurting other members. The tribe (Cosa Nostra) comes before the individual. And what broke the back of the mafia was the recent generation of plea bargainers. (Note that “honor” in the mafia is limited to such in-group solidarity—they otherwise lie, and there is nothing honorable about them in other domains. And they kill people from behind, something that on the east side of the Mediterranean is considered the purest form of cowardice.)
Likewise, we humans may have to be self-centered at the expense of other species, at the risk of ecological fragility, if it insures our survival. Our interests—as a human race—prevail over those of nature; and we can tolerate some inefficiency, some fragility, in order to protect individuals, although sacrificing nature too much may eventually hurt ourselves.
We saw the trade-off between the interests of the collective and those of the individual. An economy cannot survive without breaking individual
eggs; protection is harmful, and constraining the forces of evolution to benefit individuals does not seem required. But we can shield individuals from starvation, provide some social protection. And give them respect. Or more, as we see next.
National Entrepreneur Day
Meanwhile, if as a utopist (indeed), I hate what I am figuring out, I think that there is hope.
Heroism and the respect it commands is a form of compensation by society for those who take risks for others. And entrepreneurship is a risky and heroic activity, necessary for growth or even the mere survival of the economy.
It is also necessarily collective on epistemological grounds—to facilitate the development of expertise. Someone who did
not
find something is providing others with knowledge, the best knowledge, that of
absence
(what does not work)—yet he gets little or no credit for it. He is a central part of the process with incentives going to others and, what is worse, gets no respect.
5
I am an ingrate toward the man whose overconfidence caused him to open a restaurant and fail, enjoying my nice meal while he is probably eating canned tuna.
In order to progress, modern society should be treating ruined entrepreneurs in the same way we honor dead soldiers, perhaps not with as much honor, but using exactly the same logic (the entrepreneur is still alive, though perhaps morally broken and socially stigmatized, particularly if he lives in Japan). For there is no such thing as a failed soldier, dead or alive (unless he acted in a cowardly manner)—likewise, there is no such thing as a failed entrepreneur or failed scientific researcher, any more than there is a successful babbler, philosophaster, commentator, consultant, lobbyist, or business school professor who does not take personal risks. (Sorry.)
Psychologists label “overconfidence” a disease, blinding people to the odds of success when engaging in ventures. But there is a difference between the benign, heroic type of risk taking that is beneficial to others,
in the antifragile case, and the nastier modern type related to negative Black Swans, such as the overconfidence of “scientists” computing the risks of harm from the Fukushima reactor. In the case of the former, what they call overconfidence is a good thing, not something to medicate.
And compare entrepreneurs to the beancounting managers of companies who climb the ladder of hierarchy with hardly ever any real downside. Their cohort is rarely at risk.
What Erasmus called
ingratitudo vulgi,
the ingratitude of the masses, is increasing in the age of globalization and the Internet.
My dream—the solution—is that we would have a National Entrepreneur Day, with the following message:
Most of you will fail, disrespected, impoverished, but we are grateful for the risks you are taking and the sacrifices you are making for the sake of the economic growth of the planet and pulling others out of poverty.
You are at the source of our antifragility
. Our nation thanks you.
1
A technical comment on why the adaptability criterion is innocent of probability (the nontechnical reader should skip the rest of this note). The property in a stochastic process of not seeing at any time period
t
what would happen in time after
t,
that is, any period higher than
t,
hence reacting with a lag, an incompressible lag, is called
nonanticipative strategy,
a requirement of stochastic integration. The incompressibility of the lag is central and unavoidable. Organisms can only have nonanticipative strategies—hence nature can only be nonpredictive. This point is not trivial at all, and has even confused probabilists such as the Russian School represented by Stratonovich and the users of his method of integration, who fell into the common mental distortion of thinking that the future sends some signal detectable by us. We wish.
2
Strong antifragility is when the love of volatility knows no bound—the gains have a remote limit or are truly unlimited—the sky is the limit. These can only exist in artificial, man-made life such as economic contracts and cultural products, not really in natural processes. More in the Appendix.
3
He and his co-authors published in the journal
Genes
a paper on the idea of antifragility in biological systems. Interestingly, the article was in response to a draft of this book; in turn this book was modified in response to Danchin’s article.
4
Many people think at first that their own death is the worst Black Swan scenario. It is not. Unless they’ve studied too much modern economics, they would agree explicitly that their death
plus
the death of their loved ones
plus
the termination of humanity would be a vastly worse outcome than their own death. Recall my comment on complex systems. We are a mere part of a large chain, and we are worried about both ourselves and the system, as well as the preservation of parts of that large chain.
5
A correspondent, Jean-Louis Rheault, wrote, “I have noticed that the more people glorify the entrepreneur as an abstraction, the more they will scorn an actual one they meet.”


================================================================================
CHAPTER/SECTION 30 (Item 33)
================================================================================

BOOK II
Modernity and the Denial of Antifragility
A
s in Baudelaire’s sad poem about the albatross, what is made to fly will not do well trapped on the ground, where it is forced to traipse. And it is quite fitting that “volatility” comes from
volare,
“to fly” in Latin. Depriving political (and other) systems of volatility harms them, causing eventually greater volatility of the cascading type.
This section,
Book II
, deals with the fragility that comes from the denial of hormesis, the natural antifragility of organisms, and how we hurt systems with the very best of intentions by playing conductor. We are fragilizing social and economic systems by denying them stressors and randomness, putting them in the Procrustean bed of cushy and comfortable—but ultimately harmful—modernity.
Procrustes was an inn-keeper in Greek mythology who, in order to make the travelers fit in his bed, cut the limbs of those who were too tall and stretched those who were too short. But he had the bed fitting the visitor with total perfection.
As we saw in
Chapter 3
, treating an organism like a simple machine is a kind of simplification or approximation or reduction that is exactly like a Procrustean bed. It is often with the most noble intentions that we
do so, as we are pressured to “fix” things, so we often blow them up with our fear of randomness and love of smoothness.
1
Book II
will also discuss the competition between man and natural forces, the craving of volatility by some antifragile systems, and how we make social, political (and other) systems vulnerable to Black Swans when we overstabilize them.
1
Where simplifications fail, causing the most damage, is when something nonlinear is simplified with the linear as a substitute. That is the most common Procrustean bed.


================================================================================
CHAPTER/SECTION 31 (Item 34)
================================================================================

CHAPTER 5
The Souk and the Office Building
The Reds and the Whites all go to Zurich—War is not a prison—The turkey’s thwarted projects—Remember we are in Extremistan


================================================================================
CHAPTER/SECTION 32 (Item 35)
================================================================================

TWO TYPES OF PROFESSIONS
Consider the fate of Ioannis (John) and Georgios (George), two identical twin brothers, born in Cyprus (both of them), currently both living in the Greater London area. John has been employed for twenty-five years as a clerk in the personnel department of a large bank, dealing with the relocation of employees around the globe. George is a taxi driver.
John has a perfectly predictable income (or so he thinks), with benefits, four weeks’ annual vacation, and a gold watch every twenty-five years of employment. Every month, £3,082 is deposited in his local Nat West checking account. He spends a portion of it for the mortgage on his house west of London, the utilities, and feta cheese, and has a bit left for his savings. He used to wake up on Saturday morning, the day when people stretch and linger in bed, anxiety free, telling himself “life is good”—until the banking crisis, when he realized that his job could be “made redundant.” Unemployment would seriously hit him hard. As a personnel expert, he has seen the implosions of long careers, with persons who, laid off at the age of fifty, never recovered.
George, who lives on the same street as his brother, drives a black taxi—meaning he has a license for which he spent three years expanding
his frontal lobes by memorizing streets and itineraries in Greater London, which gives him the right to pick up clients in the streets. His income is extremely variable. Some days are “good,” and he earns several hundred pounds; some are worse, when he does not even cover his costs; but, year after year, he averages about the same as his brother. To date, he has only had a single day in his twenty-five-year career without a fare. Because of the variability of his income, he keeps moaning that he does not have the job security of his brother—but in fact this is an illusion, for he has a bit more.
This is the central illusion in life: that randomness is risky, that it is a bad thing—and that eliminating randomness is done by eliminating randomness.
Artisans, say, taxi drivers, prostitutes (a very, very old profession), carpenters, plumbers, tailors, and dentists, have some volatility in their income but they are rather robust to a minor professional Black Swan, one that would bring their income to a complete halt. Their risks are visible. Not so with employees, who have no volatility, but can be surprised to see their income going to zero after a phone call from the personnel department. Employees’ risks are hidden.
Thanks to variability, these artisanal careers harbor a bit of antifragility: small variations make them adapt and change continuously by learning from the environment and being, sort of, continuously under pressure to be fit. Remember that stressors are information; these careers face a continuous supply of these stressors that make them adjust opportunistically. In addition, they are open to gifts and positive surprises, free options—the hallmark of antifragility, as we will see in
Book IV
. George was used to having, once in a while, a crazy request, one he was free to decline: during the Icelandic volcano scare, when U.K. air traffic was shut down, he was asked by a rich old lady to drive her to a wedding in the South of France—a two-thousand-mile round-trip journey. Likewise, a prostitute faces the small probability of seeing a severely infatuated rich client give her a very expensive diamond, or even an offer of matrimony, in what can be expected to be a short transitional period before her widowhood.
And George has the freedom to continue until he drops (many people continue to drive cabs into their eighties, mostly to kill time), since he is his own boss, compared to his brother, who is completely unhireable in his fifties.
The difference between the two volatilities in income applies to political
systems—and, as we will see in the next two chapters, to about everything in life. Man-made smoothing of randomness produces the equivalent of John’s income: smooth, steady, but fragile. Such income is more vulnerable to large shocks that can make it go to zero (plus some unemployment benefits if he resides in one of the few welfare states). Natural randomness presents itself more like George’s income: smaller role for very large shocks, but daily variability. Further, such variability helps improve the system (hence the antifragility). A week with declining earnings for a taxi driver or a prostitute provides information concerning the environment and intimates the need to find a new part of town where clients hang around; a month or so without earnings drives them to revise their skills.
Further, for a self-employed person, a small (nonterminal) mistake is information, valuable information, one that directs him in his adaptive approach; for someone employed like John, a mistake is something that goes into his permanent record, filed in the personnel department. Yogi Berra once said: “We made the wrong mistake”—and for John all mistakes are wrong mistakes. Nature loves small errors (without which genetic variations are impossible), humans don’t—hence when you rely on human judgment you are at the mercy of a mental bias that disfavors antifragility.
So, alas, we humans are afraid of the second type of variability and naively fragilize systems—or prevent their antifragility—by protecting them. In other words, a point worth repeating every time it applies, this avoidance of small mistakes makes the large ones more severe.
The centralized state resembles the income of John; the city-state model that of George. John has one large employer, George many small ones—so he can select the ones that fit him the best and hence has, at any point in time, “more options.” One has the illusion of stability, but is fragile; the other one the illusion of variability, but is robust and even antifragile.
The more variability you observe in a system, the less Black Swan–prone it is. Let us now examine how this applies to political systems with the story of Switzerland.
Lenin in Zurich
I was recently in a café-turned-expensive-restaurant in Zurich poring over the overpriced menu, with prices at least triple of those in a place
of equivalent quality in the United States. The world’s recent crisis had made Switzerland even more of a safe haven than it had ever been, causing its currency to rise dramatically—Switzerland is the most antifragile place on the planet; it benefits from shocks that take place in the rest of the world. The friend, a writer, pointed out to me that Lenin, who lived in town, used to play chess in the café with the Dadaist poet Tristan Tzara. Yes, the Russian revolutionary Vladimir Ilyich Ulyanov, later known as Lenin, spent some time in Switzerland concocting his project of the great top-down modernist state and largest human experiment in centralized state control. It hit me that there was something eerie in Lenin’s presence there, for, a few days before, I had been at a conference in Montreux, on Lake Geneva, that took place in the same lakefront hotel where Vladimir Nabokov, the émigré Russian aristocrat and victim of Lenin, spent the last couple of decades of his life.
It seemed interesting to me that sheltering the reds and the whites, both the Bolsheviks and the aristocratic White Russians they later displaced, seems to be part of the primary business of the Helvetic Confederation. The main cities such as Zurich, Geneva, or Lausanne bear traces of the political refugees who went there for shelter: émigrés, from the Iranian royals thrown out by the Islamists to the latest African potentate executing “plan B.” Even Voltaire spent some time hiding in the place, in Ferney, a French suburb of Geneva near the Swiss border (before it even joined the confederation). Voltaire, the perfectly protected gadfly, would rush to Ferney after insulting the king of France, the Catholic Church, or some other authority—what people don’t usually know about him is that he also had an incentive to seek protection there for financial reasons. Voltaire was a self-made man, a wealthy merchant, investor, and speculative dealer. Much of his wealth came from the antifragility of stressors, as he started building his fortune during his early exile.
So, like Voltaire, there are refugees of other types: financial refugees coming from places of turmoil, recognizable by their expensive and boring clothes, bland vocabulary, contrived decorum, and expensive (shiny) watches—in other words, non-Voltaires. Like many rich people, they feel entitled to laugh at their own jokes. These (dull) people are not looking for personal shelter: it is their assets that are seeking refuge. While some political persons might prefer to hide from the risks of their national regime in France or England, more exciting places on Saturday night, it is most certainly in Switzerland that their checking account
wants to be. It is economically the most robust place on the planet—and has been so for quite a few centuries.
This great variety of people and their wallets are there, in Switzerland, for its shelter, safety, and stability. But all these refugees don’t notice the obvious: the most stable country in the world
does not have
a government. And it is not stable in spite of not having a government; it is stable
because
it does not have one. Ask random Swiss citizens to name their president, and count the proportion of people who can do so—they can usually name the presidents of France or the United States but not their own. Its currency works best (at the time of writing it proved to be the safest), yet its central bank is tiny, even relative to its size.
Do these politicians biding their time before (they hope) returning to power notice such absence of government, accept that they are in Switzerland because of such absence of government, and adapt their ideas on nation-states and political systems accordingly? Not at all.
It is not quite true that the Swiss do not have a government. What they do not have is a large
central
government, or what the common discourse describes as “the” government—what governs them is entirely bottom-up, municipal of sorts, regional entities called cantons, near-sovereign mini-states united in a confederation. There is plenty of volatility, with enmities between residents that stay at the level of fights over water fountains or other such uninspiring debates. This is not necessarily pleasant, since neighbors are transformed into busybodies—this is a dictatorship from the bottom, not from the top, but a dictatorship nevertheless. But this bottom-up form of dictatorship provides protection against the romanticism of utopias, since no big ideas can be generated in such an unintellectual atmosphere—it suffices to spend some time in cafés in the old section of Geneva, particularly on a Sunday afternoon, to understand that the process is highly unintellectual, devoid of any sense of the grandiose, even downright puny (there is a famous quip about how the greatest accomplishment of the Swiss was inventing the cuckoo clock while other nations produced great works—nice story except that the Swiss did not invent the cuckoo clock). But the system produces stability—boring stability—at every possible level.
Also note that the hideously glitzy scenes one encounters in Switzerland, in all of Geneva, in some parts of Zurich (the center), and particularly in the ski resorts such as Gstaadt and San Moritz are not the direct
product of the country nor part of its mission, but the result of its success, as Switzerland acts as a magnet for the ugly rich and tax refugees.
Note for now that this is the last major country that is not a nation-state, but rather a collection of small municipalities left to their own devices.


================================================================================
CHAPTER/SECTION 33 (Item 36)
================================================================================

BOTTOM-UP VARIATIONS
What I call bottom-up variations—or noise—is the type of political volatility that takes place within a municipality, the petty fights and frictions in the running of regular affairs. It is not scalable (or what is called
invariant
under scale transformation): in other words, if you increase the size, say, multiply the number of people in a community by a hundred, you will have markedly different dynamics. A large state does not behave at all like a gigantic municipality, much as a baby human does not resemble a smaller adult. The difference is qualitative: the increase in the number of persons in a given community alters the quality of the relationship between parties. Recall the nonlinearity description from the Prologue. If you multiply by ten the number of persons in a given entity, you do not preserve the properties: there is a transformation. Here conversations switch from the mundane—but effective—to abstract numbers, more interesting, more academic perhaps, but, alas, less effective.
A cluster of municipalities with charming provincial enmities, their own internal fights, and people out to get one another aggregates to a quite benign and stable state. Switzerland is similar to the income of the second brother, stable because of the variations and noise at the local level. Just as the income of the cab driver shows instability on a daily basis but annual stability, likewise Switzerland shows stability at the aggregate level, as the ensemble of cantons produces a solid system.
The way people handle local affairs is vastly different from the way they handle large, abstract public expenditures: we have traditionally lived in small units and tribes and managed rather well in small units.
1
Further, biology plays a role in a municipal environment, not in a larger system. An administration is shielded from having to feel the sting
of shame (with flushing in his face), a biological reaction to overspending and other failures such as killing people in Vietnam. Eye contact with one’s peers changes one’s behavior. But for a desk-grounded office leech, a number is a just a number. Someone you see in church Sunday morning would feel uncomfortable for his mistakes—and more responsible for them. On the small, local scale, his body and biological response would direct him to avoid causing harm to others. On a large scale, others are abstract items; given the lack of social contact with the people concerned, the civil servant’s brain leads rather than his emotions—with numbers, spreadsheets, statistics, more spreadsheets, and theories.
When I expressed this idea to my co-author Mark Blyth, he blurted out the obvious: “Stalin could not have existed in a municipality.”
Small is beautiful in so many other ways. Take for now that the small (in the aggregate, that is, a collection of small units) is more antifragile than the large—in fact the large is doomed to breaking, a mathematical property we will explain later, that, sadly, seems universal as it applies to large corporations, very large mammals, and large administrations.
2
There is another issue with the abstract state, a psychological one. We humans scorn what is not concrete. We are more easily swayed by a crying baby than by thousands of people dying elsewhere that do not make it to our living room through the TV set. The one case is a tragedy, the other a statistic. Our emotional energy is blind to probability. The media make things worse as they play on our infatuation with anecdotes, our thirst for the sensational, and they cause a great deal of unfairness that way. At the present time, one person is dying of diabetes every seven seconds, but the news can only talk about victims of hurricanes with houses flying in the air.
The problem is that by creating bureaucracies, we put civil servants in a position to make decisions based on abstract and theoretical matters, with the illusion that they will be making them in a rational, accountable way.
Also consider that lobbyists—this annoying race of lobbyists—cannot exist in a municipality or small region. The Europeans, thanks to the centralization of (some) power with the European Commission in Brussels, are quickly discovering the existence of these mutants coming to
manipulate democracy for the sake of some large corporation. By influencing one single decision or regulation in Brussels, a single lobbyist gets a large bang. It is a much larger payoff (at low cost) than with municipalities, which would require armies of lobbyists trying to convince people while embedded in their communities.
3
Consider, too, the other effect of scale: small corporations are less likely to have lobbyists.
The same bottom-up effect applies to law. The Italian political and legal philosopher Bruno Leoni has argued in favor of the robustness of judge-based law (owing to its diversity) as compared to explicit and rigid codifications. True, the choice of a court could be a lottery—but it helps prevent large-scale mistakes.
I use the example of Switzerland to show the natural antifragility of political systems and how stability is achieved by managing noise, having a mechanism for letting it run its natural course, not by minimizing it.
Note another element of Switzerland: it is perhaps the most successful country in history, yet it has traditionally had a very low level of university education compared to the rest of the rich nations. Its system, even in banking during my days, was based on apprenticeship models, nearly vocational rather than the theoretical ones. In other words, on
techne
(crafts and know how), not
episteme
(book knowledge, know what).


================================================================================
CHAPTER/SECTION 34 (Item 37)
================================================================================

AWAY FROM EXTREMISTAN
Let us now examine the technical aspects of the process, a more statistical view of the effect of human intervention on the volatility of affairs. There is a certain mathematical property to this bottom-up volatility, and to the volatility of natural systems. It generates the kind of randomness I call Mediocristan—plenty of variations that might be scary, but tend to cancel out in the aggregate (over time, or over the collection of municipalities that constitute the larger confederation or entity)—rather than the unruly one called Extremistan, in which you have mostly stability and occasionally
large chaos—errors there have large consequences. One fluctuates, the other jumps. One has a lot of small variations, the other varies in lumps. Just like the income of the driver compared to that of bank employee. The two types of randomness are qualitatively distinct.
Mediocristan has a lot of variations, not a single one of which is extreme; Extremistan has few variations, but those that take place are extreme.
Another way to understand the difference: your caloric intake is from Mediocristan. If you add the calories you consume in a year, even without adjusting for your lies, not a single day will represent much of the total (say, more than 0.5 percent of the total, five thousand calories when you may consume eight hundred thousand in a year). So the exception, the rare event, plays an inconsequential role in the aggregate and the long-term. You cannot double your weight in a single day, not even a month, not possibly in a year—but you can double your net worth or lose half of it in a single moment.
By comparison, if you take the sale of novels, more than half of sales (and perhaps 90 percent of profits) tends to come from the top 0.1 percent, so the exception, the one-in-a-thousand event, is dominant there. So financial matters—and other economic matters—tend to be from Extremistan, just like history, which moves by discontinuities and jumps from one state to another.
4
FIGURE 3
. Municipal noise, distributed variations in the souks (first) compared to that of centralized or human-managed systems (second)—or, equivalently, the income of a taxi driver (first) and that of an employee (second). The second graph shows moves taking place from cascade to cascade, or Black Swan to Black Swan. Human overintervention to smooth or control processes causes a switch from one kind of system, Mediocristan, into another, Extremistan. This effect applies to all manner of systems with constrained volatility—health, politics, economics, even someone’s mood with and without Prozac. Or the difference between the entrepreneur-driven Silicon Valley (first) and the banking system (second).
Figure 3
illustrates how antifragile systems are hurt when they are deprived of their natural variations (mostly thanks to naive intervention). Beyond municipal noise, the same logic applies to: the child who, after spending time in a sterilized environment, is left out in the open; a system with dictated political stability from the top; the effects of price controls; the advantages of size for a corporation; etc. We switch from a system that produces steady but controllable volatility (Mediocristan), closer to the statistical “bell curve” (from the benign family of the Gaussian or Normal Distribution), into one that is highly unpredictable and moves mostly by jumps, called “fat tails.” Fat tails—a synonym for Extremistan—mean that remote events, those in what is called the “tails,” play a disproportionate role. One (first graph) is volatile; it fluctuates but does not sink. The other (second graph) sinks without significant fluctuations outside of episodes of turmoil. In the long run the second system will be far more volatile—but volatility comes in lumps. When we constrain the first system we tend to get the second outcome.
Note also that in Extremistan predictability is very low. In the second, pseudo-smooth kind of randomness, mistakes appear to be rare, but they will be large, often devastating when they occur. Actually, an argument we develop in
Book IV
, anything locked into planning tends to fail precisely because of these attributes—it is quite a myth that planning helps corporations: in fact we saw that the world is too random and unpredictable to base a policy on visibility of the future. What survives comes from the interplay of some fitness and environmental conditions.
The Great Turkey Problem
Let me now move back from the technical jargon and graphs of Fat Tails and Extremistan to colloquial Lebanese. In Extremistan, one is prone to be fooled by the properties of the past and get the story exactly backwards. It is easy, looking at what is happening in the second graph of
Figure 3
, before the big jump down, to believe that the system is now safe, particularly when the system has made a progressive switch from the “scary” type of visibly volatile randomness at left to the apparently safe right. It looks like a drop in volatility—and it is not.
FIGURE 4
. A turkey using “evidence”; unaware of Thanksgiving, it is making “rigorous” future projections based on the past. Credit: George Nasr
A turkey is fed for a thousand days by a butcher; every day confirms to its staff of analysts that butchers love turkeys “with increased statistical confidence.” The butcher will keep feeding the turkey until a few days before Thanksgiving. Then comes that day when it is really not a very good idea to be a turkey. So with the butcher surprising it, the turkey will have a revision of belief—right when its confidence in the statement that
the butcher loves turkeys
is maximal and “it is very quiet” and soothingly predictable in the life of the turkey. This example builds on an adaptation of a metaphor by Bertrand Russell. The key here is that such a surprise will be a Black Swan event; but just for the turkey, not for the butcher.
We can also see from the turkey story the mother of all harmful mistakes: mistaking absence of evidence (of harm) for evidence of absence, a mistake that we will see tends to prevail in intellectual circles and one that is grounded in the social sciences.
So our mission in life becomes simply “how not to be a turkey,” or, if possible, how to be a turkey in reverse—antifragile, that is. “Not being a turkey” starts with figuring out the difference between true and manufactured stability.
The reader can easily imagine what happens when constrained,
volatility-choked systems explode. We have a fitting example: the removal of the Baath Party, with the abrupt toppling of Saddam Hussein and his regime in 2003 by the United States. More than a hundred thousand persons died, and ten years later, the place is still a mess.


================================================================================
CHAPTER/SECTION 35 (Item 38)
================================================================================

TWELVE THOUSAND YEARS
We started the discussion of the state with the example of Switzerland. Now let us go a little bit farther east.
The northern Levant, roughly today’s northern part of Syria and Lebanon, stayed perhaps the most prosperous province in the history of mankind, over the long, very long stretch of time from the pre-pottery Neolithic until very modern history, the middle of the twentieth century. That’s twelve thousand years—compared to, say, England, which has been prosperous for about five hundred years, or Scandinavia, now only prosperous for less than three hundred years. Few areas on the planet have managed to thrive with so much continuity over any protracted stretch of time, what historians call
longue durée
. Other cities came and went; Aleppo, Emesa (today Homs), and Laodicea (Lattakia) stayed relatively affluent.
The northern Levant was since ancient times dominated by traders, largely owing to its position as a central spot on the Silk Road, and by agricultural lords, as the province supplied wheat to much of the Mediterranean world, particularly Rome. The area supplied a few Roman emperors, a few Catholic popes before the schisms, and more than thirty Greek language writers and philosophers (which includes many of the heads of Plato’s academy), in addition to the ancestors of the American visionary and computer entrepreneur Steve Jobs, who brought us the Apple computer, on one of which I am recopying these lines (and the iPad tablet, on which you may be reading them). We know of the autonomy of the province from the records during Roman days, as it was then managed by the local elites, a decentralized method of ruling through locals that the Ottoman retained. Cities minted their own coins.
Then two events took place. First, after the Great War, one part of the northern Levant was integrated into the newly created nation of Syria, separated from its other section, now part of Lebanon. The entire area had been until then part of the Ottoman Empire, but functioned as somewhat autonomous regions—Ottomans, like the Romans before them, let local elites run the place so long as sufficient tax was paid,
while they focused on their business of war. The Ottoman type of imperial peace, the
pax Ottomana
, like its predecessor the
pax Romana,
was good for commerce. Contracts were enforced, and that is what governments are needed for the most. In the recent nostalgic book
Levant,
Philip Mansel documents how the cities of the Eastern Mediterranean operated as city-states separated from the hinterland.
Then, a few decades into the life of Syria, the modernist Baath Party came to further enforce utopias. As soon as the Baathists centralized the place and enforced their statist laws, Aleppo and Emesa went into instant decline.
What the Baath Party did, in its “modernization” program, was to remove the archaic mess of the souks and replace them with the crisp modernism of the office building.
The effect was immediately visible: overnight the trading families moved to places such as New York and New Jersey (for the Jews), California (for the Armenians), and Beirut (for the Christians). Beirut offered a commerce-friendly atmosphere, and Lebanon was a benign, smaller, disorganized state without any real central government. Lebanon was small enough to be a municipality on its own: it was smaller than a medium-size metropolitan area.
War, Prison, or Both
But while Lebanon had all the right qualities, the state was
too
loose, and by allowing the various Palestinian factions and the Christian militias to own weapons, it caused an arms race between the communities while placidly watching the entire buildup. There was also an imbalance between communities, with the Christians trying to impose their identity on the place. Disorganized is invigorating; but the Lebanese state was one step too disorganized. It would be like allowing each of the New York mafia bosses to have a larger army than the Joint Chiefs of Staff (just imagine John Gotti with missiles). So in 1975 a raging civil war started in Lebanon.
A sentence that still shocks me when I think about it was voiced by one of my grandfather’s friends, a wealthy Aleppine merchant who fled the Baath regime. When my grandfather asked his friend during the Lebanese war why he did not go back to Aleppo, his answer was categorical: “We people of Aleppo prefer war to prison.” I thought that he meant that they were going to put him in jail, but then I realized that by “prison” he meant the loss of political and economic freedoms.
Economic life, too, seems to prefer war to prison. Lebanon and Northern Syria had very similar wealth per individual (what economists call Gross Domestic Product) about a century ago—and had identical cultures, language, ethnicities, food, and even jokes. Everything was the same except for the rule of the “modernizing” Baath Party in Syria compared to the totally benign state in Lebanon. In spite of a civil war that decimated the population, causing an acute brain drain and setting wealth back by several decades, in addition to every possible form of chaos that rocked the place, today Lebanon has a considerably higher standard of living—between three and six times the wealth of Syria.
Nor did the point escape Machiavelli. Jean-Jacques Rousseau wrote, citing him: “It seemed, wrote Machiavelli, that in the midst of murders and civil wars, our republic became stronger [and] its citizens infused with virtues.… A little bit of agitation gives resources to souls and what makes the species prosper isn’t peace, but freedom.”
Pax Romana
The centralized nation-state is not exactly new in history. In fact, it existed in a nearly identical form in ancient Egypt. But this was an isolated event in history, and it did not survive there for long: the Egyptian high state started collapsing upon contact with the crazy unruly barbaric disorganized harassing invaders coming from Asia Minor with their assault chariots, literally a killer app.
The dynasties of ancient Egypt did not run the place like an empire but like an integrated state, which is markedly different—as we saw, it produces different types of variations. Nation-states rely on centralized bureaucracy, whereas empires, such as the Roman empire and Ottoman dynasties, have relied on local elites, in fact allowing the city-states to prosper and conserve some effective autonomy—and, what was great for peace, such autonomy was commercial, not military. In reality, the Ottomans did these vassals and suzerains a favor by preventing them from involvement in warfare—this took away militaristic temptations and helped them thrive; regardless of how iniquitous the system seemed to be on the surface, it allowed locals to focus on commerce rather than war. It protected them from themselves. This is the argument brought by David Hume in his
History of England
in favor of small states, as large states get tempted by warfare.
Clearly neither the Romans nor the Ottomans were allowing local
autonomy out of love of freedom on the part of others; they just did it for convenience. A combination of empire (for some affairs) and semi-independent regions (left alone for their own business) provides more stability than the middle: the centralized nation-state with flags and discrete borders.
But the states, even when centralized, as in Egypt or China, were, in practice, not too different from the Roman and Ottoman ones—except for the centralization of intellect with the scribes and the mandarinate system establishing a monopoly of knowledge. Some of us may remember that there were days with no Internet, no electronic monitoring of wire transfers to supervise tax receipts. And before modernity’s communication networks, with the telegraph, the train, and, later, the telephone, states had to rely on messenger services. So a local provincial ruler was king for a large number of matters, even though he was not so nominally. Until recent history, the central state represented about 5 percent of the economy—compared to about ten times that share in modern Europe. And, further, governments were sufficiently distracted by war to leave economic affairs to businessmen.
5
War or No War
Let us take a look at Europe before the creations of the nation-states of Germany and Italy (marketed as “re-unification,” as if these nations had been crisp units in some romantic past). There was, until the creation of these romantic entities, a fissiparous and amorphous mass of small statelings and city-states in constant tension—but shifting alliances. In most of their history, Genoa and Venice were competing for the Eastern and Southern Mediterranean like two hookers battling for a sidewalk. And here is something comforting about statelings at war: mediocrity cannot handle more than one enemy, so war here turns into an alliance there. Tension was always present somewhere but without large consequences, like precipitation in the British Isles; mild rain and no floods are vastly more manageable than the opposite: long droughts followed by intense rainfall. In other words, Mediocristan.
Then of course the contagious creation of nation-states in the late
nineteenth century led to what we saw with the two world wars and their sequels: more than sixty million (and possibly eighty million) victims. The difference between war and
no war
became huge, with marked discontinuity. This is no different from a switch to “winner take all” effects in industry, the domination of rare events. A collection of statelings is similar to the restaurant business we discussed earlier: volatile, but you never have a generalized restaurant crisis—unlike, say, the banking business. Why? Because it is composed of a lot of independent and competing small units that do not individually threaten the system and make it jump from one state to another. Randomness is distributed rather than concentrated.
Some people have fallen for the naive turkey-style belief that the world is getting safer and safer, and of course they naively attribute it to the holy “state” (though bottom-up Switzerland has about the lowest rate of violence of any place on the planet). It is exactly like saying that nuclear bombs are safer because they explode less often. The world is subjected to fewer and fewer acts of violence, while wars have the potential to be more criminal. We were very close to the mother of all catastrophes in the 1960s when the United States was about to pull the nuclear trigger on the Soviet Union. Very close. When we look at risks in Extremistan, we don’t look at evidence (evidence comes too late), we look at potential damage: never has the world been more prone to more damage; never.
6
It is hard to explain to naive data-driven people that risk is in the future, not in the past.
The messy multi-ethnic empire, the so-called Austro-Hungarian Empire, vanished after the great war, along with its Ottoman neighbor and rival (and, to a large extent, sibling—don’t tell them), to be replaced with crisp, clean nation-states. The Ottoman Empire with its messy nationalities—or, rather, what was left of it—became the state of Turkey, modeled after Switzerland, with nobody noticing the inconsistency. Vienna became trapped in Austria, with whom it shared very little outside the formal language. Imagine moving New York City to central Texas
and still calling it New York. Stefan Zweig, the Viennese Jewish novelist, then considered the most influential author in the world, expressed his pain in the poignant memoir
The World of Yesterday
. Vienna joined the league of multicultural cities such as Alexandria, Smyrna, Aleppo, Prague, Thessaloniki, Constantinople (now Istanbul), and Trieste, now squeezed into the Procrustean bed of the nation-state, with its citizens left in the grip of intergenerational nostalgia. Unable to handle the loss and integrate elsewhere, Zweig later committed suicide in Brazil. I first read his account as I was put in a similar situation of physical and cultural exile when my Levantine Christian world was shattered by the Lebanese war, and I wondered whether he might have stayed alive had he gone to New York instead.
1
I bypass here the economic argument as to whether autonomous city-states were invigorated with economic energy (as Henri Pirenne or Max Weber advocated, in a sort of romantic way); my (mathematical) point is that a collection of small units with semi-independent variations produces vastly different risk characteristics than a single large unit.
2
It is quite distressing to hear debates about political systems that make comparisons between countries when the size of the entities is not the same—say, comparing Singapore to Malaysia. The size of the unit may matter more than the system.
3
Thankfully, the European Union is legally protected from overcentralization thanks to the principle of subsidiarity: things should be handled by the smallest possible unit that can manage them with efficacy. The idea was inherited from the Catholic Church: philosophically, a unit doesn’t need to be very large (the state) nor very small (the individual), but somewhere in between. This is a powerful philosophical statement, particularly in light of both the transfers of fragility we saw in
Chapter 4
and the notion that size fragilizes, much on which later.
4
When randomness gets distributed across a large number of small units, along with small recurrent political disorder, we get the first type, the benign Mediocristan. When randomness concentrates, we get the second type, the sneaky Extremistan.
5
Note that people invoke an expression, “Balkanization,” about the mess created by fragmented states, as if fragmentation was a bad thing, and as if there was an alternative in the Balkans—but nobody uses “Helvetization” to describe its successes.
6
A more rigorous reading of the data—with appropriate adjustment for the unseen—shows that a war that would decimate the planet would be completely consistent with the statistics, and would not even be an “outlier.” As we will see, Ben Bernanke was similarly fooled with his
Great Moderation,
a turkey problem; one can be confused by the properties of any process with compressed volatility from the top. Some people, like Steven Pinker, misread the nature of the statistical process and hold such a thesis, similar to the “great moderation” in finance.


================================================================================
CHAPTER/SECTION 36 (Item 39)
================================================================================

CHAPTER 6
Tell Them I Love (Some) Randomness
Maxwell in Extremistan—Complicated mechanisms to feed a donkey—Virgil said to do it, and do it now
The point of the previous chapter was that the risk properties of the first brother (the fragile bank employee) are vastly different from those of the second one (the comparatively antifragile artisan taxi driver). Likewise, the risk characteristic of a centralized system is different from that of a messy municipally-led confederation. The second type is stable in the long run
because
of
some
dose of volatility.
A scientific argument showing how tight controls backfire and cause blowups was made by James Clerk Maxwell of electromagnetic theory fame. “Governors” are contraptions meant to control the speed of steam engines by compensating for abrupt variations. They aimed at stabilizing the engines, and they apparently did, but they paradoxically sometimes brought about capricious behavior and crashes. Light control works; close control leads to overreaction, sometimes causing the machinery to break into pieces. In a famous paper “On Governors,” published in 1867, Maxwell modeled the behavior and showed mathematically that tightly controlling the speed of engines leads to instability.
It is remarkable how Maxwell’s neat mathematical derivations and the dangers of tight control can be generalized across domains and help
debunk pseudo-stabilization and hidden long-term fragility.
1
In the markets, fixing prices, or, equivalently, eliminating speculators, the so-called “noise traders”—and the moderate volatility that they bring—provide an illusion of stability, with periods of calm punctuated with large jumps. Because players are unused to volatility, the slightest price variation will then be attributed to insider information, or to changes in the state of the system, and will cause panics. When a currency never varies, a slight, very slight move makes people believe that the world is ending. Injecting some confusion stabilizes the system.
Indeed, confusing people a little bit is beneficial—it is good for you and good for them. For an application of the point in daily life, imagine someone extremely punctual and predictable who comes home at exactly six o’clock every day for fifteen years. You can use his arrival to set your watch. The fellow will cause his family anxiety if he is barely a few minutes late. Someone with a slightly more volatile—hence unpredictable—schedule, with, say, a half-hour variation, won’t do so.
Variations also act as purges. Small forest fires periodically cleanse the system of the most flammable material, so this does not have the opportunity to accumulate. Systematically preventing forest fires from taking place “to be safe” makes the big one much worse. For similar reasons, stability is not good for the economy: firms become very weak during long periods of steady prosperity devoid of setbacks, and hidden vulnerabilities accumulate silently under the surface—so delaying crises is not a very good idea. Likewise, absence of fluctuations in the market causes hidden risks to accumulate with impunity. The longer one goes without a market trauma, the worse the damage when commotion occurs.
This adverse effect of stability is straightforward to model scientifically, but when I became a trader, I was told of a heuristic used by veterans, and only old seasoned veterans: when a market reaches a “new low,” that is, drops to a level not seen in a long time, there is “a lot of blood” to come, with people rushing to the exit. Some people unused to losing shekels will be experiencing a large loss and will incur distress. If such a low market level has not been seen in years, say two years, it will be called “a two-year low” and will cause more damage than a one-year
low. Tellingly, they call it a “cleanup,” getting the “weak hands” out of the way. A “weak hand” is clearly someone who is fragile but doesn’t know it and is lulled by a false sense of security. When many such weak hands rush to the door, they collectively cause crashes. A volatile market doesn’t let people go such a long time without a “cleanup” of risks, thereby preventing such market collapses.
Fluctuat nec mergitur
(fluctuates, or floats, but does not sink) goes the Latin saying.


================================================================================
CHAPTER/SECTION 37 (Item 40)
================================================================================

HUNGRY DONKEYS
So far we have argued that preventing randomness in an antifragile system is not always a good idea. Let us now look at the situation in which
adding
randomness has been a standard operating method, as the needed fuel for an antifragile system permanently hungry for it.
A donkey equally famished and thirsty caught at an equal distance between food and water would unavoidably die of hunger or thirst. But he can be saved thanks to a random nudge one way or the other. This metaphor is named Buridan’s Donkey, after the medieval philosopher Jean de Buridan, who—among other, very complicated things—introduced the thought experiment. When some systems are stuck in a dangerous impasse, randomness and only randomness can unlock them and set them free. You can see here that absence of randomness equals guaranteed death.
The idea of injecting random noise into a system to improve its functioning has been applied across fields. By a mechanism called
stochastic resonance,
adding random noise to the background makes you hear the sounds (say, music) with more accuracy. We saw earlier that the psychological effect of overcompensation helps us get signals in the midst of noise; here it is not psychological but a physical property of the system. Weak SOS signals, too weak to get picked up by remote receptors, can become audible in the presence of background noise and random interference. By adding to the signal, random hiss allows it to rise sufficiently above the threshold of detection to become audible—nothing in that situation does better than randomness, which comes for free.
Consider the method of annealing in metallurgy, a technique used to make metal stronger and more homogeneous. It involves the heating and controlled cooling of a material, to increase the size of the crystals and reduce their defects. Just as with Buridan’s donkey, the heat causes the
atoms to become unstuck from their initial positions and wander randomly through states of higher energy; the cooling gives them more chances of finding new, better configurations.
As a child I was exposed to a version of this annealing effect by watching my father, who was a man of habits, tap a wooden barometer every day upon coming home. He would gently strike the barometer, then get a reading for his homemade weather forecast. The stress on the barometer got the needle unstuck and allowed it to find its true equilibrium position. That’s a local brand of antifragility. Inspired by the metallurgical technique, mathematicians use a method of computer simulation called
simulated annealing
to bring more general optimal solutions to problems and situations, solutions that only randomness can deliver.
Randomness works well in search—sometimes better than humans. Nathan Myhrvold brought to my attention a controversial 1975 paper published in
Science
showing that random drilling was superior to whatever search method was being employed at the time.
And, ironically, the so-called chaotic systems, those experiencing a brand of variations called
chaos,
can be stabilized by adding randomness to them. I watched an eerie demonstration of the effects, presented by a doctoral student who first got balls to jump chaotically on a table in response to steady vibrations on the surface. These steady shocks made the balls jump in a jumbled and inelegant manner. Then, as by magic, he moved a switch and the jumps became orderly and smooth. The magic is that such change of regime, from chaos to order, did not take place by removing chaos, but by adding random, completely random but low-intensity shocks. I came out of the beautiful experiment with so much enthusiasm that I wanted to inform strangers on the street, “I love randomness!”
Political Annealing
It has been hard to explain to real people that stressors and uncertainty have their role in life—so you can imagine what it would be like to explain it to politicians. Yet this is where a certain dose of randomness is needed the most.
I was once shown the script of a film based on a parable of a city completely ruled by randomness—very Borgesian. At set intervals, the ruler randomly assigns to the denizens a new role in the city. Say the butcher would now become a baker, and the baker a prisoner, etc. At
the end, people end up rebelling against the ruler, asking for stability as their inalienable right.
I immediately thought that perhaps the opposite parable should be written: instead of having the rulers randomize the jobs of citizens, we should have citizens randomize the jobs of rulers, naming them by raffles and removing them at random as well. That is similar to simulated annealing—and it happens to be no less effective. It turned out that the ancients—again, those ancients!—were aware of it: the members of the Athenian assemblies were chosen by lot, a method meant to protect the system from degeneracy. Luckily, this effect has been investigated with modern political systems. In a computer simulation, Alessandro Pluchino and his colleagues showed how adding a certain number of randomly selected politicians to the process can improve the functioning of the parliamentary system.
Or sometimes the system benefits from a different type of stressor. For Voltaire, the best form of government was the one tempered with political assassination. Regicide is sort of the equivalent of tapping on the barometer to make it work better. That, too, creates some often-needed reshuffling, and one that would never have been done voluntarily. The void created at the top allows the annealing effect, causing the new leader to emerge. The secular drop in premature deaths in society has deprived us of a naturalistic managerial turnover. Murder is the standard procedure for succession in the mafia (the last publicized annealing was when John Gotti murdered his predecessor in front of a New York steakhouse to become the capo of the family). Outside the mafia, bosses and board members now stay longer, a fact that impedes many domains: CEOs, tenured academics, politicians, journalists—and we need to offset this condition with random lotteries.
Unfortunately, you cannot randomize a political party out of existence. What is plaguing us in the United States is not the two-party system, but being stuck with the
same
two parties. Parties don’t have organic built-in expiration dates.
Finally the ancients perfected the method of random draw in more or less difficult situations—and integrated it into divinations. These draws were really meant to pick a random exit without having to make a decision, so one would not have to live with the burden of the consequences later. You went with what the gods told you to do, so you would not have to second-guess yourself later. One of the methods, called
sortes
virgilianae
(fate as decided by the epic poet Virgil), involved opening Virgil’s
Aeneid
at random and interpreting the line that presented itself as direction for the course of action. You should use such method for every sticky business decision. I will repeat until I get hoarse: the ancients evolved hidden and sophisticated ways and tricks to exploit randomness. For instance, I actually practice such randomizing heuristic in restaurants. Given the lengthening and complication of menus, subjecting me to what psychologists call the
tyranny of choice,
with the stinging feeling after my decision that I should have ordered something else, I blindly and systematically duplicate the selection by the most overweight male at the table; and when no such person is present, I randomly pick from the menu without reading the name of the item, under the peace of mind that Baal made the choice for me.


================================================================================
CHAPTER/SECTION 38 (Item 41)
================================================================================

THAT TIME BOMB CALLED STABILITY
We saw that absence of fire lets highly flammable material accumulate. People are shocked and outraged when I tell them that absence of political instability, even war, lets explosive material and tendencies accumulate under the surface.
The Second Step: Do (Small) Wars Save Lives?
The anti-Enlightenment political philosopher Joseph de Maistre remarked that conflicts strengthen countries. This is highly debatable—war is not a good thing, and, as the victim of a brutal civil war, I can attest to its horrors. But what I find interesting—and elegant—in his reasoning is his pointing out the mistake of analyzing losses from a given event and ignoring the rest of the story. It is also interesting that people tend to grasp the opposite more easily, that is, spot the error of analyzing immediate gains without taking into account the long-term side effects. For we look at casualties as losses without taking into account the second step, what happens later—unlike gardeners, who understand rather well that pruning trees strengthens them.
Likewise peace—some kind of forced, constrained, non-natural peace—may be costly in lives: just consider the great complacency that led to the Great War after almost a century of relative peace in Europe, coupled with the rise of the heavily armed nation-state.
Again, we all love peace and we all love economic and emotional stability—but do not want to be suckers in the long term. We seek vaccination at every new school year (injecting ourselves with a bit of harm to build immunity) but fail to transfer the mechanism to political and economic domains.
What to Tell the Foreign Policy Makers
To summarize, the problem with artificially suppressed volatility is not just that the system tends to become extremely fragile; it is that, at the same time, it exhibits no
visible
risks. Also remember that volatility is information. In fact, these systems tend to be too calm and exhibit minimal variability as silent risks accumulate beneath the surface. Although the stated intention of political leaders and economic policy makers is to stabilize the system by inhibiting fluctuations, the result tends to be the opposite. These artificially constrained systems become prone to Black Swans. Such environments eventually experience massive blowups, of the type seen in
Figure 3
, catching everyone off guard and undoing years of stability or, in almost all cases, ending up far worse than they were in their initial volatile state. Indeed, the longer it takes for the blowup to occur, the worse the resulting harm to both economic and political systems.
Seeking stability by achieving stability (and forgetting the second step) has been a great sucker game for economic and foreign policies. The list is depressingly long. Take rotten governments like the one in Egypt before the riots of 2011, supported by the United States for four decades in order “to avoid chaos,” with the side effect of a coterie of privileged pillagers using superpowers as a backstop—identical to bankers using their “too big to fail” status to scam taxpayers and pay themselves high bonuses.
Saudi Arabia is the country that at present worries and offends me the most; it is a standard case of top-down stability enforced by a superpower at the expense of every single possible moral and ethical metric—and, of course, at the expense of stability itself.
So a place “allied” to the United States is a total monarchy, devoid of a constitution. But that is not what is morally shocking. A group of between seven and fifteen thousand members of the royal family runs the place, leading a lavish, hedonistic lifestyle in open contradiction with the
purist ideas that got them there. Look at the contradiction: the stern desert tribes whose legitimacy is derived from Amish-like austerity can, thanks to a superpower, turn to hedonistic uninhibited pleasure seeking—the king openly travels for pleasure with a retinue that fills four Jumbo jets. Quite a departure from his ancestors. The family members amassed a fortune now largely in Western safes. Without the United States, the country would have had its revolution, a regional breakup, some turmoil, then perhaps—by now—some stability. But preventing noise makes the problem worse in the long run.
Clearly the “alliance” between the Saudi royal family and the United States was meant to provide stability. What stability? How long can one confuse the system? Actually “how long” is irrelevant: this stability is similar to a loan one has to eventually pay back. And there are ethical issues I leave to
Chapter 24
, particularly casuistry, when someone finds a justification “for the sake of” to violate an otherwise inflexible moral rule.
2
Few people are aware of the fact that the bitterness of Iranians toward the United States comes from the fact that the United States—a democracy—installed a monarch, the repressive Shah of Iran, who pillaged the place but gave the United States the “stability” of access to the Persian Gulf. The theocratic regime in Iran today is largely the result of such repression. We need to learn to think in second steps, chains of consequences, and side effects.
More worrisome, U.S. policy toward the Middle East has historically, and especially since September 11, 2001, been unduly focused on the repression of any and all political fluctuations in the name of preventing “Islamic fundamentalism”—a trope that almost every regime has used. Aside from the fact that killing Islamists compounds their numbers, the West and its autocratic Arab allies have strengthened Islamic fundamentalists by forcing them underground.
Time for American policy makers to understand that the more they intervene in other countries for the sake of stability, the more they bring instability (except for emergency-room-style cases). Or perhaps time to reduce the role of policy makers in policy affairs.
One of life’s packages: no stability without volatility.


================================================================================
CHAPTER/SECTION 39 (Item 42)
================================================================================

WHAT DO WE CALL HERE MODERNITY?
My definition of modernity is humans’ large-scale domination of the environment, the systematic smoothing of the world’s jaggedness, and the stifling of volatility and stressors.
Modernity corresponds to the systematic extraction of humans from their randomness-laden ecology—physical and social, even epistemological. Modernity is not just the postmedieval, postagrarian, and postfeudal historical period as defined in sociology textbooks. It is rather the spirit of an age marked by rationalization (naive rationalism), the idea that society is understandable, hence must be designed, by humans. With it was born statistical theory, hence the beastly bell curve. So was linear science. So was the notion of “efficiency”—or optimization.
Modernity is a Procrustean bed, good or bad—a reduction of humans to what appears to be efficient and useful. Some aspects of it work: Procrustean beds are not all negative reductions. Some may be beneficial, though these are rare.
Consider the life of the lion in the comfort and predictability of the Bronx Zoo (with Sunday afternoon visitors flocking to look at him in a combination of curiosity, awe, and pity) compared to that of his cousins in freedom. We, at some point, had free-range humans and free-range children before the advent of the golden period of the soccer mom.
We are moving into a phase of modernity marked by the lobbyist, the very, very limited liability corporation, the MBA, sucker problems, secularization (or rather reinvention of new sacred values like flags to replace altars), the tax man, fear of the boss, spending the weekend in interesting places and the workweek in a putatively less interesting one, the separation of “work” and “leisure” (though the two would look identical to someone from a wiser era), the retirement plan, argumentative intellectuals who would disagree with this definition of modernity, literal thinking, inductive inference, philosophy of science, the invention of social science, smooth surfaces, and egocentric architects. Violence is transferred from individuals to states. So is financial indiscipline. At the center of all this is the denial of antifragility.
There is a dependence on narratives, an intellectualization of actions and ventures. Public enterprises and functionaries—even employees of large corporations—can only do things that seem to fit some narrative, unlike businesses that can just follow profits, with or without a good-sounding story. Remember that you need a name for the color
blue when you build a narrative, but not in action—the thinker lacking a word for “blue” is handicapped; not the doer. (I’ve had a hard time conveying to intellectuals the
intellectual
superiority of practice.)
Modernity widened the difference between the sensational and the relevant—in a natural environment the sensational is, well, sensational for a reason; today we depend on the press for such essentially human things as gossip and anecdotes and we care about the private lives of people in very remote places.
Indeed, in the past, when we were not fully aware of antifragility and self-organization and spontaneous healing, we managed to respect these properties by constructing beliefs that served the purpose of managing and surviving uncertainty. We imparted improvements to the agency of god(s). We may have denied that things can take care of themselves without some agency. But it was the gods that were the agents, not Harvard-educated captains of the ship.
So the emergence of the nation-state falls squarely into this pro-gression—the transfer of agency to mere humans. The story of the nation-state is that of the concentration and magnification of human errors. Modernity starts with the state monopoly on violence, and ends with the state’s monopoly on fiscal irresponsibility.
We will discuss next two central elements at the core of modernity. Primo, in
Chapter 7
, naive interventionism, with the costs associated with fixing things that one should leave alone. Secundo, in
Chapter 8
and as a transition to
Book III
, this idea of replacing God and the gods running future events with something even more religiously fundamentalist: the unconditional belief in the idea of scientific prediction regardless of the domain, the aim to squeeze the future into numerical reductions whether reliable or unreliable. For we have managed to transfer religious belief into gullibility for whatever can masquerade as science.
1
The financier George Cooper has revived the argument in
The Origin of Financial Crises—
the argument is so crisp that an old trader friend, Peter Nielsen, has distributed it to every person he knows.
2
Note these double standards on the part of Western governments. As a Christian, parts of Saudi Arabia are off-limits to me, as I would violate the purity of the place. But no public part of the United States or Western Europe is off-limits to Saudi citizens.


================================================================================
CHAPTER/SECTION 40 (Item 43)
================================================================================

CHAPTER 7
Naive Intervention
A tonsillectomy to kill time—Never do today what can be left to tomorrow—Let’s predict revolutions after they happen—Lessons in blackjack
Consider this need to “do something” through an illustrative example. In the 1930s, 389 children were presented to New York City doctors; 174 of them were recommended tonsillectomies. The remaining 215 children were again presented to doctors, and 99 were said to need the surgery. When the remaining 116 children were shown to yet a third set of doctors, 52 were recommended the surgery. Note that there is morbidity in 2 to 4 percent of the cases (today, not then, as the risks of surgery were very bad at the time) and that a death occurs in about every 15,000 such operations and you get an idea about the break-even point between medical gains and detriment.
This story allows us to witness probabilistic homicide at work. Every child who undergoes an unnecessary operation has a shortening of her life expectancy. This example not only gives us an idea of harm done by those who intervene, but, worse, it illustrates the lack of awareness of the need to look for a break-even point between benefits and harm.
Let us call this urge to help “naive interventionism.” Next we examine its costs.


================================================================================
CHAPTER/SECTION 41 (Item 44)
================================================================================

INTERVENTION AND IATROGENICS
In the case of tonsillectomies, the harm to the children undergoing unnecessary treatment is coupled with the trumpeted gain for
some
others. The name for such net loss, the (usually hidden or delayed) damage from treatment in excess of the benefits, is
iatrogenics,
literally, “caused by the healer,”
iatros
being a healer in Greek. We will posit in
Chapter 21
that every time you visit a doctor and get a treatment, you incur risks of such medical harm, which should be analyzed the way we analyze other trade-offs: probabilistic benefits minus probabilistic costs.
For a classic example of iatrogenics, consider the death of George Washington in December 1799: we have enough evidence that his doctors greatly helped, or at least hastened, his death, thanks to the then standard treatment that included bloodletting (between five and nine pounds of blood).
Now these risks of harm by the healer can be so overlooked that, depending on how you account for it, until penicillin, medicine had a largely negative balance sheet—going to the doctor increased your chance of death. But it is quite telling that medical iatrogenics seems to have increased over time, along with knowledge, to peak sometime late in the nineteenth century. Thank you, modernity: it was “scientific progress,” the birth of the clinic and its substitution for home remedies, that caused death rates to shoot up, mostly from what was then called “hospital fever”—Leibniz had called these hospitals
seminaria mortis,
seedbeds of death. The evidence of increase in death rates is about as strong as they come, since all the victims were now gathered in one place: people were dying in these institutions who would have survived outside them. The famously mistreated Austro-Hungarian doctor Ignaz Semmelweis had observed that more women died giving birth in hospitals than giving birth on the street. He called the establishment doctors a bunch of criminals—which they were: the doctors who kept killing patients could not accept his facts or act on them since he “had no theory” for his observations. Semmelweis entered a state of depression, helpless to stop what he saw as murders, disgusted at the attitude of the establishment. He ended up in an asylum, where he died, ironically, from the same hospital fever he had been warning against.
Semmelweis’s story is sad: a man who was punished, humiliated, and even killed for shouting the truth in order to save others. The worst punishment was his state of helplessness in the face of risks and unfairness.
But the story is also a happy one—the truth came out eventually, and his mission ended up paying off, with some delay. And the final lesson is that one should not expect laurels for bringing the truth.
Medicine is comparatively the good news, perhaps the only good news, in the field of iatrogenics. We see the problem there because things are starting to be brought under control today; it is now just what we call the cost of doing business, although medical error still currently kills between three times (as accepted by doctors) and ten times as many people as car accidents in the United States. It is generally accepted that harm from doctors—not including risks from hospital germs—accounts for more deaths than any single cancer. The methodology used by the medical establishment for decision making is still innocent of proper risk-management principles, but medicine is getting better. We have to worry about the incitation to overtreatment on the part of pharmaceutical companies, lobbies, and special interest groups and the production of harm that is not immediately salient and not accounted for as an “error.” Pharma plays the game of concealed and distributed iatrogenics, and it has been growing. It is easy to assess iatrogenics when the surgeon amputates the wrong leg or operates on the wrong kidney, or when the patient dies of a drug reaction. But when you medicate a child for an imagined or invented psychiatric disease, say, ADHD or depression, instead of letting him out of the cage, the long-term harm is largely unaccounted for. Iatrogenics is compounded by the “agency problem” or “principal-agent problem,” which emerges when one party (the agent) has personal interests that are divorced from those of the one using his services (the principal). An agency problem, for instance, is present with the stockbroker and medical doctor, whose ultimate interest is their own checking account, not your financial and medical health, respectively, and who give you advice that is geared to benefit themselves. Or with politicians working on their career.
First, Do No Harm
Medicine has known about iatrogenics since at least the fourth century before our era—
primum non nocere
(“first do no harm”) is a first principle attributed to Hippocrates and integrated in the so-called Hippocratic Oath taken by every medical doctor on his commencement day. It just took medicine about twenty-four centuries to properly execute the
brilliant idea. In spite of the recitations of
non nocere
through the ages, the term “iatrogenics” only appeared in frequent use very, very late, a few decades ago—after so much damage had been done. I for myself did not know the exact word until the writer Bryan Appleyard introduced me to it (I had used “harmful unintended side effects”). So let us leave medicine (to return to it in a dozen chapters or so), and apply this idea born in medicine to other domains of life. Since no intervention implies no iatrogenics, the source of harm lies in the denial of antifragility, and to the impression that we humans are so necessary to making things function.
Enforcing consciousness of generalized iatrogenics is a tall order. The very notion of iatrogenics is quite absent from the discourse outside medicine (which, to repeat, has been a rather slow learner). But just as with the color blue, having a word for something helps spread awareness of it. We will push the idea of iatrogenics into political science, economics, urban planning, education, and more domains. Not one of the consultants and academics in these fields with whom I tried discussing it knew what I was talking about—or thought that they could possibly be the source of any damage. In fact, when you approach the players with such skepticism, they tend to say that you are “against scientific progress.”
But the concept can be found in some religious texts. The Koran mentions “those who are wrongful while thinking of themselves that they are righteous.”
To sum up, anything in which there is naive interventionism, nay, even just intervention, will have iatrogenics.
The Opposite of Iatrogenics
While we now have a word for causing harm while trying to help, we don’t have a designation for the opposite situation, that of someone who ends up helping while trying to cause harm. Just remember that attacking the antifragile will backfire. For instance, hackers make systems stronger. Or as in the case of Ayn Rand, obsessive and intense critics help a book spread.
Incompetence is double-sided. In the Mel Brooks movie
The Producers,
two New York theater fellows get in trouble by finding success instead of the intended failure. They had sold the same shares to multiple
investors in a Broadway play, reasoning that should the play fail, they would keep the excess funds—their scheme would not be discovered if the investors got no return on their money. The problem was that they tried so hard to have a bad play—called
Springtime for Hitler
—and they were so bad at it that it turned out to be a huge hit. Uninhibited by their common prejudices, they managed to produce interesting work. I also saw similar irony in trading: a fellow was so upset with his year-end bonus that he started making huge bets with his employer’s portfolio—and ended up making them considerable sums of money, more than if he had tried to do so on purpose.
Perhaps the idea behind capitalism is an inverse-iatrogenic effect, the unintended-but-not-so-unintended consequences: the system facilitates the conversion of selfish aims (or, to be correct, not necessarily benevolent ones) at the individual level into beneficial results for the collective.
Iatrogenics in High Places
Two areas have been particularly infected with absence of awareness of iatrogenics: socioeconomic life and (as we just saw in the story of Semmelweis) the human body, matters in which we have historically combined a low degree of competence with a high rate of intervention and a disrespect for spontaneous operation and healing—let alone growth and improvement.
As we saw in
Chapter 3
, there is a distinction between organisms (biological or nonbiological) and machines. People with an engineering-oriented mind will tend to look at everything around as an engineering problem. This is a very good thing in engineering, but when dealing with cats, it is a much better idea to hire veterinarians than circuits engineers—or even better, let your animal heal by itself.
Table 3
provides a glimpse of these attempts to “improve matters” across domains and their effects. Note the obvious: in all cases they correspond to the denial of antifragility.
Click
here
for a larger image of this table.
Can a Whale Fly Like an Eagle?
Social scientists and economists have no built-in consciousness of iatrogenics, and of course no name for it—when I decided to teach a class on model error in economics and finance, nobody took me or the idea seriously, and the few who did tried to block me, asking for “a theory” (as in Semmelweis’s story) and not realizing that it was precisely the errors of theory that I was addressing and cataloguing, as well as the very idea of using a theory without considering the impact of the possible errors from theory.
For a theory is a very dangerous thing to have.
And of course one can rigorously do science without it. What scientists call phenomenology is the observation of an empirical regularity without a visible theory for it. In the Triad, I put theories in the fragile category, phenomenology in the robust one. Theories are superfragile; they come and go, then come and go, then come and go again; phenomenologies stay, and I can’t believe people don’t realize that phenomenology is “robust” and usable, and theories, while overhyped, are unreliable for decision making—outside physics.
Physics is privileged; it is the exception, which makes its imitation by other disciplines similar to attempts to make a whale fly like an eagle. Errors in physics get smaller from theory to theory—so saying “Newton was wrong” is attention grabbing, good for lurid science journalism, but ultimately mendacious; it would be far more honest to say “Newton’s
theory is imprecise in some specific cases.” Predictions made by Newtonian mechanics are of astonishing precision except for items traveling close to the speed of light, something you don’t expect to do on your next vacation. We also read nonsense-with-headlines to the effect that Einstein was “wrong” about that speed of light—and the tools used to prove him wrong are of such complication and such precision that they’ve demonstrated how inconsequential such a point will be for you and me in the near and far future.
On the other hand, social science seems to diverge from theory to theory. During the cold war, the University of Chicago was promoting laissez-faire theories, while the University of Moscow taught the exact opposite—but their respective physics departments were in convergence, if not total agreement. This is the reason I put social science theories in the left column of the Triad, as something superfragile for real-world decisions and unusable for risk analyses. The very designation “theory” is even upsetting. In social science we should call these constructs “chimeras” rather than theories.
We will have to construct a methodology to deal with these defects. We cannot afford to wait an additional twenty-four centuries. Unlike with medicine, where iatrogenics is distributed across the population (hence with Mediocristan effects), because of concentration of power, social science and policy iatrogenics can blow us up (hence, Extremistan).
Not Doing Nothing
A main source of the economic crisis that started in 2007 lies in the iatrogenics of the attempt by Überfragilista Alan Greenspan—certainly the top economic iatrogenist of all time—to iron out the “boom-bust cycle” which caused risks to go hide under the carpet and accumulate there until they blew up the economy. The most depressing part of the Greenspan story is that the fellow was a libertarian and seemingly convinced of the idea of leaving systems to their own devices; people can fool themselves endlessly. The same naive interventionism was also applied by the U.K. government of Fragilista Gordon Brown, a student of the Enlightenment whose overt grand mission was to “eliminate” the business cycle. Fragilista Prime Minister Brown, a master iatrogenist though not nearly in the same league as Greenspan, is now trying to lecture the world on “ethics” and “sustainable” finance—but his policy of centralizing information technology (leading to massive cost overruns and delays
in implementation) instead of having decentralized small units has proven difficult to reverse. Indeed, the U.K. health service was operating under the principle that a pin falling somewhere in some remote hospital should be heard in Whitehall (the street in London where the government buildings are centralized). The technical argument about the dangers of concentration is provided in
Chapter 18
.
These attempts to eliminate the business cycle lead to the mother of all fragilities. Just as a little bit of fire here and there gets rid of the flammable material in a forest, a little bit of harm here and there in an economy weeds out the vulnerable firms early enough to allow them to “fail early” (so they can start again) and minimize the long-term damage to the system.
An ethical problem arises when someone is put in charge. Greenspan’s actions were harmful, but even if he knew that, it would have taken a bit of heroic courage to justify inaction in a democracy where the incentive is to always promise a better outcome than the other guy, regardless of the actual, delayed cost.
Ingenuous interventionism is very pervasive across professions. Just as with the tonsillectomy, if you supply a typical copy editor with a text, he will propose a certain number of edits, say about five changes per page. Now accept his “corrections” and give this text to another copy editor who tends to have the same average rate of intervention (editors vary in interventionism), and you will see that he will suggest an equivalent number of edits, sometimes reversing changes made by the previous editor. Find a third editor, same.
Incidentally, those who do too much somewhere do too little elsewhere—and editing provides a quite fitting example. Over my writing career I’ve noticed that those who overedit tend to miss the real typos (and vice versa). I once pulled an op-ed from
The Washington Post
owing to the abundance of completely unnecessary edits, as if every word had been replaced by a synonym from the thesaurus. I gave the article to the
Financial Times
instead. The editor there made one single correction: 1989 became 1990.
The Washington Post
had tried so hard that they missed the only relevant mistake. As we will see, interventionism depletes mental and economic resources; it is rarely available when it is needed the most. (Beware what you wish for: small government might in the end be more effective at whatever it needs to do. Reduction in size and scope may make it even more intrusive than large government.)
Non-Naive Interventionism
Let me warn against misinterpreting the message here. The argument is not against the notion of intervention; in fact I showed above that I am equally worried about underintervention when it is truly necessary. I am just warning against
naive
intervention and lack of awareness and acceptance of harm done by it.
It is certain that the message will be misinterpreted, for a while. When I wrote
Fooled by Randomness,
which argues—a relative of this message—that we have a tendency to underestimate the role of randomness in human affairs, summarized as “it is more random than you think,” the message in the media became “it’s all random” or “it’s all dumb luck,” an illustration of the Procrustean bed that changes by reducing. During a radio interview, when I tried explaining to the journalist the nuance and the difference between the two statements I was told that I was “too complicated”; so I simply walked out of the studio, leaving them in the lurch. The depressing part is that those people who were committing such mistakes were educated journalists entrusted to represent the world to us lay persons. Here, all I am saying is that we need to avoid being blind to the natural antifragility of systems, their ability to take care of themselves, and fight our tendency to harm and fragilize them by not giving them a chance to do so.
As we saw with the overzealous editor, over-intervention comes with under-intervention. Indeed, as in medicine, we tend to over-intervene in areas with minimal benefits (and large risks) while under-intervening in areas in which intervention is necessary, like emergencies. So the message here is in favor of staunch intervention in some areas, such as ecology or to limit the economic distortions and moral hazard caused by large corporations.
What should we control?
As a rule, intervening to limit size (of companies, airports, or sources of pollution), concentration, and speed are beneficial in reducing Black Swan risks. These actions may be devoid of iatrogenics—but it is hard to get governments to limit the size of government. For instance, it has been argued since the 1970s that limiting speed on the highway (and enforcing it) leads to an extremely effective increase in safety. This can be plausible because risks of accidents increase disproportionally (that is,
nonlinearly
) with speed, and humans are not ancestrally equipped with such intuition. Someone recklessly driving a huge vehicle on the highway is endangering your safety and needs to be
stopped before he hits your convertible Mini—or put in a situation in which he is the one exiting the gene pool, not you. Speed is from modernity, and I am always suspicious of hidden fragilities coming from the post-natural—we will further show a technical proof in
Chapters 18
and
19
.
But I also buy the opposite argument that regulating street signs does not seem to reduce risks; drivers become more placid. Experiments show that alertness is weakened when one relinquishes control to the system (again, lack of overcompensation). Motorists need the stressors and tension coming from the feeling of danger to feed their attention and risk controls, rather than some external regulator—fewer pedestrians die jaywalking than using regulated crossings. Some libertarians use the example of Drachten, a town in the Netherlands, in which a dream experiment was conducted. All street signs were removed. The deregulation led to an increase in safety, confirming the antifragility of attention at work, how it is whetted by a sense of danger and responsibility. As a result, many German and Dutch towns have reduced the number of street signs. We saw a version of the Drachten effect in
Chapter 2
in the discussion of the automation of planes, which produces the exact opposite effect than what is intended by making pilots lose alertness. But one needs to be careful not to overgeneralize the Drachten effect, as it does not imply the effectiveness of removing all rules from society. As I said earlier, speed on the highway responds to a different dynamic and its risks are different.
Alas, it has been hard for me to fit these ideas about fragility and antifragility within the current U.S. political discourse—that beastly two-fossil system. Most of the time, the Democratic side of the U.S. spectrum favors hyper-intervention, unconditional regulation, and large government, while the Republican side loves large corporations, unconditional deregulation, and militarism—both are the same to me here. They are even more the same when it comes to debt, as both sides have tended to encourage indebtedness on the part of citizens, corporations, and government (which brings fragility and kills antifragility). I believe that both markets and governments are unintelligent when it comes to Black Swan events—though, again, not Mother Nature, thanks to her construction, or more ancient types of markets (like the souks), unlike the ones we have now.
Let me simplify my take on intervention. To me it is mostly about
having a systematic protocol to determine when to intervene and when to leave systems alone. And we may need to intervene to control the iatrogenics of modernity—particularly the large-scale harm to the environment and the concentration of potential (though not yet manifested) damage, the kind of thing we only notice when it is too late. The ideas advanced here are not political, but risk-management based. I do not have a political affiliation or allegiance to a specific party; rather, I am introducing the idea of harm and fragility into the vocabulary so we can formulate appropriate policies to ensure we don’t end up blowing up the planet and ourselves.


================================================================================
CHAPTER/SECTION 42 (Item 45)
================================================================================

IN PRAISE OF PROCRASTINATION—THE FABIAN KIND
There is an element of deceit associated with interventionism, accelerating in a professionalized society. It’s much easier to sell “Look what I did for you” than “Look what I avoided for you.” Of course a bonus system based on “performance” exacerbates the problem. I’ve looked in history for heroes who became heroes for what they did
not
do, but it is hard to observe
nonaction;
I could not easily find any. The doctor who refrains from operating on a back (a very expensive surgery), instead giving it a chance to heal itself, will not be rewarded and judged as favorably as the doctor who makes the surgery look indispensable, then brings relief to the patient while exposing him to operating risks, while accruing great financial rewards to himself. The latter will be driving the pink Rolls-Royce. The corporate manager who avoids a loss will not often be rewarded. The true hero in the Black Swan world is someone who prevents a calamity and, naturally, because the calamity did not take place, does not get recognition—or a bonus—for it. I will be taking the concept deeper in
Book VII
, on ethics, about the unfairness of a bonus system and how such unfairness is magnified by complexity.
However, as always, the elders seem to have far more wisdom than we moderns—and much, much simpler wisdom; the Romans revered someone who, at the least, resisted and delayed intervention. One general, Fabius Maximus was nicknamed Cunctator, “the Procrastinator.” He drove Hannibal, who had an obvious military superiority, crazy by avoiding and delaying engagement. And it is quite fitting to consider Hannibal’s militarism as a form of interventionism (à la George W. Bush,
except that Hannibal was actually in battle himself, not in the comfort of an office) and compare it to the Cunctator’s wisdom.
A very intelligent group of revolutionary fellows in the United Kingdom created a political movement called the Fabian Society, named after the Cunctator, based on opportunistically delaying the revolution. The society included George Bernard Shaw, H. G. Wells, Leonard and Virginia Woolf, Ramsay MacDonald, and even Bertrand Russell for a moment. In retrospect, it turned out to be a very effective strategy, not so much as a way to achieve their objectives, but rather to accommodate the fact that these objectives are moving targets. Procrastination turned out to be a way to let events take their course and give the activists the chance to change their minds before committing to irreversible policies. And of course members
did
change their minds after seeing the failures and horrors of Stalinism and similar regimes.
There is a Latin expression
festina lente,
“make haste slowly.” The Romans were not the only ancients to respect the act of voluntary omission. The Chinese thinker Lao Tzu coined the doctrine of
wu-wei,
“passive achievement.”
Few understand that procrastination is our natural defense, letting things take care of themselves and exercise their antifragility; it results from some ecological or naturalistic wisdom, and is not always bad—at an existential level, it is my body rebelling against its entrapment. It is my soul fighting the Procrustean bed of modernity. Granted, in the modern world, my tax return is not going to take care of itself—but by delaying a non-vital visit to a doctor, or deferring the writing of a passage until my body tells me that I am ready for it, I may be using a very potent naturalistic filter. I write only if I feel like it and only on a subject I feel like writing about—and the reader is no fool. So I use procrastination as a message from my inner self and my deep evolutionary past to resist interventionism in my writing. Yet some psychologists and behavioral economists seem to think that procrastination is a
disease
to be remedied and cured.
1
Given that procrastination has not been sufficiently pathologized yet, some associate it with the condition of
akrasia
discussed in Plato, a form of lack of self-control or weakness of will; others with
aboulia,
lack of will. And pharmaceutical companies might one day come up with a pill for it.
The benefits of procrastination apply similarly to medical procedures: we saw that procrastination protects you from error as it gives nature a chance to do its job, given the inconvenient fact that nature is less error-prone than scientists. Psychologists and economists who study “irrationality” do not realize that humans may have an instinct to procrastinate only when no life is in danger. I do not procrastinate when I see a lion entering my bedroom or fire in my neighbor’s library. I do not procrastinate after a severe injury. I do so with unnatural duties and procedures. I once procrastinated and kept delaying a spinal cord operation as a response to a back injury—and was completely cured of the back problem after a hiking vacation in the Alps, followed by weight-lifting sessions. These psychologists and economists want me to kill my naturalistic instinct (the inner b****t detector) that allowed me to delay the elective operation and minimize the risks—an insult to the antifragility of our bodies. Since procrastination is a message from our natural willpower via low motivation, the cure is changing the environment, or one’s profession, by selecting one in which one does not have to fight one’s impulses. Few can grasp the logical consequence that, instead, one should lead a life in which procrastination is good, as a naturalistic-risk-based form of decision making.
Actually I select the writing of the passages of this book by means of procrastination. If I defer writing a section, it must be eliminated. This is simple ethics: Why should I try to fool people by writing about a subject for which I feel no natural drive?
2
Using my ecological reasoning, someone who procrastinates is not irrational; it is his environment that is irrational. And the psychologist or economist calling him irrational is the one who is beyond irrational.
In fact we humans are very bad at filtering information, particularly short-term information, and procrastination can be a way for us to filter
better, to resist the consequences of jumping on information, as we discuss next.
This idea of “naturalistic” has led to confusion. Philosophers refer to an error called the
naturalistic fallacy,
implying that what is natural is not necessarily morally right—something I subscribe to, as we saw in
Chapter 4
in the discussion of the problem of applying Darwinian selection to modern society and the need to protect those who fail, something counter to nature. (The problem is that some people misuse the naturalistic fallacy outside the moral domain and misapply it to this idea of reliance on naturalistic instinct when one is in doubt.) However one slices it, it is not a fallacy when it comes to risk considerations. Time is the best test of fragility—it encompasses high doses of disorder—and nature is the only system that has been stamped “robust” by time. But some philosophasters fail to understand the primacy of risk and survival over philosophizing, and those should eventually exit the gene pool—true philosophers would agree with my statement. There is a worse fallacy: people making the opposite mistake and considering that
what is naturalistic is a fallacy
.


================================================================================
CHAPTER/SECTION 43 (Item 46)
================================================================================

NEUROTICISM IN INDUSTRIAL PROPORTIONS
Imagine someone of the type we call neurotic in common parlance. He is wiry, looks contorted, and speaks with an uneven voice. His neck moves around when he tries to express himself. When he has a small pimple, his first reaction is to assume that it is cancerous, that the cancer is of the lethal type, and that it has already spread to his lymph nodes. His hypochondria is not limited to the medical department: he incurs a small setback in business and reacts as if bankruptcy were both near and certain. In the office, he is tuned to every single possible detail, systematically transforming every molehill into a mountain. The last thing you want in life is to be stuck in traffic with him on your way to an important appointment. The verb “overreact” was designed with him in mind: he does not have reactions, just overreactions.
Compare him to someone imperturbable, with the ability to be calm under fire that is considered necessary to become a leader, military commander, or mafia godfather. Usually unruffled and immune to small information, he can impress you with his self-control in difficult circumstances. For a sample of a composed, calm, and pondered voice, listen to
interviews with “Sammy the Bull,” Salvatore Gravano, who was involved in the murder of nineteen people (all competing mobsters). He speaks with minimal effort, as if what he is discussing is “not a big deal.” This second type sometimes reacts when necessary; in the rare situations when he is angry, unlike with the neurotic fellow, everyone knows it and takes it seriously.
The supply of information to which we are exposed thanks to modernity is transforming humans from the equable second fellow into the neurotic first one. For the purpose of our discussion, the second fellow only reacts to real information, the first largely to noise. The difference between the two fellows will show us the difference between
noise
and
signal.
Noise is what you are supposed to ignore, signal what you need to heed.
Indeed, we have loosely mentioned “noise” earlier in the book; time to be precise about it. In science, noise is a generalization beyond the actual sound to describe random information that is totally useless for any purpose, and that you need to clean up to make sense of what you are listening to. Consider, for example, elements in an encrypted message that have absolutely no meaning, just randomized letters to confuse the spies, or the hiss you hear on a telephone line that you try to ignore in order to focus on the voice of your interlocutor.
And this personal or intellectual inability to distinguish noise from signal is behind overintervention.
A Legal Way to Kill People
If you want to accelerate someone’s death, give him a personal doctor. I don’t mean provide him with a bad doctor: just pay for him to choose his own. Any doctor will do.
This may be the only possible way to murder someone while staying squarely within the law. We can see from the tonsillectomy story that access to data increases intervention, causing us to behave like the neurotic fellow. Rory Sutherland signaled to me that someone with a personal doctor on staff should be particularly vulnerable to naive interventionism, hence iatrogenics; doctors need to justify their salaries and prove to themselves that they have a modicum of work ethic, something that “doing nothing” doesn’t satisfy. Indeed, Michael Jackson’s personal doctor has been sued for something equivalent to overintervention-to-stifle-antifragility (but it will take the law courts a
while to become directly familiar with the concept). Did you ever wonder why heads of state and very rich people with access to all this medical care die just as easily as regular persons? Well, it looks like this is
because
of overmedication and excessive medical care.
Likewise, those in corporations or in policy making (like Fragilista Greenspan) who are endowed with a sophisticated data-gathering department and are therefore getting a lot of “timely” statistics are capable of overreacting and mistaking noise for information—Greenspan kept an eye on such fluctuations as the sales of vacuum cleaners in Cleveland to, as they say, “get a precise idea about where the economy is going,” and of course he micromanaged us into chaos.
In business and economic decision making, reliance on data causes severe side effects—data is now plentiful thanks to connectivity, and the proportion of spuriousness in the data increases as one gets more immersed in it. A very rarely discussed property of data: it is toxic in large quantities—even in moderate quantities.
The previous two chapters showed how you can use and take advantage of noise and randomness; but noise and randomness can also use and take advantage of you, particularly when totally unnatural, as with the data you get on the Web or through the media.
The more frequently you look at data, the more noise you are disproportionally likely to get (rather than the valuable part, called the signal); hence the higher the noise-to-signal ratio. And there is a confusion which is not psychological at all, but inherent in the data itself. Say you look at information on a yearly basis, for stock prices, or the fertilizer sales of your father-in-law’s factory, or inflation numbers in Vladivostok. Assume further that for what you are observing, at a yearly frequency, the ratio of signal to noise is about one to one (half noise, half signal)—this means that about half the changes are real improvements or degradations, the other half come from randomness. This ratio is what you get from yearly observations. But if you look at the very same data on a daily basis, the composition would change to 95 percent noise, 5 percent signal. And if you observe data on an hourly basis, as people immersed in the news and market price variations do, the split becomes 99.5 percent noise to 0.5 percent signal. That is two hundred times more noise than signal—which is why anyone who listens to news (except when very, very significant events take place) is one step below sucker.
Consider the iatrogenics of newspapers. They need to fill their pages every day with a set of news items—particularly those news items also
dealt with by other newspapers. But to do things right, they ought to learn to keep silent in the absence of news of significance. Newspapers should be of two-line length on some days, two hundred pages on others—in proportion with the intensity of the signal. But of course they want to make money and need to sell us junk food. And junk food is iatrogenic.
There is a biological dimension to this story. I have been repeating that in a natural environment, a stressor is information. Too much information would thus be too much stress, exceeding the threshold of antifragility. In medicine, we are discovering the healing powers of fasting, as the avoidance of the hormonal rushes that come with the ingestion of food. Hormones convey information to the different parts of our system, and too much of them confuses our biology. Here again, as with news received at too high a frequency, too much information becomes harmful—daily news and sugar confuse our system in the same manner. And in
Chapter 24
(on ethics) I will show how too much data (particularly when it is sterile) causes statistics to be completely meaningless.
Now let’s add the psychological to this: we are not made to understand the point, so we overreact emotionally to noise. The best solution is to
only
look at very large changes in data or conditions, never at small ones.
Just as we are not likely to mistake a bear for a stone (but likely to mistake a stone for a bear), it is almost impossible for someone rational, with a clear, uninfected mind, someone who is not drowning in data, to mistake a vital signal, one that matters for his survival, for noise—unless he is overanxious, oversensitive, and neurotic, hence distracted and confused by other messages. Significant signals have a way to reach you. In the tonsillectomies story, the best filter would have been to only consider the children who were very ill, those with periodically recurring throat inflammation.
Media-Driven Neuroticism
There is so much noise coming from the media’s glorification of the anecdote. Thanks to this, we are living more and more in virtual reality, separated from the real world, a little bit more every day while realizing it less and less. Consider that every day, 6,200 persons die in the United States, many of preventable causes. But the media only report the most anecdotal and sensational cases (hurricanes, freak accidents, small plane
crashes), giving us a more and more distorted map of real risks. In an ancestral environment, the anecdote, the “interesting,” is information; today, no longer. Likewise, by presenting us with explanations and theories, the media induce an illusion of understanding the world.
And the understanding of events (and risks) on the part of members of the press is so retrospective that they would put the security checks after the plane ride, or what the ancients call
post bellum auxilium,
sending troops after the battle. Owing to domain dependence, we forget the need to check our map of the world against reality. So we are living in a more and more fragile world, while thinking it is more and more understandable.
To conclude, the best way to mitigate interventionism is to ration the supply of information, as naturalistically as possible. This is hard to accept in the age of the Internet. It has been very hard for me to explain that the more data you get, the less you know what’s going on, and the more iatrogenics you will cause. People are still under the illusion that “science” means more data.


================================================================================
CHAPTER/SECTION 44 (Item 47)
================================================================================

THE STATE CAN HELP—WHEN INCOMPETENT
The famine in China that killed 30 million people between 1959 and 1961 can enlighten us about the effect of the state “trying hard.” Xin Meng, Nancy Qian, and Pierre Yared examined its variations
between
areas, looking into how the famine was distributed. They discovered that famine was more severe in areas with higher food production in the period before the famine began, meaning that it was government policy of food distribution that was behind much of the problem, owing to the inflexibility in the procurement system. And indeed, a larger than expected share of famine over the past century has occured in economies with central planning.
But often it is the state’s incompetence that can help save us from the grip of statism and modernity—inverse iatrogenics. The insightful author Dmitri Orlov showed how calamities were avoided after the breakdown of the Soviet state because food production was inefficient and full of unintentional redundancies, which ended up working in favor of stability. Stalin played with agriculture, causing his share of famine. But he and his successors never managed to get agriculture to become “efficient,” that is, centralized and optimized as it is today in America, so every town had the staples growing around it. This was costlier, as they
did not get the benefits of specialization, but this local lack of specialization allowed people to have access to all varieties of food in spite of the severe breakdown of the institutions. In the United States, we burn twelve calories in transportation for every calorie of nutrition; in Soviet Russia, it was one to one. One can imagine what could happen to the United States (or Europe) in the event of food disruptions. Further, because of the inefficiency of housing in the Soviet state, people had been living in close quarters for three generations, and had tight bonds that ensured—as in the Lebanese war—that they stayed close to each other and lent to each other. People had real links, unlike in social networks, and fed their hungry friends, expecting that some friend (most likely another one) would help them should they get in dire circumstances.
And the top-down state is not necessarily the one that has the reputation of being so.
France Is Messier than You Think
Next we will debunk the narrative that France works well because it is a Cartesian rationalizing-rationalist top-down state. As with the Russians, the French were lucky that it was for a long time a failed aim.
I spent the past two decades wondering why France, as a country managed in a top-down manner by an oversized state, could fare so well in so many fields. It is the country of Jean-Baptiste Colbert, after all, the grand dreamer of a state that infiltrates everything. Indeed the current culture is ultra-interventionist, sort of “if it ain’t broke, fix it.” For things work—somewhat—in France, often better than elsewhere; so can France be used as evidence that central bureaucracies that repress municipal mess are favorable for growth, happiness, good science and literature, excellent weather, diversified flora with Mediterranean varieties, tall mountains, excellent transportation, attractive women, and good cuisine? Until I discovered, reading Graham Robb’s
The Discovery of France,
a major fact that led me to see the place with completely new eyes and search the literature for a revision of the story of the country.
The story was actually staring us in the face: the nation-state in France was largely nominal, in spite of attempts by Louis XIV, Napoleon, and the national education program of Jules Ferry to own the place. France in 1863 did not speak French (only one in five persons could), but rather a variety of languages and dialects (a surprising fact: the Nobel Prize in Literature in 1904 went to the Frenchman Frédéric
Mistral, who wrote in Provençal, a language of southern France no longer spoken). The lack of linguistic integration—like the variety in cheese (of which there are about four hundred different types)—expresses the difficulties in centralizing the country. There was nothing ethnic or linguistic to bind the place—it was just the property of a king and a weak aristocracy. Roads were horrible and most of the country was inaccessible to travelers. Tax collection was a dangerous profession, requiring tenacity and sagacity. Indeed, the country was progressively “discovered” by Paris, in many cases after its colonies in North Africa and elsewhere. In a thick and captivating book,
La rebellion française,
the historian Jean Nicolas shows how the culture of rioting was extremely sophisticated—historically, it counts as the true French national sport.
Paris itself was barely controlled by France—no more than the Rio slums called
favelas
are currently ruled by the Brazilian central state. Louis XIV, the Sun King, had moved the government to Versailles to escape the Parisian crowd. Paris only became controllable after Haussmann in the 1860s removed the tenements and narrow streets to make large avenues that allowed for police to control the crowds. Effectively France was still Paris and “the desert,” as Paris didn’t care much about the rest of France. The country was only centralized after long programs and “Five Year Plans” of roads, rail systems, public schools, and the spread of television—a Napoleonic dream of integration that, begun by De Gaulle after the war, was only completed during the reign of Valéry Giscard d’Estaing in the late 1970s, at which point the decentralization started taking place.
3
France might have benefited from its two decades or so under a large centralized state—but the argument could equally be that it benefited from the happy condition that the large state spurred growth and did not overstay its welcome.
Sweden and the Large State
Aside from France, I was baffled by the puzzle of Sweden and other Nordic states, which are often offered as paragons of the large state “that works”—the government represents a large portion of the total economy. How could we have the happiest nation in the world, Denmark (assuming “happiness” is both measurable and desirable), and a monstrously large state? Is it that these countries are all smaller than the New York metropolitan area? Until my coauthor, the political scientist Mark Blyth, showed me that there, too, was a false narrative: it was almost the same story as in Switzerland (but with a worse climate and no good ski resorts). The state exists as a tax collector, but the money is spent in the communes themselves, directed by the communes—for, say, skills training locally determined as deemed necessary by the community themselves, to respond to private demand for workers. The economic elites have more freedom than in most other democracies—this is far from the statism one can assume from the outside. And, most of all, these nations are the size of city-states.
Further, illustrating a case of gaining from disorder, Sweden and other Nordic countries experienced a severe recession at the end of the cold war, around 1990, to which they responded admirably with a policy of fiscal toughness, thus effectively shielding them from the severe financial crisis that took place about two decades later.


================================================================================
CHAPTER/SECTION 45 (Item 48)
================================================================================

CATALYST-AS-CAUSE CONFUSION
When constrained systems, those hungry for natural disorder, collapse, as they are eventually bound to, since they are fragile, failure is never seen as the result of fragility. Rather, such failure is interpreted as the product of poor forecasting. As with a crumbling sand pile, it would be unintelligent to attribute the collapse of a fragile bridge to the last truck that crossed it, and even more foolish to try to predict in advance which truck might bring it down. Yet it is done all too often.
In 2011, U.S. president Barack Obama blamed an intelligence failure for the government’s not foreseeing the revolution in Egypt that took place that spring (just as former U.S. president Jimmy Carter blamed an intelligence failure for his administration’s not foreseeing the 1979 Islamic Revolution in Iran), missing the point that it is the suppressed risk in the statistical “tails” that matters—not the failure to see the last grain
of sand. One analogy to economics: after the inception of the financial crisis in 2007–2008, many people thought that predicting the subprime meltdown (which seemed in their mind to have triggered it) would have helped. It would not have, for Baal’s sake, since it was a symptom of the crisis, not its underlying cause. Likewise, Obama’s blaming “bad intelligence” for his administration’s failure to predict the uprising that took place in Egypt is symptomatic of both the misunderstanding of complex systems and the bad policies involved. And superpowers are plain turkeys in that story.
Obama’s mistake illustrates the illusion of local causal chains—that is, confusing catalysts for causes and assuming that one can know which catalyst will produce which effect. The final episode of the upheaval in Egypt was unpredictable for all observers, especially those involved. As such, blaming the CIA or some other intelligence agency is as injudicious as funding it to forecast such events. Governments are wasting billions of dollars on attempting to predict events that are produced by interdependent systems and are therefore not statistically understandable at the individual level.
Most explanations that are offered for episodes of turmoil follow the catalysts-as-causes confusion. Take the “Arab Spring” of 2011. The riots in Tunisia and Egypt were initially attributed to rising commodity prices, not to stifling and unpopular dictatorships. But Bahrain and Libya were wealthy countries that could afford to import grain and other commodities. Further, we had had considerably higher commodity prices a few years earlier without any uprising at all. Again, the focus is wrong even if the logic is comforting. It is the system and its fragility, not events, that must be studied—what physicists call “percolation theory,” in which the properties of the randomness of the terrain are studied, rather than those of a single element of the terrain.
As Mark Abdollahian of Sentia Group, one of the contractors who sell predictive analytics to the U.S. government (those that failed to warn), noted regarding Egypt, policy makers should “think of this like Las Vegas. In blackjack, if you can do four percent better than the average, you’re making real money.” But the analogy is spurious—pretty much everything I stand against. There is no “four percent better” on Egypt. This was not just money wasted but the construction of a false confidence based on an erroneous focus. It is telling that the intelligence analysts made the same mistake as the risk-management systems that
failed to predict the economic crisis—and offered the exact same excuses when they failed. Political and economic “tail events” are unpredictable, and their probabilities are not scientifically measurable. No matter how many dollars are spent on research, predicting revolutions is not the same as counting cards; humans will never be able to turn politics and economics into the tractable randomness of blackjack.
1
Psychologists document the opposite of interventionism, calling it the
status quo bias
. But it seems that the two can coexist, interventionism and procrastination, in one’s profession (where one is supposed to do something) and in one’s personal life (the opposite). It depends on the domain. So it is a sociological and economic problem, one linked to norms and incentives (though doctors in the tonsillectomy study did not have direct incentives), rather than a mental property.
2
A friend who writes books remarked that painters like painting but authors like “having written.” I suggested he stop writing, for his sake and the sake of his readers.
3
Another discovery—the control of that most organic, most disorderly of things, language. France, through the institution of the French academy, has an official stamp on what can and cannot be considered proper French and written by a pupil in a document or in a letter to the local mayor complaining about the noisy garbage pickup schedules. The result is obvious: a convoluted, difficult, and narrow formal vocabulary compared to English—but an expanded spoken French misdefined as “slang” that is just as rich as English. There are even writers like Céline or Dard who write in parallel literary vocabulary mixed with exquisitely precise and rich slang, a unique brand of colloquial-literary style.


================================================================================
CHAPTER/SECTION 46 (Item 49)
================================================================================

CHAPTER 8
Prediction as a Child of Modernity
Never shout in French—Ms. Bré gains in respect—Black Swan territory
In the fall of 2009, I found myself in Korea with a collection of suit-and-tie-wearing hotshots. On a panel sat one Takatoshi Kato, then the deputy managing director of a powerful international institution. Before the panel discussion, he gave us a rapid PowerPoint presentation showing his and his department’s economic projections for 2010, 2011, 2012, 2013, and 2014.
These were the days before I decided to climb up the mountain, speak slowly and in a priestly tone, and try shaming people rather than insulting them. Listening to Kato’s presentation, I could not control myself and flew into a rage in front of two thousand Koreans—I was so angry that I almost started shouting in French, forgetting that I was in Korea. I ran to the podium and told the audience that the next time someone in a suit and tie gave them projections for some dates in the future, they should ask him to show what he had projected in the past—in this case, what he had been forecasting for 2008 and 2009 (the crisis years) two to five years earlier, in 2004, 2005, 2006, and 2007. They would then verify that Highly Venerable Kato-san and his colleagues are, to put it mildly, not very good at this predictionizing business. And it is not just Mr. Kato: our track record in figuring out significant rare events in politics and economics is not close to zero; it is
zero
. I improvised,
on the spot, my solution. We can’t put all false predictors in jail; we can’t stop people from asking for predictions; we can’t tell people not to hire the next person who makes promises about the future. “All I want is to live in a world in which predictions such as those by Mr. Kato do not harm you. And such a world has unique attributes: robustness.”
The idea of proposing the Triad was born there and then as an answer to my frustration: Fragility-Robustness-Antifragility as a replacement for predictive methods.
Ms. Bré Has Competitors
What was getting me in that state of anger was my realization that forecasting was not neutral. It is all in the iatrogenics. Forecasting can be downright injurious to risk-takers—no different from giving people snake oil medicine in place of cancer treatment, or bleeding, as in the story of George Washington. And there was evidence. Danny Kahneman—rightfully—kept admonishing me for my fits of anger and outbursts at respectable members of the establishment (respectable for now), deeming such behavior to be unbecoming of the wise member of the intelligentsia I was supposed to be. Yet he stoked my frustration and sense of outrage the most by showing me the evidence of iatrogenics. There are ample empirical findings to the effect that providing someone with a random numerical forecast increases his risk taking, even if the person
knows
the projections are random.
All I hear is complaints about forecasters, when the next step is obvious yet rarely taken: avoidance of iatrogenics from forecasting. We understand childproofing, but not forecaster-hubris-proofing.
The Predictive
What makes life simple is that the robust and antifragile don’t have to have as accurate a comprehension of the world as the fragile—and they do not need forecasting. To see how redundancy is a nonpredictive, or rather a less predictive, mode of action, let us use the argument of
Chapter 2
: if you have extra cash in the bank (in addition to stockpiles of tradable goods such as cans of Spam and hummus and gold bars in the basement), you don’t need to know with precision which event will
cause potential difficulties.
1
It could be a war, a revolution, an earthquake, a recession, an epidemic, a terrorist attack, the secession of the state of New Jersey, anything—you do not need to predict much, unlike those who are in the opposite situation, namely, in debt. Those, because of their fragility, need to predict with more, a lot more, accuracy.
Plus or Minus Bad Teeth
You can control fragility a lot more than you think. So let us refine in three points:
(i) Since detecting (anti)fragility—or, actually, smelling it, as Fat Tony will show us in the next few chapters—is easier, much easier, than prediction and understanding the dynamics of events, the entire mission reduces to the central principle of what to do to minimize harm (and maximize gain) from forecasting errors, that is, to have things that don’t fall apart, or even benefit, when we make a mistake.
(ii) We do not want to change the world for now (leave that to the Soviet-Harvard utopists and other fragilistas); we should first make things more robust to defects and forecast errors, or even exploit these errors, making lemonade out of the lemons.
(iii) As for the lemonade, it looks as if history is in the business of making it out of lemons; antifragility is necessarily how things move forward under the mother of all stressors, called time.
Further, after the occurrence of an event, we need to switch the blame from the inability to see an event coming (say a tsunami, an Arabo-Semitic spring or similar riots, an earthquake, a war, or a financial crisis) to the failure to understand (anti)fragility, namely, “why did we build something so fragile to these types of events?” Not seeing a tsunami or an economic event coming is excusable; building something fragile to them is not.
Also, as to the naive type of utopianism, that is, blindness to history, we cannot afford to rely on the rationalistic elimination of greed and other human defects that fragilize society. Humanity has been trying to
do so for thousands of years and humans remain the same, plus or minus bad teeth, so the last thing we need is even more dangerous moralizers (those who look in a permanent state of gastrointestinal distress). Rather, the more intelligent (and practical) action is to make the world greed-proof, or even hopefully make society benefit from the greed and other perceived defects of the human race.
In spite of their bad press, some people in the nuclear industry seem to be among the rare ones to have gotten the point and taken it to its logical consequence. In the wake of the Fukushima disaster, instead of predicting failure and the probabilities of disaster, these intelligent nuclear firms are now aware that they should instead focus on
exposure to failure
—making the prediction or nonprediction of failure quite irrelevant. This approach leads to building small enough reactors and embedding them deep enough in the ground with enough layers of protection around them that a failure would not affect us much should it happen—costly, but still better than nothing.
Another illustration, this time in economics, is the Swedish government’s focus on total fiscal responsibility after their budget troubles in 1991—it makes them much less dependent on economic forecasts. This allowed them to shrug off later crises.
2
The Idea of Becoming a Non-Turkey
It is obvious to anyone before drinking time that we can put a man, a family, a village with a mini town hall on the moon, and predict the trajectory of planets or the most minute effect in quantum physics, yet governments with equally sophisticated models cannot forecast revolutions, crises, budget deficits, or climate change. Or even the closing prices of the stock market a few hours from now.
There are two different domains, one in which we can predict (to some extent), the other—the Black Swan domain—in which we should only let turkeys and turkified people operate. And the demarcation is as visible (to non-turkeys) as the one between the cat and the washing machine.
Social, economic, and cultural life lie in the Black Swan domain,
physical life much less so. Further, the idea is to separate domains into those in which these Black Swans are both unpredictable and consequential, and those in which rare events are of no serious concern, either because they are predictable or because they are inconsequential.
I mentioned in the Prologue that randomness in the Black Swan domain is intractable. I will repeat it till I get hoarse. The limit is mathematical, period, and there is no way around it on this planet. What is nonmeasurable and nonpredictable will remain nonmeasurable and nonpredictable, no matter how many PhDs with Russian and Indian names you put on the job—and no matter how much hate mail I get. There is, in the Black Swan zone, a limit to knowledge that can never be reached, no matter how sophisticated statistical and risk management science ever gets.
The involvement of this author has not been so much in asserting this impossibility to ever know anything about these matters—the general skeptical problem has been raised throughout history by a long tradition of philosophers, including Sextus Empiricus, Algazel, Hume, and many more skeptics and skeptical empiricists—as in formalizing and modernizing as a background and footnote to my anti-turkey argument. So my work is about
where
one should be skeptical, and where one should not be so. In other words, focus on getting out of the f*** Fourth Quadrant—the Fourth Quadrant is the scientific name I gave to the Black Swan domain, the one in which we have a high exposure to rare, “tail” events
and
these events are incomputable.
3
Now, what is worse, because of modernity, the share of Extremistan is increasing. Winner-take-all effects are worsening: success for an author, a company, an idea, a musician, an athlete is planetary, or nothing. These worsen predictability since almost everything in socioeconomic life now is dominated by Black Swans. Our sophistication continuously puts us ahead of ourselves, creating things we are less and less capable of understanding.
No More Black Swans
Meanwhile, over the past few years, the world has also gone the other way, upon the discovery of the Black Swan idea. Opportunists are now into predicting, predictioning, and predictionizing Black Swans with even more complicated models coming from chaos-complexity-catastrophe-fractal theory. Yet, again, the answer is simple:
less is more;
move the discourse to (anti)fragility.
1
From my experiences of the Lebanese war and a couple of storms with power outages in Westchester County, New York, I suggest stocking up on novels, as we tend to underestimate the boredom of these long hours waiting for the trouble to dissipate. And books, being robust, are immune to power outages.
2
A related idea is expressed in a (perhaps apocryphal) statement by the financier Warren Buffett that he tries to invest in businesses that are “so wonderful that an idiot can run them. Because sooner or later, one will.”
3
A technical footnote (to skip): What are the Quadrants? Combining exposures and types of randomness we get four combinations: Mediocristan randomness, low exposure to extreme events (First Quadrant); Mediocristan randomness, high exposure to extreme events (Second Quadrant); Extremistan randomness, low exposure to extreme events (Third Quadrant); Extremistan randomness, high exposure to extreme events (Fourth Quadrant). The first three quadrants are ones in which knowledge or lack of it bring inconsequential errors. “Robustification” is the modification of exposures to make a switch from the fourth to the third quadrant.


================================================================================
CHAPTER/SECTION 47 (Item 50)
================================================================================

BOOK III
A Nonpredictive View of the World
W
elcome, reader, to the nonpredictive view of the world.
Chapter 10
presents Seneca’s stoicism as a starting point for understanding antifragility, with applications from philosophy and religion to engineering.
Chapter 11
introduces the barbell strategy and explains why the dual strategy of mixing high risks and highly conservative actions is preferable to just a simple medium-risk approach to things.
But first, we open
Book III
with the story of our two friends who derive some great entertainment from, and make a living by, detecting fragility and playing with the ills of fragilistas.


================================================================================
CHAPTER/SECTION 48 (Item 51)
================================================================================

CHAPTER 9
Fat Tony and the Fragilistas
Olfactory methods with the perception of fragility—The difficulties of lunch—Quickly open the envelope—A certain redivision of the world, as seen from New Jersey—The sea gets deeper and deeper


================================================================================
CHAPTER/SECTION 49 (Item 52)
================================================================================

INDOLENT FELLOW TRAVELERS
Before the economic crisis of 2008, the association between Nero Tulip and Tony DiBenedetto, also known as “Fat Tony” or the more politically acceptable “Tony Horizontal,” would have been hard to explain to an outsider.
Nero’s principal activity in life is reading books, with a few auxiliary activities in between. As to Fat Tony, he reads so little that, one day when he mentioned he wanted to write his memoirs, Nero joked that “Fat Tony would have written exactly one more book than he had read”—to which Fat Tony, always a few steps ahead of him, quoted Nero back: “You once said that if you felt like reading a novel, you would write one.” (Nero had one day cited the British prime minister and novelist Benjamin Disraeli, who wrote novels but didn’t like reading them.)
Tony grew up in Brooklyn and moved to New Jersey, and he has exactly the accent you would expect him to have. So, unburdened with time-consuming (and, to him, “useless”) reading activities, and highly allergic to structured office work, Fat Tony spent a lot of his time doing
nothing, with occasional commercial transactions in between. And, of course, a lot of eating.
The Importance of Lunch
While most people around them were running around fighting the different varieties of unsuccess, Nero and Fat Tony had this in common: they were terrified of boredom, particularly the prospect of waking up early with an empty day ahead. So the proximate reason for their getting together before that crisis was, as Fat Tony would say, “doing lunch.” If you live in an active city, say, New York, and have a friendly personality, you will have no trouble finding good dinner partners, people who can hold a conversation of some interest in an almost relaxed way. Lunch, however, is a severe difficulty, particularly during phases of high employment. It is easy to find lunch partners among resident office inmates but trust me, you don’t want to get near them. They will have liquefied stress hormones dripping from their pores, they will exhibit anxiety if they discuss anything that may divert them from what they think is in the course of their “work,” and when in the process of picking their brain you hit on a less uninteresting mine, they will cut you short with a “I have to run” or “I have a two-fifteen.”
Moreover, Fat Tony got respect in exactly the right places. Unlike Nero, whose ruminating philosophical episodes erased his social presence, making him invisible to waiters, Tony elicited warm and enthusiastic responses when he showed up in an Italian restaurant. His arrival triggered a small parade among the waiters and staff; he was theatrically hugged by the restaurant owner, and his departure after the meal was a long procedure with the owner and, sometimes, his mother seeing him outside, with some gift, like perhaps homemade grappa (or some strange liquid in an unmarked bottle), more hugs, and promises to come for the Wednesday special meal.
Accordingly, Nero, when he was in the New York area, could reduce his anxiety about lunchtime, as he could always count on Tony. He would meet Tony at the health club; there our horizontal hero did his triathlon (sauna, Jacuzzi, and steam bath), and from there they would go get some worship from restaurant owners. So Tony once explained to Nero that he had no use for him in the evenings—he could get better, more humorous, more Italian–New Jersey friends, who, unlike Nero, could give him ideas for “something useful.”
The Antifragility of Libraries
Nero lived a life of mixed (and transient) asceticism, going to bed as close to nine o’clock as he could, sometimes even earlier in the winter. He tried to leave parties when the effect of alcohol made people start talking to strangers about their personal lives or, worse, turn metaphysical. Nero preferred to conduct his activities by daylight, trying to wake up in the morning with the sun’s rays gently penetrating his bedroom, leaving stripes on the walls.
He spent his time ordering books from booksellers on the Web, and very often read them. Having terminated his turbulent, extremely turbulent, adventures, like Sindbad the sailor and Marco Polo the Venetian traveler, he ended up settling for a quiet and sedate life of post-adventure.
Nero was the victim of an aesthetic ailment that brings revulsion, even phobia, toward: people wearing flip-flops, television, bankers, politicians (right-wing, left-wing, centrists), New Jersey, rich persons from New Jersey (like Fat Tony), rich persons who take cruises (and stop in Venice wearing flip-flops), university administrators, grammatical sticklers, name droppers, elevator music, and well-dressed salespersons and businessmen. As for Fat Tony, he had different allergies: the
empty suit,
which we speculate is someone who has a command of all the superfluous and administrative details of things but misses the essential (and isn’t even aware of it), so his conversation becomes mere chitchat around the point, never getting to the central idea.
And Fat Tony was a smeller of fragility. Literally. He claimed that he could figure out a person from seeing him just walk into a restaurant, which was almost true. But Nero had noticed that Fat Tony, when talking to people for the first time, got very close to them and sniffed them, just like a dog, a habit of which Fat Tony wasn’t even aware.
Nero belonged to a society of sixty volunteer translators collaborating on previously unpublished ancient texts in Greek, Latin, or Aramaic (Syriac) for the French publishing house Les Belles Lettres. The group is organized along libertarian lines, and one of their rules is that university titles and prestige give no seniority in disputes. Another rule is mandatory attendance at two “dignified” commemorations in Paris, every November 7, the death of Plato, and every April 7, the birth of Apollo. His other membership is in a local club of weight lifters that meets on Saturdays in a converted garage. The club is mostly composed of New York
doormen, janitors, and mobster-looking fellows who walk around in the summer wearing sleeveless “wife-beater” shirts.
Alas, men of leisure become slaves to inner feelings of dissatisfaction and interests over which they have little control. The freer Nero’s time, the more compelled he felt to compensate for lost time in filling gaps in his natural interests, things that he wanted to know a bit deeper. And, as he discovered, the worst thing one can do to feel one knows things a bit deeper is to try to go into them a bit deeper.
The sea gets deeper as you go further into it,
according to a Venetian proverb.
Curiosity is antifragile, like an addiction, and is magnified by attempts to satisfy it—books have a secret mission and ability to multiply, as everyone who has wall-to-wall bookshelves knows well. Nero lived, at the time of writing, among fifteen thousand books, with the stress of how to discard the empty boxes and wrapping material after the arrival of his daily shipment from the bookstore. One subject Nero read for pleasure, rather than the strange duty-to-read-to-become-more-learned, was medical texts, for which he had a natural curiosity. The curiosity came from having had two brushes with death, the first from a cancer and the second from a helicopter crash that alerted him to both the fragility of technology and the self-healing powers of the human body. So he spent a bit of his time reading textbooks (not papers—textbooks) in medicine, or professional texts.
Nero’s formal training was in statistics and probability, which he approached as a special branch of philosophy. He had been spending all his adult life writing a philosophical-technical book called
Probability and Metaprobability
. His tendency was to abandon the project every two years and take it up again two years later. He felt that the concept of probability as used was too narrow and incomplete to express the true nature of decisions in the ecology of the real world.
Nero enjoyed taking long walks in old cities, without a map. He used the following method to detouristify his traveling: he tried to inject some randomness into his schedule by never deciding on the next destination until he had spent some time in the first one, driving his travel agent crazy—when he was in Zagreb, his next destination would be determined by his state of mind while in Zagreb. Largely, it was the smell of places that drew him to them; smell cannot be conveyed in a catalogue.
Mostly, when in New York, Nero sat in his study with his writing desk set against the window, occasionally looking dreamily at the New Jersey shore across the Hudson River and reminding himself how happy
he was to not live there. So he conveyed to Fat Tony that the “I have no use for you” was reciprocal (in equally nondiplomatic terms), which, as we will see, was not true.


================================================================================
CHAPTER/SECTION 50 (Item 53)
================================================================================

ON SUCKERS AND NONSUCKERS
After the crisis of 2008, it became clear what the two fellows had in common: they were predicting a sucker’s fragility crisis. What had gotten them together was that they had both been convinced that a crisis of such magnitude, with a snowballing destruction of the modern economic system in a way and on a scale never seen before, was bound to happen, simply because there were suckers. But our two characters came from two entirely different schools of thought.
Fat Tony believed that nerds, administrators, and, mostly, bankers were the ultimate suckers (that was when everyone still thought they were geniuses). And, what’s more, he believed that collectively they were even bigger suckers than they were individually. And he had a natural ability to detect these suckers before they fell apart. Fat Tony derived his income from that activity while leading, as we saw, a life of leisure.
Nero’s interests were similar to Tony’s, except dressed up in intellectual traditions. To Nero, a system built on illusions of understanding probability is bound to collapse.
By betting against fragility, they were antifragile.
So Tony made a bundle from the crisis, in the high eight to low nine figures—everything other than a bundle for Tony is “tawk.” Nero made a bit, though much less than Tony, but he was satisfied that he had won—as we said, he had already been financially independent and he saw money as a waste of time. To put it bluntly, Nero’s family’s wealth had peaked in 1804, so he did not have the social insecurity of other adventurers, and money to him could not possibly be a social statement—only erudition for now, and perhaps wisdom in old age. Excess wealth, if you don’t need it, is a heavy burden. Nothing was more hideous in his eyes than excessive refinement—in clothes, food, lifestyle, manners—and wealth was nonlinear. Beyond some level it forces people into endless complications of their lives, creating worries about whether the housekeeper in one of the country houses is scamming them while doing a poor job and similar headaches that multiply with money.
The ethics of betting against suckers will be discussed in
Book VII
, but there are two schools of thought. To Nero one should first warn
people that they are suckers, while Tony was against the very notion of warning. “You will be ridiculed,” he said; “words are for sissies.” A system based on verbal warnings will be dominated by non-risk-taking-babblers. These people won’t give you and your ideas respect unless you take their money.
Further, Fat Tony insisted that Nero take a ritual look at the physical embodiments of the spoils, such as a bank account statement—as we said, it had nothing to do with the financial value, nor even the purchasing power, of the items, just their symbolic value. He could understand why Julius Caesar needed to incur the cost of having Vercingetorix, the leader of the Gaul rebellion, brought to Rome and paraded in chains, just so he could exhibit victory in the flesh.
There is another dimension to the need to focus on actions and avoid words: the health-eroding dependence on external recognition. People are cruel and unfair in the way they confer recognition, so it is best to stay out of that game. Stay robust to how others treat you. Nero at some stage befriended a scientist of legendary status, a giant for whom he had immense respect. Although the fellow was about as prominent as one could get in his field (in the eyes of others), he spent his time focused on the status he had that week in the scientific community. He would become enraged at authors who did not cite him or at some committee granting a medal he had never received to someone he judged inferior, that impostor!
Nero learned that no matter how satisfied they could be with their work, these hotshots-who-depended-on-words were deprived of Tony’s serenity; they remained fragile to the emotional toll from the compliments they did
not
get, the ones others got, and from what someone of lower intellect stole from them. So Nero promised himself to escape all of this with his small ritual—just in case he should fall prone to the hotshot’s temptation. Nero’s spoils from what he called the “Fat Tony bet,” after deducting the cost of a new car (a Mini) and a new $60 Swatch watch, amounted to a dizzyingly large amount sitting in a portfolio, the summary of which was mailed to him monthly from (of all places) a New Jersey address, with three other statements from overseas countries. Again, it is not the amount but the tangibility of his action that counted—the quantities could have been a tenth, even a hundredth as much and the effect would remain the same. So he would cure himself of the game of recognition by opening the envelope containing the statement
and then going on with his day, oblivious to the presence of those cruel and unfair users of words.
But to follow ethics to their natural conclusion, Nero should have felt just as proud—and satisfied—had the envelope contained statements of losses. A man is honorable in proportion to the personal risks he takes for his opinion—in other words, the amount of downside he is exposed to. To sum him up, Nero believed in erudition, aesthetics, and risk taking—little else.
As to the funds, to avoid the charity trap, Nero followed Fat Tony’s rule of systematically making donations, but not to those who directly asked for gifts. And he never, never gave a penny to any charitable organization, with the possible exception of those in which not a single person earned a salary.
Loneliness
A word on Nero’s loneliness. For Nero, in the dark days before the economic crisis of 2008, it sometimes caused him pain to be alone with his ideas—wondering at times, typically Sunday nights, if there was something particularly wrong with him or if there was something wrong with the world. Lunch with Fat Tony was like drinking water after an episode of thirst; it brought immediate relief to realize that he was either not crazy, or at least not
alone
in being crazy. Things out there
did not make sense,
and it was impossible to convey it to others, particularly people deemed intelligent.
Consider that of the close to a million professionals employed in economic activities, whether in government (from Cameroon to Washington, D.C.), academia, media, banking, corporations, or doing their own private homework for economic and investment decisions, fewer than a handful saw it coming—furthermore, an even smaller handful managed to foresee the full extent of the damage.
And of those who saw it coming, not a single one realized that the crisis was a product of modernity.
Nero could stand near the former World Trade Center site in downtown New York, across from the colossal buildings housing mostly banks and brokerage houses, with hundreds of people running around inside them, expending gigawatts of energy just moving and commuting from New Jersey, consuming millions of bagels with cream cheese, with
insulin response inflaming their arteries, producing gigabytes of information just by talking and corresponding and writing articles.
But noise it was: wasted effort, cacophony, unaesthetic behavior, increased entropy, production of energy that causes a local warming up of the New York area ecozone, and a large-scale delusion of this thing called “wealth” that was bound to evaporate somehow.
You could stack the books and they would constitute an entire mountain. Alas, to Nero anything in them that deals with probability, statistics, or mathematical models is just
air,
in spite of evidence that and evidence this. And you learn more in a few lunches with Fat Tony than from the social science sections of the Harvard libraries,
1
with close to two million books and research papers, for a total of 33 million hours of reading, close to nine thousand years’ worth of reading as a full-time activity.
Talk about a major sucker problem.
What the Nonpredictor Can Predict
Fat Tony did not believe in predictions. But he made big bucks predicting that some people—the predictors—would go bust.
Isn’t that paradoxical? At conferences, Nero used to meet physicists from the Santa Fe Institute who believed in predictions and used fancy prediction models while their business ventures based on predictions did not do that well—while Fat Tony, who did not believe in predictions, got rich from prediction.
You can’t predict in general, but you can predict that those who rely on predictions are taking more risks, will have some trouble, perhaps even go bust. Why? Someone who predicts will be fragile to prediction errors. An overconfident pilot will eventually crash the plane. And numerical prediction leads people to take more risks.
Fat Tony is antifragile because he takes a mirror image of his fragile prey.
Fat Tony’s model is quite simple. He identifies fragilities, makes a bet on the collapse of the fragile unit, lectures Nero and trades insults with him about sociocultural matters, reacts to Nero’s jabs at New Jersey life, collects big after the collapse. Then he has lunch.
1
The only exception in that social science library is a few small sections in the cognitive science literature—some of it works.


================================================================================
CHAPTER/SECTION 51 (Item 54)
================================================================================

CHAPTER 10
Seneca’s Upside and Downside
How to survive advice—To lose nothing or gain nothing—What to do on your next shipwreck
A couple of millennia before Fat Tony, another child of the Italian peninsula solved the problem of antifragility. Except that, more intellectual than our horizontal friend, he spoke in a more distinguished prose. In addition, he was no less successful in the real world—actually he was vastly more successful in business than Fat Tony, and no less intellectual than Nero. The fellow was the stoic philosopher Seneca, whom we mentioned earlier was the alleged lover of Nero’s mother (he was not).
And he solved the problem of antifragility—what connects the elements of the Triad—using Stoic philosophy.
Is This Really Serious?
Lucius Annaeus Seneca was a philosopher who happened to be the wealthiest person in the Roman Empire, partly owing to his trading acumen, partly for having served as the tutor of the colorful Emperor Nero, the one who tried to whack his mother a few chapters ago. Seneca subscribed to, and was a prominent expositor of, the philosophical school of Stoicism, which advanced a certain indifference to fate. His work has seduced people like me and most of the friends to whom I introduced his books, because he speaks to us; he walked the walk, and he focused on
the practical aspect of Stoicism, down to how to take a trip, how to handle oneself while committing suicide (which he was ordered to do), or, mostly, how to handle adversity and poverty and, even more critically, wealth.
Because Seneca was into practical decision making, he has been described—by academics—as not theoretical or philosophical enough. Yet not a single one of his commentators detected in Seneca the ideas about asymmetry that are central to this book, and to life, the key to robustness and antifragility. Not one. My point is that wisdom in decision making is vastly more important—not just practically, but philosophically—than knowledge.
Other philosophers, when they did things, came to practice from theory. Aristotle, when he attempted to provide practical advice, and a few decades earlier Plato, with his ideas of the state and advice to rulers, particularly the ruler of Syracuse, were either ineffectual or caused debacles. To become a successful philosopher king, it is much better to start as a king than as a philosopher, as illustrated in the following contemporary story.
Modern members of the discipline of decision theory, alas, travel a one-way road from theory to practice. They characteristically gravitate to the most complicated but most inapplicable problems, calling the process “doing science.” There is an anecdote about one Professor Triffat (I am changing the name because the story might be apocryphal, though from what I have witnessed, it is very characteristic). He is one of the highly cited academics of the field of decision theory, wrote the main textbook and helped develop something grand and useless called “rational decision making,” loaded with grand and useless axioms and shmaxioms, grand and even more useless probabilities and shmobabilities. Triffat, then at Columbia University, was agonizing over the decision to accept an appointment at Harvard—many people who talk about risk can spend their lives without encountering more difficult risk taking than this type of decision. A colleague suggested he use some of his Very Highly Respected and Grandly Honored and Decorated academic techniques with something like “maximum expected utility,” as, he told him, “you always write about this.” Triffat angrily responded, “Come on, this is serious!”
By contrast, Seneca is nothing but “this is serious.” He once survived a shipwreck in which other family members perished, and he wrote letters of practical and less practical advice to his friends. In the end, when
he took his own life, he followed excellently and in a dignified way the principles he preached in his writings. So while the Harvard economist is only read by people trying to write papers, who in turn are read by people trying to write papers, and will be (hopefully) swallowed by the inexorable b***t detector of history, Lucius Annaeus, known as Seneca the Younger, is still read by real people two millennia after his passing.
Let us get into his message.
Less Downside from Life
We start with the following conflict. We introduced Seneca as the wealthiest person in the Roman Empire. His fortune was three hundred million denarii (for a sense of its equivalence, at about the same period in time, Judas got thirty denarii, the equivalent of a month’s salary, to betray Jesus). Admittedly it is certainly not very convincing to read denigrations of material wealth from a fellow writing the lines on one of his several hundred tables (with ivory legs).
The traditional understanding of Stoicism in the literature is of some
indifference
to fate—among other ideas of harmony with the cosmos that I will skip here. It is about continuously degrading the value of earthly possessions. When Zeno of Kition, the founder of the school of Stoicism, suffered a shipwreck (a lot of shipwrecks in ancient texts), he declared himself lucky to be unburdened so he could now do philosophy. And the key phrase reverberating in Seneca’s oeuvre is
nihil perditi,
“I lost nothing,” after an adverse event. Stoicism makes you desire the challenge of a calamity. And Stoics look down on luxury: about a fellow who led a lavish life, Seneca wrote: “He is in debt, whether he borrowed from another person or from fortune.”
1
Stoicism, seen this way, becomes pure robustness—for the attainment of a state of immunity from one’s external circumstances, good or bad, and an absence of fragility to decisions made by fate, is robustness. Random events won’t affect us either way (we are too strong to lose, and not greedy to enjoy the upside), so we stay in the middle column of the Triad.
What we learn from reading Seneca directly, rather than through the
commentators, is a different story. Seneca’s version of that Stoicism is antifragility from fate. No downside from Lady Fortuna, plenty of upside.
True, Seneca’s aim on paper was philosophical, trying to stick to the Stoic tradition as described above: Stoicism was not supposed to be about gains and benefits, so on paper it was not at the level of antifragility, just about a sense of control over one’s fate and the reduction of psychological fragility. But there is something that commentators have completely missed. If wealth is so much of a burden, while unnecessary, what’s the point of having it? Why did Seneca keep it?
As I said concerning the psychologists who in
Chapter 2
ignore post-traumatic growth but focus on post-traumatic harm, intellectuals have this thing against antifragility—for them the world tends to stop at robustness. I don’t know what it is, but they don’t like it. This made them avoid considering that Seneca wanted the upside from fate, and there is nothing wrong with it.
Let us first learn from the great master how he advocated the mitigation of downside, the standard message of the Stoics—robustness, protection against harm from emotions, how to move away from the first column of the Triad, that sort of thing. Second step, we will show how he truly proposed antifragility. And, third step, we will generalize his trick into a general method of detection of antifragility in
Chapters 18
and
19
.
Stoicism’s Emotional Robustification
Success brings an asymmetry: you now have a lot more to lose than to gain. You are hence fragile. Let us return to the story of Damocles’ sword. There is no good news in store, just plenty of bad news in the pipeline. When you become rich, the pain of losing your fortune exceeds the emotional gain of getting additional wealth, so you start living under continuous emotional threat. A rich person becomes trapped by belongings that take control of him, degrading his sleep at night, raising the serum concentration of his stress hormones, diminishing his sense of humor, perhaps even causing hair to grow on the tip of his nose and similar ailments. Seneca fathomed that possessions make us worry about downside, thus acting as a punishment as we depend on them. All downside, no upside. Even more: dependence on circumstances—rather, the emotions that arise from circumstances—induces a form of slavery.
This asymmetry between the effects of good and bad, benefit and harm, had to be familiar to the ancients—I found an earlier exposition in Livy: “Men feel the good less intensely than the bad” (
segnius homines bona quam mala sentiunt
), he wrote half a generation before Seneca. Ancients—mostly thanks to Seneca—stay way ahead of modern psychologists and Triffat-style decision theorists who have developed theories around the notion of “risk (or loss) aversion,” the ancients remain deeper, more practical, while transcending vulgar therapy.
Let me rephrase it in modern terms. Take the situation in which you have a lot to lose and little to gain. If an additional quantity of wealth, say, a thousand Phoenician shekels, would not benefit you, but you would feel great harm from the loss of an equivalent amount, you have an asymmetry. And it is not a good asymmetry: you are fragile.
Seneca’s practical method to counter such fragility was to go through mental exercises to write off possessions, so when losses occurred he would not feel the sting—a way to wrest one’s freedom from circumstances. It is similar to buying an insurance contract against losses. For instance, Seneca often started his journeys with almost the same belongings he would have if he were shipwrecked, which included a blanket to sleep on the ground, as inns were sparse at the time (though I need to qualify, to set things in the context of the day, that he had accompanying him “only one or two slaves”).
To show how eminently modern this is, I will next reveal how I’ve applied this brand of Stoicism to wrest back psychological control of the randomness of life. I have always hated employment and the associated dependence on someone else’s arbitrary opinion, particularly when much of what’s done inside large corporations violates my sense of ethics. So I have, accordingly, except for eight years, been self-employed. But, before that, for my last job, I wrote my resignation letter before starting the new position, locked it up in a drawer, and felt free while I was there. Likewise, when I was a trader, a profession rife with a high dose of randomness, with continuous psychological harm that drills deep into one’s soul, I would go through the mental exercise of assuming every morning that the worst possible thing had actually happened—the rest of the day would be a bonus. Actually the method of mentally adjusting “to the worst” had advantages way beyond the therapeutic, as it made me take a certain class of risks for which the worst case is clear and unambiguous, with limited and known downside. It is hard to stick to a good discipline of mental write-off when things are going well, yet
that’s when one needs the discipline the most. Moreover, once in a while, I travel, Seneca-style, in uncomfortable circumstances (though unlike him I am not accompanied by “one or two” slaves).
An intelligent life is all about such emotional positioning to eliminate the sting of harm, which as we saw is done by mentally writing off belongings so one does not feel any pain from losses. The volatility of the world no longer affects you negatively.
The Domestication of Emotions
Seen this way, Stoicism is about the domestication, not necessarily the elimination, of emotions. It is not about turning humans into vegetables. My idea of the modern Stoic sage is
someone who transforms fear into prudence, pain into information, mistakes into initiation, and desire into undertaking
.
Seneca proposes a complete training program to handle life and use emotions properly—thanks to small but effective tricks. One trick, for instance, that a Roman Stoic would use to separate anger from rightful action and avoid committing harm he would regret later would be to wait at least a day before beating up a servant who committed a violation. We moderns might not see this as particularly righteous, but just compare it to the otherwise thoughtful Emperor Hadrian’s act of stabbing a slave in the eye during an episode of uncontrolled anger. When Hadrian’s anger abated, and he felt the grip of remorse, the damage was irreversible.
Seneca also provides us a catalogue of social deeds: invest in good actions. Things can be taken away from us—not good deeds and acts of virtue.
How to Become the Master
So far, that story is well known, and we have learned to move from the left of the Triad (fragile) to the center (robust). But Seneca went beyond.
He said that wealth is the slave of the wise man and master of the fool. Thus he broke a bit with the purported Stoic habit:
he kept the upside
. In my opinion, if previous Stoics claimed to prefer poverty to wealth, we need to be suspicious of their attitude, as it may be just all talk. Since most were poor, they might have fit a narrative to the circumstances (we will see with the story of Thales of Miletus the notion of
sour grapes—cognitive games to make yourself believe that the grapes that you can’t reach taste sour). Seneca was all deeds, and we cannot ignore the fact that he kept the wealth. It is central that he showed his preference of wealth
without harm from wealth
to poverty.
Seneca even outlined his strategy in
De beneficiis,
explicitly calling it a cost-benefit analysis by using the word “bookkeeping”: “The bookkeeping of benefits is simple: it is all expenditure; if any one returns it, that is clear
gain
(my emphasis); if he does not return it, it is not lost, I gave it for the sake of giving.” Moral bookkeeping, but bookkeeping nevertheless.
So he played a trick on fate: kept the good and ditched the bad; cut the downside and kept the upside. Self-servingly, that is, by eliminating the harm from fate and un-philosophically keeping the upside. This cost-benefit analysis is not quite Stoicism in the way people understand the meaning of Stoicism (people who study Stoicism seem to want Seneca and other Stoics to think like those who study Stoicism). There is an upside-downside asymmetry.
That’s antifragility in its purest form.
2
The Foundational Asymmetry
Let us put together Seneca’s asymmetry in a single rule.
The concept I used earlier is
more to lose
from adversity. If you have more to lose than to benefit from events of fate, there is an asymmetry, and not a good one. And such asymmetry is universal. Let us see how it brings us to fragility.
Consider the package in
Chapter 1
: it does not like to be shaken, and it hates the members of the disorder family—hence it is fragile (very fragile because it has absolutely nothing to gain, hence it is very asymmetric). The antifragile package has more to gain than to lose from being shaken. Simple test: if I have “nothing to lose” then it is all gain and I am antifragile.
The entire
Table 1
with triads across fields and domains can be explained in these terms. Everything.
To see why asymmetric payoffs like volatility, just consider that if
you have less to lose than to gain, more upside than downside, then you like volatility (it will, on balance, bring benefits), and you are also antifragile.
So the job falling upon this author is to make the link between the four elements as follows with the foundational asymmetry.
Fragility implies more to lose than to gain, equals more downside than upside, equals (unfavorable) asymmetry
and
Antifragility implies more to gain than to lose, equals more upside than downside, equals (favorable) asymmetry
You are antifragile for a source of volatility if potential gains exceed potential losses (and vice versa).
Further, if you have more upside than downside, then you may be harmed by lack of volatility and stressors.
Now, how do we put this idea—reduction of downside, increase in upside—into practice? By the method of the barbell in the next chapter.
1
For those readers who wonder about the difference between Buddhism and Stoicism, I have a simple answer. A Stoic is a Buddhist with attitude, one who says “f*** you” to fate.
2
And for those who believe that Zeno, the founder of Stoicism, was completely against material wealth, I have some news: I accidentally found a mention of his activities in maritime financing, where he was an involved investor, not exactly an activity for the anti-wealth utopist.


================================================================================
CHAPTER/SECTION 52 (Item 55)
================================================================================

CHAPTER 11
Never Marry the Rock Star
A precise protocol on how and with whom to cheat on one’s husband—Introduction to barbell strategies—Transforming diplomats into writers, and vice versa
The barbell (or bimodal) strategy is a way to achieve antifragility and move to the right side of the Triad. Monogamous birds put it into practice by cheating with the local rock star and writers do better by having as a day job a sinecure devoid of writing activities.


================================================================================
CHAPTER/SECTION 53 (Item 56)
================================================================================

ON THE IRREVERSIBILITY OF BROKEN PACKAGES
The first step toward antifragility consists in first decreasing downside, rather than increasing upside; that is, by lowering exposure to negative Black Swans and letting natural antifragility work by itself.
Mitigating fragility is not an option but a requirement. It may sound obvious but the point seems to be missed. For fragility is very punishing, like a terminal disease. A package doesn’t break under adverse conditions, then manage to fix itself when proper conditions are restored. Fragility has a ratchetlike property, the irreversibility of damage. What matters is the route taken, the order of events, not just the destination—what scientists call a
path-dependent
property. Path dependence can be illustrated as follows: your experience in getting a kidney stone operation first and anesthesia later is different from having the
procedures done in the opposite sequence. Or your enjoyment of a meal with coffee and dessert first and tomato soup last would not be the same as the inverse order. The consideration of path dependence makes our approach simple: it is easy to identify the fragile and put it in the left column of the Triad, regardless of upside potential—since the broken will tend to stay permanently broken.
This fragility that comes from path dependence is often ignored by businessmen who, trained in static thinking, tend to believe that generating profits is their principal mission, with survival and risk control something to perhaps consider—they miss the strong logical precedence of survival over success. To make profits and buy a BMW, it would be a good idea to, first, survive.
Notions such as speed and growth—anything related to movement—are empty and meaningless when presented without accounting for fragility. Consider that someone driving two hundred and fifty miles per hour in New York City is quite certain to never get anywhere—the effective speed will be exactly zero miles per hour. While it is obvious that one needs to focus on the effective, not the nominal, speed, something in the sociopolitical discourse masks such an elementary point.
Under path dependence, one can no longer separate growth in the economy from risks of recession, financial returns from risks of terminal losses, and “efficiency” from danger of accident. The notion of efficiency becomes quite meaningless on its own. If a gambler has a risk of terminal blowup (losing back everything), the “potential returns” of his strategy are totally inconsequential. A few years ago, a university fellow boasted to me that their endowment fund was earning 20 percent or so, not realizing that these returns were associated with fragilities that would easily turn into catastrophic losses—sure enough, a bad year wiped out all these returns and endangered the university.
In other words, if something is fragile, its risk of breaking makes anything you do to improve it or make it “efficient” inconsequential unless you first reduce that risk of breaking. As Publilius Syrus wrote, nothing can be done both hastily and safely—almost nothing.
As to growth in GDP (gross domestic product), it can be obtained very easily by loading future generations with debt—and the future economy may collapse upon the need to repay such debt. GDP growth, like cholesterol, seems to be a Procrustean bed reduction that has been used to game systems. So just as, for a plane that has a high risk of crashing, the notion of “speed” is irrelevant, since we know it may not get to
its destination, economic growth with fragilities is not to be called growth, something that has not yet been understood by governments. Indeed, growth was very modest, less than 1 percent per head, throughout the golden years surrounding the Industrial Revolution, the period that propelled Europe into domination. But as low as it was, it was robust growth—unlike the current fools’ race of states shooting for growth like teenage drivers infatuated with speed.


================================================================================
CHAPTER/SECTION 54 (Item 57)
================================================================================

SENECA’S BARBELL
This brings us to the solution in the form of a barbell—about all solutions to uncertainty are in the form of barbells.
What do we mean by barbell? The barbell (a bar with weights on both ends that weight lifters use) is meant to illustrate the idea of a combination of extremes kept separate, with avoidance of the middle. In our context it is not necessarily symmetric: it is just composed of two extremes, with nothing in the center. One can also call it, more technically, a bimodal strategy, as it has two distinct modes rather than a single, central one.
I initially used the image of the barbell to describe a dual attitude of playing it safe in some areas (robust to negative Black Swans) and taking a lot of small risks in others (open to positive Black Swans), hence achieving antifragility. That is extreme risk aversion on one side and extreme risk loving on the other, rather than just the “medium” or the beastly “moderate” risk attitude that in fact is a sucker game (because medium risks can be subjected to huge measurement errors). But the barbell also results, because of its construction, in the reduction of downside risk—the elimination of the risk of ruin.
Let us use an example from vulgar finance, where it is easiest to explain, but misunderstood the most. If you put 90 percent of your funds in boring cash (assuming you are protected from inflation) or something called a “numeraire repository of value,” and 10 percent in very risky, maximally risky, securities, you cannot possibly lose more than 10 percent, while you are exposed to massive upside. Someone with 100 percent in so-called “medium” risk securities has a risk of total ruin from the miscomputation of risks. This barbell technique remedies the problem that risks of rare events are incomputable and fragile to estimation error; here the financial barbell has a maximum known loss.
For antifragility is the combination
aggressiveness plus paranoia
—clip
your downside, protect yourself from extreme harm, and let the upside, the positive Black Swans, take care of itself. We saw Seneca’s asymmetry: more upside than downside can come simply from the reduction of extreme downside (emotional harm) rather than improving things in the middle.
A barbell can be any dual strategy composed of extremes, without the corruption of the middle—somehow they all result in favorable asymmetries.
Again, to see the difference between barbells and nonbarbells, consider that restaurants present the main course, say, grass-fed minute steak cooked rare and salad (with Malbec wine), then, separately, after you are done with the meat, bring you the goat cheese cake (with Muscat wine). Restaurants do not take your order, then cut the cake and the steak in small pieces and mix the whole thing together with those machines that produce a lot of noise. Activities “in the middle” are like such mashing. Recall Nero in
Chapter 9
hanging around with janitors and scholars, rarely with middlebrows.
In risky matters, instead of having all members of the staff on an airplane be “cautiously optimistic,” or something in the middle, I prefer the flight attendants to be maximally optimistic and the pilot to be maximally pessimistic or, better, paranoid.
The Accountant and the Rock Star
Biological systems are replete with barbell strategies. Take the following mating approach, which we call the 90 percent accountant, 10 percent rock star. (I am just reporting, not condoning.) Females in the animal kingdom, in some monogamous species (which include humans), tend to marry the equivalent of the accountant, or, even more colorless, the economist, someone stable who can provide, and once in a while they cheat with the aggressive alpha, the rock star, as part of a dual strategy. They limit their downside while using extrapair copulation to get the genetic upside, or some great fun, or both. Even the timing of the cheating seems nonrandom, as it corresponds to periods with high likelihood of pregnancy. We see evidence of such a strategy with the so-called monogamous birds: they enjoy cheating, with more than a tenth of the broods coming from males other than the putative father. The phenomenon is real, but the theories around it vary. Evolutionary theorists claim
that females want both economic-social stability and good genes for their children. Both cannot be always obtained from someone in the middle with all these virtues (though good gene providers, those alpha males aren’t likely to be stable, and vice versa). Why not have the pie and eat it too? Stable life and good genes. But an alternative theory may be that they just want to have pleasure—or stable life and good fun.
1
Also recall from
Chapter 2
that overcompensation, to work, requires some harm and stressors as tools of discovery. It means letting children play a little bit, not much more than a little bit, with fire and learn from injuries, for the sake of their own future safety.
It also means letting people experience some, not too much, stress, to wake them up a bit. But, at the same time, they need to be protected from high danger—ignore small dangers, invest your energy in protecting them from consequential harm. And only consequential harm. This can visibly be translated into social policy, health care, and many more matters.
One finds similar ideas in ancestral lore: it is explained in a Yiddish proverb that says “Provide for the worst; the best can take care of itself.” This may sound like a platitude, but it is not: just observe how people tend to provide for the best and hope that the worst will take care of itself. We have ample evidence that people are averse to small losses, but not so much toward very large Black Swan risks (which they underestimate), since they tend to insure for small probable losses, but not large infrequent ones. Exactly backwards.
Away from the Golden Middle
Now let us continue our exploration of barbells. There are so many fields in which the middle is no “golden middle” and where the bimodal strategy (maximally safe plus maximally speculative) applies.
Take literature, that most uncompromising, most speculative, most demanding, and riskiest of all careers. There is a tradition with French and other European literary writers to look for a sinecure, say, the
anxiety-free profession of civil servant, with few intellectual demands and high job security, the kind of low-risk job that ceases to exist when you leave the office, then spend their spare time writing, free to write whatever they want, under their own standards. There is a shockingly small number of academics among French authors. American writers, on the other hand, tend to become members of the media or academics, which makes them prisoners of a system and corrupts their writing, and, in the case of research academics, makes them live under continuous anxiety, pressures, and indeed, severe bastardization of the soul. Every line you write under someone else’s standards, like prostitution, kills a corresponding segment deep inside. On the other hand, sinecure-cum-writing is a quite soothing model, next best to having financial independence, or perhaps even better than financial independence. For instance, the great French poets Paul Claudel and Saint-John Perse and the novelist Stendhal were diplomats; a large segment of English writers were civil servants (Trollope was a post office worker); Kafka was employed by an insurance company. Best of all, Spinoza worked as a lens maker, which left his philosophy completely immune to any form of academic corruption. As a teenager, I thought that the natural way to have a real literary or philosophical career was to enter the lazy, pleasant, and undemanding profession of diplomat, like many members of my family. There was an Ottoman tradition of using Orthodox Christians as emissaries and ambassadors, even ministers of foreign affairs, which was retained by the states of the Levant (my grandfather and great-grandfather had been ministers of foreign affairs). Except that I worried about the wind turning against the Christian minority, and was proved right. But I became a trader and did my writing on my own time, and, as the reader can see, on my own terms. The barbell businessman-scholar situation was ideal; after three or four in the afternoon, when I left the office, my day job ceased to exist until the next day and I was completely free to pursue what I found most valuable and interesting. When I tried to become an academic I felt like a prisoner, forced to follow others’ less rigorous, self-promotional programs.
And professions can be serial: something very safe, then something speculative. A friend of mine built himself a very secure profession as a book editor, in which he was known to be very good. Then, after a decade or so, he left completely for something speculative and highly risky. This is a true barbell in every sense of the word: he can fall back on his previous profession should the speculation fail, or fail to bring the expected
satisfaction. This is what Seneca elected to do: he initially had a very active, adventurous life, followed by a philosophical withdrawal to write and meditate, rather than a “middle” combination of both. Many of the “doers” turned “thinkers” like Montaigne have done a serial barbell: pure action, then pure reflection.
Or, if I have to work, I find it preferable (and less painful) to work intensely for very short hours, then do nothing for the rest of the time (assuming doing nothing is really doing nothing), until I recover completely and look forward to a repetition, rather than being subjected to the tedium of Japanese style low-intensity interminable office hours with sleep deprivation. Main course and dessert are separate.
Indeed, Georges Simenon, one of the most prolific writers of the twentieth century, only wrote sixty days a year, with three hundred days spent “doing nothing.” He published more than two hundred novels.
The Domestication of Uncertainty
We will see many barbells in the rest of this book that share exactly the same asymmetry and somehow, when it comes to risk, produce the same type of protection and help in the harnessing of antifragility. They all look remarkably similar.
Let us take a peek at a few domains. With personal risks, you can easily barbell yourself by removing the chances of ruin in any area. I am personally completely paranoid about certain risks, then very aggressive with others. The rules are: no smoking, no sugar (particularly fructose), no motorcycles, no bicycles in town or more generally outside a traffic-free area such as the Sahara desert, no mixing with the Eastern European mafias, and no getting on a plane not flown by a professional pilot (unless there is a co-pilot). Outside of these I can take all manner of professional and personal risks, particularly those in which there is no risk of terminal injury.
In social policy, it consists in protecting the very weak and letting the strong do their job, rather than helping the middle class to consolidate its privileges, thus blocking evolution and bringing all manner of economic problems that tend to hurt the poor the most.
Before the United Kingdom became a bureaucratic state, it was barbelled into adventurers (both economically and physically) and an aristocracy. The aristocracy didn’t really have a major role except to help keep some sense of caution while the adventurers roamed the planet in
search of trading opportunities, or stayed home and tinkered with machinery. Now the City of London is composed of bourgeois bohemian bonus earners.
My writing approach is as follows: on one hand a literary essay that can be grasped by anyone and on the other technical papers, nothing in between—such as interviews with journalists or newspaper articles or op-ed pieces, outside of the requirements of publishers.
The reader may remember the exercise regimen of
Chapter 2
, which consists in going for the maximum weight one can lift, then nothing, compared to other alternatives that entail less intense but very long hours in the gym. This, supplemented with effortless long walks, constitutes an exercise barbell.
More barbells. Do crazy things (break furniture once in a while), like the Greeks during the later stages of a drinking symposium, and stay “rational” in larger decisions. Trashy gossip magazines and classics or sophisticated works; never middlebrow stuff. Talk to either undergraduate students, cab drivers, and gardeners or the highest caliber scholars; never to middling-but-career-conscious academics. If you dislike someone, leave him alone or eliminate him; don’t attack him verbally.
2
So take for now that a barbell strategy with respect to randomness results in achieving antifragility thanks to the mitigation of fragility, the clipping of downside risks of harm—reduced pain from adverse events, while keeping the benefits of potential gains.
To return to finance, the barbell does not need to be in the form of investment in inflation-protected cash and the rest in speculative securities. Anything that removes the risk of ruin will get us to such a barbell. The legendary investor Ray Dalio has a rule for someone making speculative bets: “Make sure that the probability of the unacceptable (i.e., the risk of ruin) is nil.” Such a rule gets one straight to the barbell.
3
Another idea from Rory Sutherland: the U.K. guidelines for patients with mild problems coming from alcohol are to reduce the daily consumption to under a certain number of grams of alcohol per day. But the optimal policy is to avoid alcohol three times a week (hence give the liver a lengthy vacation) then drink liberally the remaining four. The mathematics behind this and other barbell ideas are outlined with the later discussion of Jensen’s inequality.
Most items on the right of the Triad have a barbell component, necessary, but not sufficient.
So just as Stoicism is the domestication, not the elimination, of emotions, so is the barbell a domestication, not the elimination, of uncertainty.
1
There is evidence of such a barbell strategy but no clarity about the theory behind it—evolutionary theorists enjoy narratives but I prefer evidence. We are not sure if the strategy of extrapair copulation in the animal domain actually enhances fitness. So the barbell—accountant plus cheating—while it exists, might not be aiming at the improvement of the species; it can be just be for “fun” at low risk.
2
In finance, I stood in 2008 for banks to be nationalized rather than bailed out, and other forms of speculation not entailing taxpayers left free. Nobody was getting my barbell idea—some hated the libertarian aspect, others hated the nationalization part. Why? Because the halfway—here, the regulation of both—doesn’t work, as it can be gamed by a good lawyer. Hedge funds need to be unregulated and banks nationalized, as a barbell, rather than the horror we now have.
3
Domain dependence again. People find insuring their house a necessity, not something to be judged against a financial strategy, but when it comes to their portfolios, because of the way things are framed in the press, they don’t look at them in the same way. They think that my barbell idea is a strategy that needs to be examined for its
potential return
as an investment. That’s not the point. The barbell is simply an idea of insurance of survival; it is a necessity, not an option.


================================================================================
CHAPTER/SECTION 55 (Item 58)
================================================================================

BOOK IV
Optionality, Technology, and the Intelligence of Antifragility
N
ow we get into innovation, the concept of options and optionality. How to enter the impenetrable and completely dominate it, conquer it.


================================================================================
CHAPTER/SECTION 56 (Item 59)
================================================================================

DO YOU REALLY KNOW WHERE YOU ARE GOING?
Summa Theologiae
by Saint Thomas Aquinas is the kind of book that no longer exists, the book-as-monument, a
summa
being the comprehensive treatment of a given discipline, while freeing it from the structure the authorities had given it before—the antitextbook. In this case its subject matter is theology, meaning everything philosophical, and it comments on every body of knowledge as it relates to his arguments. And it reflects—and largely directs—the thought of the Middle Ages.
Quite a departure from the book with a simple closed-end subject matter.
The erudite mind’s denigration of antifragility is best seen in a sentence that dominates the
Summa,
being repeated in many places, one variant of which is as follows: “An agent does not move except out of intention for an end,”
agen autem non movet nisi ex intentione finis
. In other words, agents are supposed to know where they are going, a teleological argument (from
telos,
“based on the end”) that originates with Aristotle. Everyone, including the Stoics, but excluding the skeptics, fell
for such teleological arguments intellectually, but certainly not in action. Incidentally, it is not Aristotle whom Aquinas is quoting—he calls him the Philosopher—but the Arab synthesizer of Aristotle’s thinking, Ibn Rushd, also known as Averroes, whom Aquinas calls the Commentator. And the Commentator has caused a great deal of damage. For Western thought is vastly more Arabian than is recognized, while post-Medieval Arabs have managed to escape medieval rationalism.
This entire heritage of thinking, grounded in the sentence “An agent does not move except out of intention for an end,” is where the most pervasive human error lies, compounded by two or more centuries of the illusion of unconditional scientific understanding. This error is also the most fragilizing one.
The Teleological Fallacy
So let us call here the teleological fallacy the illusion that you know exactly where you are going, and that you knew exactly where you were going in the past, and that others have succeeded in the past by knowing where they were going.
The rational flâneur is someone who, unlike a tourist, makes a decision at every step to revise his schedule, so he can imbibe things based on new information, what Nero was trying to practice in his travels, often guided by his sense of smell. The flâneur is not a prisoner of a plan. Tourism, actual or figurative, is imbued with the teleological illusion; it assumes completeness of vision and gets one locked into a hard-to-revise program, while the flâneur continuously—and, what is crucial, rationally—modifies his targets as he acquires information.
Now a warning: the opportunism of the flâneur is great in life and business—but not in personal life and matters that involve others. The opposite of opportunism in human relations is loyalty, a noble sentiment—but one that needs to be invested in the right places, that is, in human relations and moral commitments.
The error of thinking you know exactly where you are going and assuming that you know
today
what your preferences will be
tomorrow
has an associated one. It is the illusion of thinking that
others,
too, know where they are going, and that they would tell you what they want if you just asked them.
Never ask people what they want, or where they want to go, or where they think they should go, or, worse, what they think they will
desire tomorrow. The strength of the computer entrepreneur Steve Jobs was precisely in distrusting market research and focus groups—those based on asking people what they want—and following his own imagination. His modus was that people don’t know what they want until you provide them with it.
This ability to switch from a course of action is an
option
to change. Options—and optionality, the character of the option—are the topic of
Book IV
. Optionality will take us many places, but at the core, an option is what makes you antifragile and allows you to benefit from the positive side of uncertainty, without a corresponding serious harm from the negative side.
America’s Principal Asset
And it is optionality that makes things work and grow—but it takes a certain type of person for that. Many people keep deploring the low level of formal education in the United States (as defined by, say, math grades). Yet these people fail to realize that the
new
comes from here and gets imitated elsewhere. And it is not thanks to universities, which obviously claim a lot more credit than their accomplishments warrant.
Like Britain in the Industrial Revolution, America’s asset is, simply, risk taking and the use of optionality, this remarkable ability to engage in rational forms of trial and error, with no comparative shame in failing, starting again, and repeating failure. In modern Japan, by contrast, shame comes with failure, which causes people to hide risks under the rug, financial or nuclear, making small benefits while sitting on dynamite, an attitude that strangely contrasts with their traditional respect for fallen heroes and the so-called nobility of failure.
Book IV
will take this idea to its natural conclusion and will show evidence (ranging from medieval architecture to medicine, engineering, and innovation) that, perhaps, our greatest asset is the one we distrust the most: the built-in antifragility of certain risk-taking systems.


================================================================================
CHAPTER/SECTION 57 (Item 60)
================================================================================

CHAPTER 12
Thales’ Sweet Grapes
Where we discuss the idea of doing instead of walking the Great Walk—The idea of a free option—Can a philosopher be called nouveau riche?
An anecdote appears in Aristotle’s
Politics
concerning the pre-Socratic philosopher and mathematician Thales of Miletus. This story, barely covering half a page, expresses both antifragility and its denigration and introduces us to optionality. The remarkable aspect of this story is that Aristotle, arguably the most influential thinker of all time, got the central point of his own anecdote exactly backward. So did his followers, particularly after the Enlightenment and the scientific revolution. I am not saying this to denigrate the great Aristotle, but to show that intelligence makes you discount antifragility and ignore the power of optionality.
Thales was a philosopher, a Greek-speaking Ionian of Phoenician stock from the coastal town of Miletus in Asia Minor, and like
some
philosophers, he enjoyed what he was doing. Miletus was a trading post and had the mercantile spirit usually attributed to Phoenician settlements. But Thales, as a philosopher, was characteristically impecunious. He got tired of his buddies with more transactional lives hinting at him that “those who can, do, and others philosophize.” He performed the following prowess: he put a down payment on the seasonal use of every olive press in the vicinity of Miletus and Chios, which he got at low rent.
The harvest turned out to be extremely bountiful and there was demand for olive presses, so he released the owners of olive presses on his own terms, building a substantial fortune in the process. Then he went back to philosophizing.
What he collected was large, perhaps not enough to make him massively wealthy, but enough to make the point—to others but also, I suspect, to himself—that he talked the talk and was truly above, not below, wealth. This kind of sum I’ve called in my vernacular “f*** you money”—a sum large enough to get most, if not all, of the advantages of wealth (the most important one being independence and the ability to only occupy your mind with matters that interest you) but not its side effects, such as having to attend a black-tie charity event and being forced to listen to a polite exposition of the details of a marble-rich house renovation. The worst side effect of wealth is the social associations it forces on its victims, as people with big houses tend to end up socializing with other people with big houses. Beyond a certain level of opulence and independence, gents tend to be less and less personable and their conversation less and less interesting.
The story of Thales has many morals, all of them linked to asymmetry (and the construction of an antifragile payoff). The central one is related to the following account by Aristotle:
“But from his knowledge of astronomy he had observed while it was still winter that there was going to be a large crop of olives …”
So for Aristotle, clearly, the stated reason was Thales’ superior knowledge.
Superior knowledge?
Thales put himself in a position to take advantage of his
lack
of knowledge—and the secret property of the asymmetry. The key to our message about this upside-downside asymmetry is that he did not need to understand too much the messages from the stars.
Simply, he had a contract that is the archetype of what an asymmetry is, perhaps the only explicit asymmetry you can find in its purest form. It is an option, “the right but not the obligation” for the buyer and, of course, “the obligation but not the right” for the other party, called the seller. Thales had the right—but not the obligation—to use the olive presses in case there would be a surge in demand; the other party had the obligation, not the right. Thales paid a small price for that privilege, with a limited loss and large possible outcome. That was the very first option on record.
The option is an agent of antifragility.


================================================================================
CHAPTER/SECTION 58 (Item 61)
================================================================================

OPTION AND ASYMMETRY
The olive press episode took place about six hundred years before Seneca’s writings on his tables with ivory legs, and three hundred years before Aristotle.
The formula in
Chapter 10
was:
antifragility
equals
more to gain than to lose
equals
more upside than downside
equals
asymmetry (favorable)
equals
likes volatility
. And if you make more when you are right than you are hurt when you are wrong, then you will benefit, in the long run, from volatility (and the reverse). You are only harmed if you repeatedly pay too much for the option. But in this case Thales patently got a good deal—and we will see in the rest of
Book IV
that we don’t pay for the options given to us by nature and technological innovation. Financial options may be expensive because people know they are options and
someone
is selling them and charging a price—but most interesting options are free, or at the worst, cheap.
Centrally, we just don’t need to
know
what’s going on when we buy cheaply—when we have the asymmetry working for us. But this property goes beyond buying cheaply: we do not need to understand things when we have some edge. And the edge from optionality is in the larger payoff when you are right, which makes it unnecessary to be right too often.
The Options of Sweet Grapes
The option I am talking about is no different from what we call options in daily life—the vacation resort with the most options is more likely to provide you with the activity that satisfies your tastes, and the one with the narrowest choices is likely to fail. So you need
less information,
that is, less knowledge, about the resort with broader options.
There are other hidden options in our story of Thales. Financial independence, when used intelligently, can make you robust; it gives you options and allows you to make the right choices. Freedom is the ultimate option.
Further, you will never get to know yourself—your real preferences—unless you face options and choices. Recall that the volatility of life helps provide information to us about others, but also about ourselves. Plenty of people are poor against their initial wish and only become robust by spinning a story that it was their choice to be poor—as if they had the
option. Some are genuine; many don’t really have the option—they constructed it. Sour grapes—as in Aesop’s fable—is when someone convinces himself that the grapes he cannot reach are sour. The essayist Michel de Montaigne sees the Thales episode as a story of immunity to sour grapes: you need to know whether you
do not like
the pursuit of money and wealth because you genuinely do not like it, or because you are rationalizing your inability to be successful at it with the argument that wealth is not a good thing because it is bad for one’s digestive system or disturbing for one’s sleep or other such arguments. So the episode enlightened Thales about his own choices in life—how genuine his pursuit of philosophy was. He had other
options.
And, it is worth repeating, options, any options, by allowing you more upside than downside, are vectors of antifragility.
1
Thales, by funding his own philosophy, became his own Maecenas, perhaps the highest rank one can attain: being both independent and intellectually productive. He now had even more
options.
He did not have to tell others—those funding him—where he was going, because he himself perhaps didn’t even know where he was heading. Thanks to the power of options, he didn’t have to.
The next few vignettes will help us go deeper into the notion of
optionality
—the property of option-like payoffs and option-like situations.
Saturday Evening in London
It is Saturday afternoon in London. I am coping with a major source of stress: where to go tonight. I am fond of the brand of the unexpected one finds at parties (going to parties has optionality, perhaps the best advice for someone who wants to benefit from uncertainty with low downside). My fear of eating alone in a restaurant while rereading the same passage of Cicero’s
Tusculan Discussions
that, thanks to its pocket-fitting size, I have been carrying for a decade (and reading about three and a half pages per year) was alleviated by a telephone call. Someone, not a close friend, upon hearing that I was in town, invited me to a gathering in
Kensington, but somehow did not ask me to commit, with “drop by if you want.” Going to the party is better than eating alone with Cicero’s
Tusculan Discussions,
but these are not very interesting people (many are involved in the City, and people employed in financial institutions are rarely interesting and even more rarely likable) and I know I can do better, but I am not certain to be able to do so. So I can call around: if I can do better than the Kensington party, with, say, a dinner with any of my real friends, I would do that. Otherwise I would take a black taxi to Kensington. I have an
option,
not an obligation. It came at no cost since I did not even solicit it. So I have a small, nay, nonexistent, downside, a big upside.
This is a free option because there is no real cost to the privilege.
Your Rent
Second example: assume you are the official tenant of a rent-controlled apartment in New York City, with, of course, wall-to-wall bookshelves. You have the
option
of staying in it as long as you wish, but no obligation to do so. Should you decide to move to Ulan Bator, Mongolia, and start a new life there, you can simply notify the landlord a certain number of days in advance, and thank you goodbye. Otherwise, the landlord is obligated to let you live there somewhat permanently, at a predictable rent. Should rents in town increase enormously, and real estate experience a bubble-like explosion, you are largely protected. On the other hand, should rents collapse, you can easily switch apartments and reduce your monthly payments—or even buy a new apartment and get a mortgage with lower monthly payments.
So consider the asymmetry. You benefit from lower rents, but are not hurt by higher ones. How? Because here again, you have an option, not an obligation. In a way, uncertainty increases the worth of such privilege. Should you face a high degree of uncertainty about future outcomes, with possible huge decreases in real estate value, or huge possible increases in them, your option would become more valuable. The more uncertainty, the more valuable the option.
Again, this is an embedded option, hidden as there is no cost to the privilege.
Asymmetry
Let us examine once again the asymmetry of Thales—along with that of any option. In
Figure 5
, the horizontal axis represents the rent, the vertical axis the corresponding profits in thekels.
Figure 5
shows the asymmetry: in this situation, the payoff is larger one way (if you are right, you “earn big time”) than the other (if you are wrong, you “lose small”).
FIGURE 5
. Thales’ antifragility. He pays little to get a huge potential. We can see the asymmetry between upside and downside.
The vertical axis in
Figure 5
represents a function of the rent for oil presses (the payoff from the option). All the reader needs to note from the picture is the nonlinearity (that is, the asymmetry, with more upside than downside; asymmetry is a form of nonlinearity).
Things That Like Dispersion
One property of the option: it does not care about the average outcome, only the favorable ones (since the downside doesn’t count beyond a certain point). Authors, artists, and even philosophers are much better off having a very small number of fanatics behind them than a large number of people who appreciate their work. The number of persons who dislike the work don’t count—there is no such thing as the
opposite
of buying your book, or the equivalent of losing points in a soccer game, and this absence of negative domain for book sales provides the author with a measure of optionality.
Further, it helps when supporters are both enthusiastic and influential.
Wittgenstein, for instance, was largely considered a lunatic, a strange bird, or just a b***t operator by those whose opinion didn’t count (he had almost no publications to his name). But he had a small number of cultlike followers, and some, such as Bertrand Russell and J. M. Keynes, were massively influential.
Beyond books, consider this simple heuristic: your work and ideas, whether in politics, the arts, or other domains, are antifragile if, instead of having one hundred percent of the people finding your mission acceptable or mildly commendable, you are better off having a high percentage of people disliking you and your message (even intensely), combined with a low percentage of extremely loyal and enthusiastic supporters. Options like dispersion of outcomes and don’t care about the average too much.
Another business that does not care about the average but rather the dispersion around the average is the luxury goods industry—jewelry, watches, art, expensive apartments in fancy locations, expensive collector wines, gourmet farm-raised probiotic dog food, etc. Such businesses only care about the pool of funds available to the very rich. If the population in the Western world had an average income of fifty thousand dollars, with no inequality at all, luxury goods sellers would not survive. But if the average stays the same but with a high degree of inequality, with some incomes higher than two million dollars, and potentially some incomes higher than ten million, then the business has plenty of customers—even if such high incomes are offset by masses of people with lower incomes. The “tails” of the distribution on the higher end of the income brackets, the extreme, are much more determined by changes in inequality than changes in the average. It gains from dispersion, hence is antifragile. This explains the bubble in real estate prices in Central London, determined by inequality in Russia and the Arabian Gulf and totally independent of the real estate dynamics in Britain. Some apartments, those for the very rich, sell for twenty times the average per square foot of a building a few blocks away.
Harvard’s former president Larry Summers got in trouble (clumsily) explaining a version of the point and lost his job in the aftermath of the uproar. He was trying to say that males and females have equal intelligence, but the male population has more variations and dispersion (hence volatility), with more highly unintelligent men, and more highly intelligent ones. For Summers, this explained why men were overrepresented
in the scientific and intellectual community (and also why men were overrepresented in jails or failures). The number of successful scientists depends on the “tails,” the extremes, rather than the average. Just as an option does not care about the adverse outcomes, or an author does not care about the haters.
No one at present dares to state the obvious: growth in society may not come from raising the average the Asian way, but from increasing the number of people in the “tails,” that small, very small number of risk takers crazy enough to have ideas of their own, those endowed with that very rare ability called imagination, that rarer quality called courage, and who make things happen.


================================================================================
CHAPTER/SECTION 59 (Item 62)
================================================================================

THE THALESIAN AND THE ARISTOTELIAN
Now some philosophy. As we saw with the exposition of the Black Swan problem earlier in
Chapter 8
, the decision maker focuses on the payoff, the consequence of the actions (hence includes asymmetries and nonlinear effects). The Aristotelian focuses on being right and wrong—in other words, raw logic. They intersect less often than you think.
Aristotle made the mistake of thinking that knowledge about the event (future crop, or price of the rent for oil presses, what we showed on the horizontal axis) and making profits out of it (vertical) are the same thing. And here, because of asymmetry, the two are not, as is obvious in the graph. As Fat Tony will assert in
Chapter 14
, “they are not the same thing” (pronounced “ting”).
How to Be Stupid
If you “have optionality,” you don’t have much need for what is commonly called intelligence, knowledge, insight, skills, and these complicated things that take place in our brain cells. For you don’t have to be right that often. All you need is the wisdom to
not do
unintelligent things to hurt yourself (some acts of omission) and recognize favorable outcomes when they occur. (The key is that your assessment doesn’t need to be made beforehand, only after the outcome.)
This property allowing us to be stupid, or, alternatively, allowing us to get more results than the knowledge may warrant, I will call the “philosopher’s stone” for now, or “convexity bias,” the result of a mathematical
property called Jensen’s inequality. The mechanics will be explained later, in
Book V
when we wax technical, but take for now that evolution can produce astonishingly sophisticated objects without intelligence, simply thanks to a combination of optionality and some type of a selection filter, plus some randomness, as we see next.
Nature and Options
The great French biologist François Jacob introduced into science the notion of options (or option-like characteristics) in natural systems, thanks to trial and error, under a variant called
bricolage
in French. Bricolage is a form of trial and error close to
tweaking,
trying to make do with what you’ve got by recycling pieces that would be otherwise wasted.
Jacob argued that even within the womb, nature knows how to select: about half of all embryos undergo a spontaneous abortion—easier to do so than design the perfect baby by blueprint. Nature simply keeps what it likes if it meets its standards or does a California-style “fail early”—it has an option and uses it. Nature understands optionality effects vastly better than humans, and certainly better than Aristotle.
Nature is all about the exploitation of optionality; it illustrates how optionality is a substitute for intelligence.
2
Let us call trial and error
tinkering
when it presents small errors and large gains. Convexity, a more precise description of such positive asymmetry, will be explained in a bit of depth in
Chapter 18
.
3
The graph in
Figure 7
best illustrates the idea present in California, and voiced by Steve Jobs at a famous speech: “Stay hungry, stay foolish.” He probably meant “Be crazy but retain the rationality of choosing the upper bound when you see it.” Any trial and error can be seen as the expression of an option, so long as one is capable of identifying a favorable result and exploiting it, as we see next.
FIGURE 6
. The mechanism of optionlike trial and error (the fail-fast model), a.k.a. convex tinkering. Low-cost mistakes, with known maximum losses, and large potential payoff (unbounded). A central feature of positive Black Swans: the gains are unbounded (unlike a lottery ticket), or, rather, with an unknown limit; but the losses from errors are limited and known.
FIGURE 7
. Same situation as in
Figure 6
, but in Extremistan the payoff can be monstrous.
The Rationality
To crystallize, take this description of an option:
Option = asymmetry + rationality
The rationality part lies in keeping what is good and ditching the bad, knowing to take the profits. As we saw, nature has a filter to keep the good baby and get rid of the bad. The difference between the antifragile and the fragile lies there. The fragile has no option. But the antifragile needs to select what’s best—the best option.
It is worth insisting that the most wonderful attribute of nature is the rationality with which it selects its options and picks the best for itself—thanks to the testing process involved in evolution. Unlike the researcher afraid of doing something different, it sees an option—the asymmetry—when there is one. So it ratchets up—biological systems get locked in a state that is better than the previous one, the path-dependent property I mentioned earlier. In trial and error, the rationality consists in not rejecting something that is markedly better than what you had before.
As I said, in business, people pay for the option when it is identified and mapped in a contract, so explicit options tend to be expensive to purchase, much like insurance contracts. They are often overhyped. But because of the domain dependence of our minds, we don’t recognize it in other places, where these options tend to remain underpriced or not priced at all.
I learned about the asymmetry of the option in class at the Wharton School, in the lecture on financial options that determined my career, and immediately realized that the professor did not himself see the implications. Simply, he did not understand nonlinearities and the fact that the optionality came from some asymmetry! Domain dependence: he missed it in places where the textbook did not point to the asymmetry—he understood optionality mathematically, but not really outside the equation. He did not think of trial and error as options. He did not think of model error as negative options. And, thirty years later, little has changed in the understanding of the asymmetries by many who, ironically, teach the subject of options.
4
An option hides where we don’t want it to hide. I will repeat that options benefit from variability, but also from situations in which errors carry small costs. So these errors are like options—in the long run, happy errors bring gains, unhappy errors bring losses. That is exactly what Fat Tony was taking advantage of: certain models can have only unhappy errors, particularly derivatives models and other fragilizing situations.
What also struck me was the option blindness of us humans and intellectuals. These options were, as we will see in the next chapter, out there in plain sight.
Life Is Long Gamma
Indeed, in plain sight.
One day, my friend Anthony Glickman, a rabbi and Talmudic scholar turned option trader, then turned again rabbi and Talmudic scholar (so far), after one of these conversations about how this optionality applies to everything around us, perhaps after one of my tirades on Stoicism, calmly announced: “Life is long gamma.” (To repeat, in the jargon, “long” means “benefits from” and “short” “hurt by,” and “gamma” is a name for the nonlinearity of options, so “long gamma” means “benefits from volatility and variability.” Anthony even had as his mail address “@longgamma.com.”)
There is an ample academic literature trying to convince us that options are not rational to own because
some
options are overpriced, and they are deemed overpriced according to business school methods of computing risks that do not take into account the possibility of rare events. Further, researchers invoke something called the “long shot bias” or lottery effects by which people stretch themselves and overpay for these long shots in casinos and in gambling situations. These results, of course, are charlatanism dressed in the garb of science, with non–risk takers who, Triffat-style, when they want to think about risk, only think of casinos. As in other treatments of uncertainty by economists, these are marred with mistaking the randomness of life for the well-tractable one of the casinos, what I call the “ludic fallacy” (after
ludes,
which means “games” in Latin)—the mistake we saw made by the blackjack fellow of
Chapter 7
. In fact, criticizing all bets on rare events based on the fact that lottery tickets are overpriced is as foolish as criticizing all risk taking on grounds that casinos make money in the long run from
gamblers, forgetting that we are here because of risk taking
outside
the casinos. Further, casino bets and lottery tickets also have a known maximum upside—in real life, the sky is often the limit, and the difference between the two cases can be significant.
Risk taking
ain’t
gambling, and optionality
ain’t
lottery tickets.
In addition, these arguments about “long shots” are ludicrously cherry-picked. If you list the businesses that have generated the most wealth in history, you would see that they all have optionality. There is unfortunately the optionality of people stealing options from others and from the taxpayer (as we will see in the ethical section in
Book VII
), such as CEOs of companies with upside and no downside to themselves. But the largest generators of wealth in America historically have been, first, real estate (investors have the option at the expense of the banks), and, second, technology (which relies almost completely on trial and error). Further, businesses with negative optionality (that is, the opposite of having optionality) such as banking have had a horrible performance through history: banks lose periodically every penny made in their history thanks to blowups.
But these are all dwarfed by the role of optionality in the two evolutions: natural and scientific-technological, the latter of which we will examine in
Book IV
.
Roman Politics Likes Optionality
Even political systems follow a form of rational tinkering, when people are rational hence take the better option: the Romans got their political system by tinkering, not by “reason.” Polybius in his
Histories
compares the Greek legislator Lycurgus, who constructed his political system while “untaught by adversity,” to the more experiential Romans, who, a few centuries later, “have not reached it by
any process of reasoning
[emphasis mine], but by the discipline of many struggles and troubles, and always choosing the best by the light of the experience gained in disaster.”
Next
Let me summarize. In
Chapter 10
we saw the foundational asymmetry as embedded in Seneca’s ideas: more upside than downside and vice versa. This chapter refined the point and presented a manifestation of
such asymmetry in the form of an option, by which one can take the upside if one likes, but without the downside. An option is the weapon of antifragility.
The other point of the chapter and
Book IV
is that the option is a substitute for knowledge—actually I don’t quite understand what sterile knowledge is, since it is necessarily vague and sterile. So I make the bold speculation that many things we think are derived by skill come largely from options, but well-used options, much like Thales’ situation—and much like nature—rather than from what we claim to be understanding.
The implication is nontrivial. For if you think that education causes wealth, rather than being a result of wealth, or that intelligent actions and discoveries are the result of intelligent ideas, you will be in for a surprise. Let us see what kind of surprise.
1
I suppose that the main benefit of being rich (over just being independent) is to be able to despise rich people (a good concentration of whom you find in glitzy ski resorts) without any sour grapes. It is even sweeter when these farts don’t know that you are richer than they are.
2
We will use nature as a model to show how its operational outperformance arises from optionality rather than intelligence—but let us not fall for the naturalistic fallacy: ethical rules do not have to spring from optionality.
3
Everyone talks about luck and about trial and error, but it has led to so little difference. Why? Because it is not about luck, but about optionality. By definition luck cannot be exploited; trial and error can lead to errors. Optionality is about getting the upper half of luck.
4
I usually hesitate to discuss my career in options, as I worry that the reader will associate the idea with finance rather than the more scientific applications. I go ballistic when I use technical insights derived from derivatives and people mistake it for a financial discussion—these are only techniques, portable techniques, very portable techniques, for Baal’s sake!


================================================================================
CHAPTER/SECTION 60 (Item 63)
================================================================================

CHAPTER 13
Lecturing Birds on How to Fly
Finally, the wheel—Proto–Fat Tony thinking—The central problem is that birds rarely write more than ornithologists—Combining stupidity with wisdom rather than the opposite
Consider the story of the wheeled suitcase.
I carry a large wheeled suitcase mostly filled with books on almost all my travels. It is heavy (books that interest me when I travel always happen to be in hardcover).
In June 2012, I was rolling that generic, heavy, book-filled suitcase outside the JFK international terminal and, looking at the small wheels at the bottom of the case and the metal handle that helps pull it, I suddenly remembered the days when I had to haul my book-stuffed luggage through the very same terminal, with regular stops to rest and let the lactic acid flow out of my sore arms. I could not afford a porter, and even if I could, I would not have felt comfortable doing it. I have been going through the same terminal for three decades, with and without wheels, and the contrast was eerie. It struck me how lacking in imagination we are: we had been putting our suitcases on top of a cart with wheels, but nobody thought of putting tiny wheels directly under the suitcase.
Can you imagine that it took close to six thousand years between the invention of the wheel (by, we assume, the Mesopotamians) and this brilliant implementation (by some luggage maker in a drab industrial
suburb)? And billions of hours spent by travelers like myself schlepping luggage through corridors full of rude customs officers.
Worse, this took place three decades or so after we put a man on the moon. And consider all this sophistication used in sending someone into space, and its totally negligible impact on my life, and compare it to this lactic acid in my arms, pain in my lower back, soreness in the palms of my hands, and sense of helplessness in front of a long corridor. Indeed, though extremely consequential, we are talking about something trivial: a very simple technology.
But the technology is only trivial retrospectively—not prospectively. All those brilliant minds, usually disheveled and rumpled, who go to faraway conferences to discuss Gödel, Shmodel, Riemann’s Conjecture, quarks, shmarks, had to carry their suitcases through airport terminals, without thinking about applying their brain to such an insignificant transportation problem. (We said that the intellectual society rewards “difficult” derivations, compared to practice in which there is no penalty for simplicity.) And even if these brilliant minds had applied their supposedly overdeveloped brains to such an obvious and trivial problem, they probably would not have gotten anywhere.
This tells us something about the way we map the future. We humans lack imagination, to the point of not even knowing what tomorrow’s important things look like. We use randomness to spoon-feed us with discoveries—which is why antifragility is necessary.
The story of the wheel itself is even more humbling than that of the suitcase: we keep being reminded that the Mesoamericans did not invent the wheel. They did. They had wheels. But the wheels were on small toys for children. It was just like the story of the suitcase: the Mayans and Zapotecs did not make the leap to the application. They used vast quantities of human labor, corn maize, and lactic acid to move gigantic slabs of stone in the flat spaces ideal for pushcarts and chariots where they built their pyramids. They even rolled them on logs of wood. Meanwhile, their small children were rolling their toys on the stucco floors (or perhaps not even doing that, as the toys might have been solely used for mortuary purposes).
The same story holds for the steam engine: the Greeks had an operating version of it, for amusement, of course: the aeolipyle, a turbine that spins when heated, as described by Hero of Alexandria. But it took the Industrial Revolution for us to discover this earlier discovery.
Just as great geniuses invent their predecessors, practical innovations create their theoretical ancestry.
There is something sneaky in the process of discovery and implementation—something people usually call evolution. We are managed by small (or large) accidental changes, more accidental than we admit. We talk big but hardly have any imagination, except for a few visionaries who seem to recognize the optionality of things. We need some randomness to help us out—with a double dose of antifragility. For randomness plays a role at two levels: the invention and the implementation. The first point is not overly surprising, though we play down the role of chance, especially when it comes to our own discoveries.
But it took me a lifetime to figure out the second point: implementation does not necessarily proceed from invention. It, too, requires luck and circumstances. The history of medicine is littered with the strange sequence of discovery of a cure followed, much later, by the implementation—as if the two were completely separate ventures, the second harder, much harder, than the first. Just taking something to market requires struggling against a collection of naysayers, administrators, empty suits, formalists, mountains of details that invite you to drown, and one’s own discouraged mood on occasion. In other words, to identify the option (again, there is this option blindness). This is where all you need is the wisdom to realize what you have on your hands.
The Half-Invented.
For there is a category of things that we can call half-invented, and taking the half-invented into the invented is often the real breakthrough. Sometimes you need a visionary to figure out what to do with a discovery, a vision that he and only he can have. For instance, take the computer mouse, or what is called the graphical interface: it took Steve Jobs to put it on your desk, then laptop—only he had a vision of the dialectic between images and humans—later adding sounds to a trilectic. The things, as they say, that are “staring at us.”
Further, the simplest “technologies,” or perhaps not even technologies but tools, such as the wheel, are the ones that seem to run the world. In spite of the hype, what we call technologies have a very high mortality rate, as I will show in
Chapter 20
. Just consider that of all the means of transportation that have been designed in the past three thousand years or more since the attack weapons of the Hyksos and the drawings of Hero of Alexandria, individual transportation today is limited to bicycles
and cars (and a few variants in between the two). Even then, technologies seem to go backward and forward, with the more natural and less fragile superseding the technological. The wheel, born in the Middle East, seems to have disappeared after the Arab invasion introduced to the Levant a more generalized use of the camel and the inhabitants figured out that the camel was more robust—hence more efficient in the long run—than the fragile technology of the wheel. In addition, since one person could control six camels but only one carriage, the regression away from technology proved more economically sound.
Once More, Less Is More
This story of the suitcase came to tease me when I realized, looking at a porcelain coffee cup, that there existed a simple definition of fragility, hence a straightforward and practical testing heuristic: the simpler and more obvious the discovery, the less equipped we are to figure it out by complicated methods. The key is that the significant can only be revealed through practice. How many of these simple, trivially simple heuristics are currently looking and laughing at us?
The story of the wheel also illustrates the point of this chapter: both governments and universities have done very, very little for innovation and discovery, precisely because, in addition to their blinding rationalism, they look for the complicated, the lurid, the newsworthy, the narrated, the scientistic, and the grandiose, rarely for the wheel on the suitcase. Simplicity, I realized, does not lead to laurels.
Mind the Gaps
As we saw with the stories of Thales and the wheel, antifragility (thanks to the asymmetry effects of trial and error) supersedes intelligence. But
some
intelligence is needed. From our discussion on rationality, we see that all we need is the ability to accept that what we have on our hands is better than what we had before—in other words, to recognize the existence of the option (or “exercise the option” as people say in the business, that is, take advantage of a valuable alternative that is superior to what precedes it, with a certain gain from switching from one into the other, the only part of the process where rationality is required). And from the history of technology, this ability to use the option given to us by antifragility is not guaranteed: things can be looking at us for
a long time. We saw the gap between the wheel and its use. Medical researchers call such lag the “translational gap,” the time difference between formal discovery and first implementation, which, if anything, owing to excessive noise and academic interests, has been shown by Contopoulos-Ioannidis and her peers to be lengthening in modern times.
The historian David Wooton relates a gap of two centuries between the discovery of germs and the acceptance of germs as a cause of disease, a delay of thirty years between the germ theory of putrefaction and the development of antisepsis, and a delay of sixty years between antisepsis and drug therapy.
But things can get bad. In the dark ages of medicine, doctors used to rely on the naive rationalistic idea of a balance of humors in the body, and disease was assumed to originate with some imbalance, leading to a series of treatments that were perceived as needed to restore such balance. In her book on humors, Noga Arikha shows that after William Harvey demonstrated the mechanism of blood circulation in the 1620s, one would have expected that such theories and related practices should have disappeared. Yet people continued to refer to spirit and humors, and doctors continued to prescribe, for centuries more, phlebotomies (bloodletting), enemas (I prefer to not explain), and cataplasms (application of a moist piece of bread or cereal on inflamed tissue). This continued even after Pasteur’s evidence that germs were the cause of these infectious diseases.
Now, as a skeptical empiricist, I do not consider that resisting new technology is
necessarily
irrational: waiting for time to operate its testing might be a valid approach if one holds that we have an incomplete picture of things. This is what naturalistic risk management is about. However, it is downright irrational if one holds on to an old technology that is not naturalistic at all yet visibly harmful, or when the switch to a new technology (like the wheel on the suitcase) is obviously free of possible side effects that did not exist with the previous one. And resisting removal is downright incompetent and criminal (as I keep saying, removal of something non-natural does not carry long-term side effects; it is typically iatrogenics-free).
In other words, I do not give the resistance to the implementation of such discoveries any intellectual credit, or explain it by some hidden wisdom and risk management attitude: this is plainly mistaken. It partakes of the chronic lack of heroism and cowardice on the part of professionals:
few want to jeopardize their jobs and reputation for the sake of change.
Search and How Errors Can Be Investments
Trial and error has one overriding value people fail to understand: it is not really random, rather, thanks to optionality, it requires some rationality. One needs to be intelligent in recognizing the favorable outcome and knowing what to discard.
And one needs to be rational in not making trial and error completely random. If you are looking for your misplaced wallet in your living room, in a trial and error mode, you exercise rationality by not looking in the same place twice. In many pursuits, every trial, every failure provides additional information, each more valuable than the previous one—if you know what does not work, or where the wallet is not located. With every trial one gets closer to something, assuming an environment in which one knows exactly what one is looking for. We can, from the trial that fails to deliver, figure out progressively
where
to go.
I can illustrate it best with the modus operandi of Greg Stemm, who specializes in pulling long-lost shipwrecks from the bottom of the sea. In 2007, he called his (then) biggest find “the Black Swan” after the idea of looking for positive extreme payoffs. The find was quite sizable, a treasure with precious metals now worth a billion dollars. His Black Swan is a Spanish frigate called
Nuestra Señora de las Mercedes,
which was sunk by the British off the southern coast of Portugal in 1804. Stemm proved to be a representative hunter of positive Black Swans, and someone who can illustrate that such a search is a highly controlled form of randomness.
I met him and shared ideas with him: his investors (like mine at the time, as I was still involved in that business) were for the most part not programmed to understand that for a treasure hunter, a “bad” quarter (meaning expenses of searching but no finds) was not indicative of distress, as it would be with a steady cash flow business like that of a dentist or prostitute. By some mental domain dependence, people can spend money on, say, office furniture and not call it a “loss,” rather an investment, but would treat cost of search as “loss.”
Stemm’s method is as follows. He does an extensive analysis of the general area where the ship could be. That data is synthesized into a map
drawn with squares of probability. A search area is then designed, taking into account that they must have certainty that the shipwreck is not in a specific area before moving on to a lower probability area. It looks random but it is not. It is the equivalent of looking for a treasure in your house: every search has incrementally a higher probability of yielding a result, but only if you can be certain that the area you have searched does not hold the treasure.
Some readers might not be too excited about the morality of shipwreck-hunting, and could consider that these treasures are national, not private, property. So let us change domain. The method used by Stemm applies to oil and gas exploration, particularly at the bottom of the unexplored oceans, with a difference: in a shipwreck, the upside is limited to the value of the treasure, whereas oil fields and other natural resources are nearly unlimited (or have a very high limit).
Finally, recall my discussion of random drilling in
Chapter 6
and how it seemed superior to more directed techniques. This optionality-driven method of search is not foolishly random. Thanks to optionality, it becomes tamed and harvested randomness.
Creative and Uncreative Destructions
Someone who got a (minor) version of the point that generalized trial and error has, well,
errors,
but without much grasp of asymmetry (or what, since
Chapter 12
, we have been calling optionality), is the economist Joseph Schumpeter. He realized that some things need to break for the system to improve—what is labeled
creative destruction
—a notion developed, among so many other ones, by the philosopher Karl Marx and a concept discovered, we will show in
Chapter 17
, by Nietzsche. But a reading of Schumpeter shows that he did not think in terms of uncertainty and opacity; he was completely smoked by interventionism, under the illusion that governments could innovate by fiat, something that we will contradict in a few pages. Nor did he grasp the notion of layering of evolutionary tensions. More crucially, both he and his detractors (Harvard economists who thought that he did not know mathematics) missed the notion of antifragility as asymmetry (optionality) effects, hence the philosopher’s stone—on which, later—as the agent of growth. That is, they missed half of life.


================================================================================
CHAPTER/SECTION 61 (Item 64)
================================================================================

THE SOVIET-HARVARD DEPARTMENT OF ORNITHOLOGY
Now, since a very large share of technological know-how comes from the antifragility, the optionality, of trial and error, some people and some institutions want to hide the fact from us (and themselves), or downplay its role.
Consider two types of knowledge. The first type is not exactly “knowledge”; its ambiguous character prevents us from associating it with the strict definitions of knowledge. It is a way of doing things that we cannot really express in clear and direct language—it is sometimes called
apophatic
—but that we do nevertheless, and do well. The second type is more like what we call “knowledge”; it is what you acquire in school, can get grades for, can codify, what is explainable, academizable, rationalizable, formalizable, theoretizable, codifiable, Sovietizable, bureaucratizable, Harvardifiable, provable, etc.
The error of naive rationalism leads to overestimating the role and necessity of the second type, academic knowledge, in human affairs—and degrading the uncodifiable, more complex, intuitive, or experience-based type.
There is no proof against the statement that the role such explainable knowledge plays in life is so minor that it is not even funny.
We are very likely to believe that skills and ideas that we actually acquired by antifragile
doing,
or that came naturally to us (from our innate biological instinct), came from books, ideas, and reasoning. We get blinded by it; there may even be something in our brains that makes us suckers for the point. Let us see how.
I recently looked for definitions of technology. Most texts define it as
the application of scientific knowledge to practical projects
—leading us to believe in a flow of knowledge going chiefly, even exclusively, from lofty “science” (organized around a priestly group of persons with titles before their names) to lowly practice (exercised by uninitiated people without the intellectual attainments to gain membership into the priestly group).
So, in the corpus, knowledge is presented as derived in the following manner: basic research yields scientific knowledge, which in turn generates technologies, which in turn lead to practical applications, which in turn lead to economic growth and other seemingly interesting matters. The payoff from the “investment” in basic research will be partly directed to more investments in basic research, and the citizens will prosper
and enjoy the benefits of such knowledge-derived wealth with Volvo cars, ski vacations, Mediterranean diets, and long summer hikes in beautifully maintained public parks.
This is called the Baconian linear model, after the philosopher of science Francis Bacon; I am adapting its representation by the scientist Terence Kealey (who, crucially, as a biochemist, is a practicing scientist, not a historian of science) as follows:
Academia
→
Applied Science and Technology
→
Practice
While this model may be valid in some very narrow (but highly advertised instances), such as building the atomic bomb, the exact reverse seems to be true in most of the domains I’ve examined. Or, at least, this model is not guaranteed to be true and, what is shocking, we have no rigorous evidence that it is true. It may be that academia helps science and technology, which in turn help practice, but in unintended, nonteleological ways, as we will see later (in other words, it is
directed research
that may well be an illusion).
Let us return to the metaphor of the birds. Think of the following event: A collection of hieratic persons (from Harvard or some such place) lecture birds on how to fly. Imagine bald males in their sixties, dressed in black robes, officiating in a form of English that is full of jargon, with equations here and there for good measure. The bird flies. Wonderful confirmation! They rush to the department of ornithology to write books, articles, and reports stating that the bird has obeyed them, an impeccable causal inference. The Harvard Department of Ornithology is now indispensable for bird flying. It will get government research funds for its contribution.
Mathematics
→
Ornithological navigation and wing-flapping technologies
→
(ungrateful) birds fly
It also happens that birds write no such papers and books, conceivably because they are just birds, so we never get their side of the story. Meanwhile, the priests keep broadcasting theirs to the new generation of humans who are completely unaware of the conditions of the pre-Harvard lecturing days. Nobody discusses the possibility of the birds’ not needing lectures—and nobody has any incentive to look at the number of birds that fly without such help from the great scientific establishment.
The problem is that what I wrote above looks ridiculous, but a change of domain makes it look reasonable. Clearly, we never think that it is thanks to ornithologists that birds learn to fly—and if some people do hold such a belief, it would be hard for them to convince the birds. But why is it that when we anthropomorphize and replace “birds” with “men,” the idea that people learn to do things thanks to lectures becomes plausible? When it comes to human agency, matters suddenly become confusing to us.
So the illusion grows and grows, with government funding, tax dollars, swelling (and self-feeding) bureaucracies in Washington all devoted to helping birds fly better. Problems occur when people start cutting such funding—with a spate of accusations of killing birds by not helping them fly.
As per the Yiddish saying: “If the student is smart, the teacher takes the credit.” These illusions of contribution result largely from confirmation fallacies: in addition to the sad fact that history belongs to those who can write about it (whether winners or losers), a second bias appears, as those who write the accounts can deliver confirmatory facts (what has worked) but not a complete picture of what has worked and what has failed. For instance, directed research would tell you what has worked from funding (like AIDS drugs or some modern designer drugs), not what has failed—so you may have the impression that it fares better than random.
And of course iatrogenics is never part of the discourse. They never tell you if education hurt you in some places.
So we are blind to the possibility of the alternative process, or the role of such a process, a loop:
Random Tinkering (antifragile)
→
Heuristics (technology)
→
Practice and Apprenticeship
→
Random Tinkering (antifragile)
→
Heuristics (technology)
→
Practice and Apprenticeship …
In parallel to the above loop,
Practice
→
Academic Theories
→
Academic Theories
→
Academic Theories
→
Academic Theories … (with of course some exceptions, some accidental leaks, though these are indeed rare and overhyped and grossly generalized).
Now, crucially, one can detect the scam in the so-called Baconian model by looking at events in the days that preceded the Harvard lectures on flying and examining the birds. This is what I accidentally found (indeed, accidentally) in my own career as practitioner turned researcher in volatility, thanks to some lucky turn of events. But before that, let me explain epiphenomena and the arrow of education.


================================================================================
CHAPTER/SECTION 62 (Item 65)
================================================================================

EPIPHENOMENA
The Soviet-Harvard illusion (lecturing birds on flying and believing that the lecture is the cause of these wonderful skills) belongs to a class of causal illusions called
epiphenomena
. What are these illusions? When you spend time on the bridge of a ship or in the coxswain’s station with a large compass in front, you can easily develop the impression that the compass is directing the ship rather than merely reflecting its direction.
The lecturing-birds-how-to-fly effect is an example of epiphenomenal belief: we see a high degree of academic research in countries that are wealthy and developed, leading us to think uncritically that research is the generator of wealth. In an epiphenomenon, you don’t usually observe A without observing B with it, so you are likely to think that A causes B, or that B causes A, depending on the cultural framework or what seems plausible to the local journalist.
One rarely has the illusion that, given that so many boys have short hair, short hair determines gender, or that wearing a tie causes one to become a businessman. But it is easy to fall into other epiphenomena, particularly when one is immersed in a news-driven culture.
And one can easily see the trap of having these epiphenomena fuel action, then justify it retrospectively. A dictator—just like a government—will feel indispensable because the alternative is not easily visible, or is hidden by special interest groups. The Federal Reserve Bank of the United States, for instance, can wreak havoc on the economy yet feel convinced of its effectiveness. People are scared of the alternative.
Greed as a Cause
Whenever an economic crisis occurs, greed is pointed to as the cause, which leaves us with the impression that if we could go to the root of greed and extract it from life, crises would be eliminated. Further, we
tend to believe that greed is new, since these wild economic crises are new. This is an epiphenomenon: greed is much older than systemic fragility. It existed as far back as the eye can go into history. From Virgil’s mention of
greed of gold
and the expression
radix malorum est cupiditas
(from the Latin version of the New Testament), both expressed more than twenty centuries ago, we know that the same problems of greed have been propounded through the centuries, with no cure, of course, in spite of the variety of political systems we have developed since then. Trollope’s novel
The Way We Live Now,
published close to a century and a half ago, shows the exact same complaint of a resurgence of greed and con operators that I heard in 1988 with cries over of the “greed decade,” or in 2008 with denunciations of the “greed of capitalism.” With astonishing regularity, greed is seen as something (a) new and (b) curable. A Procrustean bed approach; we cannot change humans as easily as we can build greed-proof systems, and nobody thinks of simple solutions.
1
Likewise “lack of vigilance” is often proposed as the cause of an error (as we will see with the Société Générale story in
Book V
, the cause was size and fragility). But lack of vigilance is not the cause of the death of a mafia don; the cause of death is making enemies, and the cure is making friends.
Debunking Epiphenomena
We can dig out epiphenomena in the cultural discourse and consciousness by looking at the sequence of events and checking whether one always precedes the other. This is a method refined by the late Clive Granger (himself a refined gentleman), a well-deserved “Nobel” in Economics, that Bank of Sweden (Sveriges Riksbank) prize in honor of Alfred Nobel that has been given to a large number of fragilistas. It is the only rigorously scientific technique that philosophers of science can use to establish causation, as they can now extract, if not measure, the
so-called “Granger cause” by looking at sequences. In epiphenomenal situations, you end up seeing A and B together. But if you refine your analysis by considering the sequence, thus introducing a time dimension—which takes place first, A or B?—and analyze evidence, then you will see if truly A causes B.
Further, Granger had the great idea of studying differences, that is,
changes
in A and B, not just levels of A and B. While I do not believe that Granger’s method can lead me to believe that “A causes B” with certainty, it can most certainly help me debunk fake causation, and allow me to make the claim that “the statement that B causes A is wrong” or has insufficient evidence from the sequence.
The important difference between theory and practice lies precisely in the detection of the sequence of events and retaining the sequence in memory. If life is lived forward but remembered backward, as Kierkegaard observed, then books exacerbate this effect—our own memories, learning, and instinct have sequences in them. Someone standing today looking at events
without having lived them
would be inclined to develop illusions of causality, mostly from being mixed-up by the sequence of events. In real life, in spite of all the biases, we do not have the same number of asynchronies that appear to the student of history. Nasty history, full of lies, full of biases!
For one example of a trick for debunking causality: I am not even dead yet, but am already seeing distortions about my work. Authors theorize about some ancestry of my ideas, as if people read books then developed ideas, not wondering whether perhaps it is the other way around; people look for books that support their mental program. So one journalist (Anatole Kaletsky) saw the influence of Benoît Mandelbrot on my book
Fooled by Randomness,
published in 2001 when I did not know who Mandelbrot was. It is simple: the journalist noticed similarities of thought in one type of domain, and seniority of age, and immediately drew the false inference. He did not consider that like-minded people are inclined to hang together and that such intellectual similarity caused the relationship rather than the reverse. This makes me suspicious of the master-pupil relationships we read about in cultural history: about all the people that have been called my pupils have been my pupils because we were like-minded.
Cherry-picking (or the Fallacy of Confirmation)
Consider the tourist brochures used by countries to advertise their wares: you can expect that the pictures presented to you will look much, much better than anything you will encounter in the place. And the bias, the difference (for which humans correct, thanks to common sense), can be measured as
the country shown in the tourist brochure
minus
the country seen with your naked eyes
. That difference can be small, or large. We also make such corrections with commercial products, not overly trusting advertising.
But we don’t correct for the difference in science, medicine, and mathematics, for the same reasons we didn’t pay attention to iatrogenics. We are suckers for the sophisticated.
In institutional research, one can selectively report facts that confirm one’s story, without revealing facts that disprove it or don’t apply to it—so the public perception of science is biased into believing in the necessity of the highly conceptualized, crisp, and purified Harvardized methods. And statistical research tends to be marred with this one-sidedness. Another reason one should trust the disconfirmatory more than the confirmatory.
Academia is well equipped to tell us what it did for us, not what it did not—hence how indispensable its methods are. This ranges across many things in life. Traders talk about their successes, so one is led to believe that they are intelligent—not looking at the hidden failures. As to academic science: a few years ago, the great Anglo-Lebanese mathematician Michael Atiyah of string theory fame came to New York to raise funds for a research center in mathematics based in Lebanon. In his speech, he enumerated applications in which mathematics turned out to be useful for society and modern life, such as traffic signaling. Fine. But what about areas where mathematics led us to disaster (as in, say, economics or finance, where it blew up the system)? And how about areas out of the reach of mathematics? I thought right there of a different project: a catalog of where mathematics fails to produce results, hence causes harm.
Cherry-picking has optionality: the one telling the story (and publishing it) has the advantage of being able to show the confirmatory examples and completely ignore the rest—and the more volatility and dispersion, the rosier the best story will be (and the darker the worst story). Someone with optionality—the right to pick and choose his
story—is only reporting on what suits his purpose. You take the upside of your story and hide the downside, so only the sensational seems to count.
The real world relies on the intelligence of antifragility, but no university would swallow that—just as interventionists don’t accept that things can improve without their intervention. Let us return to the idea that universities generate wealth and the growth of useful knowledge in society. There is a causal illusion here; time to bust it.
1
Is democracy epiphenomenal? Supposedly, democracy works because of this hallowed rational decision making on the part of voters. But consider that democracy may be something completely accidental to something else, the side effect of people liking to cast ballots for completely obscure reasons, just as people enjoy expressing themselves just to express themselves. (I once put this question at a political science conference and got absolutely nothing beyond blank nerdy faces, not even a smile.)


================================================================================
CHAPTER/SECTION 63 (Item 66)
================================================================================

CHAPTER 14
When Two Things Are Not the “Same Thing”
Green lumber another “blue”—Where we look for the arrow of discovery—Putting Iraq in the middle of Pakistan—Prometheus never looked back
I am writing these lines in an appropriate place to think about the arrow of knowledge: Abu Dhabi, a city that sprang out of the desert, as if watered by oil.
It makes me queasy to see the building of these huge universities, funded by the oil revenues of governments, under the postulation that oil reserves can be turned into knowledge by hiring professors from prestigious universities and putting their kids through school (or, as is the case, waiting for their kids to feel the desire to go to school, as many students in Abu Dhabi are from Bulgaria, Serbia, or Macedonia getting a free education). Even better, they can, with a single check, import an entire school from overseas, such as the Sorbonne and New York University (among many more). So, in a few years, members of this society will be reaping the benefits of a great technological improvement.
It would seem a reasonable investment if one accepts the notion that
university knowledge generates economic wealth
. But this is a belief that comes more from superstition than empiricism. Remember the story of Switzerland in
Chapter 5
—a place with a very low level of formal education.
1
I wonder if my nausea comes from the feeling that these desert tribes are being separated from their money by the establishment that
has been sucking dry their resources and diverting them to administrators from Western universities. Their wealth came from oil, not from some vocational know-how, so I am certain that their spending on education is completely sterile and a great transfer of resources (rather than milking antifragility by forcing their citizens to make money naturally, through circumstances).
Where Are the Stressors?
There is something that escapes the Abu Dhabi model. Where are the stressors?
Recall the quote by Seneca and Ovid to the effect that sophistication is born of need, and success of difficulties—in fact many such variations, sourced in medieval days (such as
necessitas magistra
in Erasmus), found their way into our daily vernaculars, as in “necessity is the mother of invention.” The best is, as usual, from the master aphorist Publilius Syrus: “poverty makes experiences” (
hominem experiri multa paupertas iubet
). But the expression and idea appear in one form or another in so many classical writers, including Euripides, Pseudo-Theoctitus, Plautus, Apuleus, Zenobius, Juvenal, and of course it is now labeled “post-traumatic growth.”
I saw ancient wisdom at work in the exact opposite of the situation in Abu Dhabi. My Levantine village of origin, Amioun, was pillaged and evacuated during the war, sending its inhabitants into exile across the planet. Twenty-five years later, it became opulent, having bounced back with a vengeance: my own house, dynamited, is now
bigger
than the previous version. My father, showing me the multiplication of villas in the countryside while bemoaning these nouveaux riches, calmly told me, “You, too, had you stayed here, would have become a beach bum. People from Amioun only do well when shaken.” That’s antifragility.
L’Art pour l’Art, to Learn for Learning’s Sake
Now let’s look at evidence of the direction of the causal arrow, that is, whether it is true that lecture-driven knowledge leads to prosperity. Serious empirical investigation (largely thanks to one Lant Pritchet, then a World Bank economist) shows no evidence that raising the general level of education raises income at the level of a country. But we know the opposite is true, that wealth leads to the rise of education—not an optical
illusion. We don’t need to resort to the World Bank figures, we could derive this from an armchair. Let us figure out the direction of the arrow:
Education
→
Wealth and Economic Growth
or
Wealth and Economic Growth
→
Education
And the evidence is so easy to check, just lying out there in front of us. It can be obtained by looking at countries that are both wealthy and have some level of education and considering which condition preceded the other. Take the following potent and
less-is-more
-style argument by the rogue economist Ha-Joon Chang. In 1960 Taiwan had a much lower literacy rate than the Philippines and half the income per person; today Taiwan has ten times the income. At the same time, Korea had a much lower literacy rate than Argentina (which had one of the highest in the world) and about one-fifth the income per person; today it has three times as much. Further, over the same period, sub-Saharan Africa saw markedly increasing literacy rates, accompanied with a decrease in their standard of living. We can multiply the examples (Pritchet’s study is quite thorough), but I wonder why people don’t realize the simple truism, that is, the
fooled by randomness
effect: mistaking the merely associative for the causal, that is, if rich countries are educated, immediately inferring that education makes a country rich, without even checking. Epiphenomenon here again. (The error in reasoning is a bit from wishful thinking, because education is considered “good”; I wonder why people don’t make the epiphenomenal association between the wealth of a country and something “bad,” say, decadence, and infer that decadence, or some other disease of wealth like a high suicide rate, also generates wealth.)
I am not saying that for an individual, education is useless: it builds helpful credentials for one’s own career—but such effect washes out at the country level. Education stabilizes the income of families across generations. A merchant makes money, then his children go to the Sorbonne, they become doctors and magistrates. The family retains wealth because the diplomas allow members to remain in the middle class long after the ancestral wealth is depleted. But these effects don’t count for countries.
Further, Alison Wolf debunks the flaw in logic in going from the point that it is hard to imagine Microsoft or British Aerospace without advanced knowledge to the idea that more education means more wealth. “The simple one-way relationship which so entrances our politicians and commentators—education spending in, economic growth out—simply doesn’t exist. Moreover, the larger and more complex the education sector, the less obvious any links to productivity become.” And, similar to Pritchet, she looks at countries such as, say, Egypt, and shows how the giant leap in education it underwent did not translate into the Highly Cherished Golden GDP Growth That Makes Countries Important or Unimportant on the Ranking Tables.
This argument is not against adopting governmental educational policies for noble aims such as reducing inequality in the population, allowing the poor to access good literature and read Dickens, Victor Hugo, or Julien Gracq, or increasing the freedom of women in poor countries, which happens to decrease the birth rate. But then one should not use the excuses of “growth” or “wealth” in such matters.
I once ran into Alison Wolf at a party (parties are great for optionality). As I got her to explain to other people her evidence about the lack of effectiveness of funding formal education, one person got frustrated with our skepticism. Wolf’s answer to him was “real education is this,” pointing at the room full of people chatting. Accordingly, I am not saying that knowledge is not important; the skepticism in this discussion applies to the brand of commoditized, prepackaged, and pink-coated knowledge, stuff one can buy in the open market and use for self-promotion. Further, let me remind the reader that scholarship and organized education are not the same.
Another party story. Once, at a formal fancy dinner, a fellow in a quick speech deplored the education level in the United States—falling for low-math-grades alarmism. Although I agreed with all his other views, I felt compelled to intervene. I interrupted him to state the point that America’s values were “convex” risk taking and that I am glad that we are not like these helicopter-mom cultures—the kind of thing I am writing here. Everyone was shocked, either confused or in heavy but passive disagreement, except for one person who came to lend her support to me. It turned out that she was the head of the New York City school system.
Also, note that I am not saying that universities do not generate
knowledge at all and do not help growth (outside, of course, of most standard economics and other superstitions that set us back); all I am saying is that their role is overly hyped-up and that their members seem to exploit some of our gullibility in establishing wrong causal links, mostly on superficial impressions.
Polished Dinner Partners
Education has benefits aside from stabilizing family incomes. Education makes individuals more polished dinner partners, for instance, something non-negligible. But the idea of educating people to improve the economy is rather novel. The British government documents, as early as fifty years ago, an aim for education other than the one we have today: raising values, making good citizens, and “learning,” not economic growth (they were not suckers at the time)—a point also made by Alison Wolf.
Likewise, in ancient times, learning was for learning’s sake, to make someone a good person, worth talking to, not to increase the stock of gold in the city’s heavily guarded coffers. Entrepreneurs, particularly those in technical jobs, are not necessarily the best people to have dinner with. I recall a heuristic I used in my previous profession when hiring people (called “separate those who, when they go to a museum, look at the Cézanne on the wall from those who focus on the contents of the trash can”): the more interesting their conversation, the more cultured they are, the more they will be trapped into thinking that they are effective at what they are doing in real business (something psychologists call the
halo effect,
the mistake of thinking that skills in, say, skiing translate unfailingly into skills in managing a pottery workshop or a bank department, or that a good chess player would be a good strategist in real life).
2
Clearly, it is unrigorous to equate
skills at doing
with
skills at talking.
My experience of good practitioners is that they can be totally incomprehensible—they do not have to put much energy into turning their insights and internal coherence into elegant style and narratives. Entrepreneurs are selected to be just doers, not thinkers, and doers do, they don’t talk, and it would be unfair, wrong, and downright insulting to measure them in the talk department. The same with artisans: the
quality lies in their product, not their conversation—in fact they can easily have false beliefs that, as a side effect (inverse iatrogenics), lead them to make better products, so what? Bureaucrats, on the other hand, because of the lack of an objective metric of success and the absence of market forces, are selected on the “halo effects” of shallow looks and elegance. The side effect is to make them better at conversation. I am quite certain a dinner with a United Nations employee would cover more interesting subjects than one with some of Fat Tony’s cousins or a computer entrepreneur obsessed with circuits.
Let us look deeper at this flaw in thinking.


================================================================================
CHAPTER/SECTION 64 (Item 67)
================================================================================

THE GREEN LUMBER FALLACY
In one of the rare noncharlatanic books in finance, descriptively called
What I Learned Losing a Million Dollars,
the protagonist makes a big discovery. He remarks that a fellow named Joe Siegel, one of the most successful traders in a commodity called “green lumber,” actually thought that it was lumber painted green (rather than freshly cut lumber, called green because it had not been dried). And he made it his profession to trade the stuff! Meanwhile the narrator was into grand intellectual theories and narratives of what caused the price of commodities to move, and went bust.
It is not just that the successful expert on lumber was ignorant of central matters like the designation “green.” He also knew things about lumber that nonexperts think are unimportant. People we call ignorant might not be ignorant.
The fact is that predicting the order flow in lumber and the usual narrative had little to do with the details one would assume from the outside are important. People who do things in the field are not subjected to a set exam; they are selected in the most non-narrative manner—nice arguments don’t make much difference. Evolution does not rely on narratives, humans do. Evolution does not need a word for the color blue.
So let us call the
green lumber fallacy
the situation in which one mistakes a source of necessary knowledge—the greenness of lumber—for another, less visible from the outside, less tractable, less narratable.
My intellectual world was shattered as if everything I had studied was not just useless but a well-organized scam—as follows. When I first became a derivatives or “volatility” professional (I specialized in nonlinearities),
I focused on exchange rates, a field in which I was embedded for several years. I had to cohabit with foreign exchange traders—people who were not involved in technical instruments as I was; their job simply consisted of buying and selling currencies. Money changing is a very old profession with a long tradition and craft; recall the story of Jesus Christ and the money changers. Coming to this from a highly polished Ivy League environment, I was in for a bit of a shock. You would think that the people who specialized in foreign exchange understood economics, geopolitics, mathematics, the future price of currencies, differentials between prices in countries. Or that they read assiduously the economics reports published in glossy papers by various institutes. You might also imagine cosmopolitan fellows who wear ascots at the opera on Saturday night, make wine sommeliers nervous, and take tango lessons on Wednesday afternoons. Or spoke intelligible English. None of that.
My first day on the job was an astounding discovery of the real world. The population in foreign exchange was at the time mostly composed of New Jersey/Brooklyn Italian fellows. Those were street, very street people who had started in the back office of banks doing wire transfers, and when the market expanded, even exploded, with the growth of commerce and the free-floating of currencies, they developed into traders and became prominent in the business. And prosperous.
My first conversation with an expert was with a fellow called B. Something-that-ends-with-a-vowel dressed in a handmade Brioni suit. I was told that he was the biggest Swiss franc trader in the world, a legend in his day—he had predicted the big dollar collapse in the 1980s and controlled huge positions. But a short conversation with him revealed that he could not place Switzerland on the map—foolish as I was, I thought he was Swiss Italian, yet he did not know there were Italian-speaking people in Switzerland. He had never been there. When I saw that he was not the exception, I started freaking out watching all these years of education evaporating in front of my eyes. That very same day I stopped reading economic reports. I felt nauseous for a while during this enterprise of “deintellectualization”—in fact I may not have recovered yet.
If New York was blue collar in origin, London was sub–blue collar, and even more successful. The players were entirely cockney, even more separated from sentence-forming society. They were East Londoners,
street people (extremely street) with a distinctive accent, using their own numbering system. Five is “Lady Godiva” or “ching,” fifteen is a “commodore,” twenty-five is a “pony,” etc. I had to learn cockney just to communicate, and mostly to go drinking, with my colleagues during my visits there; at the time, London traders got drunk almost every day at lunch, especially on Friday before New York opened. “Beer turns you into a lion,” one fellow told me as he hurried to finish his drink before the New York open.
The most hilarious scenes were hearing on loudspeakers transatlantic conversations between New York Bensonhurst folks and cockney brokers, particularly when the Brooklyn fellow tried to put on a little bit of a cockney pronunciation to be understood (these cockneys sometimes spoke
no
standard English).
So that is how I learned the lesson that price and reality as seen by economists
are not the same thing
. One may be a function of the other but the function is too complex to map mathematically. The relation may have optionality in places, something that these non-sentence-savvy people knew deep inside.
3
How Fat Tony Got Rich (and Fat)
Fat Tony got to become (literally) Fat Tony, rich and heavier, in the aftermath of the Kuwait war (the sequence was conventional, that is, first rich, then fat). It was in January 1991, on the day the United States attacked Baghdad to restitute Kuwait, which Iraq had invaded.
Every intelligent person in socioeconomics had his theory, probabilities, scenarios, and all that. Except Fat Tony. He didn’t even know where
Iraq was, whether it was a province in Morocco or some emirate with spicy food east of Pakistan—he didn’t know the food, so the place did not exist for him.
All he knew is that suckers exist.
If you asked any intelligent “analyst” or journalist at the time, he would have predicted a rise in the price of oil
in the event
of war. But that causal link was precisely what Tony could not take for granted. So he bet against it: they are all prepared for a rise in oil from war, so the price must have adjusted to it. War could cause a rise in oil prices, but not
scheduled
war—since prices adjust to expectations. It has to be “in the price,” as he said.
Indeed, on the news of war, oil collapsed from around $39 a barrel to almost half that value, and Tony turned his investment of three hundred thousand into eighteen million dollars. “There are so few occasions in one’s life, you can’t miss them,” he later told Nero during one of their lunches as he was convincing his non–New Jersey friend to bet on a collapse of the financial system. “Good speculative bets come to you, you don’t get them by just staying focused on the news.”
And note the main Fat Tony statement: “Kuwait and oil are not the same ting [thing].” This will be a platform for our notion of conflation. Tony had greater upside than downside, and for him, that was it.
Indeed many people lost their shirt from the drop of oil—while
correctly predicting
war. They just thought it was the same
ting
. But there had been too much hoarding, too much inventory. I remember going around that time into the office of a large fund manager who had a map of Iraq on the wall in a war-room-like setting. Members of the team knew every possible thing about Kuwait, Iraq, Washington, the United Nations. Except for the very simple fact that it had nothing to do with oil—
not the same “ting.”
All these analyses were nice, but not too connected to anything. Of course the fellow got subsequently shellacked by the drop in oil price, and, from what I heard, went to law school.
Aside from the non-narrative view of things, another lesson. People with too much smoke and complicated tricks and methods in their brains start missing elementary, very elementary things. Persons in the real world can’t afford to miss these things; otherwise they crash the plane. Unlike researchers, they were selected for survival, not complications. So I saw the less is more in action: the more studies, the less obvious elementary
but fundamental things become; activity, on the other hand, strips things to their simplest possible model.


================================================================================
CHAPTER/SECTION 65 (Item 68)
================================================================================

CONFLATION
Of course, so many things are
not the same “ting”
in life. Let us generalize the conflation.
This lesson “not the same thing” is quite general. When you have optionality, or some antifragility, and can identify betting opportunities with big upside and small downside, what you do is only remotely connected to what Aristotle thinks you do.
There is
something
(here, perception, ideas, theories) and a
function of something
(here, a price or reality, or something real). The conflation problem is to mistake one for the other, forgetting that there is a “function” and that such function has different properties.
Now, the more asymmetries there are between the
something
and the
function of something,
then the more difference there is between the two. They may end up having nothing to do with each other.
This seems trivial, but there are big-time implications. As usual science—not “social” science, but smart science—gets it. Someone who escaped the conflation problem is Jim Simons, the great mathematician who made a fortune building a huge machine to transact across markets. It replicates the buying and selling methods of these sub–blue collar people and has more statistical significance than anyone on planet Earth. He claims to never hire economists and finance people, just physicists and mathematicians, those involved in pattern recognition accessing the internal logic of things, without theorizing. Nor does he ever listen to economists or read their reports.
The great economist Ariel Rubinstein gets the green lumber fallacy—it requires a great deal of intellect and honesty to see things that way. Rubinstein is one of the leaders in the field of game theory, which consists in thought experiments; he is also the greatest expert in cafés for thinking and writing across the planet. Rubinstein refuses to claim that his knowledge of theoretical matters can be translated—by him—into anything directly practical. To him, economics is like a fable—a fable writer is there to stimulate ideas, indirectly inspire practice perhaps, but certainly not to direct or determine practice. Theory should stay independent
from practice and vice versa—and we should not extract academic economists from their campuses and put them in positions of decision making. Economics is not a science and should not be there to advise policy.
In his intellectual memoirs, Rubinstein recounts how he tried to get a Levantine vendor in the souk to apply ideas from game theory to his bargaining in place of ancestral mechanisms. The suggested method failed to produce a price acceptable to both parties. Then the fellow told him: “For generations, we have bargained in our way and you come and try to change it?” Rubinstein concluded: “I parted from him shamefaced.” All we need is another two people like Rubinstein in that profession and things will be better on planet Earth.
Sometimes, even when an economic theory makes sense, its application cannot be imposed from a model, in a top-down manner, so one needs the organic self-driven trial and error to get us to it. For instance, the concept of specialization that has obsessed economists since Ricardo (and before) blows up countries when imposed by policy makers, as it makes the economies error-prone; but it works well when reached progressively by evolutionary means, with the right buffers and layers of redundancies. Another case where economists may inspire us but should never tell us what to do—more on that in the discussion of Ricardian comparative advantage and model fragility in the Appendix.
The difference between a narrative and practice—the important things that cannot be easily narrated—lies mainly in optionality, the missed optionality of things. The “right thing” here is typically an antifragile payoff. And my argument is that you don’t go to school to learn optionality, but the reverse: to become blind to it.


================================================================================
CHAPTER/SECTION 66 (Item 69)
================================================================================

PROMETHEUS AND EPIMETHEUS
In Greek legend, there were two Titan brothers, Prometheus and Epimetheus. Prometheus means “fore-thinker” while Epimetheus means “after-thinker,” equivalent to someone who falls for the retrospective distortion of fitting theories to past events in an ex post narrative manner. Prometheus gave us fire and represents the progress of civilization, while Epimetheus represents backward thinking, staleness, and lack of intelligence. It was Epimetheus who accepted Pandora’s gift, the large jar, with irreversible consequences.
Optionality is Promethean, narratives are Epimethean—one has reversible and benign mistakes, the other symbolizes the gravity and irreversibility of the consequences of opening Pandora’s box.
You make forays into the future by opportunism and optionality. So far in
Book IV
we have seen the power of optionality as an alternative way of doing things, opportunistically, with some large edge coming from asymmetry with large benefits and benign harm. It is a way—the only way—to domesticate uncertainty, to work rationally without understanding the future, while reliance on narratives is the exact opposite: one is domesticated by uncertainty, and ironically set back. You cannot look at the future by naive projection of the past.
This brings us to the difference between doing and thinking. The point is hard to understand from the vantage point of intellectuals. As Yogi Berra said, “In theory there is no difference between theory and practice; in practice there is.” So far we have seen arguments that intellect is associated with fragility and instills methods that conflict with tinkering. So far we saw the option as the expression of antifragility. We separated knowledge into two categories, the formal and the Fat Tonyish, heavily grounded in the antifragility of trial and error and risk taking with less downside, barbell-style—a de-intellectualized form of risk taking (or, rather, intellectual in its own way). In an opaque world, that is the only way to go.
Table 4
summarizes the different aspects of the opposition between narrating and tinkering, the subject of the next three chapters.
Click
here
for a larger image of this table.
All this does not mean that tinkering and trial and error are devoid of narrative: they are just not overly dependent on the narrative being true—the narrative is not epistemological but instrumental. For instance, religious stories might have no value as narratives, but they may get you to do something convex and antifragile you otherwise would not do, like mitigate risks. English parents controlled children with the false narrative that if they didn’t behave or eat their dinner, Boney (Napoleon Bonaparte) or some wild animal might come and take them away. Religions often use the equivalent method to help adults get out of trouble, or avoid debt. But intellectuals tend to believe their own b***t and take their ideas too literally, and that is vastly dangerous.
Consider the role of heuristic (rule-of-thumb) knowledge embedded in traditions. Simply, just as evolution operates on individuals, so does it act on these tacit, unexplainable rules of thumb transmitted through generations—what Karl Popper has called evolutionary epistemology. But let me change Popper’s idea ever so slightly (actually quite a bit): my take is that this evolution is not a competition between ideas, but between humans and systems based on such ideas. An idea does not survive because it is better than the competition, but rather because the person who holds it has survived! Accordingly, wisdom you learn from your grandmother should be vastly superior (empirically, hence scientifically) to what you get from a class in business school (and, of course, considerably cheaper). My sadness is that we have been moving farther and farther away from grandmothers.
Expert problems (in which the expert knows a lot but less than he thinks he does) often bring fragilities, and acceptance of ignorance the reverse.
4
Expert problems put you on the wrong side of asymmetry. Let us examine the point with respect to risk. When you are fragile you need to know a lot more than when you are antifragile. Conversely, when you think you know more than you do, you are fragile (to error).
We showed earlier the evidence that classroom education does not
lead to wealth as much as it comes from wealth (an epiphenomenon). Next let us see how, similarly, antifragile risk taking—not education and formal, organized research—is largely responsible for innovation and growth, while the story is dressed up by textbook writers. It does not mean that theories and research play no role; it is that just as we are fooled by randomness, so we are fooled into overestimating the role of good-sounding ideas. We will look at the confabulations committed by historians of economic thought, medicine, technology, and other fields that tend to systematically downgrade practitioners and fall into the green lumber fallacy.
1
Switzerland’s education system has traditionally been apprenticeship-based. But it is now more and more oriented toward formal education, and might lose its edge. Success and wealth bring transformations that end up bringing fragilities.
2
The halo effect is largely the opposite of domain dependence.
3
At first I thought that economic theories were not necessary to understand short-term movements in exchange rates, but it turned out that the same limitation applied to long-term movements as well. Many economists toying with foreign exchange have used the notion of “purchasing power parity” to try to predict exchange rates on the basis that in the long run “equilibrium” prices cannot diverge too much and currency rates need to adjust so a pound of ham will eventually need to carry a similar price in London and Newark, New Jersey. Put under scrutiny, there seems to be no operational validity to this theory—currencies that get expensive tend to get even more expensive, and most Fat Tonys in fact made fortunes following the inverse rule. But theoreticians would tell you that “in the long run” it should work. Which long run? It is impossible to make a decision based on such a theory, yet they still teach it to students, because being academics, lacking heuristics, and needing something complicated, they never found anything better to teach.
4
Overconfidence leads to reliance on forecasts, which causes borrowing, then to the fragility of leverage. Further, there is convincing evidence that a PhD in economics or finance causes people to build vastly more fragile portfolios. George Martin and I listed all the major financial economists who were involved with funds, calculated the blowups by funds, and observed a far higher proportional incidence of such blowups on the part of finance professors—the most famous one being Long Term Capital Management, which employed Fragilistas Robert Merton, Myron Scholes, Chi-Fu Huang, and others.


================================================================================
CHAPTER/SECTION 67 (Item 70)
================================================================================

CHAPTER 15
History Written by the Losers
The birds may perhaps listen—Combining stupidity with wisdom rather than the opposite—Where we look for the arrow of discovery—A vindication of trial and error
Because of a spate of biases, historians are prone to epiphenomena and other illusions of cause and effect. To understand the history of technology, you need accounts by nonhistorians, or historians with the right frame of mind who developed their ideas by watching the formation of technologies, instead of just reading accounts concerning it. I mentioned earlier Terence Kealey’s debunking of the so-called linear model and that he was a practicing scientist.
1
A practicing laboratory scientist, or an engineer, can witness the real-life production of, say, pharmacological innovations or the jet engine and can thus avoid falling for epiphenomena, unless he was brainwashed prior to starting practice.
I have seen evidence—as an eyewitness—of results that owe
nothing
to academizing science, rather evolutionary tinkering that was dressed up and claimed to have come from academia.
Click
here
for a larger image of this table.
Long before I knew of the results in
Table 5
, of other scholars debunking the lecturing-birds-how-to-fly effect, the problem started screaming at me, as follows, around 1998. I was sitting in a Chicago restaurant with the late Fred A., an economist, though a true, thoughtful gentleman. He was the chief economist of one of the local exchanges and had to advise them on new, complicated financial products and wanted my opinion on these, as I specialized in and had published a textbook of sorts on the so-called very complicated “exotic options.” He recognized that the demand for these products was going to be very large, but he wondered “how traders could handle these complicated exotics if they do not understand the Girsanov theorem.” The Girsanov theorem is something mathematically complicated that at the time was only known by a very small number of persons. And we were talking about pit traders who—as we saw in the last chapter—would most certainly mistake
Girsanov for a vodka brand. Traders, usually uneducated, were considered overeducated if they could spell their street address correctly, while the professor was truly under the epiphenomenal impression that traders studied mathematics to produce an option price. I for myself had figured out by trial and error and picking the brains of experienced people how to play with these complicated payoffs before I heard of these theorems.
Something hit me then. Nobody worries that a child ignorant of the various theorems of aerodynamics and incapable of solving an equation of motion would be unable to ride a bicycle. So why didn’t he transfer the point from one domain to another? Didn’t he realize that these Chicago pit traders respond to supply and demand, little more, in competing to make a buck, with no need for the Girsanov theorem, any more than a trader of pistachios in the Souk of Damascus needs to solve general equilibrium equations to set the price of his product?
For a minute I wondered if I was living on another planet or if the gentleman’s PhD and research career had led to this blindness and his strange loss of common sense—or if people without practical sense usually manage to get the energy and interest to acquire a PhD in the fictional world of equation economics. Is there a selection bias?
I smelled a rat and got extremely excited but realized that for someone to be able to help me, he had to be both a practitioner and a researcher, with practice coming before research. I knew of only one other person, a trader turned researcher, Espen Haug, who had to have observed the same mechanism. Like me, he got his doctorate
after
spending time in trading rooms. So we immediately embarked on an investigation about the source of the option pricing formula that we were using: what did people use before? Is it thanks to the academically derived formula that we are able to operate, or did the formula come through some antifragile evolutionary discovery process based on trial and error, now expropriated by academics? I already had a hint, as I had worked as a pit trader in Chicago and had observed veteran traders who refused to touch mathematical formulas, using simple heuristics and saying “real men don’t use sheets,” the “sheets” being the printouts of output from the complex formulas that came out of computers. Yet these people had survived. Their prices were sophisticated and more efficient than those produced by the formula, and it was obvious what came first. For instance, the prices accounted for Extremistan and “fat tails,” which the standard formulas ignored.
Haug has some interests that diverge from mine: he was into the subject
of finance and eager to collect historical papers by practitioners. He called himself “the collector,” even used it as a signature, as he went to assemble and collect books and articles on option theory written before the Great War, and from there we built a very precise image of what had taken place. To our great excitement, we had proof after proof that traders had vastly, vastly more sophistication than the formula. And their sophistication preceded the formula by at least a century. It was of course picked up through natural selection, survivorship, apprenticeship to experienced practitioners, and one’s own experience.
Traders trade
→
traders figure out techniques and products
→
academic economists find formulas and claim traders are using them
→
new traders believe academics
→
blowups (from theory-induced fragility)
Our paper sat for close to seven years before publication by an academic economics journal—until then, a strange phenomenon: it became one the most downloaded papers in the history of economics, but was not cited at all during its first few years. Nobody wanted to stir the pot.
2
Practitioners don’t write; they do. Birds fly and those who lecture them are the ones who write their story. So it is easy to see that history is truly written by losers with time on their hands and a protected academic position.
The greatest irony is that we watched firsthand how narratives of thought are made, as we were lucky enough to face another episode of blatant intellectual expropriation. We received an invitation to publish our side of the story—being option practitioners—in the honorable
Wiley Encyclopedia of Quantitative Finance
. So we wrote a version of the previous paper mixed with our own experiences. Shock: we caught the editor of the historical section, one Barnard College professor, red-handed trying to modify our account. A historian of economic thought, he proceeded to rewrite our story to play down, if not reverse, its message and change the arrow of the formation of knowledge. This was scientific history in the making. The fellow sitting in his office in
Barnard College was now dictating to us what we saw as traders—we were supposed to override what we saw with our own eyes with his logic.
I came to notice a few similar inversions of the formation of knowledge. For instance, in his book written in the late 1990s, the Berkeley professor Highly Certified Fragilista Mark Rubinstein attributed to publications by finance professors techniques and heuristics that we practitioners had been extremely familiar with (often in more sophisticated forms) since the 1980s, when I got involved in the business.
No, we don’t put theories into practice. We create theories out of practice. That was our story, and it is easy to infer from it—and from similar stories—that the confusion is generalized. The theory is the child of the cure, not the opposite—
ex cura theoria nascitur
.
The Evidence Staring at Us
It turned out that engineers, too, get sandbagged by historians.
Right after the previous nauseating episode I presented the joint paper I had written with Haug on the idea of lecturing birds on how to fly in finance at the London School of Economics, in their sociology of science seminar. I was, of course, heckled (but was by then very well trained at being heckled by economists). Then, surprise. At the conclusion of the session, the organizers informed me that, exactly a week earlier, Phil Scranton, a professor from Rutgers, had delivered the exact same story. But it was not about the option formula; it was about the jet engine.
Scranton showed that we have been building and using jet engines in a completely trial-and-error experiential manner, without anyone truly understanding the theory. Builders needed the original engineers who knew how to twist things to make the engine work.
Theory came later,
in a lame way, to satisfy the intellectual bean counter. But that’s not what you tend to read in standard histories of technology: my son, who studies aerospace engineering, was not aware of this. Scranton was polite and focused on situations in which innovation is messy, “distinguished from more familiar analytic and synthetic innovation approaches,” as if the latter were the norm, which it is obviously not.
I looked for more stories, and the historian of technology David Edgerton presented me with a quite shocking one. We think of cybernetics—
which led to the “cyber” in cyberspace—as invented by Norbert Wiener in 1948. The historian of engineering David Mindell debunked the story; he showed that Wiener was articulating ideas about feedback control and digital computing that had long been in practice in the engineering world. Yet people—even today’s engineers—have the illusion that we owe the field to Wiener’s mathematical thinking.
Then I was hit with the following idea. We all learn geometry from textbooks based on axioms, like, say, Euclid’s
Book of Elements,
and tend to think that it is thanks to such learning that we today have these beautiful geometric shapes in buildings, from houses to cathedrals; to think the opposite would be anathema. So I speculated immediately that the ancients developed an interest in Euclid’s geometry and other mathematics because they were already using these methods, derived by tinkering and experiential knowledge, otherwise they would not have bothered at all. This is similar to the story of the wheel: recall that the steam engine had been discovered and developed by the Greeks some two millennia before the Industrial Revolution. It is just that things that are implemented tend to want to be born from practice, not theory.
Now take a look at architectural objects around us: they appear so geometrically sophisticated, from the pyramids to the beautiful cathedrals of Europe. So a sucker problem would make us tend to believe that mathematics led to these beautiful objects, with exceptions here and there such as the pyramids, as these preceded the more formal mathematics we had after Euclid and other Greek theorists. Some facts: architects (or what were then called Masters of Works) relied on heuristics, empirical methods, and tools, and almost nobody knew any mathematics—according to the medieval science historian Guy Beaujouan, before the thirteenth century no more than five persons in the whole of Europe knew how to perform a division. No theorem, shmeorem. But builders could figure out the resistance of materials without the equations we have today—buildings that are, for the most part, still standing. The thirteenth-century French architect Villard de Honnecourt documents with his series of drawings and notebooks in Picard (the language of the Picardie region in France) how cathedrals were built: experimental heuristics, small tricks and rules, later tabulated by Philibert de l’Orme in his architectural treatises. For instance, a triangle was visualized as the head of a horse. Experimentation can make people much more careful than theories.
Further, we are quite certain that the Romans, admirable engineers, built aqueducts without mathematics (Roman numerals did not make quantitative analysis very easy). Otherwise, I believe, these would not be here, as a patent side effect of mathematics is making people over-optimize and cut corners, causing fragility. Just look how the new is increasingly more perishable than the old.
And take a look at Vitruvius’ manual,
De architectura,
the bible of architects, written about three hundred years after Euclid’s
Elements
. There is little formal geometry in it, and, of course, no mention of Euclid, mostly heuristics, the kind of knowledge that comes out of a master guiding his apprentices. (Tellingly, the main mathematical result he mentions is Pythagoras’s theorem, amazed that the right angle could be formed “without the contrivances of the artisan.”) Mathematics had to have been limited to mental puzzles until the Renaissance.
Now I am not saying that theories or academic science are not behind some practical technologies at all, directly derived from science for their final use (not for some tangential use)—what the researcher Joel Mokyr calls an “epistemic base,” or propositional knowledge, a sort of repository of formal “knowledge” that embeds the theoretical and empirical discoveries and becomes a rulebook of sorts, used to generate more knowledge and (he thinks) more applications. In other words, a body of theories from which further theories can be directly derived.
But let’s not be suckers: following Mr. Mokyr would make one want to study economic geography to predict foreign exchange prices (I would have loved to introduce him to the expert in green lumber). While I accept the notion of epistemic base, what I question is the role it has really played in the history of technology. The evidence of a strong effect is not there, and I am waiting for someone to show it to me. Mokyr and the advocates of such view provide no evidence that it is not epiphenomenal—nor do they appear to understand the implications of asymmetric effects. Where is the role of optionality in this?
There is a body of know-how that was transmitted from master to apprentice, and transmitted
only
in such a manner—with degrees necessary as a selection process or to make the profession more respectable, or to help here and there, but not systematically. And the role of such formal knowledge will be overappreciated precisely because it is highly visible.
Is It Like Cooking?
Cooking seems to be the perfect business that depends on optionality. You add an ingredient and have the option of keeping the result if it is in agreement with Fat Tony’s taste buds, or fuhgetaboudit if it’s not. We also have wiki-style collaborative experimentation leading to a certain body of recipes. These recipes are derived entirely without conjectures about the chemistry of taste buds, with no role for any “epistemic base” to generate theories out of theories. Nobody is fooled so far by the process. As Dan Ariely once observed, we cannot reverse engineer the taste of food from looking at the nutritional label. And we can observe ancestral heuristics at work: generations of collective tinkering resulting in the evolution of recipes. These food recipes are embedded in cultures. Cooking schools are entirely apprenticeship based.
On the other side, we have pure physics, with theories used to generate theories with some empirical validation. There the “epistemic base” can play a role. The discovery of the Higgs Boson is a modern case of a particle entirely expected from theoretical derivations. So was Einstein’s relativity. (Prior to the Higgs Boson, one spectacular case of a discovery with a small number of existing external data is that of the French astronomer Le Verrier’s derivation of the existence of the planet Neptune. He did that on the basis of solitary computation, from the behavior of the surrounding planets. When the planet was actually sighted he refused to look at it, so comfortable was he with his result. These are exceptions, and tend to take place in physics and other places I call “linear,” where errors are from Mediocristan, not from Extremistan.)
Now use this idea of cooking as a platform to grasp other pursuits: do other activities resemble it? If we put technologies through scrutiny, we would see that most do in fact resemble cooking a lot more than physics, particularly those in the complex domain.
Even medicine today remains an apprenticeship model with some theoretical science in the background, but made to look entirely like science. And if it leaves the apprenticeship model, it would be for the “evidence-based” method that relies less on biological theories and more on the cataloging of empirical regularities, the phenomenology I explained in
Chapter 7
. Why is it that science comes and goes and technologies remain stable?
Now, one can see a possible role for basic science, but not in the way
it is intended to be.
3
For an example of a chain of unintended uses, let us start with Phase One, the computer. The mathematical discipline of combinatorics, here basic science, derived from propositional knowledge, led to the building of computers, or so the story goes. (And, of course, to remind the reader of cherry-picking, we need to take into account the body of theoretical knowledge that went nowhere.) But at first, nobody had an idea what to do with these enormous boxes full of circuits as they were cumbersome, expensive, and their applications were not too widespread, outside of database management, only good to process quantities of data. It is as if one needed to invent an application for the thrill of technology. Baby boomers will remember those mysterious punch cards. Then someone introduced the console to input with the aid of a screen monitor, using a keyboard. This led, of course, to word processing, and the computer took off because of its fitness to word processing, particularly with the microcomputer in the early 1980s. It was convenient, but not much more than that until some other unintended consequence came to be mixed into it. Now Phase Two, the Internet. It had been set up as a resilient military communication network device, developed by a research unit of the Department of Defense called DARPA and got a boost in the days when Ronald Reagan was obsessed with the Soviets. It was meant to allow the United States to survive a generalized military attack. Great idea, but add the personal computer
plus
Internet and we get social networks, broken marriages, a rise in nerdiness, the ability for a post-Soviet person with social difficulties to find a matching spouse. All that thanks to initial U.S. tax dollars (or rather budget deficit) during Reagan’s anti-Soviet crusade.
So for now we are looking at the forward arrow and at no point, although science was of
some
use along the way since computer technology relies on science in most of its aspects; at no point did academic science serve in setting its direction, rather it served as a slave to chance discoveries in an opaque environment, with almost no one but college dropouts and overgrown high school students benefiting along the way. The process remained self-directed and unpredictable at every step. And the great fallacy is to make it sound irrational—the irrational resides in not seeing a free option when it is handed to us.
China might be a quite convincing story, through the works of a genius observer, Joseph Needham, who debunked quite a few Western beliefs and figured out the powers of Chinese science. As China became a top-down mandarinate (that is, a state managed by Soviet-Harvard centralized scribes, as Egypt had been before), the players somehow lost the zest for bricolage, the hunger for trial and error. Needham’s biographer Simon Winchester cites the sinologist Mark Elvin’s description of the problem, as the Chinese did not have, or, rather, no longer had, what he called the “European mania for tinkering and improving.” They had all the means to develop a spinning machine, but “nobody tried”—another example of knowledge hampering optionality. They probably needed someone like Steve Jobs—blessed with an absence of college education and the right aggressiveness of temperament—to take the elements to their natural conclusion. As we will see in the next section, it is precisely this type of uninhibited doer who made the Industrial Revolution happen.
We will next examine two cases, first, the Industrial Revolution, and second, medicine. So let us start by debunking a causal myth about the Industrial Revolution, the overstatement of the role of science in it.
The Industrial Revolution
Knowledge formation, even when theoretical, takes time, some boredom, and the freedom that comes from having another occupation, therefore allowing one to escape the journalistic-style pressure of modern publish-and-perish academia to produce cosmetic knowledge, much like the counterfeit watches one buys in Chinatown in New York City, the type that you know is counterfeit although it looks like the real thing. There were two main sources of technical knowledge and innovation in the nineteenth and early twentieth centuries: the hobbyist and the English rector, both of whom were generally in barbell situations.
An extraordinary proportion of work came out of the rector, the English parish priest with no worries, erudition, a large or at least comfortable house, domestic help, a reliable supply of tea and scones with clotted cream, and an abundance of free time. And, of course, optionality. The enlightened amateur, that is. The Reverends Thomas Bayes (as in Bayesian probability) and Thomas Malthus (Malthusian overpopulation) are the most famous. But there are many more surprises, cataloged in Bill Bryson’s
Home,
in which the author found ten times
more vicars and clergymen leaving recorded traces for posterity than scientists, physicists, economists, and even inventors. In addition to the previous two giants, I randomly list contributions by country clergymen: Rev. Edmund Cartwright invented the power loom, contributing to the Industrial Revolution; Rev. Jack Russell bred the terrier; Rev. William Buckland was the first authority on dinosaurs; Rev. William Greenwell invented modern archaeology; Rev. Octavius Pickard-Cambridge was the foremost authority on spiders; Rev. George Garrett invented the submarine; Rev. Gilbert White was the most esteemed naturalist of his day; Rev. M. J. Berkeley was the top expert on fungi; Rev. John Michell helped discover Uranus; and many more. Note that, just as with our episode documented with Haug, that organized science tends to skip the “not made here,” so the list of visible contribution by hobbyists and doers is most certainly shorter than the real one, as some academic might have appropriated the innovation by his predecessor.
4
Let me get poetic for a moment. Self-directed scholarship has an aesthetic dimension. For a long time I had on the wall of my study the following quote by Jacques Le Goff, the great French medievalist, who believes that the Renaissance came out of independent humanists, not professional scholars. He examined the striking contrast in period paintings, drawings, and renditions that compare medieval university members and humanists:
One is a professor surrounded and besieged by huddled students. The other is a solitary scholar, sitting in the tranquility and privacy of his chambers, at ease in the spacious and comfy room where his thoughts can move freely. Here we encounter the tumult of schools, the dust of classrooms, the indifference to beauty in collective workplaces,
There, it is all order and beauty,
Luxe, calme et volupté
As to the hobbyist in general, evidence shows him (along with the hungry adventurer and the private investor) to be at the source of the Industrial Revolution. Kealey, who we mentioned was not a historian and, thankfully, not an economist, in
The Economic Laws of Scientific
Research
questions the conventional “linear model” (that is, the belief that academic science leads to technology)—for him, universities prospered as a consequence of national wealth, not the other way around. He even went further and claimed that like naive interventions, these had iatrogenics that provided a negative contribution. He showed that in countries in which the government intervened by funding research with tax money, private investment decreased and moved away. For instance, in Japan, the almighty MITI (Ministry for Technology and Investment) has a horrible record of investment. I am not using his ideas to prop up a political program against science funding, only to debunk causal arrows in the discovery of important things.
The Industrial Revolution, for a refresher, came from “technologists building technology,” or what he calls “hobby science.” Take again the steam engine, the one artifact that more than anything else embodies the Industrial Revolution. As we saw, we had a blueprint of how to build it from Hero of Alexandria. Yet the theory didn’t interest anyone for about two millennia. So practice and rediscovery had to be the cause of the interest in Hero’s blueprint, not the other way around.
Kealey presents a convincing—very convincing—argument that the steam engine emerged from preexisting technology and was created by uneducated, often isolated men who applied practical common sense and intuition to address the mechanical problems that beset them, and whose solutions would yield obvious economic reward.
Now, second, consider textile technologies. Again, the main technologies that led to the jump into the modern world owe, according to Kealey, nothing to science. “In 1733,” he writes, “John Kay invented the flying shuttle, which mechanized weaving, and in 1770 James Hargreaves invented the spinning jenny, which as its name implies, mechanized spinning. These major developments in textile technology, as well as those of Wyatt and Paul (spinning frame, 1758), Arkwright (water frame, 1769), presaged the Industrial Revolution, yet they owed nothing to science; they were empirical developments based on the trial, error, and experimentation of skilled craftsmen who were trying to improve the productivity, and so the profits, of their factories.”
David Edgerton did some work questioning the link between academic science and economic prosperity, along with the idea that people believed in the “linear model” (that is, that academic science was at the source of technology) in the past. People were
no suckers
in the nineteenth
and twentieth centuries; we believe today that they believed in the said linear model then but they did not. In fact academics were mostly just teachers, not researchers, until well into the twentieth century.
Now, instead of looking into a scholar’s writings to see whether he is credible or not, it is always best to consider what his detractors say—they will uncover what’s worst in his argument. So I looked for the detractors of Kealey, or people opposing his ideas, to see if they address anything of merit—and to see where they come from. Aside from some comments by Joel Mokyr, who, as I said, has not yet discovered optionality, and an attack by an economist of the type that doesn’t count, given the devaluation of the currency of the economics profession, the main critique against Kealey, published in the influential journal
Nature
by a science bureaucrat, was that he uses data from government-sponsored agencies such as the OECD in his argument against tax-funded research. So far, no substantive evidence that Kealey was wrong. But, let us flip the burden of evidence: there is
zero
evidence that the opposite of his thesis is remotely right. Much of all of this is a religious belief in the
unconditional
power of organized science, one that has replaced unconditional religious belief in organized religion.
Governments Should Spend on Nonteleological Tinkering, Not Research
Note that I do not believe that the argument set forth above should logically lead us to say that
no
money should be spent by government. This reasoning is more against teleology than research in general. There has to be a form of spending that works. By some vicious turn of events, governments have gotten huge payoffs from research, but not as intended—just consider the Internet. And look at the recapture we’ve had of military expenditures with innovations, and, as we will see, medical cures. It is just that functionaries are too teleological in the way they look for things (particularly the Japanese), and so are large corporations. Most large corporations, such as Big Pharma, are their own enemies.
Consider
blue sky
research, whereby research grants and funding are given to people, not projects, and spread in small amounts across many researchers. The sociologist of science Steve Shapin, who spent time in California observing venture capitalists, reports that investors tend to back entrepreneurs, not ideas. Decisions are largely a matter of opinion strengthened with “who you know” and “who said what,” as, to use the venture capitalist’s lingo, you bet on the jockey, not the horse. Why?
Because innovations drift, and one needs flâneur-like abilities to keep capturing the opportunities that arise, not stay locked up in a bureaucratic mold. The significant venture capital decisions, Shapin showed, were made without real business plans. So if there was any “analysis,” it had to be of a backup, confirmatory nature. I myself spent some time with venture capitalists in California, with an eye on investing myself, and sure enough, that was the mold.
Visibly the money should go to the tinkerers, the aggressive tinkerers who you trust will milk the option.
Let us use statistical arguments and get technical for a paragraph. Payoffs from research are from Extremistan; they follow a power-law type of statistical distribution, with big, near-unlimited upside but, because of optionality, limited downside. Consequently, payoff from research should necessarily be linear to number of trials, not total funds involved in the trials. Since, as in
Figure 7
, the winner will have an explosive payoff, uncapped, the right approach requires a certain style of blind funding. It means the right policy would be what is called “one divided by n” or “1/N” style, spreading attempts in as large a number of trials as possible: if you face
n
options, invest in all of them in equal amounts.
5
Small amounts per trial, lots of trials, broader than you want. Why? Because in Extremistan, it is more important to be in something in a small amount than to miss it. As one venture capitalist told me: “The payoff can be so large that you can’t afford not to be in everything.”


================================================================================
CHAPTER/SECTION 68 (Item 71)
================================================================================

THE CASE IN MEDICINE
Unlike technology, medicine has a long history of domestication of luck; it now has accepted randomness in its practice. But not quite.
Medical data allow us to assess the performance of teleological research compared to randomly generated discoveries. The U.S. government provides us with the ideal dataset for that: the activities of the National Cancer Institute that came out of the Nixon “war on cancer” in the early 1970s. Morton Meyers, a practicing doctor and researcher, writes in his wonderful
Happy Accidents: Serendipity in Modern Medical Breakthroughs:
“Over a twenty-year period of screening more than
144,000 plant extracts, representing about 15,000 species, not a single plant-based anticancer drug reached approved status. This failure stands in stark contrast to the discovery in the late 1950s of a major group of plant-derived cancer drugs, the Vinca Alcaloids—a discovery that came about by chance, not through directed research.”
John LaMatina, an insider who described what he saw after leaving the pharmaceutical business, shows statistics illustrating the gap between public perception of academic contributions and truth: private industry develops nine drugs out of ten. Even the tax-funded National Institutes of Health found that out of forty-six drugs on the market with significant sales, about three had anything to do with federal funding.
We have not digested the fact that cures for cancer had been coming from other branches of research. You search for noncancer drugs (or noncancer nondrugs) and find something you were not looking for (and vice versa). But the interesting constant is that when a result is initially discovered by an academic researcher, he is likely to disregard the consequences because it is not what he wanted to find—an academic has a script to follow. So, to put it in option terms, he does not exercise his option in spite of its value, a strict violation of rationality (no matter how you define rationality), like someone who both is greedy and does not pick up a large sum of money found in his garden. Meyers also shows the lecturing-birds-how-to-fly effect as discoveries are ex post narrated back to some academic research, contributing to our illusion.
In some cases, because the source of the discovery is military, we don’t know exactly what’s going on. Take for instance chemotherapy for cancer, as discussed in Meyers’s book. An American ship carrying mustard gas off Bari in Italy was bombed by the Germans in 1942. It helped develop chemotherapy owing to the effect of the gas on the condition of the soldiers who had liquid cancers (eradication of white blood cells). But mustard gas was banned by the Geneva Conventions, so the story was kept secret—Churchill purged all mention from U.K. records, and in the United States, the information was stifled, though not the research on the effect of nitrogen mustard.
James Le Fanu, the doctor and writer about medicine, wrote that the therapeutic revolution, or the period in the postwar years that saw a large number of effective therapies, was not ignited by a major scientific insight. It came from the exact opposite, “the realization by doctors and scientists that it was not necessary to understand in any detail what was wrong, but that synthetic chemistry blindly and randomly would deliver
the remedies that had eluded doctors for centuries.” (He uses as a central example the sulfonamides identified by Gerhard Domagk.)
Further, the increase in our theoretical understanding—the “epistemic base,” to use Mokyr’s term—came with a
decrease
in the number of new drugs. This is something Fat Tony or the green lumber fellow could have told us. Now, one can argue that we depleted the low-hanging fruits, but I go further, with more cues from other parts (such as the payoff from the Human Genome Project or the stalling of medical cures of the past two decades in the face of the growing research expenditures)—knowledge, or what is called “knowledge,” in complex domains inhibits research.
Or, another way to see it, studying the chemical composition of ingredients will make you neither a better cook nor a more expert taster—it might even make you worse at both. (Cooking is particularly humbling for teleology-driven fellows.)
One can make a list of medications that came Black Swan–style from serendipity and compare it to the list of medications that came from design. I was about to embark on such a list until I realized that the notable exceptions, that is, drugs that were discovered in a teleological manner, are too few—mostly AZT, AIDS drugs. Designer drugs have a main property—they are designed (and are therefore teleological). But it does not look as if we are capable of designing a drug while taking into account the potential side effects. Hence a problem for the future of designer drugs. The more drugs there are on the market, the more interactions with one another—so we end up with a swelling number of possible interactions with every new drug introduced. If there are twenty unrelated drugs, the twenty-first would need to consider twenty interactions, no big deal. But if there are a thousand, we would need to predict a little less than a thousand. And there are tens of thousands of drugs available today. Further, there is research showing that we may be underestimating the interactions of
current
drugs, those already on the market, by a factor of four so, if anything, the pool of available drugs should be shrinking rather than growing.
There is an obvious drift in that business, as a drug can be invented for something and find new applications, what the economist John Kay calls
obliquity
—aspirin, for instance, changed many times in uses; or the ideas of Judah Folkman about restricting the blood supply of tumors (angiogenesis inhibitors) have led to the treatment of macular degeneration
(bevacizumab, known as Avastin), an effect that is more effective than the original intent.
Now, instead of giving my laundry list of drugs here (too inelegant), I refer the reader to, in addition to Meyers’s book, Claude Bohuon and Claude Monneret,
Fabuleux hasards, histoire de la découverte des médicaments,
and Jie Jack Li’s
Laughing Gas, Viagra and Lipitor
.
Matt Ridley’s Anti-Teleological Argument
The great medieval Arabic-language skeptic philosopher Algazel, aka Al-Ghazali, who tried to destroy the teleology of Averroes and his rationalism, came up with the famous metaphor of the pin—now falsely attributed to Adam Smith. The pin doesn’t have a single maker, but twenty-five persons involved; these are all collaborating in the absence of a central planner—a collaboration guided by an invisible hand. For not a single one knows how to produce it on his own.
In the eyes of Algazel, a skeptic fideist (i.e., a skeptic with religious faith), knowledge was not in the hands of humans, but in those of God, while Adam Smith calls it the law of the market and some modern theorist presents it as self-organization. If the reader wonders why fideism is epistemologically equivalent to pure skepticism about human knowledge and embracing the hidden logics of things, just replace God with nature, fate, the Invisible, Opaque, and Inaccessible, and you mostly get the same result. The logic of things stands outside of us (in the hands of God or natural or spontaneous forces); and given that nobody these days is in direct communication with God, even in Texas, there is little difference between God and opacity. Not a single individual has a clue about the general process, and that is central.
The author Matt Ridley produces a more potent argument thanks to his background in biology. The difference between humans and animals lies in the ability to collaborate, engage in business, let ideas, pardon the expression, copulate. Collaboration has explosive upside, what is mathematically called a superadditive function, i.e., one plus one equals more than two, and one plus one plus one equals much, much more than three. That is pure nonlinearity with explosive benefits—we will get into details on how it benefits from the philosopher’s stone. Crucially, this is an argument for unpredictability and Black Swan effects: since you cannot forecast collaborations and cannot direct them, you cannot see
where the world is going. All you can do is create an environment that facilitates these collaborations, and lay the foundation for prosperity. And, no, you cannot centralize innovations, we tried that in Russia.
Remarkably, to get a bit more philosophical with the ideas of Algazel, one can see religion’s effect here in reducing dependence on the fallibility of human theories and agency—so Adam Smith meets Algazel in that sense. For one the invisible hand is the market, for the other it is God. It has been difficult for people to understand that, historically, skepticism has been mostly skepticism of expert knowledge rather than skepticism about abstract entities like God, and that all the great skeptics have been largely either religious or, at least, pro-religion (that is, in favor of
others
being religious).
Corporate Teleology
When I was in business school I rarely attended lectures in something called strategic planning, a required course, and when I showed my face in class, I did not listen for a nanosecond to what was said there; did not even buy the books. There is something about the common sense of student culture; we knew that it was all babble. I passed the required classes in management by confusing the professors, playing with complicated logics, and I felt it intellectually dishonest to enroll in more classes than the strictly necessary.
Corporations are in love with the idea of the strategic plan. They need to pay to figure out where they are going. Yet there is no evidence that strategic planning works—we even seem to have evidence against it. A management scholar, William Starbuck, has published a few papers debunking the effectiveness of planning—it makes the corporation option-blind, as it gets locked into a non-opportunistic course of action.
Almost everything theoretical in management, from Taylorism to all productivity stories, upon empirical testing, has been exposed as pseudoscience—and like most economic theories, lives in a world parallel to the evidence. Matthew Stewart, who, trained as a philosopher, found himself in a management consultant job, gives a pretty revolting, if funny, inside story in
The Management Myth
. It is similar to the self-serving approach of bankers. Abrahamson and Friedman, in their beautiful book
A Perfect Mess,
also debunk many of these neat, crisp,
teleological approaches. It turns out, strategic planning is just superstitious babble.
For an illustration of business drift, rational and opportunistic business drift, take the following. Coca-Cola began as a pharmaceutical product. Tiffany & Co., the fancy jewelry store company, started life as a stationery store. The last two examples are close, perhaps, but consider next: Raytheon, which made the first missile guidance system, was a refrigerator maker (one of the founders was no other than Vannevar Bush, who conceived the teleological linear model of science we saw earlier; go figure). Now, worse: Nokia, who used to be the top mobile phone maker, began as a paper mill (at some stage they were into rubber shoes). DuPont, now famous for Teflon nonstick cooking pans, Corian countertops, and the durable fabric Kevlar, actually started out as an explosives company. Avon, the cosmetics company, started out in door-to-door book sales. And, the strangest of all, Oneida Silversmiths was a community religious cult but for regulatory reasons they needed to use as cover a joint stock company.


================================================================================
CHAPTER/SECTION 69 (Item 72)
================================================================================

THE INVERSE TURKEY PROBLEM
Now some plumbing behind what I am saying—epistemology of statistical statements. The following discussion will show how the unknown, what you don’t see, can contain good news in one case and bad news in another. And in Extremistan territory, things get even more accentuated.
To repeat (it is necessary to repeat because intellectuals tend to forget it), absence of evidence is not evidence of absence, a simple point that has the following implications: for the antifragile, good news tends to be absent from past data, and for the fragile it is the bad news that doesn’t show easily.
Imagine going to Mexico with a notebook and trying to figure out the average wealth of the population from talking to people you randomly encounter. Odds are that, without Carlos Slim in your sample, you have little information. For out of the hundred or so million Mexicans, Slim would (I estimate) be richer than the bottom seventy to ninety million all taken together. So you may sample fifty million persons and unless you include that “rare event,” you may have nothing in your sample and underestimate the total wealth.
Remember the graphs in
Figures 6
or
7
illustrating the payoff from
trial and error. When engaging in tinkering, you incur a lot of small losses, then once in a while you find something rather significant. Such methodology will show nasty attributes when seen from the outside—it hides its qualities, not its defects.
In the antifragile case (of positive asymmetries, positive Black Swan businesses), such as trial and error, the sample track record will tend to underestimate the long-term average; it will hide the qualities, not the defects.
(A chart is included in the appendix for those who like to look at the point graphically.)
Recall our mission to “not be a turkey.” The take-home is that, when facing a long sample subjected to turkey problems, one tends to estimate a
lower
number of adverse events—simply, rare events are rare, and tend not to show up in past samples, and given that
the rare is almost always negative,
we get a rosier picture than reality. But here we face the mirror image, the reverse situation. Under positive asymmetries, that is, the antifragile case, the “unseen” is positive. So “empirical evidence” tends to miss positive events and underestimate the total benefits.
As to the classic turkey problem, the rule is as follows.
In the fragile case of negative asymmetries (turkey problems), the sample track record will tend to overestimate the long-term average; it will hide the defects and display the qualities.
The consequences make life simple. But since standard methodologies do not take asymmetries into account, about anyone who studied conventional statistics without getting very deep into the subject (just to theorize in social science or teach students) will get the turkey problem wrong. I have a simple rule, that those who teach at Harvard should be expected to have much less understanding of things than cab drivers or people innocent of canned methods of inference (it is a heuristic, it can be wrong, but it works; it came to my attention as the Harvard Business School used to include Fragilista Robert C. Merton on its staff).
So let us pick on Harvard Business School professors who deserve it quite a bit. When it comes to the first case (the error of ignoring positive asymmetries), one Harvard Business School professor, Gary Pisano,
writing about the potential of biotech, made the elementary inverse-turkey mistake, not realizing that in a business with limited losses and unlimited potential (the exact opposite of banking), what you don’t see can be both significant and hidden from the past. He writes: “Despite the commercial success of several companies and the stunning growth in revenues for the industry as a whole, most biotechnology firms earn no profit.” This may be correct, but the inference from it is wrong, possibly backward, on two counts, and it helps to repeat the logic owing to the gravity of the consequences. First, “most companies” in Extremistan make no profit—the rare event dominates, and a small number of companies generate all the shekels. And whatever point he may have, in the presence of the kind of asymmetry and optionality we see in
Figure 7
, it is inconclusive, so it is better to write about another subject, something less harmful that may interest Harvard students, like how to make a convincing PowerPoint presentation or the difference in managerial cultures between the Japanese and the French. Again, he may be right about the pitiful potential of biotech investments, but not on the basis of the data he showed.
Now why is such thinking by the likes of Professor Pisano dangerous? It is not a matter of whether or not he would inhibit research in biotech. The problem is that such a mistake inhibits everything in economic life that has antifragile properties (more technically, “right-skewed”). And it would fragilize by favoring matters that are “sure bets.”
Remarkably, another Harvard professor, Kenneth Froot, made the exact same mistake, but in the opposite direction, with the negative asymmetries. Looking at reinsurance companies (those that insure catastrophic events), he thought that he found an aberration. They made too much profit given the risks they took, as catastrophes seemed to occur
less often
than what was reflected in the premia. He missed the point that catastrophic events hit them only negatively, and tend to be absent from past data (again, they are rare). Remember the turkey problem. One single episode, the asbestos liabilities, bankrupted families of Lloyd underwriters, losing income made over generations. One single episode.
We will return to these two distinct payoffs, with “bounded left” (limited losses, like Thales’ bet) and “bounded right” (limited gains, like insurance or banking). The distinction is crucial, as most payoffs in life fall in either one or the other category.
To Fail Seven Times, Plus or Minus Two
Let me stop to issue rules based on the chapter so far. (i) Look for optionality; in fact, rank things according to optionality, (ii) preferably with open-ended, not closed-ended, payoffs; (iii) Do not invest in business plans but in people, so look for someone capable of changing six or seven times over his career, or more (an idea that is part of the modus operandi of the venture capitalist Marc Andreessen); one gets immunity from the backfit narratives of the business plan by investing in people. It is simply more robust to do so; (iv) Make sure you are barbelled, whatever that means in your business.


================================================================================
CHAPTER/SECTION 70 (Item 73)
================================================================================

THE CHARLATAN, THE ACADEMIC, AND THE SHOWMAN
I end the chapter on a sad note: our ingratitude toward many who have helped us get here—letting our ancestors survive.
Our misunderstanding of convex tinkering, antifragility, and how to tame randomness is woven into our institutions—though not consciously and explicitly. There is a category of people in medicine called the empirics, or empirical skeptics, the doers, and that is about it—we do not have many names for them as they have not written a lot of books. Many of their works were destroyed or hidden from cultural consciousness, or have naturally dropped out of the archives, and their memory has been treated very badly by history. Formal thinkers and theorizing theorizers tend to write books; seat-of-the-pants people tend to be practitioners who are often content to get the excitement, make or lose the money, and discourse at the pub. Their experiences are often formalized by academics; indeed, history has been written by those who want you to believe that reasoning has a monopoly or near monopoly on the production of knowledge.
So the final point here is about those called charlatans. Some were, others were less so; some were not; and many were borderline. For a long time official medicine had to compete with crowds of flashy showmen, mountebanks, quacks, sorcerers and sorceresses, and all manner of unlicensed practitioners. Some were itinerant, going from town to town carrying out their curative acts in front of large gatherings. They would perform surgery on occasion while repeating incantations.
This category included doctors who did not subscribe to the dominant Graeco-Arabic school of rational medicine, developed in the Hellenistic
world of Asia Minor and later grown by the Arabic language school. The Romans were an anti-theoretical pragmatic bunch; the Arabs loved everything philosophical and “scientific” and put Aristotle, about whom nobody seemed to have cared much until then, on a pedestal. For instance we know very, very little of the skeptical empirical school of Menodotus of Nicomedia—we know a lot more about Galen, the rationalist. Medicine, for the Arabs, was a scholarly pursuit and founded on the logic of Aristotle and the methods of Galen; they abhorred experience.
6
Medical practitioners were the Other.
The regulation of the medical establishment corresponds to worries about the empirics for economic reasons as competition made their incomes drop. So no wonder these were bundled with the thieves, to wit this long title for an Elizabethan treatise:
A short discourse, or, discouery of certaine stratagems, whereby our London-empericks, haue bene obserued strongly to oppugne, and oft times to expugne their poore patients purses.
“Charlatan” was held to be a synonym for
empirick
. The word “empiric” designated someone who relied on experiment and experience to ascertain what was correct. In other words, trial and error and tinkering. That was held to be inferior—professionally, socially, and intellectually. It is still not considered to be very “intelligent.”
But luckily for us, the empirics enjoyed immense popular support and could not be uprooted. You do not see their works, but they left a huge imprint on medicine.
Note the initial peaking of iatrogenics after the academization—and institutionalization—of medicine with the onset of modernity. It has only recently started to reverse. Also, formal academics, seen in the light of history, were not better than those they called charlatans—they just hid their fraud under the weight of more convincing rationalizations. They were just
organized
quacks. My hope is for that to change.
Now, I agree that most nonacademically vetted medical practitioners were scoundrels, mountebanks, quacks, and often even worse than these. But let’s hold off jumping to the wrong conclusions. Formalists, to protect their turf, have always played on the logical fallacy that if quacks are found among nonacademics, nonacademics are all quacks. They keep doing it: the statement
all that is nonrigorous is nonacademic
(assuming
one is a sucker and believes it) does not imply that
all that is nonacademic is nonrigorous
. The fight between the “legitimate” doctors and the Others is quite enlightening, particularly when you note that doctors were silently (and reluctantly) copying some of the remedies and cures developed and promoted by the Others. They had to do so for economic reasons. They benefited from the collective trial and error of the Others. And the process led to cures, now integrated into medicine.
Now, reader, let us take a minute and pay some respect. Consider our ingratitude to those who got us here, got our disrespect, and do not even know that they were heroes.
1
According to David Edgerton, the so-called linear model was not believed in much in the early twentieth century; it is just that we believe
now
that we believed
then
in the supremacy of teleological science.
2
We also figured out that two fragilistas, Myron Scholes and Robert Merton, got the Memorial Prize in Economics called “Nobel” for the packaging of a formula that other people discovered in much more sophisticated form before them. Furthermore, they used fictional mathematics. It is quite unsettling.
3
I remind the reader that the bone in
Book IV
is teleology and sense of direction, and while this is largely skeptical of formal academia (i.e. anti-universities), this is staunchingly anti-pseudoscience (or cosmetic science) and ultra-pro-science. It is just that what many call science is highly unscientific. Science is an anti-sucker problem.
4
Remarkably, Johan Jensen, of Jensen’s inequality, which provides the major technical support behind the ideas of this book, was an amateur mathematician who never held any academic position.
5
This is a technical comment. “1/N” is the argument Mandelbrot and I used in 2005 to debunk optimized portfolios and modern finance theory on simple mathematical grounds; under Extremistan effects, we favor broad, very broad diversification with small equal allocations rather than what modern financial theory stipulates.
6
It is not very well noticed that Arabic thought favors abstract thinking and science in the most theoretical sense of the word — violently rationalistic, away from empiricism.


================================================================================
CHAPTER/SECTION 71 (Item 74)
================================================================================

CHAPTER 16
A Lesson In Disorder
Where is the next street fight?—How to decommoditize, detouristify—The intelligent student (also in reverse)—Flâneur as options
Let us continue with teleology and disorder—in private life and individual education. Then an autobiographical vignette.


================================================================================
CHAPTER/SECTION 72 (Item 75)
================================================================================

THE ECOLOGICAL AND THE LUDIC
As we saw with the fellow making the common but false analogy to blackjack in
Chapter 7
, there are two domains, the ludic, which is set up like a game, with its rules supplied in advance in an explicit way, and the ecological, where we don’t know the rules and cannot isolate variables, as in real life. Seeing the nontransferability of skills from one domain to the other led me to skepticism in general about whatever skills are acquired in a classroom, anything in a non-ecological way, as compared to street fights and real-life situations.
It is not well advertised that there is no evidence that abilities in chess lead to better reasoning off the chessboard—even those who play blind chess games with an entire cohort can’t remember things outside the board better than a regular person. We accept the domain-specificity of games, the fact that they do not really train you for life, that there are severe losses in translation. But we find it hard to apply this lesson to technical skills acquired in schools, that is, to accept the crucial fact that
what is picked up in the classroom
stays
largely in the classroom. Worse even, the classroom can bring some detectable harm, a measure of iatrogenics hardly ever discussed: Laura Martignon showed me results from her doctoral student Birgit Ulmer demonstrating that children’s ability to
count
degrades right after they are taught arithmetic. When you ask children how many intervals there are between fifteen poles, those who don’t know arithmetic figure out that there are fourteen of them. Those who studied arithmetic get confused and often make the mistake that there are fifteen.
The Touristification of the Soccer Mom
The biologist and intellectual E. O. Wilson was once asked what represented the most hindrance to the development of children; his answer was the soccer mom. He did not use the notion of the Procrustean bed, but he outlined it perfectly. His argument is that they repress children’s natural biophilia, their love of living things. But the problem is more general; soccer moms try to eliminate the trial and error, the antifragility, from children’s lives, move them away from the ecological and transform them into nerds working on preexisting (soccer-mom-compatible) maps of reality. Good students, but nerds—that is, they are like computers except slower. Further, they are now totally untrained to handle ambiguity. As a child of civil war, I disbelieve in structured learning—actually I believe that one can be an intellectual without being a nerd, provided one has a private library instead of a classroom, and spends time as an aimless (but rational) flâneur benefiting from what randomness can give us inside and outside the library. Provided we have the right type of rigor, we need randomness, mess, adventures, uncertainty, self-discovery, near-traumatic episodes, all these things that make life worth living, compared to the structured, fake, and ineffective life of an empty-suit CEO with a preset schedule and an alarm clock. Even their leisure is subjected to a clock, squash between four and five, as their life is sandwiched between appointments. It is as if the mission of modernity was to squeeze every drop of variability and randomness out of life—with (as we saw in
Chapter 5
) the ironic result of making the world a lot more unpredictable, as if the goddesses of chance wanted to have the last word.
Only the autodidacts are free. And not just in school matters—those who decommoditize, detouristify their lives. Sports try to put randomness
in a box like the ones sold in aisle six next to canned tuna—a form of alienation.
If you want to understand how vapid are the current modernistic arguments (and understand your existential priorities), consider the difference between lions in the wild and those in captivity. Lions in captivity live longer; they are technically richer, and they are guaranteed job security for life, if these are the criteria you are focusing on …
As usual, an ancient, here Seneca, detected the problem (and the difference) with his saying “We do not study for life, but only for the lecture room,”
non vitae, sed scolae discimus,
which to my great horror has been corrupted and self-servingly changed to fit the motto of many colleges in the United States, with
non scolae, sed vitae discimus
as their motto, meaning that “We study [here] for life, not for the lecture hall.”
Most of the tension in life will take place when the one who reduces and fragilizes (say the policy maker) invokes rationality.


================================================================================
CHAPTER/SECTION 73 (Item 76)
================================================================================

AN ANTIFRAGILE (BARBELL) EDUCATION
Something cured me of the effect of education, and made me very skeptical of the very notion of standardized learning.
For I am a pure autodidact, in spite of acquiring degrees.
My father was known in Lebanon as the “Intelligent Student Student Intelligent,” a play on words, as the Arabic phrase for “intelligent student” (or scholar) is
taleb nagib
and his name was Nagib Taleb. That was the way the newspaper published his name for having the highest grade on the Lebanese high school exit exam. He was a national valedictorian of sorts, and the main newspaper announced his passing in 2002 with a front-page headline with a pun on his predestined name, T
HE
I
NTELLIGENT
S
TUDENT
S
TUDENT
I
NTELLIGENT
I
S
N
O
L
ONGER
. His school education was harrowing, though, as he attended the elite Jesuit school. The Jesuits’ mission was to produce the mandarins who ran the place, by filtering and filtering students after every year. They were successful beyond their aim, as in addition to having one of the highest success rates in the world in the French baccalaureate (in spite of the war), their school had a world-class roster of former students. The Jesuits also deprived pupils of free time, so many gave up voluntarily. So one can surmise that having a father as national valedictorian would definitely have provided me with a cure against school, and it did. My father himself did not seem to overvalue school education, since he did not put me in the
Jesuit school—to spare me what he went through. But this clearly left me to seek ego fulfillment elsewhere.
Observing my father close up made me realize what being a valedictorian meant, what being an
Intelligent Student
meant, mostly in the negative: they were things that intelligent students were unable to understand. Some blindness came with the package. This idea followed me for a long time, as when I worked in trading rooms, where you sit most of the time waiting for things to happen, a situation similar to that of people sitting in bars or mafia men “hanging around.” I figured out how to select people on their ability to integrate socially with others while sitting around doing nothing and enjoying fuzziness. You select people on their ability to hang around, as a filter, and studious people were not good at hanging around: they needed to have a clear task.
When I was about ten I realized that good grades weren’t as good outside school as they were in it, as they carried some side effects. They had to correspond to a sacrifice, an intellectual sacrifice of sorts. Actually my father kept hinting to me the problem of getting good grades himself: the person who was at the exact bottom of his class (and ironically, the father of a classmate at Wharton) turned out to be a self-made merchant, by far the most successful person in his class (he had a huge yacht with his initials prominently displayed on it); another one made a killing buying wood in Africa, retired before forty, then became an amateur historian (mostly in ancient Mediterranean history) and entered politics. In a way my father did not seem to value education, rather culture or money—and he prompted me to go for these two (I initially went for culture). He had a total fascination with erudites and businessmen, people whose position did not depend on credentials.
My idea was to be rigorous in the open market. This made me focus on what an intelligent antistudent needed to be: an autodidact—or a person of knowledge compared to the students called “swallowers” in Lebanese dialect, those who “swallow school material” and whose knowledge is only derived from the curriculum. The edge, I realized, isn’t in the package of what was on the official program of the baccalaureate, which everyone knew with small variations multiplying into large discrepancies in grades, but exactly what lay outside it.
Some can be more intelligent than others in a structured environment—in fact school has a selection bias as it favors those quicker in such an environment, and like anything competitive, at the expense of performance outside it. Although I was not yet familiar with gyms, my
idea of knowledge was as follows. People who build their strength using these modern expensive gym machines can lift extremely large weights, show great numbers and develop impressive-looking muscles, but fail to lift a stone; they get completely hammered in a street fight by someone trained in more disorderly settings. Their strength is extremely domain-specific and their domain doesn’t exist outside of ludic—extremely organized—constructs. In fact their strength, as with overspecialized athletes, is the result of a deformity. I thought it was the same with people who were selected for trying to get high grades in a small number of subjects rather than follow their curiosity: try taking them slightly away from what they studied and watch their decomposition, loss of confidence, and denial. (Just like corporate executives are selected for their ability to put up with the boredom of meetings, many of these people were selected for their ability to concentrate on boring material.) I’ve debated many economists who claim to specialize in risk and probability: when one takes them slightly outside their narrow focus, but within the discipline of probability, they fall apart, with the disconsolate face of a gym rat in front of a gangster hit man.
Again, I wasn’t exactly an autodidact, since I did get degrees; I was rather a barbell autodidact as I studied the exact minimum necessary to pass any exam, overshooting accidentally once in a while, and only getting in trouble a few times by undershooting. But I read voraciously, wholesale, initially in the humanities, later in mathematics and science, and now in history—outside a curriculum, away from the gym machine so to speak. I figured out that whatever I selected myself I could read with more depth and more breadth—there was a match to my curiosity. And I could take advantage of what people later pathologized as Attention Deficit Hyperactive Disorder (ADHD) by using natural stimulation as a main driver to scholarship. The enterprise needed to be totally effortless in order to be worthwhile. The minute I was bored with a book or a subject I moved to another one, instead of giving up on reading altogether—when you are limited to the school material and you get bored, you have a tendency to give up and do nothing or play hooky out of discouragement. The trick is to be bored with a specific book, rather than with the act of reading. So the number of pages absorbed could grow faster than otherwise. And you find gold, so to speak, effortlessly, just as in rational but undirected trial-and-error-based research. It is exactly like options, trial and error, not getting stuck, bifurcating when
necessary but keeping a sense of broad freedom and opportunism. Trial and error is freedom.
(I confess I still use that method at the time of this writing. Avoidance of boredom is the only worthy mode of action. Life otherwise is not worth living.)
My parents had an account with the largest bookstore in Beirut and I would pick up books in what seemed to me unlimited quantities. There was such a difference between the shelves of the library and the narrow school material; so I realized that school was a plot designed to deprive people of erudition by squeezing their knowledge into a narrow set of authors. I started, around the age of thirteen, to keep a log of my reading hours, shooting for between thirty and sixty a week, a practice I’ve kept up for a long time. I read the likes of Dostoyevsky, Turgenev, Chekhov, Bishop Bossuet, Stendhal, Dante, Proust, Borges, Calvino, Céline, Schultz, Zweig (didn’t like), Henry Miller, Max Brod, Kafka, Ionesco, the surrealists, Faulkner, Malraux (along with other wild adventurers such as Conrad and Melville; the first book I read in English was
Moby-Dick
) and similar authors in literature, many of them obscure, and Hegel, Schopenhauer, Nietzsche, Marx, Jaspers, Husserl, Lévi-Strauss, Levinas, Scholem, Benjamin, and similar ones in philosophy because they had the golden status of not being on the school program, and I managed to read
nothing
that was prescribed by school so to this day I haven’t read Racine, Corneille, and other bores. One summer I decided to read the twenty novels by Émile Zola in twenty days, one a day, and managed to do so at great expense. Perhaps joining an underground anti-government group motivated me to look into Marxist studies, and I picked up the most about Hegel indirectly, mostly through Alexandre Kojève.
When I decided to come to the United States, I repeated, around the age of eighteen, the marathon exercise by buying a few hundred books in English (by authors ranging from Trollope to Burke, Macaulay, and Gibbon, with Anaïs Nin and other then fashionable authors
de scandale
), not showing up to class, and keeping the thirty- to sixty-hour discipline.
In school, I had figured out that when one could write essays with a rich, literary, but precise vocabulary (though not inadequate to the topic at hand), and maintain some coherence throughout, what one writes about becomes secondary and the examiners get a hint about one’s style
and rigor from that. And my father gave me a complete break after I got published as a teenager in the local paper—“just don’t flunk” was his condition. It was a barbell—play it safe at school and read on your own, have
zero
expectation from school. Later, after I was jailed for assaulting a policeman in a student riot, he acted scared of me and let me do whatever I wanted. When I reached the “f*** you money” stage in my twenties, at the time when it was much, much rarer than today, in spite of a war raging in the home country, my father took credit for it by attributing it to the breadth of the education he allowed me to have and how it differentiated me from others like him with narrow background.
When, at Wharton, I discovered that I wanted to specialize in a profession linked to probability and rare events, a probability and randomness obsession took control of my mind. I also smelled some flaws with statistical stuff that the professor could not explain, brushing them away—it was what the professor was brushing away that had to be the meat. I realized that there was a fraud somewhere, that “six sigma” events (measures of very rare events) were grossly miscomputed and we had no basis for their computation, but I could not articulate my realization clearly, and was getting humiliated by people who started smoking me with complicated math. I saw the limits of probability in front of me, clear as crystal, but could not find the words to express the point. So I went to the bookstore and ordered (there was no Web at the time) almost every book with “probability” or “stochastic” in its title. I read nothing else for a couple of years, no course material, no newspaper, no literature, nothing. I read them in bed, jumping from one book to the next when stuck with something I did not get immediately or felt ever so slightly bored. And I kept ordering those books. I was hungry to go deeper into the problem of small probabilities. It was effortless. That was my best investment—risk turned out to be the topic I know the best. Five years later I was set for life and now I am making a research career out of various aspects of small probability events. Had I studied the subject by prepackaged means, I would be now brainwashed into thinking that uncertainty was something to be found in a casino, that kind of thing. There is such a thing as nonnerdy applied mathematics: find a problem first, and figure out the math that works for it (just as one acquires language), rather than study in a vacuum through theorems and artificial examples, then change reality to make it look like these examples.
One day in the 1980s I had dinner with a famous speculator, a hugely successful man. He muttered the hyperbole that hit home: “much of what other people know isn’t worth knowing.”
To this day I still have the instinct that the treasure, what one needs to know for a profession, is necessarily what lies outside the corpus, as far away from the center as possible. But there is something central in following one’s own direction in the selection of readings: what I was given to study in school I have forgotten; what I decided to read on my own, I still remember.


================================================================================
CHAPTER/SECTION 74 (Item 77)
================================================================================

CHAPTER 17
Fat Tony Debates Socrates
Piety for the impious—Fat Tony does not drink milk—Always ask poets to explain their poetry—Mystagogue philosophaster
Fat Tony believes that they were totally justified in putting Socrates to death.
This chapter will allow us to complete the discussion of the difference between narrated, intelligible knowledge, and the more opaque kind that is entirely probed by tinkering—the two columns of
Table 4
separating narrative and non-narrative action. There is this error of thinking that things always have a
reason
that is accessible to us—that we can comprehend easily.
Indeed, the most severe mistake made in life is to mistake the unintelligible for the unintelligent—something Nietzsche figured out. In a way, it resembles the turkey problem, mistaking what we don’t see for the nonexistent, a sibling to mistaking absence of evidence for evidence of absence.
We’ve been falling for the green lumber problem since the beginning of the golden age of philosophy—we saw Aristotle mistaking the source of Thales’ success; now we turn to Socrates, the greatest of the great masters.


================================================================================
CHAPTER/SECTION 75 (Item 78)
================================================================================

EUTHYPHRO
Plato expressed himself chiefly through his use of the person who no doubt became the most influential philosopher in history, Socrates the Athenian, the first philosopher in the modern sense. Socrates left no writing of his own, so we get direct representation of him mainly through Plato and Xenophon. And just as Fat Tony has, as his self-appointed biographer, yours truly trying to satisfy his own agenda, leading to distortions in his character and self-serving representation of some of the said author’s ideas, so I am certain that the Socrates of Plato is a more Platonic character than the true Socrates.
1
In one of Plato’s dialogues,
Euthyphro,
Socrates was outside the courthouse, awaiting the trial in which he was eventually put to death, when the eponymous Euthyphro, a religious expert and prophet of sorts, struck up a conversation with him. Socrates started explaining that for the “activities” with which he was charged by the court (corrupting the youth and introducing new gods at the expense of the older ones), not only he did not charge a fee, but he was in perfect readiness to pay for people to listen to him.
It turned out that Euthyphro was on his way to charge his father with manslaughter, not a bad conversation starter. So Socrates started out by wondering how charging his own father with manslaughter was compatible with Euthyphro’s religious duties.
Socrates’ technique was to make his interlocutor, who started with a thesis, agree to a series of statements, then proceed to show him how the statements he agreed to are inconsistent with the original thesis, thus establishing that he has no clue as to what he was taking about. Socrates used it mostly to show people how lacking in clarity they were in their thoughts, how little they knew about the concepts they used routinely—and the need for philosophy to elucidate these concepts.
In the beginning of the
Euthypro
dialogue, he catches his interlocutor using the word “piety,” characterizing the prosecution of his father as a
pious act and so giving the impression that he was conducting the prosecution on grounds of piety. But he could not come up with a definition that suited Socrates. Socrates kept pestering the poor fellow as he could not produce a definition of piety. The dialogue continued with more definitions (what is “moral rectitude”?), until Euthyphro found some polite excuse to run away. The dialogue ended abruptly, but the reader is left with the impression that it could have gone on until today, twenty-five centuries later, without it bringing us any closer to anything.
Let us reopen it.


================================================================================
CHAPTER/SECTION 76 (Item 79)
================================================================================

FAT TONY VERSUS SOCRATES
How would Fat Tony have handled the cross-examination by the relentless Athenian? Now that the reader is acquainted with our hefty character, let us examine, as a thought experiment, an equivalent dialogue between Fat Tony and Socrates, properly translated of course.
Clearly, there are similarities between the two characters. Both had time on their hands and enjoyed unlimited leisure, though, in Tony’s case, free time was the result of productive insights. Both like to argue, and both look at active conversation (instead of TV screen or concert hall passivity) as a main source of entertainment. Both dislike writing: Socrates because he did not like the definitive and immutable character that is associated with the written word when for him answers are never final and should not be fixed. Nothing should be written in stone, even literally: Socrates in the
Euthyphro
boasts for ancestry the sculptor Daedalus, whose statues came alive as soon as the work was completed. When you talk to one of Daedalus’ statues, it talks back to you, unlike the ones you see in the Metropolitan Museum of Art in New York City. Tony, for his part, did not like writing for other, no less respectable reasons: he almost flunked out of high school in Bay Ridge, Brooklyn.
But the similarities stop somewhere, which would be good enough for a dialogue. Of course we can expect a bit of surprise on the part of Fat Tony standing in front of the man described to him by Nero as the greatest philosopher of all time: Socrates, we are told, had looks beyond unprepossessing. Socrates was repeatedly described as having a protruding belly, thin limbs, bulging eyes, a snub nose. He looked haggard. He might even have had body odor, as he was said to bathe much less than his peers. You can imagine Fat Tony sneering while pointing his finger at
the fellow: “Look, Neeero, you want me to talk to …
dis
?” Or perhaps not: Socrates was said to have a presence, a certain personal confidence and a serenity of mind that made some young men find him “beautiful.”
What Nero was certain of was that Fat Tony would initially get close to Socrates and form his opinion on the fellow after some olfactory investigation—and as we said, Fat Tony doesn’t even realize that this is part of his modus operandi.
Now assume Fat Tony was asked by Socrates how he defined piety. Fat Tony’s answer would have been most certainly to
get lost—
Fat Tony, aware of Socrates’ statement that not only would he debate for free, but he would be ready to pay for conversation, would have claimed one doesn’t argue with someone who is ready to pay you to argue with him.
But Fat Tony’s power in life is that he never lets the other person frame the question. He taught Nero that an answer is planted in every question; never respond with a straight answer to a question that makes no sense to you.
F
AT
T
ONY
: “You are asking me to define what characteristic makes a difference between pious and nonpious. Do I really
need
to be able to tell you what it is to be able to conduct a pious action?”
S
OCRATES
: “How can you use a word like ‘piety’ without knowing what it means, while pretending to know what it means?”
F
AT
T
ONY
: “Do I actually have to be able to tell you in plain barbarian non-Greek English, or in pure Greek, what it means to prove that I know and understand what it means? I don’t know it in words but I know what it is.”
No doubt Fat Tony would have taken Socrates of Athens further down his own road and be the one doing the framing of the question:
F
AT
T
ONY
: “Tell me, old man. Does a child need to define mother’s milk to understand the need to drink it?”
S
OCRATES
: “No, he does not need to.”
F
AT
T
ONY
(using the same repetitive pattern of Socrates in the Plato dialogues): “And my dear Socrates, does a dog need to define what an owner is to be loyal to him?”
S
OCRATES
(puzzled to have someone ask him questions): “A dog has … instinct. It does not reflect on its life. He doesn’t examine his life. We are not dogs.”
F
AT
T
ONY
: “I agree, my dear Socrates, that a dog has instinct and that we are not dogs. But are we humans so fundamentally different as to be completely stripped of instinct leading us to do things we have no clue about? Do we have to limit life to what we can answer in proto-Brooklyn English?”
Without waiting for Socrates’ answer (only suckers wait for answers; questions are not made for answers):
F
AT
T
ONY
: “Then, my good Socrates, why do you think that we need to fix the meaning of things?”
S
OCRATES
: “My dear Mega-Tony, we need to know what we are talking about when we talk about things. The entire idea of philosophy is to be able to reflect and understand what we are doing, examine our lives. An unexamined life is not worth living.”
F
AT
T
ONY
: “The problem, my poor old Greek, is that you are killing the things we can know but not express. And if I asked someone riding a bicycle just fine to give me the theory behind his bicycle riding, he would fall from it. By bullying and questioning people you confuse them and hurt them.”
Then, looking at him patronizingly, with a smirk, very calmly:
F
AT
T
ONY
: “My dear Socrates … you know why they are putting you to death? It is because you make people feel stupid for blindly following habits, instincts, and traditions. You may be occasionally right. But you may confuse them about things they’ve been doing just fine without getting in trouble. You are destroying people’s illusions about themselves. You are taking the joy of ignorance out of the things we don’t understand. And you have
no
answer; you have
no
answer to offer them.”


================================================================================
CHAPTER/SECTION 77 (Item 80)
================================================================================

PRIMACY OF DEFINITIONAL KNOWLEDGE
You can see that what Fat Tony is hitting here is the very core of philosophy: it is indeed with Socrates that the main questions that became philosophy today were first raised, questions such as “what is existence?,” “what are morals?,” “what is a proof?,” “what is science?,” “what is this?” and “what is that?”
The question we saw in
Euthyphro
pervades the various dialogues written by Plato. What Socrates is seeking relentlessly are definitions of the essential nature of the thing concerned rather than descriptions of the properties by means of which we can recognize them.
Socrates went even as far as questioning the poets and reported that they had no more clue than the public about their own works. In Plato’s account of his trial in the
Apology,
Socrates recounted how he cross-examined the poets in vain: “I took them some of the most elaborate passages in their own writings, and asked what was the meaning of them. I am almost ashamed to speak of this, but still I must say that there is hardly a person present who wouldn’t have talked better about their poetry than they did themselves.”
And this priority of definitional knowledge led to Plato’s thesis that you cannot know anything unless you know the Forms, which are what definitions specify. If we cannot define piety from working with particulars, then let us start with the universals from which these particulars should flow. In other words, if you cannot get a map from a territory, build a territory out of the map.
In defense of Socrates, his questions lead to a major result: if they could not allow him to define what something was, at least they allowed him to be certain about what a thing was not.
Mistaking the Unintelligible for the Unintelligent
Fat Tony, of course, had many precursors. Many we will not hear about, because of the primacy of philosophy and the way it got integrated into daily practices by Christianity and Islam. By “philosophy,” I mean theoretical and conceptual knowledge, all knowledge, things we can write down. For, until recently, the term largely referred to what we call today science—natural philosophy, this attempt to rationalize Nature, penetrate her logic.
A vivid modern attack on the point came from the young Friedrich Nietzsche, though dressed up in literary flights on optimism and pessimism mixed with a hallucination on what “West,” a “typical Hellene,” and “the German soul” mean. The young Nietzsche wrote his first book,
The Birth of Tragedy,
while in his early twenties. He went after Socrates, whom he called the “mystagogue of science,” for “making existence appear comprehensible.” This brilliant passage exposes what I call the sucker-rationalistic fallacy:
Perhaps—thus he [Socrates] should have asked himself—what is not intelligible to me is not necessarily unintelligent? Perhaps there is a realm of wisdom from which the logician is exiled?
“What is not intelligible to me is not necessarily unintelligent” is perhaps the most potent sentence in all of Nietzsche’s century—and we used a version of it in the prologue, in the very definition of the fragilista who mistakes what he does not understand for nonsense.
Nietzsche is also allergic to Socrates’ version of truth, largely motivated by the agenda of the promotion of understanding, since according to Socrates, one does not knowingly do evil—an argument that seems to have pervaded the Enlightenment as such thinkers as Condorcet made truth the only and sufficient source for the good.
This argument is precisely what Nietzsche vituperated against: knowledge is the panacea; error is evil; hence science is an optimistic enterprise. The mandate of scientific optimism irritated Nietzsche: this use of reasoning and knowledge at the service of utopia. Forget the optimism/pessimism business that is addressed when people discuss Nietzsche, as the so-called Nietzschean pessimism distracts from the point: it is the very
goodness
of knowledge that he questioned.
It took me a long time to figure out the central problem that Nietzsche addressed in
The Birth of Tragedy
. He sees two forces, the Apollonian and the Dionysian. One is measured, balanced, rational, imbued with reason and self-restraint; the other is dark, visceral, wild, untamed, hard to understand, emerging from the inner layers of our selves. Ancient Greek culture represented a balance of the two, until the influence of Socrates on Euripides gave a larger share to the Apollonian and disrupted the Dionysian, causing this excessive rise of rationalism. It is equivalent to disrupting the natural chemistry of your body by the injection of hormones. The Apollonian without the Dionysian is, as the Chinese would say, yang without yin.
Nietzsche’s potency as a thinker continues to surprise me: he figured out antifragility. While many attribute (mistakenly) the notion of “creative destruction” to the economist Joseph Schumpeter (not wondering how something insightful and deep can come out of an economist),
2
while, as we saw, the more erudite source it to Karl Marx, it is indeed Nietzsche who was first to coin the term with reference to Dionysus, whom he called “creatively destructive” and “destructively creative.” Nietzsche indeed figured out—in his own way—antifragility.
I read Nietzsche’s
The Birth of Tragedy
twice, first as a child when I was very green. The second time, after a life thinking of randomness, it hit me that Nietzsche understood something that I did not find explicitly stated in his work: that growth in knowledge—or in anything—cannot proceed without the Dionysian. It reveals matters that we can select at some point, given that we have optionality. In other words, it can be the source of stochastic tinkering, and the Apollonian can be part of the rationality in the selection process.
Let me bring the big boss, Seneca, into the picture. He, too, referred to Dionysian and Apollonian attributes. He appeared to present, in one of his writings a richer version of our human tendencies. Talking about a God (whom he also calls “destiny,” equating him with the interaction of causes), he gives him three manifestations. First, the “Liber Pater,” the Bacchic force (that is, the Dionysos to whom Nietzsche referred) that gives seminal power to the continuation of life; second, Hercules, who embodies strength; and third, Mercury, who represented (for Seneca’s contemporaries) craft, science, and reason (what for Nietzsche appeared to be the Apollonian). Richer than Nietzsche, he included strength as an additional dimension.
As I said, earlier attacks on “philosophy” in the sense of rationalistic knowledge from the Plato and Aristotle traditions came from a variety of people, not necessarily visible in the corpus, mostly in forgotten or rarely mentioned texts. Why forgotten? Because structured learning likes the impoverishment and simplification of naive rationalism, easy to teach, not the rich texture of empiricism, and, as I said, those who attacked academic thinking had little representation (something that we will see is starkly apparent in the history of medicine).
An even more accomplished, and far more open-minded, classical scholar than Nietzsche, the nineteenth-century French thinker Ernest Renan, knew, in addition to the usual Greek and Latin, Hebrew, Aramaic (Syriac), and Arabic. In his attack on Averroes, he expressed the famous idea that logic excludes—by definition—nuances, and since truth resides exclusively in the nuances, it is “a useless instrument for finding Truth in the moral and political sciences.”
Tradition
As Fat Tony said, Socrates was put to death because he disrupted something that, in the eyes of the Athenian establishment, was working just fine. Things are too complicated to be expressed in words; by doing so, you kill humans. Or people—as with the green lumber—may be focusing on the right things but we are not good enough to figure it out intellectually.
Death and martyrdom make good marketing, particularly when one faces destiny while unwavering in his opinions. A hero is someone imbued with intellectual confidence and ego, and death is something too small for him. While most of the accounts we hear of Socrates make him heroic, thanks to his death and his resignation to die in a philosophical way, he had some classical critics who believed that Socrates was destroying the foundations of society—the heuristics that are transmitted by the elders and that we may not be mature enough to question.
Cato the Elder, whom we met in
Chapter 2
, was highly allergic to Socrates. Cato had the bottom-line mind of Fat Tony, but with a much higher civic sense, sense of mission, respect for tradition, and commitment to moral rectitude. He was also allergic to things Greek, as exhibited in his allergy to philosophers and doctors—an allergy which, as we will see in later chapters, had remarkably modern justifications. Cato’s commitment to democracy led him to believe in both freedom and the rules of custom, in combination with fear of tyranny. Plutarch quotes him as saying: “Socrates was a mighty babbler who tried to make himself tyrant of his country in order to destroy its customs and entice its citizens into holding views contrary to law and order.”
So the reader can see how the ancients saw naive rationalism: by impoverishing—rather than enhancing—thought, it introduces fragility. They knew that incompleteness—half-knowledge—is always dangerous.
Many other people than the ancients have been involved in defending—and inviting us to respect—this different type of knowledge. First, Edmund Burke, the Irish statesman and political philosopher, who also countered the French Revolution for disrupting the “collected reasons of the ages.” He believed that large social variations can expose us to unseen effects and thus advocated the notion of small trial-and-error experiments (in effect, convex tinkering) in social systems, coupled with respect for the complex heuristics of tradition. Also Michael Oakeshot, the twentieth-century conservative political philosopher and philosopher
of history who believed that traditions provide an aggregation of filtered collective knowledge. Another one in that league would be Joseph de Maistre, who as we saw thought in “second steps.” He was a French-language royalist and counter-Enlightenment thinker who was vocal against the ills of the Revolution and believed in the fundamental depravity of men unless checked by some dictatorship.
Clearly, Wittgenstein would be at the top of the list of modern antifragile thinkers, with his remarkable insight into the inexpressible with words. And of all thinkers he best understands the green lumber issue—he may be the first ever to express a version of it when he doubted the ability of language to express the literal. In addition, the fellow was a saint—he sacrificed his life, his friendships, his fortune, his reputation, everything, for the sake of philosophy.
We may be drawn to think that Friedrich Hayek would be in that antifragile, antirationalist category. He is the twentieth-century philosopher and economist who opposed social planning on the grounds that the pricing system reveals through transactions the knowledge embedded in society, knowledge not accessible to a social planner. But Hayek missed the notion of optionality as a substitute for the social planner. In a way, he believed in intelligence, but as a distributed or collective intelligence—not in optionality as a replacement for intelligence.
3
The anthropologist Claude Lévi-Strauss showed that nonliterate peoples had their own “science of the concrete,” a holistic way of thinking about their environment in terms of objects and their “secondary,” sensuous qualities which was not necessarily less coherent than many of our scientific approaches and, in many respects, can be as rich as and even richer than ours. Again, green lumber.
Finally, John Gray, the contemporary political philosopher and essayist who stands against human hubris and has been fighting the prevailing ideas that the Enlightenment is a panacea—treating a certain category of thinkers as Enlightenment fundamentalists. Gray showed repeatedly how what we call scientific progress can be just a mirage. When he, myself, and the essayist Bryan Appleyard got together for lunch I was mentally prepared to discuss ideas, and advocate my own. I was pleasantly surprised by what turned out to be the best lunch I ever
had in my entire life. There was this smoothness of knowing that the three of us tacitly understood the same point and, instead, went to the second step of discussing applications—something as mundane as replacing our currency holdings with precious metals, as these are not owned by governments. Gray worked in an office next to Hayek and told me that Hayek was quite a dull fellow, lacking playfulness—hence optionality.


================================================================================
CHAPTER/SECTION 78 (Item 81)
================================================================================

THE SUCKER-NONSUCKER DISTINCTION
Let us introduce the philosopher’s stone back into this conversation. Socrates is about knowledge. Not Fat Tony, who has no idea what it is.
For Tony, the distinction in life isn’t True or False, but rather sucker or nonsucker. Things are always simpler with him. In real life, as we saw with the ideas of Seneca and the bets of Thales, exposure is more important than knowledge; decision effects supersede logic. Textbook “knowledge” misses a dimension, the hidden asymmetry of benefits—just like the notion of average. The need to focus on the payoff from your actions instead of studying the structure of the world (or understanding the “True” and the “False”) has been largely missed in intellectual history. Horribly missed.
The payoff, what happens to you (the benefits or harm from it), is always the most important thing, not the event itself
.
Philosophers talk about truth and falsehood. People in life talk about payoff, exposure, and consequences (risks and rewards), hence fragility and antifragility. And sometimes philosophers and thinkers and those who study conflate Truth with risks and rewards.
My point taken further is that True and False (hence what we call “belief”) play a poor, secondary role in human decisions; it is the payoff from the True and the False that dominates—and it is almost always asymmetric, with one consequence much bigger than the other, i.e., harboring positive and negative asymmetries (fragile or antifragile). Let me explain.
Fragility, Not Probability
We check people for weapons before they board the plane. Do we believe that they are terrorists: True or False? False, as they are not likely
to be terrorists (a tiny probability). But we check them nevertheless because we are fragile to terrorism. There is an asymmetry. We are interested in the payoff, and the consequence, or payoff, of the True (that they turn out to be terrorists) is too large and the costs of checking are too low. Do you think the nuclear reactor is likely to explode in the next year? False. Yet you want to behave as if it were True and spend millions on additional safety, because we are fragile to nuclear events. A third example: Do you think that this random medicine will harm you? False. Do you ingest these pills? No, no, no.
If you sat with a pencil and jotted down all the decisions you’ve taken in the past week, or, if you could, over your lifetime, you would realize that almost all of them have had asymmetric payoff, with one side carrying a larger consequence than the other.
You decide principally based on fragility, not probability.
Or to rephrase,
You decide principally based on fragility, not so much on True/False.
Let us discuss the idea of the insufficiency of True/False in decision making in the real world, particularly when probabilities are involved. True or False are interpretations corresponding to high or low probabilities. Scientists have something called “confidence level”; a result obtained with a 95 percent confidence level means that there is no more than a 5 percent probability of the result being wrong. The idea of course is inapplicable as it ignores the size of the effects, which of course, makes things worse with extreme events. If I tell you that some result is true with 95 percent confidence level, you would be quite satisfied. But what if I told you that the plane was safe with 95 percent confidence level? Even 99 percent confidence level would not do, as a 1 percent probability of a crash would be quite a bit alarming (today commercial planes operate with less than one in several hundred thousand probabilities of crashing, and the ratio is improving, as we saw that every error leads to the improvement of overall safety). So, to repeat, the probability (hence True/False) does not work in the real world; it is the payoff that matters.
You have taken probably a billion decisions in your life. How many times have you computed probabilities? Of course, you may do so in casinos, but not elsewhere.
Conflation of Events and Exposure
This brings us again to the green lumber fallacy. A Black Swan event and how it affects you—its impact on your finances, emotions, the destruction
it will cause—are
not the same “ting.”
And the problem is deeply ingrained in standard reactions; the predictors’ reply when we point out their failures has typically been “we need better computation” in order to predict the event better and figure out the probabilities, instead of the vastly more effective “modify your exposure” and learn to get out of trouble, something religions and traditional heuristics have been better at enforcing than naive and cosmetic science.


================================================================================
CHAPTER/SECTION 79 (Item 82)
================================================================================

CONCLUSION TO BOOK IV
In addition to the medical empirics, this section has attempted to vindicate the unreasonable mavericks, engineers, freelance entrepreneurs, innovative artists, and anti-academic thinkers who have been reviled by history. Some of them had great courage—not just the courage to put forth their ideas, but the courage to accept to live in a world they knew they did not understand. And they enjoyed it.
To conclude this section, note that doing is wiser than you are prone to believe—and more rational. What I did here is just debunk the
Lecturing-Birds-How-to-Fly
epiphenomenon and the “linear model,” using among other things the simple mathematical properties of optionality, which does not require knowledge or intelligence, merely rationality in choice.
Remember that there is no empirical evidence to support the statement that organized research in the sense it is currently marketed leads to the great things promised by universities. And the promoters of the Soviet-Harvard idea do not use optionality, or second-order effects—this absence of optionality in their accounts invalidates their views about the role of teleological science. They need to rewrite the history of technology.
What Will Happen Next?
When I last met Alison Wolf we discussed this dire problem with education and illusions of academic contribution, with Ivy League universities becoming in the eyes of the new Asian and U.S. upper class a status luxury good. Harvard is like a Vuitton bag or a Cartier watch. It is a huge drag on the middle-class parents who have been plowing an increased share of their savings into these institutions, transferring their
money to administrators, real estate developers, professors, and other agents. In the United States, we have a buildup of student loans that automatically transfer to these rent extractors. In a way it is no different from racketeering: one needs a decent university “name” to get ahead in life; but we know that collectively society doesn’t appear to advance with organized education.
She requested that I write to her my thoughts about the future of education—as I told her that I was optimistic on the subject. My answer: b**t is fragile. Which scam in history has lasted forever? I have an enormous faith in Time and History as eventual debunkers of fragility. Education is an institution that has been growing without external stressors; eventually the thing will collapse.
The next two books, V and VI, will deal with the notion that fragile things break—predictably.
Book V
will show how to detect fragility (in a more technical manner) and will present the mechanics behind the philosopher’s stone.
Book VI
is based on the idea that Time is an eraser rather than a builder, and a good one at breaking the fragile—whether buildings or ideas.
4
1
The other biographer of Socrates, Xenophon, presents a different picture. The Socrates of the
Memorabilia
is no-nonsense and down to earth; he despises sterile knowledge, and the experts who study matters without practical consequence when so many useful and important things are neglected (instead of looking at stars to understand causes, figure out how you can use them to navigate; use geometry to measure land, but no more).
2
Adam Smith was first and last a moral philosopher. Marx was a philosopher. Kahneman and Simon are psychologist and cognitive scientist, respectively. The exception is, of course, Hayek.
3
The philosopher Rupert Read convinced me that Hayek harbored in fact a strain of naive rationalism, as did Popper, and presents convincing arguments that the two should not be included in the category of antifragile thinkers.
4
The reader might wonder about the connection between education and disorder. Education is teleological and hates disorder. It tends to cater to fragilistas.


================================================================================
CHAPTER/SECTION 80 (Item 83)
================================================================================

BOOK V
The Nonlinear and the Nonlinear
1
T
ime for another autobiographical vignette. As Charles Darwin wrote in a historical section of his
On the Origin of Species,
presenting a sketch of the progress of opinion: “I hope I may be excused for entering on these personal details, as I give them to show that I have not been hasty in coming to a decision.” For it is not quite true that there is no exact word, concept, and application for antifragility. My colleagues and I had one without knowing it. And I had it for a long, very long time. So I have been thinking about the exact same problem most of my life, partly consciously, partly without being aware of it.
Book V
explores the journey and the idea that came with it.


================================================================================
CHAPTER/SECTION 81 (Item 84)
================================================================================

ON THE IMPORTANCE OF ATTICS
In the mid-1990s, I quietly deposited my necktie in the trash can at the corner of Forty-fifth Street and Park Avenue in New York. I decided to take a few years off and locked myself in the attic, trying to express what was coming out of my guts, trying to frame what I called “hidden nonlinearities” and their effects.
What I had wasn’t quite an idea, rather, just a method, for the deeper central idea eluded me. But using this method, I produced close to a
six-hundred-page-long discussion of managing nonlinear effects, with graphs and tables. Recall from the prologue that “nonlinearity” means that the response is not a straight line. But I was going further and looking at the link with volatility, something that should be clear soon. And I went deep into the volatility of volatility, and such higher-order effects.
The book that came out of this solitary investigation in the attic, finally called
Dynamic Hedging,
was about the “techniques to manage and handle complicated nonlinear derivative exposures.” It was a technical document that was completely
ab ovo
(from the egg), and as I was going, I knew in my guts that the point had vastly more import than the limited cases I was using in my profession; I knew that my profession was the perfect platform to start thinking about these issues, but I was too lazy and too conventional to venture beyond. That book remained by far my favorite work (before this one), and I fondly remember the two harsh New York winters in the near-complete silence of the attic, with the luminous effect of the sun shining on the snow warming up both the room and the project. I thought of nothing else for years.
I also learned something quite amusing from the episode. My book was mistakenly submitted to four referees, all four of them academic financial economists instead of “quants” (quantitative analysts who work in finance using mathematical models). The person who made the submissions wasn’t quite aware of the difference. The four academics rejected my book, interestingly, for four sets of completely different reasons, with absolutely no intersection in their arguments. We practitioners and quants aren’t too fazed by remarks on the part of academics—it would be like prostitutes listening to technical commentary by nuns. What struck me was that if I had been wrong, all of them would have provided the exact same reason for rejection. That’s antifragility. Then, of course, as the publisher saw the mistake, the book was submitted to quantitative reviewers, and it saw the light of day.
2
The Procrustean bed in life consists precisely in simplifying the nonlinear and making it linear—the simplification that distorts.
Then my interest in the nonlinearity of exposures went away as I began to deal with other matters related to uncertainty, which seemed more intellectual and philosophical to me, like the nature of
randomness—rather than how things react to random events. This may also have been due to the fact that I moved and no longer had that attic.
But some events brought me back to a second phase of intense seclusion.
After the crisis of the late 2000s, I went through an episode of hell owing to contact with the press. I was suddenly deintellectualized, corrupted, extracted from my habitat, propelled into being a public commodity. I had not realized that it is hard for members of the media and the public to accept that the job of a scholar is to ignore insignificant current affairs, to write books, not emails, and not to give lectures dancing on a stage; that he has other things to do, like read in bed in the morning, write at a desk in front of a window, take long walks (slowly), drink espressos (mornings), chamomile tea (afternoons), Lebanese wine (evenings), and Muscat wines (after dinner), take more long walks (slowly), argue with friends and family members (but never in the morning), and read (again) in bed before sleeping, not keep rewriting one’s book and ideas for the benefit of strangers and members of the local chapter of Networking International who haven’t read it.
Then I opted out of public life. When I managed to retake control of my schedule and my brain, recovered from the injuries deep into my soul, learned to use email filters and autodelete functions, and restarted my life, Lady Fortuna brought two ideas to me, making me feel stupid—for I realized I had had them inside me all along.
Clearly, the tools of analysis of nonlinear effects are quite universal. The sad part is that until that day in my new-new life of solitary walker cum chamomile drinker, when I looked at a porcelain cup I had not realized that everything nonlinear around me could be subjected to the same techniques of detection as the ones that hit me in my previous episode of seclusion.
What I found is described in the next two chapters.
1
The nontechnical reader can skip
Book V
without any loss: the definition of antifragility from Seneca’s asymmetry is amply sufficient for a literary read of the rest of the book. This is a more technical rephrasing of it.
2
A similar test: when a collection of people write “There is nothing new here” and each one cites a different originator of the idea, one can safely say there is something effectively new.


================================================================================
CHAPTER/SECTION 82 (Item 85)
================================================================================

CHAPTER 18
On the Difference Between a Large Stone and a Thousand Pebbles
How to punish with a stone—I landed early (once)—Why attics are always useful—On the great benefits of avoiding Heathrow unless you have a guitar
FIGURE 8.
The solicitor knocking on doors in concave (left) and convex (right) position. He illustrates the two forms of nonlinearity; if he were “linear” he would be upright, standing straight. This chapter will show—a refinement of Seneca’s asymmetry—how one position (the convex) represents antifragility in all its forms, the other, fragility (the concave), and how we can easily detect and even measure fragility by evaluating how humped (convex) or how slumped (concave) the courtier is standing.
I noticed looking at the porcelain cup that it did not like volatility or variability or action. It just wanted calm and to be left alone in the tranquility of the home study-library. The realization that fragility was simply
vulnerability to the volatility of the things that affect it
was a huge personal embarrassment for me, since my specialty was the link between volatility and nonlinearity; I know, I know, a very strange specialty. So let us start with the result.


================================================================================
CHAPTER/SECTION 83 (Item 86)
================================================================================

A SIMPLE RULE TO DETECT THE FRAGILE
A story present in the rabbinical literature (
Midrash Tehillim
), probably originating from earlier Near Eastern lore, says the following. A king, angry at his son, swore that he would crush him with a large stone. After he calmed down, he realized he was in trouble, as a king who breaks his oath is unfit to rule. His sage advisor came up with a solution. Have the stone cut into very small pebbles, and have the mischievous son pelted with them.
The difference between a thousand pebbles and a large stone of equivalent weight is a potent illustration of how fragility stems from nonlinear effects. Nonlinear? Once again, “nonlinear” means that the response is not straightforward and not a straight line, so if you double, say, the dose, you get a lot more or a lot less than double the effect—if I throw at someone’s head a ten-pound stone, it will cause more than twice the harm of a five-pound stone, more than five times the harm of a two-pound stone, etc. It is simple: if you draw a line on a graph, with harm on the vertical axis and the size of the stone on the horizontal axis, it will be curved, not a straight line. That is a refinement of asymmetry.
Now the very simple point, in fact, that allows for a detection of fragility:
For the fragile, shocks bring higher harm as their intensity increases (up to a certain level).
FIGURE 9
. The King and His Son. The harm from the size of the stone as a function of the size of the stone (up to a point). Every additional weight of the stone harms more than the previous one. You see nonlinearity (the harm curves inward, with a steeper and steeper vertical slope).
The example is shown in
Figure 9
. Let us generalize. Your car is fragile. If you drive it into the wall at 50 miles per hour, it would cause more damage than if you drove it into the same wall ten times at 5 mph. The harm at 50 mph is more than ten times the harm at 5 mph.
Other examples. Drinking seven bottles of wine (Bordeaux) in one sitting, then purified water with lemon twist for the remaining six days is more harmful than drinking one bottle of wine a day for seven days (spread out in two glasses per meal). Every additional glass of wine harms you more than the preceding one, hence your system is fragile to alcoholic consumption. Letting a porcelain cup drop on the floor from a height of one foot (about thirty centimeters) is worse than twelve times the damage from a drop from a height of one inch (two and a half centimeters).
Jumping from a height of thirty feet (ten meters) brings more than ten times the harm of jumping from a height of three feet (one meter)—actually, thirty feet seems to be the cutoff point for death from free fall.
Note that this is a simple expansion of the foundational asymmetry we saw two chapters ago, as we used Seneca’s thinking as a pretext to talk about nonlinearity. Asymmetry is necessarily nonlinearity. More harm than benefits: simply, an increase in intensity brings more harm than a corresponding decrease offers benefits.
Why Is Fragility Nonlinear?
Let me explain the central argument—why fragility is generally in the nonlinear and not in the linear. That was the intuition from the porcelain cup. The answer has to do with the structure of survival probabilities: conditional on something being unharmed (or having survived), then it is more harmed by a single rock than a thousand pebbles, that is, by a single large infrequent event than by the cumulative effect of smaller shocks.
If for a human, jumping one millimeter (an impact of small force) caused an exact linear fraction of the damage of, say, jumping to the ground from thirty feet, then the person would already be dead from cumulative harm. Actually a simple computation shows that he would have expired within hours from touching objects or pacing in his living room, given the multitude of such stressors and their total effect. The fragility that comes from linearity is immediately visible, so we rule it out because the object would be already broken. This leaves us with the following: what is fragile is something that is both unbroken and subjected to nonlinear effects—and extreme, rare events, since impacts of large size (or high speed) are rarer than ones of small size (and slow speed).
Let me rephrase this idea in connection with Black Swans and extreme events. There are a lot more ordinary events than extreme events. In the financial markets, there are at least ten thousand times more events of 0.1 percent magnitude than events of 10 percent magnitude. There are close to eight thousand microearthquakes daily on planet Earth, that is, those below 2 on the Richter scale—about three million a year. These are totally harmless, and, with three million per year, you would need them to be so. But shocks of intensity 6 and higher on the scale make the newspapers. Take objects such as porcelain cups. They get a lot of hits, a million more hits of, say, one hundredth of a pound per square inch (to take an arbitrary measure) than hits of a hundred pounds per square inch. Accordingly, we are necessarily immune to the
cumulative
effect of small deviations, or shocks of very small magnitude, which implies that these affect us disproportionally less (that is, nonlinearly less) than larger ones.
Let me reexpress my previous rule:
For the fragile, the cumulative effect of small shocks is smaller than the single effect of an equivalent single large shock.
This leaves me with the principle that the fragile is what is hurt a lot more by extreme events than by a succession of intermediate ones. Finito—and there is
no other
way to be fragile.
Now let us flip the argument and consider the antifragile. Antifragility, too, is grounded in nonlinearties, nonlinear responses.
For the antifragile, shocks bring more benefits (equivalently, less harm) as their intensity increases (up to a point).
A simple case—known heuristically by weight lifters. In the bodyguard-emulating story in
Chapter 2
, I focused only on the maximum I could do. Lifting one hundred pounds once brings more benefits than lifting fifty pounds twice, and certainly a lot more than lifting one pound a hundred times. Benefits here are in weight-lifter terms: strengthening the body, muscle mass, and bar-fight looks rather than resistance and the ability to run a marathon. The second fifty pounds play a larger role, hence the nonlinear (that is, we will see,
convexity
) effect. Every additional pound brings more benefits, until one gets close to the limit, what weight lifters call “failure.”
1
For now, note the reach of this simple curve: it affects about just anything in sight, even medical error, government size, innovation—anything that touches uncertainty. And it helps put the “plumbing” behind the statements on size and concentration in
Book II
.
When to Smile and When to Frown
Nonlinearity comes in two kinds: concave (curves inward), as in the case of the king and the stone, or its opposite, convex (curves outward). And of course, mixed, with concave and convex sections.
Figures 10
and
11
show the following simplifications of nonlinearity: the convex and the concave resemble a smile and a frown, respectively.
FIGURE 10
. The two types of nonlinearities, the convex (left) and the concave (right). The convex curves outward, the concave inward.
FIGURE 11.
Smile! A better way to understand convexity and concavity. What curves outward looks like a smile—what curves inward makes a sad face. The convex (left) is antifragile, the concave (right) is fragile (has negative convexity effects).
I use the term “convexity effect” for both, in order to simplify the vocabulary, saying “positive convexity effects” and “negative convexity effects.”
Why does asymmetry map to convexity or concavity? Simply, if for a given variation you have more upside than downside and you draw the curve, it will be convex; the opposite for the concave.
Figure 12
shows the asymmetry reexpressed in terms of nonlinearities. It also shows the magical effect of mathematics that allowed us to treat steak tartare, entrepreneurship, and financial risk in the same breath: the convex graph turns into concave when one simply puts a minus sign in front of it. For instance, Fat Tony had the exact opposite payoff than, say, a bank or financial institution in a certain transaction: he made a buck whenever they lost one, and vice versa. The profits and losses are mirror images of each other at the end of the day, except that one is the minus sign times the other.
Figure 12
also shows why the convex
likes volatility
. If you earn more than you lose from fluctuations, you want a lot of fluctuations.
FIGURE 12.
Pain More than Gain, or Gain More than Pain. Assume you start from the “You Are Here” spot. In the first case, should the variable
x
increase, i.e., move to the right on the horizontal axis, the gains (vertical axis) are larger than the losses encountered by moving left, i.e., an equivalent decrease in the variable
x
. The graph illustrates how positive asymmetry (first graph) turns into convex (inward) curving and negative asymmetry (second graph) turns into concave (outward) curving. To repeat, for a set deviation in a variable, in equivalent amounts in both directions, the convex gains more than it loses, and the reverse for the concave.
Why Is the Concave Hurt by Black Swan Events?
Now the idea that has inhabited me all my life—I never realized it could show so clearly when put in graphical form.
Figure 13
illustrates the effect of harm and the unexpected. The more concave an exposure, the more harm from the unexpected, and disproportionately so. So very large deviations have a disproportionately larger and larger effect.
FIGURE 13.
Two exposures, one linear, one nonlinear, with negative convexity—that is, concavity—in the first graph, positive convexity in the second. An unexpected event affects the nonlinear disproportionately more. The larger the event, the larger the difference.
Next, let us apply this very simple technique to the detection of fragility and position in the Triad.


================================================================================
CHAPTER/SECTION 84 (Item 87)
================================================================================

TRAFFIC IN NEW YORK
Let us apply “convexity effects” to things around us. Traffic is highly nonlinear. When I take the day flight from New York to London, and I leave my residence around five in the morning (yes, I know), it takes me around 26 minutes to reach the British Air terminal at JFK airport. At that time, New York is empty, eerily non–New York. When I leave my place at six o’clock for the later flight, there is almost no difference in travel time, although traffic is a bit denser. One can add more and more cars on the highway, with no or minimal impact on time spent in traffic.
Then, a mystery—increase the number of cars by 10 percent and watch the travel time jump by 50 percent (I am using approximate numbers). Look at the convexity effect at work: the average number of cars on the road does not matter at all for traffic speed. If you have 90,000 cars for one hour, then 110,000 cars for another hour, traffic would be much slower than if you had 100,000 cars for two hours. Note that travel time is a negative, so I count it as a cost, like an expense, and a rise is a bad thing.
So travel cost is fragile to the
volatility
of the number of cars on the highway; it does not depend so much on their average number. Every additional car increases travel time more than the previous one.
This is a hint to a central problem of the world today, that of the misunderstanding of nonlinear response by those involved in creating “efficiencies” and “optimization” of systems. For instance, European airports and railroads are stretched, seeming overly efficient. They operate at close to maximal capacity, with minimal redundancies and idle capacity, hence acceptable costs; but a small increase in congestion, say 5 percent more planes in the sky owing to a tiny backlog, can give rise to chaos in airports and cause scenes of unhappy travelers camping on floors, their only solace some bearded fellow playing French folk songs on his guitar.
We can see applications of the point across economic domains: central banks can print money; they print and print with no effect (and claim the “safety” of such a measure), then, “unexpectedly,” the printing causes a jump in inflation. Many economic results are completely canceled by convexity effects—and the happy news is that we know why. Alas, the tools (and culture) of policy makers are based on the overly linear, ignoring these hidden effects. They call it “approximation.”
When you hear of a “second-order” effect, it means convexity is causing the failure of approximation to represent the real story.
I have put a (very hypothetical) graph of the response of traffic to cars on the road in
Figure 14
. Note for now the curved shape of the graph. It curves inward.
FIGURE 14.
The graph shows how the author’s travel time (and travel costs) to JFK depend, beyond a certain point, nonlinearly on the number of cars on the road. We show travel costs as curving inward—concave, not a good thing.
Someone Call New York City Officials
An apt illustration of how convexity effects affect an overoptimized system, along with misforecasting large deviations, is this simple story of an underestimation made by New York City officials of the effect of a line closure on traffic congestion. This error is remarkably general: a small modification with compounded results in a system that is extremely stretched, hence fragile.
One Saturday evening in November 2011, I drove to New York City to meet the philosopher Paul Boghossian for dinner in the Village—typically a forty-minute trip. Ironically, I was meeting him to talk about my book, this book, and more particularly, my ideas on redundancy in systems. I have been advocating the injection of redundancy into people’s lives and had been boasting to him and others that, since my New Year’s resolution of 2007, I have never been late to anything, not even by a minute (well, almost). Recall in
Chapter 2
my advocacy of redundancies as an aggressive stance. Such personal discipline forces me to build buffers, and, as I carry a notebook, it allowed me to write an entire book of aphorisms. Not counting long visits to bookstores. Or I can sit in a
café and read hate mail. With, of course, no stress, as I have no fear of being late. But the greatest benefit of such discipline is that it prevents me from cramming my day with appointments (typically, appointments are neither useful nor pleasant). Actually, by another rule of personal discipline I do not make appointments (other than lectures) except the very same morning, as a date on the calendar makes me feel like a prisoner, but that’s another story.
As I hit Midtown, around six o’clock, traffic stopped. Completely. By eight I had moved hardly a few blocks. So even my “redundancy buffer” failed to let me keep the so-far-unbroken resolution. Then, after relearning to operate the noisy cacophonic thing called the radio, I started figuring out what had happened: New York City had authorized a film company to use the Fifty-ninth Street Bridge, blocking part of it, assuming that it would be no problem on a Saturday. And the small traffic problem turned into mayhem, owing to the multiplicative effects. What they felt would be at the worst a few minutes’ delays was multiplied by two orders of magnitude; minutes became hours. Simply, the authorities running New York City did not understand nonlinearities.
This is the central problem of efficiency: these types of errors compound, multiply, swell, with an effect that only goes in one direction—the wrong direction.


================================================================================
CHAPTER/SECTION 85 (Item 88)
================================================================================

WHERE MORE IS DIFFERENT
Another intuitive way to look at convexity effects: consider the scaling property. If you double the exposure to something, do you more than double the harm it will cause? If so, then this is a situation of fragility. Otherwise, you are robust.
The point has been aptly expressed by P. W. Anderson in the title of his paper “More Is Different.” And what scientists involved in complexity call “emerging properties” is the nonlinear result of adding units, as the sum becomes increasingly different from the parts. Just look at how different the large stone is from the pebbles: the latter have the same weight and the same general shape, but that’s about it. Likewise, we saw in
Chapter 5
that a city is not a large village; a corporation is not a larger small business. We also saw how randomness changes in nature from Mediocristan to Extremistan, how a state is not a large village, and
many alterations that come from size—and speed. All these show nonlinearity in action.
A “Balanced Meal”
Another example of missing the hidden dimension, that is, variability: we are currently told by the Soviet-Harvard U.S. health authorities to eat set quantities of nutrients (total calories, protein, vitamins, etc.) every day, in some recommended amounts of each. Every food item has a “percentage daily allowance.” Aside from the total lack of empirical rigor in the way these recommendations are currently derived (more on that in the medical chapters), there is another sloppiness in the edict: an insistence in the discourse on the
regularity
. Those recommending the nutritional policies fail to understand that “steadily” getting your calories and nutrients throughout the day, with “balanced” composition and metronomic regularity, does not necessarily have the same effect as consuming them unevenly or randomly, say by having a lot of proteins one day, fasting completely another, feasting the third, etc.
This is a denial of hormesis, the slight stressor of episodic deprivation. For a long time, nobody even bothered to try to figure out whether variability in distribution—the second-order effect—mattered as much as long-term composition. Now research is starting to catch up to such a very, very simple point. It turns out that the effect of variability in food sources and the nonlinearity in the physiological response is central to biological systems. Consuming no protein at all on Monday and catching up on Wednesday seemingly causes a different—better—physiological response, possibly because the deprivation, as a stressor, activates some pathways that facilitate the subsequent absorption of the nutrients (or something similar). And, until a few recent (and disconnected) empirical studies, this convexity effect has been totally missed by science—though not by religions, ancestral heuristics, and traditions. And if scientists get some convexity effects (as we said about domain dependence, doctors, just like weight lifters, understand here and there nonlinearities in dose response), the notion of convexity effects itself appears to be completely missing from their language and methods.
Run, Don’t Walk
Another illustration, this time a situation that benefits from variation—positive convexity effects. Take two brothers, Castor and Polydeuces, who need to travel a mile. Castor walks the mile at a leisurely pace and arrives at the destination in twenty minutes. Polydeuces spends fourteen minutes playing with his handheld device getting updates on the gossip, then runs the same mile in six minutes, arriving at the same time as Castor.
So both persons have covered the exact same distance, in exactly the same time—same average. Castor, who walked all the way, presumably will not get the same health benefits and gains in strength as Polydeuces, who sprinted. Health benefits are
convex
to speed (up to a point, of course).
The very idea of exercise is to gain from antifragility to workout stressors—as we saw, all kinds of exercise are just exploitations of convexity effects.


================================================================================
CHAPTER/SECTION 86 (Item 89)
================================================================================

SMALL MAY BE UGLY, IT IS CERTAINLY LESS FRAGILE
We often hear the expression “small is beautiful.” It is potent and appealing; many ideas have been offered in its support—almost all of them anecdotal, romantic, or existential. Let us present it within our approach of
fragility
equals
concavity
equals
dislike of randomness
and see how we can measure such an effect.
How to Be Squeezed
A squeeze occurs when people have no choice but to do something, and do it right away, regardless of the costs.
Your other half is to defend a doctoral thesis in the history of German dance and you need to fly to Marburg to be present at such an important moment, meet the parents, and get formally engaged. You live in New York and manage to buy an economy ticket to Frankfurt for $400 and you are excited about how cheap it is. But you need to go through London. Upon getting to New York’s Kennedy airport, you are apprised by the airline agent that the flights to London are canceled, sorry, delays due to backlog due to weather problems, that type of thing. Something
about Heathrow’s fragility. You can get a last-minute flight to Frankfurt, but now you need to pay $4,000, close to ten times the price, and hurry, as there are very few seats left. You fume, shout, curse, blame yourself, your upbringing and parents who taught you to save, then shell out the $4,000. That’s a squeeze.
Squeezes are exacerbated by size. When one is large, one becomes vulnerable to some errors, particularly horrendous squeezes. The squeezes become nonlinearly costlier as size increases.
To see how size becomes a handicap, consider the reasons one should not own an elephant as a pet, regardless of what emotional attachment you may have to the animal. Say you can afford an elephant as part of your postpromotion household budget and have one delivered to your backyard. Should there be a water shortage—hence a squeeze, since you have no choice but to shell out the money for water—you would have to pay a higher and higher price for each additional gallon of water. That’s fragility, right there, a negative convexity effect coming from getting too big. The unexpected cost, as a percentage of the total, would be monstrous. Owning, say, a cat or a dog would not bring about such high unexpected additional costs at times of squeeze—the overruns taken as a percentage of the total costs would be very low.
In spite of what is studied in business schools concerning “economies of scale,” size hurts you at times of stress; it is not a good idea to be large during difficult times. Some economists have been wondering why mergers of corporations do not appear to play out. The combined unit is now much larger, hence more powerful, and according to the theories of economies of scale, it should be more “efficient.” But the numbers show, at best, no gain from such increase in size—that was already true in 1978, when Richard Roll voiced the “hubris hypothesis,” finding it irrational for companies to engage in mergers given their poor historical record. Recent data, more than three decades later, still confirm both the poor record of mergers and the same hubris as managers seem to ignore the bad economic aspect of the transaction. There appears to be something about size that is harmful to corporations.
As with the idea of having elephants as pets, squeezes are much, much more expensive (relative to size) for large corporations. The gains from size are visible but the risks are hidden, and some concealed risks seem to bring frailties into the companies.
Large animals, such as elephants, boa constrictors, mammoths, and
other animals of size tend to become rapidly extinct. Aside from the squeeze when resources are tight, there are mechanical considerations. Large animals are more fragile to shocks than small ones—again, stone and pebbles. Jared Diamond, always ahead of others, figured out such vulnerability in a paper called “Why Cats Have Nine Lives.” If you throw a cat or a mouse from an elevation of several times their height, they will typically manage to survive. Elephants, by comparison, break limbs very easily.
Kerviel and Micro-Kerviel
Let us look at a case study from vulgar finance, a field in which participants are very good at making mistakes. On January 21, 2008, the Parisian bank Societé Générale rushed to sell in the market close to seventy billion dollars’ worth of stocks, a very large amount for any single “fire sale.” Markets were not very active (called “thin”), as it was Martin Luther King Day in the United States, and markets worldwide dropped precipitously, close to 10 percent, costing the company close to six billion dollars in losses just from their fire sale. The entire point of the squeeze is that they couldn’t wait, and they had no option but to turn a sale into a fire sale. For they had, over the weekend, uncovered a fraud. Jerome Kerviel, a rogue back office employee, was playing with humongous sums in the market and hiding these exposures from the main computer system. They had no choice but to sell, immediately, these stocks they didn’t know they owned.
Now, to see the effect of fragility from size, look at
Figure 15
showing losses as a function of quantity sold. A fire sale of $70 billion worth of stocks leads to a loss of $6 billion. But a fire sale a tenth of the size, $7 billion would result in no loss at all, as markets would absorb the quantities without panic, maybe without even noticing. So this tells us that if, instead of having one very large bank, with Monsieur Kerviel as a rogue trader, we had ten smaller banks, each with a proportional Monsieur Micro-Kerviel, and each conducted his rogue trading independently and at random times, the total losses for the ten banks would be close to nothing.
FIGURE 15.
Small may be beautiful; it is certainly less fragile. The graph shows transaction costs as a function of the size of the error: they increase nonlinearly, and we can see the megafragility.
About a few weeks before the Kerviel episode, a French business school hired me to present to the board of executives of the Societé Générale meeting in Prague my ideas of Black Swan risks. In the eyes of the bankers, I was like a Jesuit preacher visiting Mecca in the middle of the annual Hajj—their “quants” and risk people hated me with passion, and I regretted not having insisted on speaking in Arabic given that they had simultaneous translation. My talk was about pseudo risk techniques à la Triffat—methods commonly used, as I said, to measure and predict events, methods that have never worked before—and how we needed to focus on fragility and barbells. During the talk I was heckled relentlessly by Kerviel’s boss and his colleague, the head of risk management. After my talk, everyone ignored me, as if I were a Martian, with a “who brought this guy here” awkward situation (I had been selected by the school, not the bank). The only person who was nice to me was the chairman, as he mistook me for someone else and had no clue about what I was discussing.
So the reader can imagine my state of mind when, shortly after my return to New York, the Kerviel trading scandal broke. It was also tantalizing that I had to keep my mouth shut (which I did, except for a few slips) for legal reasons.
Clearly, the postmortem analyses were mistaken, attributing the
problem to
bad
controls by the
bad
capitalistic system, and lack of vigilance on the part of the bank. It was not. Nor was it “greed,” as we commonly assume. The problem is primarily size, and the fragility that comes from size.
Always keep in mind the difference between a stone and its weight in pebbles. The Kerviel story is illustrative, so we can generalize and look at evidence across domains.
In project management, Bent Flyvbjerg has shown firm evidence that an increase in the size of projects maps to poor outcomes and higher and higher costs of delays as a proportion of the total budget. But there is a nuance: it is the size per segment of the project that matters, not the entire project—some projects can be divided into pieces, not others. Bridge and tunnel projects involve monolithic planning, as these cannot be broken up into small portions; their percentage costs overruns increase markedly with size. Same with dams. For roads, built by small segments, there is no serious size effect, as the project managers incur only small errors and can adapt to them. Small segments go one small error at the time, with no serious role for squeezes.
Another aspect of size: large corporations also end up endangering neighborhoods. I’ve used the following argument against large superstore chains in spite of the advertised benefits. A large super-megastore wanted to acquire an entire neighborhood near where I live, causing uproar owing to the change it would bring to the character of the neighborhood. The argument in favor was the revitalization of the area, that type of story. I fought the proposal on the following grounds: should the company go bust (and the statistical elephant in the room is that it eventually will), we would end up with a massive war zone. This is the type of argument the British advisors Rohan Silva and Steve Hilton have used in favor of small merchants, along the poetic “small is beautiful.” It is completely wrong to use the calculus of benefits without including the probability of failure.
2
How to Exit a Movie Theater
Another example of the costs of a squeeze: Imagine how people exit a movie theater. Someone shouts “fire,” and you have a dozen persons squashed to death. So we have a fragility of the theater to size, stemming from the fact that every additional person exiting brings more and more trauma (such disproportional harm is a negative convexity effect). A thousand people exiting (or trying to exit) in one minute is not the same as the same number exiting in half an hour. Someone unfamiliar with the business who naively
optimizes
the size of the place (Heathrow airport, for example) might miss the idea that smooth functioning at regular times is different from the rough functioning at times of stress.
It so happens that contemporary economic optimized life causes us to build larger and larger theaters, but with the exact same door. They no longer make this mistake too often while building cinemas, theaters, and stadiums, but we tend to make the mistake in other domains, such as, for instance, natural resources and food supplies. Just consider that the price of wheat more than tripled in the years 2004–2007 in response to a small increase in net demand, around 1 percent.
3
Bottlenecks are the mothers of all squeezes.


================================================================================
CHAPTER/SECTION 87 (Item 90)
================================================================================

PROJECTS AND PREDICTION
Why Planes Don’t Arrive Early
Let us start as usual with a transportation problem, and generalize to other areas. Travelers (typically) do not like uncertainty—especially when they are on a set schedule. Why? There is a one-way effect.
I’ve taken the very same London–New York flight most of my life. The flight takes about seven hours, the equivalent of a short book plus a
brief polite chat with a neighbor and a meal with port wine, stilton cheese, and crackers. I recall a few instances in which I arrived early, about twenty minutes, no more. But there have been instances in which I got there more than two or three hours late, and in at least one instance it has taken me more than two days to reach my destination.
Because travel time cannot be really negative, uncertainty tends to cause delays, making arrival time increase, almost never decrease. Or it makes arrival time decrease by just minutes, but increase by hours, an obvious asymmetry. Anything unexpected, any shock, any volatility, is much more likely to extend the total flying time.
This also explains the irreversibility of time, in a way, if you consider the passage of time as an increase in disorder.
Let us now apply this concept to projects. Just as when you add uncertainty to a flight, the planes tend to land later, not earlier (and these laws of physics are so universal that they even work in Russia), when you add uncertainty to projects, they tend to cost more and take longer to complete. This applies to many, in fact almost all, projects.
The interpretation I had in the past was that a psychological bias, the underestimation of the random structure of the world, was the cause behind such underestimation—projects take longer than planned because the estimates are too optimistic. We have evidence of such bias, called overconfidence. Decision scientists and business psychologists have theorized something called the “planning fallacy,” in which they try to explain the fact that projects take longer, rarely less time, using psychological factors.
But the puzzle was that such underestimation did not seem to exist in the past century or so, though we were dealing with the very same humans, endowed with the same biases. Many large-scale projects a century and a half ago were completed on time; many of the tall buildings and monuments we see today are not just more elegant than modernistic structures but were completed within, and often ahead of, schedule. These include not just the Empire State Building (still standing in New York), but the London Crystal Palace, erected for the Great Exhibition of 1851, the hallmark of the Victorian reign, based on the inventive ideas of a gardener. The Palace, which housed the exhibition, went from concept to grand opening in just nine months. The building took the form of a massive glass house, 1,848 feet long by 454 feet wide; it was constructed from cast iron frame components and glass made almost exclusively in Birmingham and Smethwick.
The obvious is usually missed here: the Crystal Palace project did not use computers, and the parts were built not far from the source, with a small number of businesses involved in the supply chain. Further, there were no business schools at the time to teach something called “project management” and increase overconfidence. There were no consulting firms. The agency problem (which we defined as the divergence between the interest of the agent and that of his client) was not significant. In other words, it was a much more linear economy—less complex—than today. And we have more nonlinearities—asymmetries, convexities—in today’s world.
Black Swan effects are necessarily increasing, as a result of complexity, interdependence between parts, globalization, and the beastly thing called “efficiency” that makes people now sail too close to the wind. Add to that consultants and business schools. One problem somewhere can halt the entire project—so the projects tend to get as weak as the weakest link in their chain (an acute negative convexity effect). The world is getting less and less predictable, and we rely more and more on technologies that have errors and interactions that are harder to estimate, let alone predict.
And the information economy is the culprit. Bent Flyvbjerg, the one of bridge and road projects mentioned earlier in this chapter, showed another result. The problem of cost overruns and delays is much more acute in the presence of information technologies (IT), as computer projects cause a large share of these cost overruns, and it is better to focus on these principally. But even outside of these IT-heavy projects, we tend to have very severe delays.
But the logic is simple: again, negative convexity effects are the main culprit, a direct and visible cause. There is an asymmetry in the way errors hit you—the same as with travel.
No psychologist who has discussed the “planning fallacy” has realized that, at the core, it is not essentially a psychological problem, not an issue with human errors; it is inherent to the nonlinear structure of the projects. Just as time cannot be negative, a three-month project cannot be completed in zero or negative time. So, on a timeline going left to right, errors add to the right end, not the left end of it. If uncertainty were linear we would observe some projects completed extremely early (just as we would arrive sometimes very early, sometimes very late). But this is not the case.
Wars, Deficits, and Deficits
The Great War was estimated to last only a few months; by the time it was over, it had gotten France and Britain heavily in debt; they incurred at least ten times what they thought their financial costs would be, aside from all the horrors, suffering, and destruction. The same of course for the second war, which added to the U.K. debt, causing it to become heavily indebted, mostly to the United States.
In the United States the prime example remains the Iraq war, expected by George W. Bush and his friends to cost thirty to sixty billion, which so far, taking into account all the indirect costs, may have swelled to more than two trillion—indirect costs multiply, causing chains, explosive chains of interactions, all going in the same direction of more costs, not less. Complexity plus asymmetry (plus such types as George W. Bush), once again, lead to explosive errors.
The larger the military, the disproportionally larger the cost overruns.
But wars—with more than twentyfold errors—are only illustrative of the way governments underestimate explosive nonlinearities (convexity effects) and why they should not be trusted with finances or any large-scale decisions. Indeed, governments do not need wars at all to get us in trouble with deficits: the underestimation of the costs of their projects is chronic for the very same reason 98 percent of contemporary projects have overruns. They just end up spending more than they tell us. This has led me to install a governmental golden rule: no borrowing allowed, forced fiscal balance.


================================================================================
CHAPTER/SECTION 88 (Item 91)
================================================================================

WHERE THE “EFFICIENT” IS NOT EFFICIENT
We can easily see the costs of fragility swelling in front of us, visible to the naked eye. Global disaster costs are today more than three times what they were in the 1980s, adjusting for inflation. The effect, noted a while ago by the visionary researcher on extreme events Daniel Zajdenweber, seems to be accelerating. The economy can get more and more “efficient,” but fragility is causing the costs of errors to be higher.
The stock exchanges have converted from “open outcry” where wild traders face each other, yelling and screaming as in a souk, then
go drink together. Traders were replaced by computers, for very small visible benefits and massively large risks. While errors made by traders are confined and distributed, those made by computerized systems go wild—in August 2010, a computer error made the entire market crash (the “flash crash”); in August 2012, as this manuscript was heading to the printer, the Knight Capital Group had its computer system go wild and cause $10 million dollars of losses a minute, losing $480 million.
And naive cost-benefit analyses can be a bit harmful, an effect that of course swells with size. For instance, the French have in the past focused on nuclear energy as it seemed “clean” and cheap. And “optimal” on a computer screen. Then, after the wake-up call of the Fukushima disaster of 2011, they realized that they needed additional safety features and scrambled to add them, at any cost. In a way this is similar to the squeeze I mentioned earlier: they are forced to invest, regardless of price. Such additional expense was not part of the cost-benefit analysis that went into the initial decision and looked good on a computer screen. So when deciding on one source of fuel against another, or similar comparisons, we do not realize that model error may hit one side more than the other.
Pollution and Harm to the Planet
From this we can generate a simple ecological policy. We know that fossil fuels are harmful in a nonlinear way. The harm is necessarily concave (if a little bit of it is devoid of harm, a lot can cause climatic disturbances). While on epistemological grounds, because of opacity, we do not need to believe in anthropogenic climate change (caused by humans) in order to be ecologically conservative, we can put these convexity effects to use in producing a risk management rule for pollution. Simply, just as with size, split your sources of pollution among many natural sources. The harm from polluting with ten different sources is smaller than the equivalent pollution from a single source.
4
Let’s look at naturelike ancestral mechanisms for regulating the concentration effects. We contemporary humans go to the stores to purchase the same items, say tuna, coffee or tea, rice, mozzarella, Cabernet
wine, olive oil, and other items that appear to us as not easily substitutable. Because of sticky contemporary habits, cultural contagion, and the rigidity of factories, we are led to the excessive use of specific products. This concentration is harmful. Extreme consumption of, say, tuna, can hurt other animals, mess with the ecosystem, and lead species to extinction. And not only does the harm scale nonlinearly, but the shortages lead to disproportional rises in prices.
Ancestral humans did it differently. Jennifer Dunne, a complexity researcher who studies hunter-gatherers, examined evidence about the behavior of the Aleuts, a North American native tribe, for which we have ample data, covering five millennia. They exhibit a remarkable lack of concentration in their predatorial behavior, with a strategy of prey switching. They were not as sticky and rigid as us in their habits. Whenever they got low on a resource, they switched to another one, as if to preserve the ecosystem. So they understood convexity effects—or, rather, their habits did.
Note that globalization has had the effect of making contagions planetary—as if the entire world became a huge room with narrow exits and people rushing to the same doors, with accelerated harm. Just as about every child reads Harry Potter and joins (for now) Facebook, people when they get rich are starting to engage in the same activities and buy the same items. They drink Cabernet wine, hope to visit Venice and Florence, dream of buying a second home in the South of France, etc. Tourist locations are becoming unbearable: just go to Venice next July.
The Nonlinearity of Wealth
We can certainly attribute the fragilizing effect of contemporary globalization to complexity, and how connectivity and cultural contagions make gyrations in economic variables much more severe—the classic switch to Extremistan. But there is another effect: wealth. Wealth means more, and because of nonlinear scaling, more is different. We are prone to make more severe errors because we are simply wealthier. Just as projects of one hundred million dollars are more unpredictable and more likely to incur overruns than five-million-dollar ones, simply by being richer, the world is troubled with additional unpredictability and fragility. This comes with growth—at a country level, this Highly Dreamed-of GDP Growth. Even at an individual level, wealth means
more headaches; we may need to work harder at mitigating the complications arising from wealth than we do at acquiring it.
Conclusion
To conclude this chapter, fragility in any domain, from a porcelain cup to an organism, to a political system, to the size of a firm, or to delays in airports, resides in the nonlinear. Further, discovery can be seen as an antideficit. Think of the exact opposite of airplane delays or project overruns—something that benefits from uncertainty. And discovery presents the mirror image of what we saw as fragile, randomness-hating situations.
1
Actually there are different muscle fibers, each one responding to different sets of conditions with varied asymmetries of responses. The so-called “fast-twitch” fibers, the ones used to lift very heavy objects, are very antifragile, as they are convex to weight. And they die in the absence of intensity.
2
A nuance: the notions of “large” and “small” are relative to a given ecology or business structure. Small for an airplane maker is different from “small” when it comes to a bakery. As with the European Union’s subsidiarity principle, “small” here means the smallest possible unit for a given function or task that can operate with a certain level of efficiency.
3
The other problem is that of misunderstanding the nonlinearity of natural resources, or anything particularly scarce and vital. Economists have the so-called law of scarcity, by which things increase in value according to the demand for them—but they ignore the consequences of nonlinearities on risk. My former thesis director, Hélyette Geman, and I are currently studying a “law of convexity” that makes commodities, particularly vital ones, even dearer than previously thought.
4
Volatility and uncertainty are equivalent, as we saw with the table of the Disorder family. Accordingly, note that the fragile is harmed by an increase in uncertainty.


================================================================================
CHAPTER/SECTION 89 (Item 92)
================================================================================

CHAPTER 19
The Philosopher’s Stone and Its Inverse
They tell you when they are going bust—Gold is sometimes a special variety of lead
And now, reader, after the Herculean effort I put into making the ideas of the last few chapters clearer to you, my turn to take it easy and express things technically, sort of. Accordingly, this chapter—a deepening of the ideas of the previous one—will be denser and should be skipped by the enlightened reader.


================================================================================
CHAPTER/SECTION 90 (Item 93)
================================================================================

HOW TO DETECT WHO WILL GO BUST
Let us examine a method to detect fragility—the inverse philosopher’s stone. We can illustrate it with the story of the giant government-sponsored lending firm called Fannie Mae, a corporation that collapsed leaving the United States taxpayer with hundreds of billions of dollars of losses (and, alas, still counting).
One day in 2003, Alex Berenson, a
New York Times
journalist, came into my office with the secret risk reports of Fannie Mae, given to him by a defector. It was the kind of report getting into the guts of the methodology for risk calculation that only an insider can see—Fannie Mae made its own risk calculations and disclosed what it wanted to whomever it wanted, the public or someone else. But only a defector could show us the guts to see how the risk was calculated.
We looked at the report: simply, a move upward in an economic variable led to massive losses, a move downward (in the opposite direction), to small profits. Further moves upward led to even larger additional losses and further moves downward to even smaller profits. It looked exactly like the story of the stone in
Figure 9
. Acceleration of harm was obvious—in fact it was monstrous. So we immediately saw that their blowup was inevitable: their exposures were severely “concave,” similar to the graph of traffic in
Figure 14
: losses that accelerate as one deviates economic variables (I did not even need to understand which one, as fragility to one variable of this magnitude implies fragility to all other parameters). I worked with my emotions, not my brain, and I had a pang before even understanding what numbers I had been looking at. It was the mother of all fragilities and, thanks to Berenson,
The New York Times
presented my concern. A smear campaign ensued, but nothing too notable. For I had in the meantime called a few key people charlatans and they were not too excited about it.
The key is that the nonlinear is vastly more affected by extreme events—and nobody was interested in extreme events since they had a mental block against them.
I kept telling anyone who would listen to me, including random taxi drivers (well, almost), that the company Fannie Mae was “sitting on a barrel of dynamite.” Of course, blowups don’t happen every day (just as poorly built bridges don’t collapse immediately), and people kept saying that my opinion was wrong and unfounded (using some argument that the stock was going up or something even more circular). I also inferred that other institutions, almost all banks, were in the same situation. After checking similar institutions, and seeing that the problem was general, I realized that a total collapse of the banking system was a certainty. I was so certain I could not see straight and went back to the markets to get my revenge against the turkeys. As in the scene from
The Godfather
(III), “Just when I thought I was out, they pull me back in.”
Things happened as if they were planned by destiny. Fannie Mae went bust, along with other banks. It just took a bit longer than expected, no big deal.
The stupid part of the story is that I had not seen the link between financial and general fragility—nor did I use the term “fragility.” Maybe I didn’t look at too many porcelain cups. However, thanks to the episode of the attic I had a measure for fragility, hence antifragility.
It all boils down to the following: figuring out if our miscalculations
or misforecasts are on balance more harmful than they are beneficial, and how accelerating the damage is. Exactly as in the story of the king, in which the damage from a ten-kilogram stone is more than twice the damage from a five-kilogram one. Such accelerating damage means that a large stone would eventually kill the person. Likewise a large market deviation would eventually kill the company.
Once I figured out that fragility was directly from nonlinearity and convexity effects, and that convexity was measurable, I got all excited. The technique—detecting
acceleration
of harm—applies to anything that entails decision making under uncertainty, and risk management. While it was the most interesting in medicine and technology, the immediate demand was in economics. So I suggested to the International Monetary Fund a measure of fragility to substitute for their measures of risk that they knew didn’t work. Most people in the risk business had been frustrated by the poor (rather, the random) performance of their models, but they didn’t like my earlier stance: “don’t use any model.” They wanted something. And a risk measure was there.
1
So here is something to use. The technique, a simple heuristic called the
fragility (and antifragility) detection heuristic,
works as follows. Let’s say you want to check whether a town is overoptimized. Say you measure that when traffic increases by ten thousand cars, travel time grows by ten minutes. But if traffic increases by ten thousand more cars, travel time now extends by an extra thirty minutes. Such acceleration of traffic time shows that traffic is fragile and you have too many cars and need to reduce traffic until the acceleration becomes mild (acceleration, I repeat, is acute concavity, or negative convexity effect).
Likewise, government deficits are particularly concave to changes in economic conditions. Every additional deviation in, say, the unemployment rate—particularly when the government has debt—makes deficits incrementally worse. And financial leverage for a company has the same
effect: you need to borrow more and more to get the same effect. Just as in a Ponzi scheme.
The same with operational leverage on the part of a fragile company. Should sales increase 10 percent, then profits would increase less than they would decrease should sales drop 10 percent.
That was in a way the technique I used intuitively to declare that the Highly Respected Firm Fannie Mae was on its way to the cemetery—and it was easy to produce a rule of thumb out of it. Now with the IMF we had a simple measure with a stamp. It looks simple, too simple, so the initial reaction from “experts” was that it was “trivial” (said by people who visibly never detected these risks before—academics and quantitative analysts scorn what they can understand too easily and get ticked off by what they did not think of themselves).
According to the wonderful principle that one should use people’s stupidity to have fun, I invited my friend Raphael Douady to collaborate in expressing this simple idea using the most opaque mathematical derivations, with incomprehensible theorems that would take half a day (for a professional) to understand. Raphael, Bruno Dupire, and I had been involved in an almost two-decades-long continuous conversation on how everything entailing risk—everything—can be seen with a lot more rigor and clarity from the vantage point of an option professional. Raphael and I managed to prove the link between nonlinearity, dislike of volatility, and fragility. Remarkably—as has been shown—if you can say something straightforward in a complicated manner with complex theorems, even if there is no large gain in rigor from these complicated equations, people take the idea very seriously. We got nothing but positive reactions, and we were now told that this simple detection heuristic was “intelligent” (by the same people who had found it trivial). The only problem is that mathematics is addictive.
The Idea of Positive and Negative Model Error
Now what I believe is my true specialty: error in models.
When I was in the transaction business, I used to make plenty of errors of execution. You buy one thousand units and in fact you discover the next day that you bought two thousand. If the price went up in the meantime you had a handsome profit. Otherwise you had a large loss. So these errors are in the long run neutral in effect, since they can affect you both ways. They increase the variance, but they don’t affect your
business too much. There is no one-sidedness to them. And these errors can be kept under control thanks to size limits—you make a lot of small transactions, so errors remain small. And at year end, typically, the errors “wash out,” as they say.
But that is not the case with most things we build, and with errors related to things that are fragile, in the presence of negative convexity effects. This class of errors has a one-way outcome, that is, negative, and tends to make planes land later, not earlier. Wars tend to get worse, not better. As we saw with traffic, variations (now called disturbances) tend to increase travel time from South Kensington to Piccadilly Circus, never shorten it. Some things, like traffic, do rarely experience the equivalent of positive disturbances.
This one-sidedness brings both underestimation of randomness and underestimation of harm, since one is more exposed to harm than benefit from error. If in the long run we get as much variation in the source of randomness one way as the other, the harm would severely outweigh the benefits.
So—and this is the key to the Triad—we can classify things by three simple distinctions: things that, in the long run, like disturbances (or errors), things that are neutral to them, and those that dislike them. By now we have seen that evolution likes disturbances. We saw that discovery likes disturbances. Some forecasts are hurt by uncertainty—and, like travel time, one needs a buffer. Airlines figured out how to do it, but not governments, when they estimate deficits.
This method is very general. I even used it with Fukushima-style computations and realized how fragile their computation of small probabilities was—in fact all small probabilities tend to be very fragile to errors, as a small change in the assumptions can make the probability rise dramatically, from one per million to one per hundred. Indeed, a ten-thousand-fold underestimation.
Finally, this method can show us where the math in economic models is bogus—which models are fragile and which ones are not. Simply do a small change in the assumptions, and look at how large the effect, and if there is acceleration of such effect. Acceleration implies—as with Fannie Mae—that someone relying on the model blows up from Black Swan effects.
Molto facile.
A detailed methodology to detect which results are bogus in economics—along with a discussion of small probabilities—is provided in the Appendix. What I can say for now is that much of what
is taught in economics that has an equation, as well as econometrics, should be immediately ditched—which explains why economics is largely a charlatanic profession. Fragilistas,
semper fragilisti
!


================================================================================
CHAPTER/SECTION 91 (Item 94)
================================================================================

HOW TO LOSE A GRANDMOTHER
Next I will explain the following effect of nonlinearity: conditions under which the average—the first order effect—does not matter. As a first step before getting into the workings of the philosopher’s stone.
As the saying goes:
Do not cross a river if it is on average four feet deep.
You have just been informed that your grandmother will spend the next two hours at the very desirable average temperature of seventy degrees Fahrenheit (about twenty-one degrees Celsius). Excellent, you think, since seventy degrees is the optimal temperature for grandmothers. Since you went to business school, you are a “big picture” type of person and are satisfied with the summary information.
But there is a second piece of data. Your grandmother, it turns out, will spend the first hour at zero degrees Fahrenheit (around minus eighteen Celsius), and the second hour at one hundred and forty degrees (around 60º C), for an average of the very desirable Mediterranean-style seventy degrees (21º C). So it looks as though you will most certainly end up with no grandmother, a funeral, and, possibly, an inheritance.
Clearly, temperature changes become more and more harmful as they deviate from seventy degrees. As you see, the second piece of information, the variability, turned out to be more important than the first. The notion of average is of no significance when one is fragile to variations—the dispersion in possible thermal outcomes here matters much more. Your grandmother is fragile to variations of temperature, to the volatility of the weather. Let us call that second piece of information the
second-order effect,
or, more precisely, the
convexity effect
.
Here, consider that, as much as a good simplification the notion of average can be, it can also be a Procrustean bed. The information that the average temperature is seventy degrees Fahrenheit does not simplify the situation for your grandmother. It is information squeezed into a Procrustean bed—and these are necessarily committed by scientific modelers,
since a model is
by its very nature
a simplification. You just don’t want the simplification to distort the situation to the point of being harmful.
Figure 16
shows the fragility of the health of the grandmother to variations. If I plot health on the vertical axis, and temperature on the horizontal one, I see a shape that curves inward—a “concave” shape, or
negative
convexity effect.
If the grandmother’s response was “linear” (no curve, a straight line), then the harm of temperature below seventy degrees would be offset by the benefits of temperature above it. And the fact is that the health of the grandmother has to be capped at a maximum, otherwise she would keep improving.
FIGURE 16
. Megafragility. Health as a function of temperature curves inward. A combination of 0 and 140 degrees (F) is worse for your grandmother’s health than just 70 degrees. In fact almost
any
combination averaging 70 degrees is worse than just 70 degrees.
2
The graph shows concavity or negative convexity effects—curves inward.
Take this for now as we rapidly move to the more general attributes; in the case of the grandmother’s health response to temperature: (a) there is nonlinearity (the response is not a straight line, not “linear”),
(b) it curves inward, too much so, and, finally, (c) the more nonlinear the response, the less relevant the average, and the more relevant the stability around such average.
NOW THE PHILOSOPHER’S STONE
3
Much of medieval thinking went into finding the philosopher’s stone. It is always good to be reminded that chemistry is the child of alchemy, much of which consisted of looking into the chemical powers of substances. The main efforts went into creating value by transforming metals into gold by the method of
transmutation
. The necessary substance was called the philosopher’s stone—
lapis philosophorum
. Many people fell for it, a list that includes such scholars as Albertus Magnus, Isaac Newton, and Roger Bacon and great thinkers who were not quite scholars, such as Paracelsus.
It is a matter of no small import that the operation of transmutation was called the
Magnus Opus
—the great(est) work. I truly believe that the operation I will discuss—based on some properties of optionality—is about as close as we can get to the philosopher’s stone.
The following note would allow us to understand:
(a) The severity of the problem of conflation (mistaking the price of oil for geopolitics, or mistaking a profitable bet for good forecasting—not convexity of payoff and optionality).
(b) Why anything with optionality has a long-term advantage—and how to measure it.
(c) An additional subtle property called Jensen’s inequality.
Recall from our traffic example in
Chapter 18
that 90,000 cars for an hour, then 110,000 cars for the next one, for an average of 100,000, and traffic will be horrendous. On the other hand, assume we have 100,000 cars for two hours, and traffic will be smooth and time in traffic short.
The number of cars is the
something,
a variable; traffic time is the
function of something
. The behavior of the
function
is such that it is, as
we said, “not the same thing.” We can see here that the
function of something
becomes different from the
something
under nonlinearities.
(a) The more nonlinear, the more the
function of something
divorces itself from the
something
. If traffic were linear, then there would be no difference in traffic time between the two following situations: 90,000, then 110,000 cars on the one hand, or 100,000 cars on the other.
(b) The more volatile the
something
—the more uncertainty—the more the
function
divorces itself from the
something
. Let us consider the average number of cars again. The function (travel time) depends more on the volatility around the average. Things degrade if there is unevenness of distribution. For the same average you prefer to have 100,000 cars for both time periods; 80,000 then 120,000, would be even worse than 90,000 and 110,000.
(c) If the function is convex (antifragile), then the average of the function
of something
is going to be higher than the function of the average
of something
. And the reverse when the function is concave (fragile).
As an example for (c), which is a more complicated version of the bias, assume that the function under question is the squaring function (multiply a number by itself). This is a convex function. Take a conventional die (six sides) and consider a payoff equal to the number it lands on, that is, you get paid a number equivalent to what the die shows—1 if it lands on 1, 2 if it lands on 2, up to 6 if it lands on 6. The square of the expected (average) payoff is then (1+2+3+4+5+6 divided by 6)
2
, equals 3.5
2
, here 12.25. So the
function of the average
equals 12.25.
But the average of the function is as follows. Take the square of every payoff, 1
2
+2
2
+3
2
+4
2
+5
2
+6
2
divided by 6, that is, the average square payoff, and you can see that
the average of the function
equals 15.17.
So, since squaring is a convex function, the average of the square payoff is higher than the square of the average payoff. The difference here between 15.17 and 12.25 is what I call the hidden benefit of antifragility—here, a 24 percent “edge.”
There are two biases: one elementary convexity effect, leading to mistaking the properties of the average of something (here 3.5) and those of a (convex) function of something (here 15.17), and the second, more involved, in mistaking an average of a function for the function of an average, here 15.17 for 12.25. The latter represents optionality.
Someone with a linear payoff needs to be right more than 50 percent of the time. Someone with a convex payoff, much less. The hidden benefit of antifragility is that you can guess worse than random and still end up outperforming. Here lies the power of optionality—your
function of something
is very convex, so you can be wrong and still do fine—the more uncertainty, the better.
This explains my statement that you can be dumb and antifragile and still do very well.
This hidden “convexity bias” comes from a mathematical property called Jensen’s inequality. This is what the common discourse on innovation is missing. If you ignore the convexity bias, you are missing a chunk of what makes the nonlinear world go round. And it is a fact that such an idea is missing from the discourse. Sorry.
4
How to Transform Gold into Mud: The Inverse Philosopher’s Stone
Let us take the same example as before, using as the function the square root (the exact inverse of squaring, which is concave, but much less concave than the square function is convex).
The square root of the expected (average) payoff is then √(1+2+3+4+5+6 divided by 6), equals √3.5, here 1.87. The
function of the average
equals 1.87.
But the average of the function is as follows. Take the square root of every payoff, (√1+√2+√3+√4+√5+√6), divided by 6, that is, the average square root payoff, and you can see that
the average of the function
equals 1.80.
The difference is called the “negative convexity bias” (or, if you are a stickler, “concavity bias”). The hidden harm of fragility is that you need to be much, much better than random in your prediction and knowing where you are going, just to offset the negative effect.
Let me summarize the argument: if you have favorable asymmetries, or positive convexity, options being a special case, then in the long run you will do reasonably well, outperforming the average in the presence of uncertainty. The more uncertainty, the more role for optionality to kick in, and the more you will outperform. This property is very central to life.
1
The method does not require a good model for risk measurement. Take a ruler. You know it is wrong. It will not be able to measure the height of the child. But it can certainly tell you if he is growing. In fact the error you get about the rate of growth of the child is much, much smaller than the error you would get measuring his height. The same with a scale: no matter how defective, it will almost always be able to tell you if you are gaining weight, so stop blaming it.
Convexity is about acceleration. The remarkable thing about measuring convexity effects to detect model errors is that even if the model used for the computation is wrong, it can tell you if an entity is fragile and by how much it is fragile. As with the defective scale, we are only looking for second-order effects.
2
I am simplifying a bit. There may be a few degrees’ variation around 70 at which the grandmother might be better off than just at 70, but I skip this nuance here. In fact younger humans are antifragile to thermal variations, up to a point, benefiting from some variability, then losing such antifragility with age (or disuse, as I suspect that thermal comfort ages people and makes them fragile).
3
I remind the reader that this section is technical and can be skipped.
4
The grandmother does better at 70 degrees Fahrenheit than at an average of 70 degrees with one hour at 0, another at 140 degrees. The more dispersion around the average, the more harm for her. Let us see the counterintuitive effect in terms of
x
and function of
x
,
f
(
x
). Let us write the health of the grandmother as
f
(
x
), with
x
the temperature. We have a function of the average temperature,
f
{(0 + 140)/2}, showing the grandmother in excellent shape. But {f(o) + f(140)}/2 leaves us with a dead grandmother at
f
(0) and a dead grandmother at
f
(140), for an “average” of a dead grandmother. We can see an explanation of the statement that the properties of
f
(
x
) and those of
x
become divorced from each other when
f
(
x
) is nonlinear. The average of
f
(
x
) is different from
f
(average of
x
).


================================================================================
CHAPTER/SECTION 92 (Item 95)
================================================================================

BOOK VI
Via Negativa
R
ecall that we had no name for the color blue but managed rather well without it—we stayed for a long part of our history culturally, not biologically, color blind. And before the composition of
Chapter 1
, we did not have a name for antifragility, yet systems have relied on it effectively in the absence of human intervention. There are many things without words, matters that we know and can act on but cannot describe directly, cannot capture in human language or within the narrow human concepts that are available to us. Almost anything around us of significance is hard to grasp linguistically—and in fact the more powerful, the more incomplete our linguistic grasp.
But if we cannot express what something is exactly, we can say something about what it is not—the indirect rather than the direct expression. The “apophatic” focuses on what cannot be said directly in words, from the Greek
apophasis
(saying no, or mentioning without mentioning). The method began as an avoidance of direct description, leading to a focus on negative description, what is called in Latin
via negativa
, the negative way, after theological traditions, particularly in the Eastern Orthodox Church.
Via negativa
does not try to express what God is—leave that to the primitive brand of contemporary thinkers and philosophasters with scientistic tendencies. It just lists what God is
not
and proceeds by the process of elimination. The idea is mostly associated with the mystical theologian Pseudo-Dionysos the Areopagite. He was some obscure Near Easterner by the name of Dionysos who wrote powerful mystical treatises and was for a long time confused with Dionysos the
Areopagite, a judge in Athens who was converted by the preaching of Paul the Apostle. Hence the qualifier of “Pseudo” added to his name.
Neoplatonists were followers of Plato’s ideas; they focused mainly on Plato’s forms, those abstract objects that had a distinct existence on their own. Pseudo-Dionysos was the disciple of Proclus the Neoplatonist (himself the student of Syrianus, another Syrian Neoplatonist). Proclus was known to repeat the metaphor that statues are carved by subtraction. I have often read a more recent version of the idea, with the following apocryphal pun. Michelangelo was asked by the pope about the secret of his genius, particularly how he carved the statue of David, largely considered the masterpiece of all masterpieces. His answer was: “It’s simple. I just remove everything that is not David.”
The reader might thus recognize the logic behind the barbell. Remember from the logic of the barbell that it is necessary to first remove fragilities.
Where Is the Charlatan?
Recall that the interventionista focuses on positive action—
doing
. Just like positive definitions, we saw that acts of commission are respected and glorified by our primitive minds and lead to, say, naive government interventions that end in disaster, followed by generalized complaints about naive government interventions, as these, it is now accepted, end in disaster, followed by more naive government interventions. Acts of omission,
not
doing something, are not considered acts and do not appear to be part of one’s mission.
Table 3
showed how generalized this effect can be across domains, from medicine to business.
I have used all my life a wonderfully simple heuristic: charlatans are recognizable in that they will give you positive advice, and only positive advice, exploiting our gullibility and sucker-proneness for recipes that hit you in a flash as just obvious, then evaporate later as you forget them. Just look at the “how to” books with, in their title, “Ten Steps for—” (fill in: enrichment, weight loss, making friends, innovation, getting elected, building muscles, finding a husband, running an orphanage, etc.). Yet in practice it is the negative that’s used by the pros, those selected by evolution: chess grandmasters usually win by not losing; people become rich by not going bust (particularly when others do); religions are mostly about interdicts; the learning of life is about what to
avoid. You reduce most of your personal risks of accident thanks to a small number of measures.
Further, being fooled by randomness is that in most circumstances fraught with a high degree of randomness, one cannot really tell if a successful person has skills, or if a person with skills will succeed—but we can pretty much predict the negative, that a person totally devoid of skills will eventually fail.
Subtractive Knowledge
Now when it comes to knowledge, the same applies. The greatest—and most robust—contribution to knowledge consists in removing what we think is wrong—subtractive epistemology.
In life, antifragility is reached by
not
being a sucker. In
Peri mystikes theologias,
Pseudo-Dionysos did not use these exact words, nor did he discuss disconfirmation, nor did he get the idea with clarity, but in my view he figured out this subtractive epistemology and asymmetries in knowledge. I have called “Platonicity” the love of some crisp abstract forms, the theoretical forms and universals that make us blind to the mess of reality and cause Black Swan effects. Then I realized that there was an asymmetry. I truly believe in Platonic ideas when they come in reverse, like negative universals.
So the central tenet of the epistemology I advocate is as follows: we know a lot more what is wrong than what is right, or, phrased according to the fragile/robust classification, negative knowledge (what is wrong, what does not work) is more robust to error than positive knowledge (what is right, what works). So knowledge grows by subtraction much more than by addition—given that what we know today might turn out to be wrong but what we know to be wrong cannot turn out to be right, at least not easily. If I spot a black swan (not capitalized), I can be quite certain that the statement “all swans are white” is wrong. But even if I have never seen a black swan, I can never hold such a statement to be true. Rephrasing it again: since one small observation can disprove a statement, while millions can hardly confirm it, disconfirmation is more rigorous than confirmation.
This idea has been associated in our times with the philosopher Karl Popper, and I quite mistakenly thought that he was its originator (though he is at the origin of an even more potent idea on the fundamental
inability to predict the course of history). The notion, in fact, is vastly more ancient, and was one of the central tenets of the skeptical-empirical school of medicine of the postclassical era in the Eastern Mediterranean. It was well known to a group of nineteenth-century French scholars who rediscovered these works. And this idea of the power of disconfirmation permeates the way we do hard science.
As you can see, we can link this to the general tableaus of positive (additive) and negative (subtractive): negative knowledge is more robust. But it is not perfect. Popper has been criticized by philosophers for his treatment of disconfirmation as hard, unequivocal, black-and-white. It is not clear-cut: it is impossible to figure out whether an experiment failed to produce the intended results—hence “falsifying” the theory—because of the failure of the tools, because of bad luck, or because of fraud by the scientist. Say you saw a black swan. That would certainly invalidate the idea that all swans are white. But what if you had been drinking Lebanese wine, or hallucinating from spending too much time on the Web? What if it was a dark night, in which all swans look gray? Let us say that, in general, failure (and disconfirmation) are more informative than success and confirmation, which is why I claim that negative knowledge is just “more robust.”
Now, before starting to write this section, I spent some time scouring Popper’s complete works wondering how the great thinker, with his obsessive approach to falsification, completely missed the idea of fragility. His masterpiece,
The Poverty of Historicism,
in which he presents the limits of forecasting, shows the impossibility of an acceptable representation of the future. But he missed the point that if an incompetent surgeon is operating on a brain, one can safely predict serious damage, even the death of the patient. Yet such subtractive representation of the future is perfectly in line with his idea of disconfirmation, its logical second step. What he calls falsification of a theory should lead, in practice, to the breaking of the object of its application.
In political systems, a good mechanism is one that helps remove the bad guy; it’s not about what to do or who to put in. For the bad guy can cause more harm than the collective actions of good ones. Jon Elster goes further and presents another kind of
via negativa
: A good negative is one that protects the ordinary guy from bad influences. He recently wrote a book with the telling title
Preventing Mischief
in which he bases negative action on Bentham’s idea that “the art of the legislator is limited to the prevention of everything that might
prevent the development of their [members of the assembly] liberty and their intelligence.”
And, as expected,
via negativa
is part of classical wisdom. For the Arab scholar and religious leader Ali Bin Abi-Taleb (no relation), keeping one’s distance from an ignorant person is equivalent to keeping company with a wise man.
Finally, consider this modernized version in a saying from Steve Jobs: “People think focus means saying yes to the thing you’ve got to focus on. But that’s not what it means at all. It means saying no to the hundred other good ideas that there are. You have to pick carefully. I’m actually as proud of the things we haven’t done as the things I have done. Innovation is saying no to 1,000 things.”


================================================================================
CHAPTER/SECTION 93 (Item 96)
================================================================================

BARBELLS, AGAIN
Subtractive knowledge is a form of barbell. Critically, it is convex. What is wrong is quite robust, what you don’t know is fragile and speculative, but you do not take it seriously so you make sure it does not harm you in case it turns out to be false.
Now another application of
via negativa
lies in the less-is-more idea.
Less Is More
The less-is-more idea in decision making can be traced to Spyros Makridakis, Robyn Dawes, Dan Goldstein, and Gerd Gigerenzer, who have all found in various contexts that simpler methods for forecasting and inference can work much, much better than complicated ones. Their simple rules of thumb are not perfect, but are designed to not be perfect; adopting some intellectual humility and abandoning the aim at sophistication can yield powerful effects. The pair of Goldstein and Gigerenzer coined the notion of “fast and frugal” heuristics that make good decisions despite limited time, knowledge, and computing power.
I realized that the less-is-more heuristic fell squarely into my work in two places. First, extreme effects: there are domains in which the rare event (I repeat, good or bad) plays a disproportionate share and we tend to be blind to it, so focusing on the exploitation of such a rare event, or protection against it, changes a lot, a lot of the risky exposure. Just worry about Black Swan exposures, and life is easy.
Less is more
has proved to be shockingly easy to find and apply—and “robust” to mistakes and change of minds. There may not be an easily identifiable cause for a large share of the problems, but often there is an easy solution (not to all problems, but good enough; I mean really good enough), and such a solution is immediately identifiable, sometimes with the naked eye rather than the use of complicated analyses and highly fragile, error-prone, cause-ferreting nerdiness.
Some people are aware of the
eighty/twenty
idea, based on the discovery by Vilfredo Pareto more than a century ago that 20 percent of the people in Italy owned 80 percent of the land, and vice versa. Of these 20 percent, 20 percent (that is, 4 percent) would have owned around 80 percent of the 80 percent (that is, 64 percent). We end up with less than 1 percent representing about 50 percent of the total. These describe winner-take-all Extremistan effects. These effects are very general, from the distribution of wealth to book sales per author.
Few realize that we are moving into the far more uneven distribution of 99/1 across many things that used to be 80/20: 99 percent of Internet traffic is attributable to less than 1 percent of sites, 99 percent of book sales come from less than 1 percent of authors … and I need to stop because numbers are emotionally stirring. Almost everything contemporary has winner-take-all effects, which includes sources of harm and benefits. Accordingly, as I will show, 1 percent modification of systems can lower fragility (or increase antifragility) by about 99 percent—and all it takes is a few steps, very few steps, often at low cost, to make things better and safer.
For instance, a small number of homeless people cost the states a disproportionate share of the bills, which makes it obvious where to look for the savings. A small number of employees in a corporation cause the most problems, corrupt the general attitude—and vice versa—so getting rid of these is a great solution. A small number of customers generate a large share of the revenues. I get 95 percent of my smear postings from the same three obsessive persons, all representing the same prototypes of failure (one of whom has written, I estimate, close to one hundred thousand words in posts—he needs to write more and more and find more and more stuff to critique in my work and personality to get the same effect). When it comes to health care, Ezekiel Emanuel showed that half the population accounts for less than 3 percent of the costs, with the sickest 10 percent consuming 64 percent of the total pie. Bent Flyvbjerg (of
Chapter 18
) showed in his
Black Swan management
idea that the bulk of cost overruns by corporations are simply attributable to large technology projects—implying that that’s what we need to focus on instead of talking and talking and writing complicated papers.
As they say in the mafia, just work on removing the pebble in your shoe.
There are some domains, like, say, real estate, in which problems and solutions are crisply summarized by a heuristic, a rule of thumb to look for the three most important properties: “location, location, and location”—much of the rest is supposed to be chickensh***t. Not quite and not always true, but it shows the central thing to worry about, as the rest takes care of itself.
Yet people want more data to “solve problems.” I once testified in Congress against a project to fund a crisis forecasting project. The people involved were blind to the paradox that we have never had more data than we have now, yet have less predictability than ever. More data—such as paying attention to the eye colors of the people around when crossing the street—can make you miss the big truck. When you cross the street, you remove data, anything but the essential threat.
1
As Paul Valéry once wrote:
que de choses il faut ignorer pour agir
—how many things one should disregard in order to act.
Convincing—and confident—disciplines, say, physics, tend to use little statistical backup, while political science and economics, which have never produced anything of note, are full of elaborate statistics and statistical “evidence” (and you know that once you remove the smoke, the evidence is not evidence). The situation in science is similar to detective novels in which the person with the largest number of alibis turns out to be the guilty one. And you do not need reams of paper full of data to destroy the megatons of papers using statistics in economics: the simple argument that Black Swans and tail events run the socioeconomic world—and these events cannot be predicted—is sufficient to invalidate their statistics.
We have further evidence of the potency of less-is-more from the following experiment. Christopher Chabris and Daniel Simons, in their book
The Invisible Gorilla,
show how people watching a video of a
basketball game, when diverted with attention-absorbing details such as counting passes, can completely miss a gorilla stepping into the middle of the court.
I discovered that I had been intuitively using the less-is-more idea as an aid in decision making (contrary to the method of putting a series of pros and cons side by side on a computer screen). For instance, if you have more than one reason to do something (choose a doctor or veterinarian, hire a gardener or an employee, marry a person, go on a trip), just don’t do it. It does not mean that one reason is better than two, just that by invoking more than one reason you are trying to convince yourself to do something. Obvious decisions (robust to error)
require
no more than a single reason. Likewise the French army had a heuristic to reject excuses for absenteeism for more than one reason, like death of grandmother, cold virus, and being bitten by a boar. If someone attacks a book or idea using more than one argument, you know it is not real: nobody says “he is a criminal, he killed many people, and he also has bad table manners and bad breath and is a very poor driver.”
I have often followed what I call Bergson’s razor: “A philosopher should be known for one single idea, not more” (I can’t source it to Bergson, but the rule is good enough). The French essayist and poet Paul Valéry once asked Einstein if he carried a notebook to write down ideas. “I never have ideas” was the reply (in fact he just did not have chickens***t ideas). So, a heuristic: if someone has a long bio, I skip him—at a conference a friend invited me to have lunch with an overachieving hotshot whose résumé “can cover more than two or three lives”; I skipped to sit at a table with the trainees and stage engineers.
2
Likewise when I am told that someone has three hundred academic papers and twenty-two honorary doctorates, but no other single compelling contribution or main idea behind it, I avoid him like the bubonic plague.
1
Recall that the overediting interventionist missed the main mistake in
Chapter 7
. The 663-page document
Financial Crisis Inquiry Report
by the Financial Crisis Inquiry Commission missed what I believe are the main reasons: fragility and absence of skin in the game. But of course they listed every possible epiphenomenon you can think of as cause.
2
Even the Nobel, with all its ills of inducing competition in something as holy as science, is not granted for a collection of papers but rarely for more than a single, but major, contribution.


================================================================================
CHAPTER/SECTION 94 (Item 97)
================================================================================

CHAPTER 20
Time and Fragility
Prophecy, like knowledge, is subtractive, not additive—The Lindy effect, or how the old prevails over the new, especially in technology, no matter what they say in California—Prophecy not a recommended and voluntary career
Antifragility implies—contrary to initial instinct—that the old is superior to the new, and much more than you think. No matter how something looks to your intellectual machinery, or how well or poorly it narrates, time will know more about its fragilities and break it when necessary. Here, I expose a contemporary disease—linked to interventionism—called
neomania,
which brings fragility but I believe may be treatable if one is patient enough.
What survives must be good at serving some (mostly hidden) purpose that time can see but our eyes and logical faculties can’t capture. In this chapter we use the notion of fragility as a central driver of prediction.
Recall the foundational asymmetry: the antifragile benefits from volatility and disorder, the fragile is harmed. Well, time is the same as disorder.


================================================================================
CHAPTER/SECTION 95 (Item 98)
================================================================================

FROM SIMONIDES TO JENSEN
As an exercise in the use of the distinction between fragility and antifragility, let us play prophet, with the understanding that it is not a good
career choice unless you have a thick skin, a good circle of friends, little access to the Internet, a library with a good set of ancient proverbs, and, if possible, the ability to derive personal benefits from your prophecy. As shown from the track record of the prophets: before you are proven right, you will be reviled; after you are proven right, you will be hated for a while, or, what’s worse, your ideas will appear to be “trivial” thanks to retrospective distortion. This makes it far more convincing to follow the Fat Tony method of focusing on shekels more than recognition. And such treatment has continued in modern times: twentieth-century intellectuals who have embraced the wrong ideas, such as Communism or even Stalinism, have remained fashionable—and their books remain on the bookstore shelves—while those who, like the political philosopher Raymond Aron, saw the problems got short shrift both before and after being acknowledged as having seen things right.
Now close your eyes and try to imagine your future surroundings in, say, five, ten, or twenty-five years. Odds are your imagination will produce
new
things in it, things we call
innovation, improvements, killer technologies,
and other inelegant and hackneyed words from the business jargon. These common concepts concerning innovation, we will see, are not just offensive aesthetically, but they are nonsense both empirically and philosophically.
Why? Odds are that your imagination will be adding things to the present world. I am sorry, but I will show in this chapter that this approach is exactly backward: the way to do it rigorously, according to the notions of fragility and antifragility, is to
take away
from the future, reduce from it, simply, things that do not belong to the coming times.
Via negativa
. What is fragile will eventually break; and, luckily, we can easily tell what is fragile. Positive Black Swans are more unpredictable than negative ones.
“
Time has sharp teeth that destroy everything,” declaimed the sixth-century (
B.C.
) poet Simonides of Ceos, perhaps starting a tradition in Western literature about the inexorable effect of time. I can trace a plethora of elegant classical expressions, from Ovid (
tempus edax rerum—
time devours everything) to the no less poetic twentieth-century Franco-Russian poetess Elsa Triolet (“time burns but leaves no ashes”). Naturally, this exercise triggered some poetic waxing, so I am now humming a French poem put to music titled
“Avec le temps”
about how time erases things, even bad memories (though it doesn’t say that it erases us as well in the process). Now, thanks to convexity effects, we can put a
little bit of science in these, and produce our own taxonomy of what should be devoured the fastest by that inexorable time. The fragile will eventually break—and, luckily, we are capable of figuring out what is fragile. Even what we believe is antifragile will eventually break, but it should take much, much longer to do so (wine does well with time, but up to a point; and not if you put it in the crater of a volcano).
The verse by Simonides that started the previous paragraph continues with the stipulation “even the most solid.” So Simonides had the adumbration of the idea, quite useful, that the most solid will be swallowed with more difficulty, hence last. Naturally, he did not think that something could be antifragile, hence never swallowed.
Now, I insist on the
via negativa
method of prophecy as being the only valid one: there is no other way to produce a forecast without being a turkey somewhere, particularly in the complex environment in which we live today. Now, I am not saying that new technologies will not emerge—something new will rule its day, for a while. What is currently fragile will be replaced by something else, of course. But this “something else” is unpredictable. In all likelihood, the technologies you have in your mind are not the ones that will make it, no matter your perception of their fitness and applicability—with all due respect to your imagination.
Recall that the most fragile is the predictive, what is built on the basis of predictability—in other words, those who underestimate Black Swans will eventually exit the population.
An interesting apparent paradox is that, according to these principles, longer-term predictions are more reliable than short-term ones, given that one can be quite certain that what is Black Swan–prone will be eventually swallowed by history since time augments the probability of such an event. On the other hand, typical predictions (not involving the currently fragile) degrade with time; in the presence of nonlinearities, the longer the forecast the worse its accuracy. Your error rate for a ten-year forecast of, say, the sales of a computer plant or the profits of a commodity vendor can be a thousand times that of a one-year projection.


================================================================================
CHAPTER/SECTION 96 (Item 99)
================================================================================

LEARNING TO SUBTRACT
Consider the futuristic projections made throughout the past century and a half, as expressed in literary novels such as those by Jules Verne,
H. G. Wells, or George Orwell, or in now forgotten narratives of the future produced by scientists or futurists. It is remarkable that the tools that seem to currently dominate the world, such as the Internet, or more mundane matters such as the wheel on the suitcase of
Book IV
, were completely missing from these forecasts. But it is not here that the major error lies. The problem is that almost everything that was imagined never took place, except for a few overexploited anecdotes (such as the steam engine by Hero the Alexandrian or the assault vehicle by Leonardo da Vinci). Our world looks too close to theirs, much closer to theirs than they ever imagined or wanted to imagine. And we tend to be blind to that fact—there seems to be no correcting mechanism that can make us aware of the point as we go along forecasting a highly technocratic future.
There may be a selection bias: those people who engage in producing these accounts of the future will tend to have (incurable and untreatable)
neomania,
the love of the modern for its own sake.
Tonight I will be meeting friends in a restaurant (tavernas have existed for at least twenty-five centuries). I will be walking there wearing shoes hardly different from those worn fifty-three hundred years ago by the mummified man discovered in a glacier in the Austrian Alps. At the restaurant, I will be using silverware, a Mesopotamian technology, which qualifies as a “killer application” given what it allows me to do to the leg of lamb, such as tear it apart while sparing my fingers from burns. I will be drinking wine, a liquid that has been in use for at least six millennia. The wine will be poured into glasses, an innovation claimed by my Lebanese compatriots to come from their Phoenician ancestors, and if you disagree about the source, we can say that glass objects have been sold by them as trinkets for at least twenty-nine hundred years. After the main course, I will have a somewhat younger technology, artisanal cheese, paying higher prices for those that have not changed in their preparation for several centuries.
Had someone in 1950 predicted such a minor gathering, he would have imagined something quite different. So, thank God, I will not be dressed in a shiny synthetic space-style suit, consuming nutritionally optimized pills while communicating with my dinner peers by means of screens. The dinner partners, in turn, will be expelling airborne germs on my face, as they will not be located in remote human colonies across the galaxy. The food will be prepared using a very archaic technology (fire), with the aid of kitchen tools and implements that have not changed since
the Romans (except in the quality of some of the metals used). I will be sitting on an (at least) three-thousand-year-old device commonly known as the chair (which will be, if anything, less ornate that its majestic Egyptian ancestor). And I will be not be repairing to the restaurant with the aid of a flying motorcycle. I will be walking or, if late, using a cab from a century-old technology, driven by an immigrant—immigrants were driving cabs in Paris a century ago (Russian aristocrats), same as in Berlin and Stockholm (Iraqis and Kurdish refugees), Washington, D.C. (Ethiopian postdoc students), Los Angeles (musically oriented Armenians), and New York (multinationals) today.
David Edgerton showed that in the early 2000s we produce two and a half times as many bicycles as we do cars and invest most of our technological resources in maintaining existing equipment or refining old technologies (note that this is not just a Chinese phenomenon: Western cities are aggressively trying to become bicycle-friendly). Also consider that one of the most consequential technologies seems to be the one people talk about the least: the condom. Ironically, it wants to look like less of a technology; it has been undergoing meaningful improvements, with the precise aim of being less and less noticeable.
FIGURE 17
. Cooking utensils from Pompeii, hardly different from those found in today’s (good) kitchens
So, the prime error is as follows. When asked to imagine the future, we have the tendency to take the present as a baseline, then produce a
speculative destiny by adding new technologies and products to it and what sort of
makes sense,
given an interpolation of past developments. We also represent society according to our utopia of the moment, largely driven by our wishes—except for a few people called doomsayers, the future will be largely inhabited by our desires. So we will tend to over-technologize it and underestimate the might of the equivalent of these small wheels on suitcases that will be staring at us for the next millennia.
A word on the blindness to this over-technologizing. After I left finance, I started attending some of the fashionable conferences attended by pre-rich and post-rich technology people and the new category of technology intellectuals. I was initially exhilarated to see them wearing no ties, as, living among tie-wearing abhorrent bankers, I had developed the illusion that anyone who doesn’t wear a tie was not an empty suit. But these conferences, while colorful and slick with computerized images and fancy animations, felt depressing. I knew I did not belong. It was not just their additive approach to the future (failure to subtract the fragile rather than add to destiny). It was not entirely their blindness by uncompromising neomania. It took a while for me to realize the reason: a profound lack of elegance. Technothinkers tend to have an “engineering mind”—to put it less politely, they have autistic tendencies. While they don’t usually wear ties, these types tend, of course, to exhibit all the textbook characteristics of nerdiness—mostly lack of charm, interest in objects instead of persons, causing them to neglect their looks. They love precision at the expense of applicability. And they typically share an absence of literary culture.
This absence of literary culture is actually a marker of future blindness because it is usually accompanied by a denigration of history, a byproduct of unconditional neomania. Outside of the niche and isolated genre of science fiction, literature is about the past. We do not learn physics or biology from medieval textbooks, but we still read Homer, Plato, or the very modern Shakespeare. We cannot talk about sculpture without knowledge of the works of Phidias, Michelangelo, or the great Canova. These are in the past, not in the future. Just by setting foot into a museum, the aesthetically minded person is connecting with the elders. Whether overtly or not, he will tend to acquire and respect historical knowledge, even if it is to reject it. And the past—properly handled, as we will see in the next section—is a much better teacher about the properties of the future than the present. To understand the future, you do
not need technoautistic jargon, obsession with “killer apps,” these sort of things. You just need the following: some respect for the past, some curiosity about the historical record, a hunger for the wisdom of the elders, and a grasp of the notion of “heuristics,” these often unwritten rules of thumb that are so determining of survival. In other words, you will be forced to give weight to things that have been around, things that have survived.
Technology at Its Best
But technology can cancel the effect of bad technologies, by self-subtraction.
Technology is at its best when it is invisible. I am convinced that technology is of greatest benefit when it displaces the deleterious, unnatural, alienating, and, most of all, inherently fragile preceding technology. Many of the modern applications that have managed to survive today came to disrupt the deleterious effect of the philistinism of modernity, particularly the twentieth century: the large multinational bureaucratic corporation with “empty suits” at the top; the isolated family (nuclear) in a one-way relationship with the television set, even more isolated thanks to car-designed suburban society; the dominance of the state, particularly the militaristic nation-state, with border controls; the destructive dictatorship on thought and culture by the established media; the tight control on publication and dissemination of economic ideas by the charlatanic economics establishment; large corporations that tend to control their markets now threatened by the Internet; pseudorigor that has been busted by the Web; and many others. You no longer have to “press 1 for English” or wait in line for a rude operator to make bookings for your honeymoon in Cyprus. In many respects, as unnatural as it is, the Internet removed some of the even more unnatural elements around us. For instance, the absence of paperwork makes bureaucracy—something modernistic—more palatable than it was in the days of paper files. With a little bit of luck a computer virus will wipe out all records and free people from their past mistakes.
Even now, we are using technology to reverse technology. Recall my walk to the restaurant wearing shoes not too dissimilar to those worn by the ancient, preclassical person found in the Alps. The shoe industry, after spending decades “engineering” the perfect walking and running shoe, with all manner of “support” mechanisms and material for cushioning,
is now selling us shoes that replicate being barefoot—they want to be so unobtrusive that their only claimed function is to protect our feet from the elements, not to dictate how we walk as the more modernistic mission was. In a way they are selling us the calloused feet of a hunter-gatherer that we can put on, use, and then remove upon returning to civilization. It is quite exhilarating to wear these shoes when walking in nature as one wakes up to a new dimension while feeling the three dimensions of the terrain. Regular shoes feel like casts that separate us from the environment. And they don’t have to be inelegant: the technology is in the sole, not the shoe, as the new soles can be both robust and very thin, thus allowing the foot to hug the ground as if one were barefoot—my best discovery is an Italian-looking moccasin made in Brazil that allows me to both run on stones and go to dinner in restaurants.
Then again, perhaps they should just sell us reinforced waterproof socks (in effect, what the Alpine fellow had), but it would not be very profitable for these firms.
1
And the great use of the tablet computer (notably the iPad) is that it allows us to return to Babylonian and Phoenician roots of writing and take notes on a tablet (which is how it started). One can now jot down handwritten, or rather fingerwritten, notes—it is much more soothing to write longhand, instead of having to go through the agency of a keyboard. My dream would be to someday write everything longhand, as almost every writer did before modernity.
So it may be a natural property of technology to only want to be displaced by itself.
Next let me show how the future is mostly in the past.


================================================================================
CHAPTER/SECTION 97 (Item 100)
================================================================================

TO AGE IN REVERSE: THE LINDY EFFECT
Time to get more technical, so a distinction is helpful at this stage. Let us separate the perishable (humans, single items) from the nonperishable, the potentially perennial. The nonperishable is anything that does not have an organic unavoidable expiration date. The perishable is typically an object, the nonperishable has an informational nature to it. A
single car is perishable, but the automobile as a technology has survived about a century (and we will speculate should survive another one). Humans die, but their genes—a code—do not necessarily. The physical book is perishable—say, a specific copy of the Old Testament—but its contents are not, as they can be expressed into another physical book.
Let me express my idea in Lebanese dialect first. When you see a young and an old human, you can be confident that the younger will survive the elder. With something nonperishable, say a technology, that is not the case. We have two possibilities: either both are expected to have the same additional life expectancy (the case in which the probability distribution is called
exponential
), or the old is expected to have a longer expectancy than the young, in proportion to their relative age. In that situation, if the old is eighty and the young is ten, the elder is expected to live eight times as long as the younger one.
Click
here
for a larger image of this table.
Now conditional on something belonging to either category, I propose the following (building on the so-called Lindy effect in the version later developed by the great Benoît Mandelbrot):
2
For the perishable, every additional day in its life translates into a
shorter
additional life expectancy. For the nonperishable, every additional day may imply a
longer
life expectancy.
So the longer a technology lives, the longer it can be expected to live. Let me illustrate the point (people have difficulty understanding it at the first go). Say I have for sole information about a gentleman that he is 40 years old and I want to predict how long he will live. I can look at actuarial tables and find his age-adjusted life expectancy as used by insurance companies. The table will predict that he has an extra 44 to go. Next year, when he turns 41 (or, equivalently, if applying the reasoning today to another person currently 41), he will have a little more than 43 years to go. So every year that elapses reduces his life expectancy by about a year (actually, a little less than a year, so if his life expectancy at birth is 80, his life expectancy at 80 will not be zero, but another decade or so).
3
The opposite applies to nonperishable items. I am simplifying numbers here for clarity. If a book has been in print for forty years, I can expect it to be in print for another forty years. But, and that is the main difference, if it survives another decade, then it will be expected to be in print another fifty years. This, simply, as a rule, tells you why things that have been around for a long time are not “aging” like persons, but “aging” in reverse. Every year that passes without extinction doubles the additional life expectancy.
4
This is an indicator of some robustness. The robustness of an item is proportional to its life!
The physicist Richard Gott applied what seems to be completely different reasoning to state that whatever we observe in a randomly selected way is likely to be neither in the beginning nor in the end of its life, most likely in its middle. His argument was criticized for being rather incomplete. But by testing his argument he tested the one I just outlined above, that the expected life of an item is proportional to its past life. Gott made a list of Broadway shows on a given day, May 17, 1993, and
predicted that
the longest-running ones would last longest, and vice versa
. He was proven right with 95 percent accuracy. He had, as a child, visited both the Great Pyramid (fifty-seven hundred years old), and the Berlin Wall (twelve years old), and correctly guessed that the former would outlive the latter.
The proportionality of life expectancy does not need to be tested explicitly—it is the direct result of “winner-take-all” effects in longevity.
Two mistakes are commonly made when I present this idea—people have difficulties grasping probabilistic notions, particularly when they have spent too much time on the Internet (not that they need the Internet to be confused; we are naturally probability-challenged). The first mistake is usually in the form of the presentation of the counterexample of a technology that we currently see as inefficient and dying, like, say, telephone land lines, print newspapers, and cabinets containing paper receipts for tax purposes. These arguments come with anger as many neomaniacs get offended by my point. But my argument is not about
every
technology, but about life expectancy, which is simply a probabilistically derived average. If I know that a forty-year-old has terminal pancreatic cancer, I will no longer estimate his life expectancy using unconditional insurance tables; it would be a mistake to think that he has forty-four more years to live, like others in his age group who are cancer-free. Likewise someone (a technology guru) interpreted my idea as suggesting that the World Wide Web, being currently less than about twenty years old, will
only
have another twenty to go—this is a noisy estimator that should work on average, not in every case. But in general, the older the technology, not only the longer it is expected to last, but the more certainty I can attach to such a statement.
5
Remember the following principle: I am not saying that
all
technologies do not age, only that those technologies that were prone to aging are already dead.
The second mistake is to believe that one would be acting “young” by adopting a “young” technology, revealing both a logical error and mental bias. It leads to the inversion of the power of generational contributions, producing the illusion of the contribution of the new generations over the old—statistically, the “young” do almost nothing. This
mistake has been made by many people, but most recently I saw an angry “futuristic” consultant who accuses people who don’t jump into technology of “thinking old” (he is actually older than I am and, like most technomaniacs I know, looks sickly and pear-shaped and has an undefined transition between his jaw and his neck). I didn’t understand why one would be acting particularly “old” by loving things historical. So by loving the classics (“older”) I would be acting “older” than if I were interested in the “younger” medieval themes. This is a mistake similar to believing that one would turn into a cow by eating cow meat. It is actually a worse fallacy than the inference from eating: a technology, being informational rather than physical, does not age organically, like humans, at least not necessarily so. The wheel is not “old” in the sense of experiencing degeneracy.
This idea of “young” and “old” attached to certain crowd behavior is even more dangerous. Supposedly, if those who don’t watch prepackaged 18-minute hyped-up lectures on the Web paid attention to people in their teens and twenties, who do, and in whom supposedly the key to the future lies, they would be thinking differently. Much progress comes from the young because of their relative freedom from the system and courage to take action that older people lose as they become trapped in life. But it is precisely the young who propose ideas that are fragile, not because they are young, but because most unseasoned ideas are fragile. And, of course, someone who sells “futuristic” ideas will not make a lot of money selling the value of the past! New technology is easier to hype up.
I received an interesting letter from Paul Doolan from Zurich, who was wondering how we could teach children skills for the twenty-first century since we do not know which skills will be needed in the twenty-first century—he figured out an elegant application of the large problem that Karl Popper called the error of historicism. Effectively my answer would be to make them read the classics. The future is in the past. Actually there is an Arabic proverb to that effect:
he who does not have a past has no future
.
6


================================================================================
CHAPTER/SECTION 98 (Item 101)
================================================================================

A FEW MENTAL BIASES
Next I present an application of the
fooled by randomness
effect. Information has a nasty property: it hides failures. Many people have been drawn to, say, financial markets after hearing success stories of someone getting rich in the stock market and building a large mansion across the street—but since failures are buried and we don’t hear about them, investors are led to overestimate their chances of success. The same applies to the writing of novels: we do not see the wonderful novels that are now completely out of print, we just think that because the novels that have done well are well written (whatever that means), that what is well written will do well. So we confuse the necessary and the causal: because all surviving technologies have some obvious benefits, we are led to believe that all technologies offering obvious benefits will survive. I will leave the discussion of what impenetrable property may help survival to the section on Empedocles’ dog. But note here the mental bias that causes people to believe in the “power of” some technology and its ability to run the world.
Another mental bias causing the overhyping of technology comes from the fact that we notice change, not statics. The classic example, discovered by the psychologists Daniel Kahneman and Amos Tversky, applies to wealth. (The pair developed the idea that our brains like minimal effort and get trapped that way, and they pioneered a tradition of cataloging and mapping human biases with respect to perception of random outcomes and decision making under uncertainty). If you announce to someone “you lost $10,000,” he will be much more upset than if you tell him “your portfolio value, which was $785,000, is now $775,000.” Our brains have a predilection for shortcuts, and the variation is easier to notice (and store) than the entire record. It requires less memory storage. This psychological heuristic (often operating without our awareness), the error of variation in place of total, is quite pervasive, even with matters that are visual.
We notice what varies and changes more than what plays a large role but doesn’t change. We rely more on water than on cell phones but because water does not change and cell phones do, we are prone to thinking that cell phones play a larger role than they do. Second, because the new generations are more aggressive with technology, we notice that they try more things, but we ignore that these implementations don’t
usually stick. Most “innovations” are failures, just as most books are flops, which should not discourage anyone from trying.
Neomania and Treadmill Effects
You are driving on the highway in your two-year-old Japanese car when you are overtaken by a vehicle of the same make, the latest version, that looks markedly different. And markedly better. Markedly better? The bumper is slightly larger and the taillights are wider. Other than these cosmetic details (and perhaps some hidden technical improvements) representing less than a few percentage points in variation, the car looks the same, but you can’t tell by just looking at it. You just see the lights and feel that you are due an upgrade. And the upgrade will cost you, after you sell your car, about the third of the price of a new vehicle—all that motivated by small, mostly cosmetic variations. But switching cars is a small cost compared to switching computers—the recovery value of an old computer is so negligible.
You use an Apple Mac computer. You just bought a new version a week before. The person on the plane next to you just pulled out of his bag an older version. It has a family resemblance to yours, but looks so inferior. It is thicker and has a much less elegant screen. But you forget the days when you used to have the same model and were thrilled with it.
The same with a cell phone: you look down at those carrying older, larger models. But a few years ago you would have considered these small and slick.
So with so many technologically driven and modernistic items—skis, cars, computers, computer programs—it seems that we notice differences between versions rather than commonalities. We even rapidly tire of what we have, continuously searching for versions 2.0 and similar iterations. And after that, another “improved” reincarnation. These impulses to buy new things that will eventually lose their novelty, particularly when compared to newer things, are called
treadmill effects
. As the reader can see, they arise from the same generator of biases as the one about the salience of variations mentioned in the section before: we notice differences and become dissatisfied with some items and some classes of goods. This treadmill effect has been investigated by Danny Kahneman and his peers when they studied the psychology of what they call hedonic states. People acquire a new item, feel
more satisfied
after an
initial boost, then rapidly revert to their baseline of well-being. So, when you “upgrade,” you feel a boost of satisfaction with
changes
in technology. But then you get used to it and start hunting for the
new
new thing.
But it looks as though we don’t incur the same treadmilling techno-dissatisfaction with classical art, older furniture—whatever we do not put in the category of the technological. You may have an oil painting and a flat-screen television set inhabiting the same room of your house. The oil painting is an imitation of a classic Flemish scene made close to a century ago, with the dark ominous skies of Flanders, majestic trees, and an uninspiring but calmative rural scene. I am quite certain that you are not eager to upgrade the oil painting but that soon your flat-screen TV set will be donated to the local chapter of some kidney foundation.
The same with dishes—recall that we try to replicate nineteenth-century dinner customs. So there is at least one other domain in which we do not try to optimize matters.
I am initially writing these lines longhand, using a seasoned fountain pen. I do not fuss over the state of my pens. Many of them are old enough to cross decades; one of them (the best) I have had for at least thirty years. Nor do I obsess over small variations in the paper. I prefer to use Clairefontaine paper and notebooks that have hardly changed since my early childhood—if anything, they have degraded in quality.
But when it comes to transcribing my writing into electronic form, then I get worried that my Mac computer may not be the best tool for the job. I heard somewhere that the new version had a longer-lasting battery and I plan to upgrade soon, during my next impulse buying episode.
Note here is a strange inconsistency in the way we perceive items across the technological and real domains. Whenever I sit on an airplane next to some businessman reading the usual trash businessmen read on an e-reader, said businessperson will not resist disparaging my use of the book by comparing the two items. Supposedly, an e-reader is more “efficient.” It delivers the essence of the book, which said businessman assumes is information, but in a more convenient way, as he can carry a library on his device and “optimize” his time between golf outings. I have never heard anyone address the large differences between e-readers and physical books, like smell, texture, dimension (books are in three dimensions), color, ability to change pages, physicality of an object compared to a computer screen, and hidden properties causing unexplained
differences in enjoyment. The focus of the discussion will be commonalities (how close to a book this wonderful device is). Yet when he compares his version of an e-reader to another e-reader, he will invariably focus on minute differences. Just as when Lebanese run into Syrians, they focus on the tiny variations in their respective Levantine dialects, but when Lebanese run into Italians, they focus on similarities.
There may be a heuristic that helps put such items in categories. First, the electronic on-off switch. Whatever has an “off” or “on” switch that I need to turn off before I get yelled at by the flight attendant will necessarily be in one category (but not the opposite as many items without an on-off switch will be prone to neomania). For these items, I focus on variations, with attendant neomania. But consider the difference between the artisanal—the other category—and the industrial. What is artisanal has the love of the maker infused in it, and tends to satisfy—we don’t have this nagging impression of incompleteness we encounter with electronics.
It also so happens that whatever is technological happens to be fragile. Articles made by an artisan cause fewer treadmill effects. And they tend to have some antifragility—recall how my artisanal shoes take months before becoming comfortable. Items with an on-off switch tend to have no such redeeming antifragility.
But alas, some things we wish were a bit more fragile—which brings us to architecture.


================================================================================
CHAPTER/SECTION 99 (Item 102)
================================================================================

ARCHITECTURE AND THE IRREVERSIBLE NEOMANIA
There is some evolutionary warfare between architects producing a compounded form of neomania. The problem with modernistic—and functional—architecture is that it is not fragile enough to break physically, so these buildings stick out just to torture our consciousness—you cannot exercise your prophetic powers by leaning on their fragility.
Urban planning, incidentally, demonstrates the central property of the so-called top-down effect: top-down is usually irreversible, so mistakes tend to stick, whereas bottom-up is gradual and incremental, with creation and destruction along the way, though presumably with a positive slope.
Further, things that grow in a natural way, whether cities or individual houses, have a fractal quality to them. Like everything alive, all organisms, like lungs, or trees, grow in some form of self-guided but tame
randomness. What is fractal? Recall Mandelbrot’s insight in
Chapter 3
: “fractal” entails both jaggedness and a form of self-similarity in things (Mandelbrot preferred “self-affinity”), such as trees spreading into branches that look like small trees, and smaller and smaller branches that look like a slightly modified, but recognizable, version of the whole. These fractals induce a certain wealth of detail based on a small number of rules of repetition of nested patterns. The fractal require some jaggedness, but one that has some method to its madness. Everything in nature is fractal, jagged, and rich in detail, though with a certain pattern. The smooth, by comparison, belongs to the class of Euclidian geometry we study in school, simplified shapes that lose this layer of wealth.
Alas, contemporary architecture is smooth, even when it tries to look whimsical. What is top-down is generally unwrinkled (that is, unfractal) and feels dead.
Sometimes modernism can take a naturalistic turn, then stop in its tracks. Gaudi’s buildings in Barcelona, from around the turn of the twentieth century, are inspired by nature and rich architecture (Baroque and Moorish). I managed to visit a rent-controlled apartment there: it felt like an improved cavern with rich, jagged details. I was convinced that I had been there in a previous life. Wealth of details, ironically, leads to inner peace. Yet Gaudi’s idea went nowhere, except in promoting modernism in its unnatural and naive versions: later modernistic structures are smooth and completely stripped of fractal jaggedness.
I also enjoy writing facing trees, and, if possible, wild untamed gardens with ferns. But white walls with sharp corners and Euclidian angles and crisp shapes strain me. And once they are built, there is no way to get rid of them. Almost everything built since World War II has an unnatural smoothness to it.
For some, these buildings cause even more than aesthetic harm—many Romanians are bitter about the dictator Nicolae Ceausescu’s destruction of traditional villages replaced by modern high-rises. Neomania and dictatorship are an explosive combination. In France, some blame the modernistic architecture of housing projects for the immigrant riots. As the journalist Christopher Caldwell wrote about the unnatural living conditions: “Le Corbusier called houses ‘machines for living.’ France’s housing projects, as we now know, became machines for alienation.”
Jane Jacobs, the New York urban activist, took a heroic stance as a political-style resistant against neomania in architecture and urban planning, as the modernistic dream was carried by Robert Moses, who
wanted to improve New York by razing tenements and installing large roads and highways, committing a greater crime against natural order than Haussmann, who, as we saw in
Chapter 7
, removed during the nineteenth century entire neighborhoods of Paris to make room for the “Grand Boulevards.” Jacobs stood against tall buildings as they deform the experience of urban living, which is conducted at street level. Further, her bone with Robert Moses concerns the highway, as these engines for travel suck life out of the city—to her a city should be devoted to pedestrians. Again, we have the machine-organism dichotomy: to her the city is an organism, for Moses it is a machine to be improved upon. Indeed, Moses had plans to raze the West Village; it is thanks to her petitions and unremitting resistance that the neighborhood—the prettiest in Manhattan—has survived nearly intact. One might want to give Moses some credit, for not all his projects turned out to be nefarious—some might have been beneficial, such as the parks and beaches now accessible to the middle class thanks to the highways.
Recall the discussion of municipal properties—they don’t translate into something larger because problems become more abstract as they scale up, and the abstract is not something human nature can manage properly. The same principle needs to apply to urban life: neighborhoods are villages, and need to remain villages.
I was recently stuck in a traffic jam in London where, one hears, the speed of traveling is equal to what it was a century and a half ago, if not slower. It took me almost two hours to cross London from one end to the other. As I was depleting the topics of conversation with the (Polish) driver, I wondered whether Haussmann was not right, and whether London would be better off if it had its Haussmann razing neighborhoods and plowing wide arteries to facilitate circulation. Until it hit me that, in fact, if there was so much traffic in London, as compared to other cities, it was because people wanted to be there, and being there for them exceeded the costs. More than a third of the residents in London are foreign-born, and, in addition to immigrants, most high net worth individuals on the planet get their starter pied-à-terre in Central London. It could be that the absence of these large avenues and absence of a dominating state is part of its appeal. Nobody would buy a pied-à-terre in Brasilia, the perfectly top-down city built from scratch on a map.
I also checked and saw that the most expensive neighborhoods in
Paris today (such as the Sixth Arrondissement or Île Saint-Louis) were the ones that had been left alone by the nineteenth-century renovators.
Finally, the best argument against teleological design is as follows. Even after they are built, buildings keep incurring mutations as if they needed to slowly evolve and be taken over by the dynamical environment: they change colors, shapes, windows—and character. In his book
How Buildings Learn,
Stewart Brand shows in pictures how buildings change through time, as if they needed to metamorphose into unrecognizable shapes—strangely buildings, when erected, do not account for the optionality of future alterations.
Wall to Wall Windows
The skepticism about architectural modernism that I am proposing is not unconditional. While most of it brings unnatural stress, some elements are a certain improvement. For instance, floor-to-ceiling windows in a rural environment expose us to nature—here again technology making itself (literally) invisible. In the past, the size of windows was dictated by thermal considerations, as insulation was not possible—heat escaped rather quickly from windows. Today’s materials allow us to avoid such constraint. Further, much French architecture was a response to the tax on windows and doors installed after the Revolution, so many buildings have a very small number of windows.
Just as with the unintrusive shoes that allow us to feel the terrain, modern technology allows some of us to reverse that trend, as expressed by Oswald Spengler, which makes civilization go from plants to stone, that is, from the fractal to the Euclidian. We are now moving back from the smooth stone to the rich fractal and natural. Benoît Mandelbrot wrote in front of a window overlooking trees: he craved fractal aesthetics so much that the alternative would have been inconceivable. Now modern technology allows us to merge with nature, and instead of a small window, an entire wall can be transparent and face lush and densely forested areas.
Metrification
One example of the neomania of states: the campaign for metrification, that is, the use of the metric system to replace “archaic” ones on grounds
of efficiency—it “makes sense.” The logic might be impeccable (until of course one supersedes it with a better, less naive logic, an attempt I will make here). Let us look at the wedge between rationalism and empiricism in this effort.
Warwick Cairns, a fellow similar to Jane Jacobs, has been fighting in courts to let market farmers in Britain keep selling bananas by the pound, and similar matters as they have resisted the use of the more “rational” kilogram. The idea of metrification was born out of the French Revolution, as part of the utopian mood, which includes changing the names of the winter months to
Nivôse, Pluviôse, Ventôse
, descriptive of weather, having decimal time, ten-day weeks, and similar naively rational matters. Luckily the project of changing time has failed. However, after repeated failures, the metric system was implemented there—but the old system has remained refractory in the United States and England. The French writer Edmond About, who visited Greece in 1832, a dozen years after its independence, reports how peasants struggled with the metric system as it was completely unnatural to them and stuck to Ottoman standards instead. (Likewise, the “modernization” of the Arabic alphabet from the easy-to-memorize old Semitic sequence made to sound like words, ABJAD, HAWWAZ, to the logical sequence A-B-T-TH has created a generation of Arabic speakers without the ability to recite their alphabet.)
But few realize that naturally born weights have a logic to them: we use feet, miles, pounds, inches, furlongs, stones (in Britain) because these are remarkably intuitive and we can use them with a minimal expenditure of cognitive effort—and all cultures seem to have similar measurements with some physical correspondence to the everyday. A meter does not match anything; a foot does. I can imagine the meaning of “thirty feet” with minimal effort. A mile, from the Latin
milia passum,
is a thousand paces. Likewise a stone (14 pounds) corresponds to … well, a stone. An inch (or
pouce
) corresponds to a thumb. A furlong is the distance one can sprint before running out of breath. A pound, from
libra,
is what you can imagine holding in your hands. Recall from the story of Thales in
Chapter 12
that we used
thekel
or
shekel:
these mean “weight” in Canaanite-Semitic languages, something with a physical connotation, similar to the pound. There is a certain nonrandomness to how these units came to be in an ancestral environment—and the digital system itself comes from the correspondence to the ten fingers.
As I am writing these lines, no doubt, some European Union official
of the type who eats 200 grams of well-cooked meat with 200 centiliters’ worth of red wine every day for dinner (the optimal quantity for his health benefits) is concocting plans to promote the “efficiency” of the metric system deep into the countryside of the member countries.


================================================================================
CHAPTER/SECTION 100 (Item 103)
================================================================================

TURNING SCIENCE INTO JOURNALISM
So, we can apply criteria of fragility and robustness to the handling of information—the fragile in that context is, like technology, what does not stand the test of time. The best filtering heuristic, therefore, consists in taking into account the age of books and scientific papers. Books that are one year old are usually not worth reading (a very low probability of having the qualities for “surviving”), no matter the hype and how “earth-shattering” they may seem to be. So I follow the Lindy effect as a guide in selecting what to read: books that have been around for ten years will be around for ten more; books that have been around for two millennia should be around for quite a bit of time, and so forth. Many understand this point but do not apply it to academic work, which is, in much of its modern practice, hardly different from journalism (except for the occasional original production). Academic work, because of its attention-seeking orientation, can be easily subjected to Lindy effects: think of the hundreds of thousands of papers that are just noise, in spite of how hyped they were at the time of publication.
The problem in deciding whether a scientific result or a new “innovation” is a breakthrough, that is, the opposite of noise, is that one needs to see all aspects of the idea—and there is always some opacity that time, and only time, can dissipate. Like many people watching cancer research like a hawk, I fell for the following. There was at some point a great deal of excitement about the work of Judah Folkman, who, as we saw in
Chapter 15
, believed that one could cure cancer by choking the blood supply (tumors require nutrition and tend to create new blood vessels, what is called
neovascularization
). The idea looked impeccable on paper, but, about a decade and a half later, it appears that the only significant result we got was completely outside cancer, in the mitigation of macular degeneration.
Likewise, seemingly uninteresting results that go unnoticed, can, years later turn out to be breakthroughs.
So time can act as a cleanser of noise by confining to its dustbins all these overhyped works. Some organizations even turn such scientific
production into a cheap spectator sport, with ranking of the “ten hottest papers” in, say, rectal oncology or some such sub-sub-specialty.
If we replace scientific results with scientists, we often get the same neomaniac hype. There is a disease to grant a prize for a promising scientist “under forty,” a disease that is infecting economics, mathematics, finance, etc. Mathematics is a bit special because the value of its results can be immediately seen—so I skip the criticism. Of the fields I am familiar with, such as literature, finance, and economics, I can pretty much ascertain that the prizes given to those under forty are the best reverse indicator of value (much like the belief—well tested—by traders that companies that get hyped up for their potential and called “best” on the cover of magazines or in books such as
Good to Great
are about to underperform and one can derive an abnormal profit by shorting their stock). The worst effect of these prizes is penalizing those who don’t get them and debasing the field by turning it into an athletic competition.
Should we have a prize, it should be for “over a hundred”: it took close to one hundred and forty years to validate the contribution of one Jules Regnault, who discovered optionality and mapped it mathematically—along with what we dubbed the philosopher’s stone. His work stayed obscure all this time.
Now if you want to be convinced of my point of how noisy science can be, take any elementary textbook you read in high school or college with interest then—in any discipline. Open it to a random chapter, and see if the idea is still relevant. Odds are that it may be boring, but still relevant—or nonboring, and still relevant. It could be the famous 1215 Magna Carta (British history), Caesar’s Gallic wars (Roman history), a historical presentation of the school of Stoics (philosophy), an introduction to quantum mechanics (physics), or the genetic trees of cats and dogs (biology).
Now try to get the proceedings of a random conference about the subject matter concerned that took place five years ago. Odds are it will feel no different from a five-year-old newspaper, perhaps even less interesting. So attending breakthrough conferences might be, statistically speaking, as much a waste of time as buying a mediocre lottery ticket, one with a small payoff. The odds of the paper’s being relevant—and interesting—in five years is no better than one in ten thousand. The fragility of science!
Even the conversation of a high school teacher or that of an unsuccessful college professor is likely to be more worthwhile than the latest
academic paper, less corrupted with neomania. My best conversations in philosophy have been with French lycée teachers who love the topic but are not interested in pursuing a career writing papers in it (in France they teach philosophy in the last year of high school). Amateurs in any discipline are the best, if you can connect with them. Unlike dilettantes, career professionals are to knowledge what prostitutes are to love.
Of course you may be lucky enough to hit on a jewel here and there, but in general, at best, conversation with an academic would be like the conversation of plumbers, at the worst that of a concierge bandying the worst brand of gossip: gossip about uninteresting people (other academics), small talk. True, the conversation of top scientists can sometimes be captivating, those people who aggregate knowledge and for whom cruising the subject is effortless as the entire small parts of the field come glued together. But these people are just currently too rare on this planet.
I complete this section with the following anecdote. One of my students (who was majoring in, of all subjects, economics) asked me for a rule on what to read. “As little as feasible from the last twenty years, except history books that are not about the last fifty years,” I blurted out, with irritation as I hate such questions as “what’s the best book you’ve ever read,” or “what are the ten best books,”—my “ten best books ever” change at the end of every summer. Also, I have been hyping Daniel Kahneman’s recent book, because it is largely an exposition of his research of thirty-five and forty years ago, with filtering and modernization. My recommendation seemed impractical, but, after a while, the student developed a culture in original texts such as Adam Smith, Karl Marx, and Hayek, texts he believes he will cite at the age of eighty. He told me that after his detoxification, he realized that all his peers do is read
timely
material that becomes instantly obsolete.


================================================================================
CHAPTER/SECTION 101 (Item 104)
================================================================================

WHAT SHOULD BREAK
In 2010,
The Economist
magazine asked me to partake in an exercise imagining the world in 2036. As they were aware of my reticence concerning forecasters, their intention was to bring a critical “balance” and use me as a counter to the numerous imaginative forecasts, hoping for my usual angry, dismissive, and irascible philippic.
Quite surprised they were when, after a two-hour (slow) walk, I wrote a series of forecasts at one go and sent them the text. They probably thought at first that I was pulling a prank on them, or that someone
got the wrong email and was impersonating me. Outlining the reasoning on fragility and asymmetry (concavity to errors), I explained that I would expect the future to be populated with wall-to-wall bookshelves, the device called the telephone, artisans, and such, using the notion that most technologies that are now twenty-five years old should be around in another twenty-five years—once again, most, not all.
7
But the fragile should disappear, or be weakened. Now, what is fragile? The large, optimized, overreliant on technology, overreliant on the so-called scientific method instead of age-tested heuristics. Corporations that are large today should be gone, as they have always been weakened by what they think is their strength: size, which is the enemy of corporations as it causes disproportionate fragility to Black Swans. City-states and small corporations are more likely to be around, even thrive. The nation-state, the currency-printing central bank, these things called economics departments, may stay nominally, but they will have their powers severely eroded. In other words, what we saw in the left column of the Triad should be gone—alas to be replaced by other fragile items.


================================================================================
CHAPTER/SECTION 102 (Item 105)
================================================================================

PROPHETS AND THE PRESENT
By issuing warnings based on vulnerability—that is, subtractive prophecy—we are closer to the original role of the prophet: to warn, not necessarily to predict, and to predict calamities
if people don’t listen
.
The classical role of the prophet, at least in the Levantine sense, is not to look into the future but to talk about the present. He tells people what to do, or, rather, in my opinion, the more robust what
not
to do. In the Near Eastern monotheistic traditions, Judaism, Christianity, and Islam, the major role of the prophets is the protection of monotheism from its idolatrous and pagan enemies that may bring calamities on the straying population. The prophet is someone who is in communication with the unique God, or at least can read his mind—and, what is key, issues warnings to His subjects. The Semitic
nby,
expressed as
Nevi
or
nebi
(in the original Hebrew), the same with minor differences in pronunciation in Aramaic (
nabi’y
) and Arabic (
nabi
), is principally someone connecting with God, expressing what is on God’s mind—the meaning of
nab’
in Arabic is “news” (the original Semitic root in Acadian,
nabu,
meant “to call”). The initial Greek translation,
pro-phetes,
meant “spokesman,” which is retained in Islam, as a dual role for Mohammed the Prophet is that of the Messenger (
rasoul
)—there were some small ranking differences between the roles of spokesman (
nabi
) and messenger (
rasoul
). The job of mere forecasting is rather limited to seers, or the variety of people involved in divination such as the “astrologers” so dismissed by the Koran and the Old Testament. Again, the Canaanites had been too promiscuous in their theologies and various approaches to handling the future, and the prophet is precisely someone who deals only with the One God, not with the future like a mere Baalite.
Nor has the vocation of Levantine prophet been a particularly desirable professional occupation. As I said at the beginning of the chapter, acceptance was far from guaranteed: Jesus, mentioning the fate of Elijah (who warned against Baal, then ironically had to go find solace in Sidon, where Baal was worshipped), announced that
no one becomes a prophet in his own land
. And the prophetic mission was not necessarily voluntary. Consider Jeremiah’s life, laden with
jeremiads
(lamentations), as his unpleasant warnings about destruction and captivity (and their causes) did not make him particularly popular and he was the personification of the notion of “shoot the messenger” and the expression
veritas odium parit—
truth brings hatred. Jeremiah was beaten, punished, persecuted, and the victim of numerous plots, which involved his own brothers. Apocryphal and imaginative accounts even have him stoned to death in Egypt.
Further north of the Semites, in the Greek tradition, we find the same focus on messages, warnings about the present, and the same punishment inflicted on those able to understand things others don’t. For example, Cassandra gets the gift of prophecy, along with the curse of not being believed, when the temple snakes cleaned her ears so she could hear some special messages. Tiresias was made blind and transformed into a woman for revealing the secrets of the gods—but, as a consolation, Athena licked his ears so he could understand secrets in the songs of birds.
Recall the inability we saw in
Chapter 2
to learn from past behavior. The problem with lack of recursion in learning—lack of second-order thinking—is as follows. If those delivering some messages deemed valuable for the long term have been persecuted in past history, one would expect that there would be a correcting mechanism, that intelligent people
would end up learning from such historical experience so those delivering new messages would be greeted with the new understanding in mind. But nothing of the sort takes place.
This lack of recursive thinking applies not just to prophecy, but to other human activities as well: if you believe that what will work and do well is going to be a
new
idea that others did not think of, what we commonly call “innovation,” then you would expect people to pick up on it and have a clearer eye for new ideas without too much reference to the perception of others. But they don’t: something deemed “original” tends to be modeled on something that was new at the time but is no longer new, so being an Einstein for many scientists means solving a similar problem to the one Einstein solved when at the time Einstein was not solving a standard problem at all. The very idea of being an Einstein in physics is no longer original. I’ve detected in the area of risk management the similar error, made by scientists trying to be new in a standard way. People in risk management only consider risky things that have hurt them in the past (given their focus on “evidence”), not realizing that, in the past, before these events took place, these occurrences that hurt them severely were completely without precedent, escaping standards. And my personal efforts to make them step outside their shoes to consider these second-order considerations have failed—as have my efforts to make them aware of the notion of fragility.


================================================================================
CHAPTER/SECTION 103 (Item 106)
================================================================================

EMPEDOCLES’ DOG
In Aristotle’s
Magna Moralia,
there is a possibly apocryphal story about Empedocles, the pre-Socratic philosopher, who was asked why a dog prefers to always sleep on the same tile. His answer was that there had to be some
likeness
between the dog and that tile. (Actually the story might be even twice as apocryphal since we don’t know if
Magna Moralia
was actually written by Aristotle himself.)
Consider the match between the dog and the tile. A natural, biological, explainable or nonexplainable match, confirmed by long series of recurrent frequentation—in place of rationalism, just consider the history of it.
Which brings me to the conclusion of our exercise in prophecy.
I surmise that those human technologies such as writing and reading that have survived are like the tile to the dog, a match between natural friends, because they correspond to something deep in our nature.
Every time I hear someone trying to make a comparison between a book and an e-reader, or something ancient and a new technology, “opinions” pop up, as if reality cared about opinions and narratives. There are secrets to our world that only practice can reveal, and no opinion or analysis will ever capture in full.
This secret property is, of course, revealed through time, and, thankfully, only through time.
What Does Not Make Sense
Let’s take this idea of Empedocles’ dog a bit further: If something that makes no sense to you (say, religion—if you are an atheist—or some age-old habit or practice called irrational); if that something has been around for a very, very long time, then, irrational or not, you can expect it to stick around much longer, and outlive those who call for its demise.
1
There is anecdotal evidence from barefoot runners and users of “five finger” style athletic shoes—which includes myself—that one’s feet store some memory of the terrain, remembering where they have been in the past.
2
If something does not have a natural upper bound then the distribution of any specified event time is constrained only by fragility.
3
The phrase originates, it seems, with a June 13, 1964, article in
The New Republic,
though the article made the mistake of applying it to perishable items. The author wrote that “the future career expectations of a television comedian is proportional to the total amount of his past exposure on the medium.” This would work for a young comedian, not an older one (comedians are, alas, perishable items). But technologies and books do not have such constraint.
4
This is where my simplification lies: I am assuming that every year doubles the additional life expectancy. It can actually get better, increase by 2½ or more. So the Lindy effect, says, mathematically, that the nonperishable has a life expectancy that
increases
with every day it survives.
5
Note also that the Lindy effect is invariant to the definition of the technology. You can define a technology as a “convertible car,” a more general “car,” a “bound book,” or a broadly defined “book” (which would include electronic texts); the life expectancy will concern the item as defined.
6
By the same Lindy effect, diseases and conditions that were not known to be diseases a hundred or so years ago are likely to be either (1) diseases of civilization, curable by
via negativa,
or (2) not diseases, just invented conditions. This applies most to psychological “conditions” and buzzwords putting people in silly buckets: “Type A,” “passive aggressive,” etc.
7
I have had the privilege of reading a five-hundred-year-old book, an experience hardly different from that of reading a modern book. Compare such robustness to the lifespan of electronic documents: some of the computer files of my manuscripts that are less than a decade old are now irretrievable.


================================================================================
CHAPTER/SECTION 104 (Item 107)
================================================================================

CHAPTER 21
Medicine, Convexity, and Opacity
What they call nonevidence—Where medicine fragilizes humans, then tries to save them—Newton’s law or evidence?
The history of medicine is the story—largely documented—of the dialectic between doing and thinking—and how to make decisions under opacity. In the medieval Mediterranean, Maimonides, Avicenna, Al-Ruhawi, and the Syriac doctors such as Hunain Ibn Ishaq were at once philosophers and doctors. A doctor in the medieval Semitic world was called Al-Hakim, “the wise,” or “practitioner of wisdom,” a synonym for philosopher or rabbi (
hkm
is the Semitic root for “wisdom”). Even in the earlier period there was a crop of Hellenized fellows who stood in the exact middle between medicine and the practice of philosophy—the great skeptic philosopher Sextus Empiricus was himself a doctor member of the skeptical empirical school. So were Menodotus of Nicomedia and the experience-based predecessor of evidence-based medicine—on whom a bit more in a few pages. The works of these thinkers, or whatever remains extant are quite refreshing for those of us who distrust those who talk without doing.
Simple, quite simple decision rules and heuristics emerge from this chapter.
Via negativa,
of course (by removal of the unnatural): only resort to medical techniques when the health payoff is very large (say, saving a life) and visibly exceeds its potential harm, such as incontrovertibly
needed surgery or lifesaving medicine (penicillin). It is the same as with government intervention. This is squarely Thalesian, not Aristotelian (that is, decision making based on payoffs, not knowledge). For in these cases medicine has positive asymmetries—convexity effects—and the outcome will be less likely to produce fragility. Otherwise, in situations in which the benefits of a particular medicine, procedure, or nutritional or lifestyle modification appear small—say, those aiming for comfort—we have a large potential sucker problem (hence putting us on the wrong side of convexity effects). Actually, one of the unintended side benefits of the theorems that Raphael Douady and I developed in our paper mapping risk detection techniques (in
Chapter 19
) is an exact link between (a) nonlinearity in exposure or dose-response and (b) potential fragility or antifragility.
I also extend the problem to epistemological grounds and make rules for
what should be considered evidence:
as with whether a cup should be considered half-empty or half-full, there are situations in which we focus on
absence
of evidence, others in which we focus on evidence. In some cases one can be confirmatory, not others—it depends on the risks. Take smoking, which was, at some stage, viewed as bringing small gains in pleasure and even health (truly, people thought it was a good thing). It took decades for its harm to become visible. Yet had someone questioned it, he would have faced the canned-naive-academized and faux-expert response “do you have
evidence
that this is harmful?” (the same type of response as “is there evidence that polluting is harmful?”). As usual, the solution is simple, an extension of
via negativa
and Fat Tony’s
don’t-be-a-sucker
rule: the non-natural needs to prove its benefits, not the natural—according to the statistical principle outlined earlier that nature is to be considered much less of a sucker than humans. In a complex domain, only time—a long time—is evidence.
For any decision, the unknown will preponderate on one side more than the other.
The “do you have evidence” fallacy, mistaking evidence of no harm for no evidence of harm, is similar to the one of misinterpreting NED (no evidence of disease) for evidence of no disease. This is the same error as mistaking absence of evidence for evidence of absence, the one that tends to affect smart and educated people, as if education made people more confirmatory in their responses and more liable to fall into simple logical errors.
And recall that under nonlinearities, the simple statements “harmful” or “beneficial” break down: it is all in the dosage.


================================================================================
CHAPTER/SECTION 105 (Item 108)
================================================================================

HOW TO ARGUE IN AN EMERGENCY ROOM
I once broke my nose … walking. For the sake of antifragility, of course. I was trying to walk on uneven surfaces, as part of my antifragility program, under the influence of Erwan Le Corre, who believes in naturalistic exercise. It was exhilarating; I felt the world was richer, more fractal, and when I contrasted this terrain with the smooth surfaces of sidewalks and corporate offices, those felt like prisons. Unfortunately, I was carrying something much less ancestral, a cellular phone, which had the insolence to ring in the middle of my walk.
In the emergency room, the doctor and staff insisted that I should “ice” my nose, meaning apply an ice-cold patch to it. In the middle of the pain, it hit me that the swelling that Mother Nature gave me was most certainly not directly caused by the trauma. It was my own body’s response to the injury. It seemed to me that it was an insult to Mother Nature to override her programmed reactions unless we had a good reason to do so, backed by proper empirical testing to show that we humans can do better; the burden of evidence falls on us humans. So I mumbled to the emergency room doctor whether he had any statistical evidence of benefits from applying ice to my nose or if it resulted from a naive version of an
interventionism
.
His response was: “You have a nose the size of Cleveland and you are now interested in … numbers?” I recall developing from his blurry remarks the thought that he had no answer.
Effectively, he had no answer, because as soon as I got to a computer, I was able to confirm that there is no compelling empirical evidence in favor of the reduction of swelling. At least, not outside of the very rare cases in which the swelling would threaten the patient, which was clearly not the case. It was pure sucker-rationalism in the mind of doctors, following what made sense to boundedly intelligent humans, coupled with interventionism, this need to
do something,
this defect of thinking that we knew better, and denigration of the unobserved. This defect is not limited to our control of swelling: this confabulation plagues the entire history of medicine, along with, of course, many other fields of practice. The researchers Paul Meehl and Robin Dawes pioneered a tradition to catalog the tension between “clinical” and actuarial (that is, statistical)
knowledge, and examine how many things believed to be true by professionals and clinicians aren’t so and don’t match empirical evidence. The problem is of course that these researchers did not have a clear idea of where the burden of empirical evidence lies (the difference between naive or pseudo empiricism and rigorous empiricism)—the onus is on the doctors to show us why reducing fever is good, why eating breakfast before engaging in activity is healthy (there is no evidence), or why bleeding patients is the best alternative (they’ve stopped doing so). Sometimes I get the answer that they have no clue when they have to utter defensively “I am a doctor” or “are you a doctor?” But worst, I sometimes get some letters of support and sympathy from the alternative medicine fellows, which makes me go postal: the approach in this book is ultra-orthodox, ultra-rigorous, and ultra-scientific, certainly not in favor of alternative medicine.
The hidden costs of health care are largely in the denial of antifragility. But it may not be just medicine—what we call diseases of civilization result from the attempt by humans to make life comfortable for ourselves against our own interest, since the comfortable is what fragilizes. The rest of this chapter focuses on specific medical cases with hidden negative convexity effects (small gains, large losses)—and reframes the ideas of iatrogenics in connection with my notion of fragility and nonlinearities.


================================================================================
CHAPTER/SECTION 106 (Item 109)
================================================================================

FIRST PRINCIPLE OF IATROGENICS (EMPIRICISM)
The first principle of iatrogenics is as follows: we do not need
evidence of harm
to claim that a drug or an unnatural
via positiva
procedure is dangerous. Recall my comment earlier with the turkey problem that harm is in the future, not in the narrowly defined past. In other words, empiricism is not naive empiricism.
We saw the smoking argument. Now consider the adventure of a human-invented fat, trans fat. Somehow, humans discovered how to make fat products and, as it was the great era of scientism, they were convinced they could make it
better
than nature. Not just equal; better. Chemists assumed that they could produce a fat replacement that was superior to lard or butter from so many standpoints. First, it was more convenient: synthetic products such as margarine stay soft in the refrigerator, so you can immediately spread them on a piece of bread without
the usual wait while listening to the radio. Second, it was economical, as the synthetic fats were derived from vegetables. Finally, what is worst, trans fat was assumed to be healthier. Its use propagated very widely and after a few hundred million years of consumption of animal fat, people suddenly started getting scared of it (particularly something called “saturated” fat), mainly from shoddy statistical interpretations. Today trans fat is widely banned as it turned out that it kills people, as it is behind heart disease and cardiovascular problems.
For another murderous example of such sucker (and fragilizing) rationalism, consider the story of Thalidomide. It was a drug meant to reduce the nausea episodes of pregnant women. It led to birth defects. Another drug, Diethylstilbestrol, silently harmed the fetus and led to delayed gynecological cancer among daughters.
These two mistakes are quite telling because, in both cases, the benefits appeared to be obvious and immediate, though small, and the harm remained delayed for years, at least three-quarters of a generation. The next discussion will be about the burden of evidence, as you can easily imagine that someone defending these treatments would have immediately raised the objection, “Monsieur Taleb, do you have
evidence
for your statement?”
Now we can see the pattern: iatrogenics, being a cost-benefit situation, usually results from the treacherous condition in which the benefits are small, and visible—and the costs very large, delayed, and hidden. And of course, the potential costs are much worse than the cumulative gains.
For those into graphs, the appendix shows the potential risks from different angles and expresses iatrogenics as a probability distribution.


================================================================================
CHAPTER/SECTION 107 (Item 110)
================================================================================

SECOND PRINCIPLE OF IATROGENICS (NONLINEARITY IN RESPONSE)
Second principle of iatrogenics: it is not linear. We should not take risks with near-healthy people; but we should take a lot, a lot more risks with those deemed in danger.
1
Why do we need to focus treatment on more serious cases, not marginal
ones? Take this example showing nonlinearity (convexity). When hypertension is mild, say marginally higher than the zone accepted as “normotensive,” the chance of benefiting from a certain drug is close to 5.6 percent (only one person in eighteen benefit from the treatment). But when blood pressure is considered to be in the “high” or “severe” range, the chances of benefiting are now 26 and 72 percent, respectively (that is, one person in four and two persons out of three will benefit from the treatment). So the treatment benefits are convex to condition (the benefits rise disproportionally, in an accelerated manner). But consider that the iatrogenics should be constant for all categories! In the very ill condition, the benefits are large relative to iatrogenics; in the borderline one, they are small. This means that we need to focus on high-symptom conditions and ignore, I mean really ignore, other situations in which the patient is not very ill.
The argument here is based on the structure of conditional survival probabilities, similar to the one that we used to prove that harm needs to be nonlinear for porcelain cups. Consider that Mother Nature had to have tinkered through selection in inverse proportion to the rarity of the condition. Of the hundred and twenty thousand drugs available today, I can hardly find a
via positiva
one that makes a healthy person unconditionally “better” (and if someone shows me one, I will be skeptical of yet-unseen side effects). Once in a while we come up with drugs that enhance performance, such as, say, steroids, only to discover what people in finance have known for a while: in a “mature” market there is no free lunch anymore, and what appears as a free lunch has a hidden risk. When you think you have found a free lunch, say, steroids or trans fat, something that helps the healthy without visible downside, it is most likely that there is a concealed trap somewhere. Actually, my days in trading, it was called a “sucker’s trade.”
And there is a simple statistical reason that explains why we have not been able to find drugs that make us feel unconditionally better when we are well (or unconditionally stronger, etc.): nature would have been likely to find this magic pill by itself. But consider that illness is rare, and the more ill the person the less likely nature would have found the solution by itself, in an accelerating way. A condition that is, say, three units of deviation away from the norm is more than three hundred times rarer than normal; an illness that is five units of deviation from the norm is more than a million times rarer!
The medical community has not modeled such nonlinearity of benefits
to iatrogenics, and if they do so in words, I have not seen it in formalized in papers, hence into a decision-making methodology that takes probability into account (as we will see in the next section, there is little explicit use of convexity biases). Even risks seem to be linearly extrapolated, causing both underestimation and overestimation, most certainly miscalculation of degrees of harm—for instance, a paper on the effect of radiation states the following: “The standard model currently in use applies a linear scale, extrapolating cancer risk from high doses to low doses of ionizing radiation.” Further, pharmaceutical companies are under financial pressures to find diseases and satisfy the security analysts. They have been scraping the bottom of the barrel, looking for disease among healthier and healthier people, lobbying for reclassifications of conditions, and fine-tuning sales tricks to get doctors to overprescribe. Now, if your blood pressure is in the upper part of the range that used to be called “normal,” you are no longer “normotensive” but “pre-hypertensive,” even if there are no symptoms in view. There is nothing wrong with the classification if it leads to healthier lifestyle and robust
via negativa
measures—but what is behind such classification, often, is a drive for more medication.
I am not against the function and mission of pharma, rather, its business practice: they should focus
for their own benefit
on extreme diseases, not on reclassifications or pressuring doctors to prescribe medicines. Indeed, pharma plays on the interventionism of doctors.
Another way to view it: the iatrogenics is in the patient, not in the treatment. If the patient is close to death, all speculative treatments should be encouraged—no holds barred. Conversely, if the patient is near healthy, then Mother Nature should be the doctor.
Jensen’s Inequality in Medicine
The philosopher’s stone explained that the volatility of an exposure can matter more than its average—the difference is the “convexity bias.” If you are antifragile (i.e., convex) to a given substance, then you are better off having it randomly distributed, rather than provided steadily.
I’ve found very few medical papers making use of nonlinearity by applying convexity effects to medical problems, in spite of the ubiquity of nonlinear responses in biology. (I am being generous; I actually found only one explicit use of Jensen’s inequality in one single application—
thanks to my friend Eric Briys—and only one that used it properly, so the response “we know that” by medical researchers when the consequence nonlinearity is explained to them is rather lame.)
Remarkably, convexity effects work in an identical way with options, innovations, anything convex. Now let us apply it … to lungs.
The next paragraph is a bit technical and can be skipped.
People with a variety of lung diseases, including acute respiratory distress syndrome, used to be put on mechanical ventilators. The belief was that constant pressure and volume were desirable—steadiness seemed a good idea. But the reaction of the patient is nonlinear to the pressure (convex over an initial range, then concave above it), and he suffers from such regularity. Further, people with very sick lungs cannot take high pressure for a long time—while they need a lot of volume. J. F. Brewster and his associates figured out that dispensing higher pressure on occasion, and low pressure at other times, allowed them to provide a lot more volume to the lungs for a given mean pressure and thus decrease patient mortality. An additional benefit is that an occasional spike in pressure helps to open up collapsed alveoli. Actually, that’s how our lungs function when healthy: with variations and “noise” rather than steady airflow. Humans are antifragile to lung pressure. And this arises directly from the nonlinearity of the response since as we saw everything convex is antifragile, up to a certain dosage. Brewster’s paper went through empirical validation, but this is not even necessary: you don’t need empirical data to prove that one plus one equals two, or that probabilities need to add up to 100 percent.
2
It does not look as though people who deal with nutrition have examined the difference between random calories and steady nutrition, something to which we will return in the next chapter.
Not using models of nonlinear effects such as convexity biases while “doing empirical work” is like having to catalog every apple falling from a tree and call the operation “empiricism” instead of just using Newton’s equation.


================================================================================
CHAPTER/SECTION 108 (Item 111)
================================================================================

BURYING THE EVIDENCE
Now some historical background. What made medicine mislead people for so long is that its successes were prominently displayed, and its mistakes literally buried—just like so many other interesting stories in the cemetery of history.
I cannot resist the following illustration of intervention bias (with negative convexity effects). In the 1940s and 1950s many children and teenagers received radiation for acne, thymus gland enlargement, tonsillitis, to remove birthmarks and treat ringworm of the scalp. In addition to the goiters and other late complications, approximately 7 percent of patients who received this radiation developed thyroid cancer two to four decades later. But let’s not write off radiation, when it comes from Mother Nature. We are necessarily antifragile to some dose of radiation—at naturally found levels. It may be that small doses prevent injuries and cancers coming from larger ones, as the body develops some kind of immunity. And, talking about radiation, few wonder why, after hundreds of million of years of having our skins exposed to sun rays, we suddenly need so much protection from them—is it that our exposure is more harmful than before because of changes in the atmosphere, or populations living in an environment mismatching the pigmentation of their skin—or rather, that makers of sun protection products need to make some profits?
The Never-ending History of Turkey Situations
The list of such attempts to outsmart nature driven by naive rationalism is long—always meant to “improve” things—with continuous first-order learning, that is, banning the offending drug or medical procedure but not figuring out that we could be making the mistake again, elsewhere.
Statins
. Statin drugs are meant to lower cholesterol in your blood. But there is an asymmetry, and a severe one. One needs to treat fifty high risk persons for five years to avoid a single cardiovascular event. Statins can potentially harm people who are not very sick, for whom the benefits are either minimal or totally nonexistent. We will not be able to get an evidence-based picture of the hidden harm in the short term (we need years for that—remember smoking) and, further, the arguments currently made in favor of the routine administration of these drugs often lie in a few statistical illusions or even manipulation (the experiments
used by drug companies seem to play on nonlinearities and bundle the very ill and the less ill, in addition to assuming that the metric “cholesterol” equates 100 percent with health). Statins fail in their application the first principle of iatrogenics (unseen harm); further, they certainly
do
lower cholesterol, but as a human your objective function is not to lower a certain metric to get a grade to pass a school-like test, but get in better health. Further, it is not certain whether these indicators people try to lower are causes or manifestations that correlate to a condition—just as muzzling a baby would certainly prevent him from crying but would not remove the cause of his emotions. Metric-lowering drugs are particularly vicious because of a legal complexity. The doctor has the incentive to prescribe it because should the patient have a heart attack, he would be sued for negligence; but the error in the opposite direction is not penalized at all, as side effects do not appear at all as being caused by the medicine.
The same problem of naive interpretation mixed with intervention bias applies to cancer detection: there is a marked bias in favor of treatment, even when it brings more harm, because the legal system favors intervention.
Surgery
. Historians show that surgery had, for a long time, a much better track record than medicine; it was checked by the necessary rigor of visible results. Consider that, when operating on victims of very severe trauma, say, to extract a bullet or to push bowels back in their place, the iatrogenics is reduced; the downside of the operation is small compared to the benefits—hence positive convexity effects. Unlike with the usual pharmaceutical interventions, it is hard to say that Mother Nature would have done a better job. The surgeons used to be blue-collar workers, or closer to artisans than high science, so they did not feel too obligated to theorize.
The two professions of medical doctor and surgeon were kept professionally and socially separate, one was an
ars,
the other s
cientia,
hence one was a craft built around experience-driven heuristics and the other reposed on theories, nay, a general theory of humans. Surgeons were there for emergencies. In England, France, and some Italian cities, surgeons’ guilds were merged with those of barbers. So the Soviet-Harvardification of surgery was for a long time constrained by the visibility of the results—you can’t fool the eye. Given that for a long time people operated without anesthetics, one did not have to overly justify
doing nothing
and waiting for Nature to play her role.
But today’s surgery, thanks to anesthesia, is done with a much smaller hurdle—and surgeons now need to attend medical school, albeit a less theoretical one than the Sorbonne or Bologna of the Middle Ages. By contrast, in the past, letting blood (phlebotomy) was one of the few operations performed by surgeons without any disincentive. For instance, back surgery done in modern times to correct sciatica is often useless, minus the possible harm from the operation. Evidence shows that six years later, such an operation is, on average, equivalent to doing nothing, so we have a certain potential deficit from the back operation as every operation brings risks such as brain damage from anesthesia, medical error (the doctor harming the spinal cord), or exposure to hospital germs. Yet spinal cord surgery such as lumbar disc fusion is still practiced liberally, particularly as it is very lucrative for the doctor.
3
Antibiotics.
Every time you take an antibiotic, you help, to some degree, the mutation of germs into antibiotic-resistant strains. Add to that the toying with your immune system. You transfer the antifragility from your body to the germ. The solution, of course, is to do it only when the benefits are large. Hygiene, or excessive hygiene, has the same effect, particularly when people clean their hands with chemicals after every social exposure.
Here are some verified and potential examples of iatrogenics (in terms of larger downside outside of very ill patients, whether such downside has been verified or not)
4
: Vioxx, the anti-inflammatory medicine with delayed heart problems as side effects. Antidepressants (used beyond the necessary cases). Bariatric surgery (in place of starvation of overweight diabetic patients). Cortisone. Disinfectants, cleaning products potentially giving rise to autoimmune diseases. Hormone replacement therapy. Hysterectomies. Cesarean births beyond the strictly necessary. Ear tubes in babies as an immediate response to ear infection. Lobotomies. Iron supplementation. Whitening of rice and wheat—it was considered progress. The sunscreen creams suspected to cause harm.
Hygiene (beyond a certain point, hygiene may make you fragile by denying hormesis—our own antifragility). We ingest probiotics because we don’t eat enough “dirt” anymore. Lysol and other disinfectants killing so many “germs” that kids’ developing immune systems are robbed of necessary workout (or robbed of the “good” friendly germs and parasites). Dental hygiene: I wonder if brushing our teeth with toothpaste full of chemical substances is not mostly to generate profits for the toothpaste industry—the brush is natural, the toothpaste might just be to counter the abnormal products we consume, such as starches, sugars and high fructose corn syrup. Speaking of which, high fructose corn syrup was the result of neomania, financed by a Nixon administration in love with technology and victim of some urge to subsidize corn farmers. Insulin injections for Type II diabetics, based on the assumption that the harm from diabetes comes from blood sugar, not insulin resistance (or something else associated with it). Soy milk. Cow milk for people of Mediterranean and Asian descent. Heroin, the most dangerously addictive substance one can imagine, was developed as a morphine substitute for cough suppressants that did not have morphine’s addictive side effects. Psychiatry, particularly child psychiatry—but I guess I don’t need to convince anyone about its dangers. I stop here.
Again, my statements here are risk-management-based: if the person is very ill, there are no iatrogenics to worry about. So it is the marginal case that brings dangers.
The cases I have been discussing so far are easy to understand, but some applications are far more subtle. For instance, counter to “what makes sense” at a primitive level, there is no clear evidence that sugar-free sweetened drinks make you lose weight in accordance with the calories saved. But it took thirty years of confusing the biology of millions of people for us to start asking such questions. Somehow those recommending these drinks are under the impression, driven by the laws of physics (naive translation from thermodynamics), that the concept that we gain weight from calories is sufficient for further analysis. This would be certainly true in thermodynamics, as in a simple machine responding to energy without feedback, say, a car that burns fuel. But the reasoning does not hold in an informational dimension in which food is not just a source of energy; it conveys information about the environment (like stressors). The ingestion of food combined with one’s activity brings about hormonal cascades (or something similar that conveys information), causing cravings (hence consumption of other foods) or changes in
the way your body burns the energy, whether it needs to conserve fat and burn muscle, or vice versa. Complex systems have feedback loops, so what you “burn” depends on what you consume, and how you consume it.


================================================================================
CHAPTER/SECTION 109 (Item 112)
================================================================================

NATURE’S OPAQUE LOGIC
At the time of this writing, the biologist Craig Venter is engaging in the creation of artificial life. He conducted experiments and stated them in a famous paper titled “Creation of a Bacterial Cell Controlled by a Chemically Synthesized Genome.” I have an immense respect for Craig Venter, whom I consider one of the smartest men who ever breathed, and a “doer” in the full sense of the word, but giving fallible humans such powers is similar to giving a small child a bunch of explosives.
If I understand this well, to the creationists, this should be an insult to God; but, further, to the evolutionist, this is certainly an insult to evolution. And to the probabilist, like myself and my peers, this is an insult to human prudence, the beginning of the mother of all exposures to Black Swans.
Let me repeat the argument here in one block to make it clearer. Evolution proceeds by undirected, convex bricolage or tinkering, inherently robust, i.e., with the achievement of potential stochastic gains thanks to continuous, repetitive, small, localized mistakes. What men have done with top-down, command-and-control science has been exactly the reverse: interventions with negative convexity effects, i.e., the achievement of small certain gains through exposure to massive potential mistakes. Our record of understanding risks in complex systems (biology, economics, climate) has been pitiful, marred with retrospective distortions (we only understand the risks after the damage takes place, yet we keep making the mistake), and there is nothing to convince me that we have gotten better at risk management. In this particular case, because of the scalability of the errors, you are exposed to the wildest possible form of randomness.
Simply, humans should not be given explosive toys (like atomic bombs, financial derivatives, or tools to create life).
Guilty or Innocent
Let me phrase the last point a bit differently. If there is something in nature you don’t understand, odds are it makes sense in a deeper way that is beyond your understanding. So there is a logic to natural things that is much superior to our own. Just as there is a dichotomy in law:
innocent until proven guilty
as opposed to
guilty until proven innocent,
let me express my rule as follows: what Mother Nature does is rigorous until proven otherwise; what humans and science do is flawed until proven otherwise.
Let us close on this business of b***t “evidence.” If you want to talk about the “statistically significant,” nothing on the planet can be as close to “statistically significant” as nature. This is in deference to her track record and the sheer statistical significance of her massively large experience—the way she has managed to survive Black Swan events. So overriding her requires some very convincing justification on our part, rather than the reverse, as is commonly done, and it is very hard to beat her on statistical grounds—as I wrote in
Chapter 7
in the discussion on procrastination, we can invoke the naturalistic fallacy when it comes to ethics, not when it comes to risk management.
5
Let me repeat violations of logic in the name of “evidence” owing to their gravity. I am not joking: just as I face the shocking request “Do you have evidence?” when I question a given unnatural treatment, such as icing one’s swollen nose, in the past, many faced the question “Do you have evidence that trans fat is harmful?” and needed to produce proofs—which they were obviously unable to do because it took decades before the harm became apparent. These questions are offered more often than not by smart people, even doctors. So when the (present) inhabitants of Mother Earth want to do something counter to nature, they are the ones that need to produce the evidence, if they can.
Everything nonstable or breakable has had ample chance to break over time. Further, the interactions between components of Mother Nature had to modulate in such a way as to keep the overall system alive. What emerges over millions of years is a wonderful combination of solidity,
antifragility, and local fragility, sacrifices in one area made in order for nature to function better. We sacrifice ourselves in favor of our genes, trading our fragility for their survival. We age, but they stay young and get fitter and fitter outside us. Things break on a small scale all the time, in order to avoid large-scale generalized catastrophes.
Plead Ignorance of Biology: Phenomenology
I have explained that phenomenology is more potent than theories—and should lead to more rigorous policy making. Let me illustrate here.
I was in a gym in Barcelona next to the senior partner of a consulting firm, a profession grounded in building narratives and naive rationalization. Like many people who have lost weight, the fellow was eager to talk about it—it is easier to talk about weight loss theories than to stick to them. The fellow told me that he did not believe in such diets as the low-carbohydrate Atkins or Dukan diet, until he was told of the mechanism of “insulin,” which convinced him to embark on the regimen. He then lost thirty pounds—he had to wait for a theory before taking any action. That was in spite of the empirical evidence showing people losing one hundred pounds by avoiding carbohydrates, without changing their total food intake—just the composition! Now, being the exact opposite of the consultant, I believe that “insulin” as a cause is a fragile theory but that the phenomenology, the empirical effect, is real. Let me introduce the ideas of the postclassical school of the skeptical empiricists.
We are built to be dupes for theories. But theories come and go; experience stays. Explanations change all the time, and have changed all the time in history (because of causal opacity, the invisibility of causes) with people involved in the incremental development of ideas thinking they always had a definitive theory; experience remains constant.
As we saw in
Chapter 7
, what physicists call the phenomenology of the process is the empirical manifestation, without looking at how it glues to existing general theories. Take for instance the following statement, entirely evidence-based:
if you build muscle, you can eat more without getting more fat deposits in your belly
and can gorge on lamb chops without having to buy a new belt. Now in the past the theory to rationalize it was “Your metabolism is higher because muscles burn calories.” Currently I tend to hear “You become more insulin-sensitive and store less fat.” Insulin, shminsulin; metabolism, shmetabolism: another
theory will emerge in the future and some other substance will come about, but the exact same effect will continue to prevail.
The same holds for the statement
Lifting weights increases your muscle mass
. In the past they used to say that weight lifting caused the “micro-tearing of muscles,” with subsequent healing and increase in size. Today some people discuss hormonal signaling or genetic mechanisms, tomorrow they will discuss something else. But the effect has held forever and will continue to do so.
When it comes to narratives, the brain seems to be the last province of the theoretician-charlatan. Add
neurosomething
to a field, and suddenly it rises in respectability and becomes more convincing as people now have the illusion of a strong causal link—yet the brain is too complex for that; it is both the most complex part of the human anatomy and the one that seems most susceptible to sucker-causation. Christopher Chabris and Daniel Simons brought to my attention the evidence I had been looking for: whatever theory has a reference in it to brain circuitry seems more “scientific” and more convincing, even when it is just randomized psychoneurobabble.
But this causation is highly rooted in orthodox medicine as it was traditionally built. Avicenna in his
Canon
(which in Arabic means law): “We must know the causes of health and illness if we wish to make [medicine] a
scientia
.”
I am writing about health, but I do not want to rely on biology beyond the minimum required (not in the theoretical sense)—and I believe that my strength will lie there. I just want to understand as little as possible to be able to look at regularities of experience.
So the
modus operandi
in every venture is to remain as robust as possible to changes in theories (let me repeat that my deference to Mother Nature is entirely statistical and risk-management-based, i.e., again, grounded in the notion of fragility). The doctor and medical essayist James Le Fanu showed how our understanding of the biological processes was coupled with a decline of pharmaceutical discoveries, as if rationalistic theories were blinding and somehow a handicap.
In other words, we have in biology a green lumber problem!
Now, a bit of history of ancient and medieval medicine. Traditionally, medicine used to be split into three traditions: rationalists (based on preset theories, the need of global understanding of what things were made
for
), skeptical empiricists (who refused theories and were skeptical
of ideas making claims about the unseen), and methodists (who taught each other some simple medical heuristics stripped of theories and found an even more practical way to be empiricists). While differences can be overplayed by the categorization, one can look at the three traditions not as entirely dogmatic approaches, but rather ones varying in their starting point, the weight of the prior beliefs: some start with theories, others with evidence.
Tensions among the three tendencies have always existed over time—and I put myself squarely in the camp attempting to vindicate the empiricists, who, as a philosophical school, were swallowed by late antiquity. I have been trying to bring alive these ideas of Aenesidemus of Knossos, Antiochus of Laodicea, Menodotus of Nicomedia, Herodotus of Tarsus, and of course Sextus Empiricus. The empiricists insisted on the “I did not know” while facing situations
not exactly seen
in the past, that is, in nearly identical conditions. The methodists did not have the same strictures against analogy, but were still careful.
The Ancients Were More Caustic
This problem of iatrogenics is not new—and doctors have been traditionally the butt of jokes.
Martial in his epigrams gives us an idea of the perceived expert problem in medicine in his time: “I thought that Diaulus was a doctor, not a caretaker—but for him it appears to be the same job” (
Nuper erat medicus, nunc est uispillo Diaulus: quod uispillo facit, fecerat et medicus
) or “I did not feel ill, Symmache; now I do (after your ministrations).” (
Non habui febrem, Symmache, nunc habeo
).
The Greek term
pharmakon
is ambiguous, as it can mean both “poison” and “cure” and has been used as a pun to warn against iatrogenics by the Arab doctor Ruhawi.
An
attribution problem
arises when the person imputes his positive results to his own skills and his failures to luck. Nicocles, as early as the fourth century
B.C.
, asserts that doctors claimed responsibility for success and blamed failure on nature, or on some external cause. The very same idea was rediscovered by psychologists some twenty-four centuries later, and applied to stockbrokers, doctors, and managers of companies.
According to an ancient anecdote, the Emperor Hadrian continually exclaimed, as he was dying, that it was his doctors who had killed him.
Montaigne, mostly a synthesizer of classical writers, has his
Essays
replete with anecdotes: A Lacedaemonian was asked what had made him live so long; he answered, “Ignoring medicine.” Montaigne also detected the agency problem, or why the last thing a doctor needs is for you to be healthy: “No doctor derives pleasure from the health of his friends, wrote the ancient Greek satirist, no soldier from the peace of his city, etc.”
(Nul médecin ne prent plaisir à la santé de ses amis mesmes, dit l’ancien Comique Grec, ny soldat à la paix de sa ville: ainsi du reste.)
How to Medicate Half the Population
Recall how a personal doctor can kill you.
We saw in the story of the grandmother our inability to distinguish in our logical reasoning (though not in intuitive actions) between average and other, richer properties of what we observe.
I was once attending a lunch party at the country house of a friend when someone produced a handheld blood pressure measuring tool. Tempted, I measured my arterial pressure, and it turned out to be slightly higher than average. A doctor, who was part of the party and had a very friendly disposition, immediately pulled out a piece of paper prescribing some medication to lower it—which I later threw in the garbage can. I subsequently bought the same measuring tool and discovered that my blood pressure was much lower (hence better) than average, except once in a while, when it peaked episodically. In short, it exhibits some variability. Like everything in life.
This random variability is often mistaken for information, hence leading to intervention. Let us play a thought experiment, without making any assumption on the link between blood pressure and health. Further, assume that “normal” pressure is a certain, known number. Take a cohort of healthy persons. Suppose that because of randomness, half the time a given person’s pressure will be above that number, and half the time, for the same person, the measurement will be below. So on about half the doctor’s visits they will show the alarming “above normal.” If the doctor automatically prescribes medication on the days the patients are above normal, then half the
normal
population will be on medication. And note that we are quite certain that their life expectancy will be reduced by unnecessary treatments. Clearly I am simplifying here; sophisticated doctors are aware of the variable nature of the measurements and do not prescribe medication when the numbers are not compelling (though it is easy to fall into the trap, and not all doctors are sophisticated).
But the thought experiment can show how frequent visits to the doctor, particularly outside the cases of a life-threatening ailment or an uncomfortable condition—just like frequent access to information—can be harmful. This example also shows us the process outlined in
Chapter 7
by which a personal doctor ends up killing the patient—simply by overreacting to noise.
This is more serious than you think: it seems that medicine has a hard time grasping normal variability in samples—it is hard sometimes to translate the difference between “statistically significant” and “significant” in effect. A certain disease might marginally lower your life expectancy, but it can be deemed to do so with “high statistical significance,” prompting panics when in fact all these studies might be saying is they established
with a significant statistical margin
that in some cases, say, 1 percent of the cases, patients are likely to be harmed by it. Let me rephrase: the magnitude of the result, the importance of the effect, is not captured by what is called “statistical significance,” something that tends to deceive specialists. We need to look in two dimensions: how much a condition, say, blood pressure a certain number of points higher than normal, is likely to affect your life expectancy; and how significant the result is.
Why is this serious? If you think that the statistician really understands “statistical significance” in the complicated texture of real life (the “large world,” as opposed to the “small world” of textbooks), some surprises. Kahneman and Tversky showed that statisticians themselves made practical mistakes in real life in violation of their teachings, forgetting that they were statisticians (thinking, I remind the reader, requires effort). My colleague Daniel Goldstein and I did some research on “quants,” professionals of quantitative finance, and realized that the overwhelming majority did not understand the practical effect of elementary notions such as “variance” or “standard deviation,” concepts they used in about every one of their equations. A recent powerful study by Emre Soyer and Robin Hogarth showed that many professionals and experts in the field of econometrics supplying pompous numbers such as “regression” and “correlation” made egregious mistakes translating into practice the numbers they were producing themselves—they get the equation right but make severe translation mistakes when expressing it into reality. In all cases they underestimate randomness and underestimate the uncertainty in the results. And we are talking about errors of
interpretation
made by the statisticians,
not by the users of statistics such as social scientists and doctors.
Alas, all these biases lead to action, almost never inaction.
In addition, we now know that the craze against fats and the “fat free” slogans result from an elementary mistake in interpreting the results of a regression: when two variables are jointly responsible for an effect (here, carbohydrates and fat), sometimes one of them shows sole responsibility. Many fell into the error of attributing problems under joint consumption of fat and carbohydrates to fat rather than carbohydrates. Further, the great statistician and debunker of statistical misinterpretation David Freedman showed (very convincingly) with a coauthor that the link everyone is obsessing about between salt and blood pressure has no statistical basis. It may exist for some hypertensive people, but it is more likely the exception than the rule.
The “Rigor of Mathematics” in Medicine
For those of us who laugh at the charlatanism hidden behind fictional mathematics in social science, one may wonder why this did not happen to medicine.
And indeed the cemetery of bad ideas (and hidden ideas) shows that mathematics fooled us there. There have been many forgotten attempts to mathematize medicine. There was a period during which medicine derived its explanatory models from the physical sciences. Giovanni Borelli, in
De motu animalium,
compared the body to a machine consisting of animal levers—hence we could apply the rules of linear physics.
Let me repeat: I am not against rationalized learned discourse, provided it is not fragile to error; I am first and last a decision maker hybrid and will never separate the philosopher-probabilist from the decision maker, so I am that joint person all the time, in the morning when I drink the ancient liquid called coffee, at noon when I eat with my friends, and at night when I go to bed clutching a book. What I am against is
naive
rationalized, pseudolearned discourse, with green lumber problems—one that focuses solely on the known and
ignores the unknown
. Nor am I against the use of mathematics when it comes to gauging the importance of the unknown—this is the robust application of mathematics. Actually
the arguments in this chapter and the next are all based on the mathematics of probability—but it is not a rationalistic use of mathematics and much of it allows the detection of blatant inconsistencies between statements about severity of disease and intensity of treatment. On the other hand, the use of mathematics in social science is like interventionism. Those who practice it professionally tend to use it everywhere except where it can be useful.
The only condition for such brand of more sophisticated rationalism: to believe and act as if one does not have the full story—to be sophisticated you need to accept that you are not so.
Next
This chapter has introduced the idea of convexity effects and burden of evidence into medicine and into the assessment of risk of iatrogenics. Next, let us look at more applications of convexity effects and discuss
via negativa
as a rigorous approach to life.
1
A technical comment. This is a straightforward result of convexity effects on the probability distribution of outcomes. By the “inverse barbell effect,” when the gains are small to iatrogenics, uncertainty harms the situation. But by the “barbell effect,” when the gains are large in relation to potential side effects, uncertainty tends to be helpful. An explanation with ample graphs is provided in the Appendix.
2
In other words, the response for, say, 50 percent of a certain dose during one period, followed by 150 percent of the dose in a subsequent period in convex cases, is superior to 100 percent of the dose in both periods. We do not need much empiricism to estimate the convexity bias: by theorem, such bias is a necessary result of convexity.
3
Stuart McGill, an evidence-based scientist who specializes in back conditions, describes the self-healing process as follows: the sciatic nerve, when trapped in too narrow a cavity, causing the common back problem that is thought (by doctors) to be curable only by (lucrative) surgery, produces acid substances that cut through the bone and, over time, carves itself a larger passage. The body does a better job than surgeons.
4
The core point in this chapter and the next is nonlinearity as it links to fragility, and how to make use of it in medical decision making, not specific medical treatments and errors. These examples are just illustrative of things we look at without considering concave responses.
5
A common mistake is to argue that the human body is not perfectly adapted, as if the point had consequences for decision making. This is not the point here; the idea is that nature is computationally more able than humans (and has proven to be so), not that it is perfect. Just look at it as the master of high-dimensional trial and error.


================================================================================
CHAPTER/SECTION 110 (Item 113)
================================================================================

CHAPTER 22
To Live Long, but Not Too Long
Wednesdays and Fridays, plus Lent—How to live forever, according to Nietzsche or others—Or why, when you think about it, not to live longer


================================================================================
CHAPTER/SECTION 111 (Item 114)
================================================================================

LIFE EXPECTANCY AND CONVEXITY
Whenever you question some aspects of medicine—or unconditional technological “progress”—you are invariably and promptly provided the sophistry that “we tend to live longer” than past generations. Note that some make the even sillier argument that a propensity to natural things implies favoring a return to a day of “brutish and short” lives, not realizing it is the exact same argument as saying that eating fresh, noncanned foods implies rejecting civilization, the rule of law, and humanism. So there are a lot of nuances in this life expectancy argument.
Life expectancy has increased (conditional on no nuclear war) because of the combination of many factors: sanitation, penicillin, a drop in crime, life-saving surgery, and of course,
some
medical practitioners operating in severe life-threatening situations. If we live longer, it is thanks to medicine’s benefits in cases that are lethal, in which the condition is severe—hence low iatrogenics, as we saw, the convex cases. So it is a serious error to infer that if we live longer because of medicine, that all medical treatments make us live longer.
Further, to account for the effect of “progress,” we need to deduct of course, from the gains in medical treatment, the costs of the diseases of
civilization (primitive societies are largely free of cardiovascular disease, cancer, dental cavities, economic theories, lounge music, and other modern ailments); advances in lung cancer treatment need to be offset by the effect of smoking. From the research papers, one can estimate that medical practice may have contributed a small number of years to the increase, but again, this depends greatly on the gravity of the disease (cancer doctors certainly provide a positive contribution in advanced—and curable—cases, while interventionistic personal doctors, patently, provide a negative one). We need to take into account the unfortunate fact that iatrogenics, hence medicine, reduces life expectancy in a set—and easy to map—number of cases, the concave ones. We have a few pieces of data from the small number of hospital strikes during which only a small number of operations are conducted (for the most urgent cases), and elective surgery is postponed. Depending on whose side in the debate you join, life expectancy either increases in these cases or, at the least, does not seem to drop. Further, which is significant, many of the elective surgeries are subsequently canceled upon the return to normalcy—evidence of the denigration of Mother Nature’s work by
some
doctors.
Another fooled-by-randomness-style mistake is to think that because life expectancy at birth used to be thirty until the last century, that people lived
just
thirty years. The distribution was massively skewed, with the bulk of the deaths coming from birth and childhood mortality. Conditional life expectancy was high—just consider that ancestral men tended to die of trauma.
1
Perhaps legal enforcement contributed more than doctors to the increase in length of life—so the gains in life expectancy are more societal than from the result of scientific advance.
As a case study, consider mammograms. It has been shown that administering them to women over forty on an annual basis does not lead to an increase in life expectancy (at best; it could even lead to a decrease). While female mortality from breast cancer decreases for the cohort subjected to mammograms, the death
from other causes
increases markedly. We can spot here simple measurable iatrogenics. The doctor, seeing the tumor, cannot avoid doing something harmful, like surgery followed by radiation, chemotherapy, or both—that is, more harmful than the tumor. There is a break-even point that is easily crossed by panicked doctors and patients: treating
the tumor that will not kill you
shortens your life—chemotherapy is toxic. We have built up so much paranoia against cancer, looking at the chain backward, an error of logic called
affirming the consequent
. If all of those dying prematurely from cancer had a malignant tumor, that does not mean that all malignant tumors lead to death from cancer. Most equally intelligent persons do not infer from the fact that all Cretans are liars that all liars are Cretan, or from the condition that all bankers are corrupt that all corrupt people are bankers. Only in extreme cases does nature allow us to make such violations of logic (called
modus ponens
) in order to help us survive. Overreaction is beneficial in an ancestral environment.
2
Misunderstanding of the problems with mammograms has led to overreactions on the part of politicians (another reason to have a society immune from the stupidity of lawmakers by decentralization of important decisions). One politician of the primitive kind, Hillary Clinton, went so far as to claim that critics of the usefulness of mammograms were killing women.
We can generalize the mammogram problem to unconditional laboratory tests, finding deviations from the norm, and acting to “cure” them.
Subtraction Adds to Your Life
Now I speculate the following, having looked closely at data with my friend Spyros Makridakis, a statistician and decision scientist who we introduced a few chapters ago as the first to find flaws in statistical forecasting methods. We estimated that cutting medical expenditures by a certain amount (while limiting the cuts to elective surgeries and treatments) would extend people’s lives in most rich countries, especially the United States. Why? Simple basic convexity analysis; a simple examination
of conditional iatrogenics: the error of treating the mildly ill puts them in a concave position. And it looks as if we know very well how to do this. Just raise the hurdle of medical intervention in favor of cases that are most severe, for which the iatrogenics effect is very small. It may even be better to increase expenditures on these and reduce the one on elective ones.
In other words, reason backward, starting from the iatrogenics to the cure, rather than the other way around. Whenever possible, replace the doctor with human antifragility. But otherwise don’t be shy with aggressive treatments.
Another application of
via negativa:
spend less, live longer is a subtractive strategy. We saw that iatrogenics comes from the intervention bias,
via positiva,
the propensity to want to
do something,
causing all the problems we’ve discussed. But let’s do some
via negativa
here: removing things can be quite a potent (and, empirically, a more rigorous) action.
Why? Subtraction of a substance not seasoned by our evolutionary history reduces the possibility of Black Swans while leaving one open to improvements. Should the improvements occur, we can be pretty comfortable that they are as free of unseen side effects as one can get.
So there are many hidden jewels in
via negativa
applied to medicine. For instance, telling people
not
to smoke seems to be the greatest medical contribution of the last sixty years. Druin Burch, in
Taking the Medicine,
writes: “The harmful effects of smoking are roughly equivalent to the combined good ones of
every
medical intervention developed since the war.… Getting rid of smoking provides more benefit than being able to cure people of every possible type of cancer.”
As usual, the ancients. As Ennius wrote, “The good is mostly in the absence of bad”;
Nimium boni est, cui nihil est mali.
Likewise, happiness is best dealt with as a negative concept; the same nonlinearity applies. Modern happiness researchers (who usually look quite unhappy), often psychologists turned economists (or vice versa), do not use nonlinearities and convexity effects when they lecture us about happiness as if we knew what it was and whether that’s what we should be after. Instead, they should be lecturing us about unhappiness (I speculate that just as those who lecture on happiness look unhappy, those who lecture on unhappiness would look happy); the “pursuit of happiness” is not equivalent to the “avoidance of unhappiness.” Each of
us certainly knows not only what makes us unhappy (for instance, copy editors, commuting, bad odors, pain, the sight of a certain magazine in a waiting room, etc.), but what to do about it.
Let us probe the wisdom of the ages. “Sometimes scantiness of nourishment restores the system,” wrote Plotinus—and the ancients believed in purges (one manifestation of which was the oft-harmful, though often beneficial, routine of bloodletting). The regimen of the Salerno School of Medicine: joyful mood, rest, and scant nourishment.
Si tibi deficiant medici, medici tibi fiant haec tria: mens laeta, requies, moderata diaeta.
There is a seemingly apocryphal (but nevertheless interesting) story about Pomponius Atticus, famous for being Cicero’s relative and epistolary recipient. Being ill, incurably ill, he tried to put an end to both his life and his suffering by abstinence, and only succeeded in ending the latter, as, according to Montaigne, his health was restored. But I am citing the story in spite of its apocryphal nature simply because, from a scientific perspective, it seems that the only way we may manage to extend people’s lives is through caloric restriction—which seems to cure many ailments in humans and extend lives in laboratory animals. But, as we will see in the next section, such restriction does not need to be permanent—just an occasional (but painful) fast might do.
We know we can cure many cases of diabetes by putting people on a very strict starvation-style diet, shocking their system—in fact the mechanism had to have been known heuristically for a long time since there are institutes and sanatoria for curative starvation in Siberia.
It has been shown that many people benefit from the removal of products that did not exist in their ancestral habitat: sugars and other carbohydrates in unnatural format, wheat products (those with celiac disease, but almost all of us are somewhat ill-adapted to this new addition to the human diet), milk and other cow products (for those of non–Northern European origin who did not develop lactose tolerance), sodas (both diet and regular), wine (for those of Asian origin who do not have the history of exposure), vitamin pills, food supplements, the family doctor, headache medicine and other painkillers. Reliance on painkillers encourages people to avoid addressing the cause of the headache with trial and error, which can be sleep deprivation, tension in the neck, or bad stressors—it allows them to keep destroying themselves in a
Procrustean-bed-style life. But one does not have to go far, just start removing the medications that your doctor gave you, or, preferably, remove your doctor—as Oliver Wendell Holmes Sr. put it, “if all the medications were dumped in the sea, it would be better for mankind but worse for the fishes.” My father, an oncologist (who also did research in anthropology) raised me under that maxim (alas, while not completely following it in practice; he cited it enough, though).
I, for my part, resist eating fruits not found in the ancient Eastern Mediterranean (I use “I” here in order to show that I am not narrowly generalizing to the rest of humanity). I avoid any fruit that does not have an ancient Greek or Hebrew name, such as mangoes, papayas, even oranges. Oranges seem to be the postmedieval equivalent of candy; they did not exist in the ancient Mediterranean. Apparently, the Portuguese found a sweet citrus tree in Goa or elsewhere and started breeding it for sweeter and sweeter fruits, like a modern confectionary company. Even the apples we see in the stores are to be regarded with some suspicion: original apples were devoid of sweet taste and fruit corporations bred them for maximal sweetness—the mountain apples of my childhood were acid, bitter, crunchy, and much smaller than the shiny variety in U.S. stores said to keep the doctor away.
As to liquid, my rule is drink no liquid that is not at least a thousand years old—so its fitness has been tested. I drink just wine, water, and coffee. No soft drinks. Perhaps the most possibly deceitfully noxious drink is the orange juice we make poor innocent people imbibe at the breakfast table while, thanks to marketing, we convince them it is “healthy.” (Aside from the point that the citrus our ancestors ingested was not sweet, they never ingested carbohydrates without large, very large quantities of fiber. Eating an orange or an apple is not biologically equivalent to drinking orange or apple juice.) From such examples, I derived the rule that what is called “healthy” is generally unhealthy, just as “social” networks are antisocial, and the “knowledge”-based economy is typically ignorant.
I would add that, in my own experience, a considerable jump in my personal health has been achieved by removing offensive irritants: the morning newspapers (the mere mention of the names of the fragilista journalists Thomas Friedman or Paul Krugman can lead to explosive bouts of unrequited anger on my part), the boss, the daily commute, air-conditioning (though not heating), television, emails from documentary
filmmakers, economic forecasts, news about the stock market, gym “strength training” machines, and many more.
3
The Iatrogenics of Money
To understand the outright denial of antifragility in the way we seek wealth, consider that construction laborers seem happier with a ham and cheese baguette than businessmen with a Michelin three-star meal. Food tastes so much better after exertion. The Romans had a strange relation to wealth: anything that “softens” or “mollifies” was seen negatively. Their reputation for decadence is a bit overdone—history likes the lurid; they disliked comfort and understood its side effects. The same with the Semites, split between desert tribes and city dwellers, with city dwellers harboring a certain cross-generational nostalgia for their roots and their original culture; so there is the culture of the desert, full of poetry, chivalry, contemplation, rough episodes, and frugality, plotted against the cities’ comfort, which is associated with physical and moral decay, gossip, and decadence. The city dweller repairs to the desert for purification, as Christ did for forty days in the Judean desert, or Saint Mark in the Egyptian desert, starting a tradition of such asceticism. There was at some point an epidemic of monasticism in the Levant, perhaps the most impressive being Saint Simeon, who spent forty years on top of a column in Northern Syria. The Arabs kept the tradition, shedding possessions to go to silent, barren, empty spaces. And of course, with mandatory fasting, on which a bit later.
Note that medical iatrogenics is the result of wealth and sophistication rather than poverty and artlessness, and of course the product of partial knowledge rather than ignorance. So this idea of shedding possessions to go to the desert can be quite potent as a
via negativa
–style subtractive strategy. Few have considered that money has its own iatrogenics, and that separating some people from their fortune would simplify their lives and bring great benefits in the form of healthy stressors. So being poorer might not be completely devoid of benefits if one does it right. We need modern civilization for many things, such as the legal
system and emergency room surgery. But just imagine how by the subtractive perspective,
via negativa,
we can be better off by getting tougher: no sunscreen, no sunglasses if you have brown eyes, no air-conditioning, no orange juice (just water), no smooth surfaces, no soft drinks, no complicated pills, no loud music, no elevator, no juicer, no … I stop.
When I see pictures of my friend the godfather of the Paleo ancestral lifestyle, Art De Vany, who is extremely fit in his seventies (much more than most people thirty years younger than him), and those of the pear-shaped billionaires Rupert Murdoch or Warren Buffett or others in the same age group, I am invariably hit with the following idea. If true wealth consists in worriless sleeping, clear conscience, reciprocal gratitude, absence of envy, good appetite, muscle strength, physical energy, frequent laughs, no meals alone, no gym class, some physical labor (or hobby), good bowel movements, no meeting rooms, and periodic surprises, then it is largely subtractive (elimination of iatrogenics).
Religion and Naive Interventionism
Religion has invisible purposes beyond what the literal-minded scientistic-scientifiers identify—one of which is to protect us from scientism, that is, them. We can see in the corpus of inscriptions (on graves) accounts of people erecting fountains or even temples to their favorite gods after these succeeded where doctors failed. Indeed we rarely look at religion’s benefits in limiting the intervention bias and its iatrogenics:
in a large set of circumstances (marginal disease), anything that takes you away from the doctor and allows you to do nothing (hence gives nature a chance to do its work) will be beneficial
. So going to church (or the temple of Apollo) for mild cases—say, those devoid of trauma, like a mild discomfort, not injuries from a car accident, those situations in which the risk of iatrogenics exceeds the benefit of cure, to repeat it again, the cases with negative convexity—will certainly help. We have so many inscriptions on temples of the type
Apollo saved me, my doctors tried to kill me
—typically the patient has bequeathed his fortune to the temple.
And it seems to me that human nature does, deep down, know when to resort to the solace of religion, and when to switch to science.
4


================================================================================
CHAPTER/SECTION 112 (Item 115)
================================================================================

IF IT’S WEDNESDAY, I MUST BE VEGAN
Sometimes, for a conference dinner, the organizers send me a form asking me if I have dietary requirements. Some do so close to six months in advance. In the past, my usual answer had been that I avoid eating cats, dogs, rats, and humans (especially economists). Today, after my personal evolution, I truly need to figure out the day of the week to know if I will be vegan then or capable of eating those thick monstrous steaks. How? Just by looking at the Greek Orthodox calendar and its required fasts. This confuses the usual categorizing business-reader-TED-conference modern version of the naive fellow who cannot place me in the “Paleo camp” or the “vegan camp.” (The “Paleo” people are carnivores who try to replicate the supposed ancestral high-meat, high-animal-fat diet of hunter-gatherers; vegans are people who eat no animal product, not even butter). We will see further down why it is a naive rationalistic mistake to be in either category (except for religious or spiritual reasons) except episodically.
I believe in the heuristics of religion and blindly accommodate its rules (as an Orthodox Christian, I can cheat once in a while, as it is part of the game). Among other things the role of religion is to tame the iatrogenics of abundance—fasting makes you lose your sense of entitlement. But there are more subtle aspects.
Convexity Effects and Random Nutrition
Recall from the lung ventilator discussion this practical consequence of Jensen’s inequality: irregularity has its benefits in some areas; regularity has its detriments. Where Jensen’s inequality applies, irregularity might be medicine.
Perhaps what we mostly need to remove is a few meals at random, or at least avoid steadiness in food consumption. The error of missing nonlinearities is found in two places, in the mixture and in the frequency of food intake.
The problem with the mixture is as follows. We humans are said to be omnivorous, compared to more specialized mammals, such as cows and elephants (who eat salads) and lions (who eat prey, generally salad-eating prey). But such ability to be omnivorous had to come in response to more variegated environments with unplanned, haphazard, and, what is key, serial availability of sources—specialization is the response
to a very stable habitat free of abrupt changes, redundancy of pathways the response to a more variegated one. Diversification of function had to come in response to variety. And a variety of a certain structure.
Note a subtlety in the way we are built: the cow and other herbivores are subjected to much less randomness than the lion in their food intake; they eat steadily but need to work extremely hard in order to metabolize all these nutrients, spending several hours a day just eating. Not to count the boredom of standing there eating salads. The lion, on the other hand, needs to rely on more luck; it succeeds in a small percentage of the kills, less than 20 percent, but when it eats, it gets in a quick and easy way all these nutrients produced thanks to very hard and boring work by the prey. So take the following principles derived from the random structure of the environment: when we are herbivores, we eat steadily; but when we are predators we eat more randomly. Hence our proteins need to be consumed randomly for statistical reasons.
So if you agree that we need “balanced” nutrition of a certain combination, it is wrong to immediately assume that we need such balance
at every meal
rather than serially so. Assuming that we need on average certain quantities of the various nutrients that have been identified, say a certain quantity of carbohydrates, proteins, and fats.
5
There is a big difference between getting them together, at every meal, with the classical steak, salad, followed by fresh fruits, or having them separately, serially.
Why? Because deprivation is a stressor—and we know what stressors do when allowed adequate recovery. Convexity effects at work here again: getting three times the daily dose of protein in one day and nothing the next two is certainly not biologically equivalent to “steady” moderate consumption if our metabolic reactions are nonlinear. It should have some benefits—at least this is how we are designed to be.
I speculate; in fact I more than speculate: I am convinced (an inevitable result of nonlinearity) that we are antifragile to randomness in food delivery and composition—at least over a certain range, or number of days.
And one blatant denial of convexity bias is the theory about the benefits of the so-called Cretan (or Mediterranean) diet that triggered a change in the eating habits of the U.S. enlightened class, away from steak and potatoes in favor of grilled fish with salad and feta cheese. It happened as follows. Someone looked at the longevity of Cretans, cataloged what they ate, then inferred—naively—that they lived longer because of the types of food they consumed. It could be true, but the second-order effect (the variations in intake) could be dominant, something that went unnoticed by mechanistic researchers. Indeed, it took a while to notice the following: the Greek Orthodox church has, depending on the severity of the local culture, almost two hundred days of fasting per year; and these are harrowing fasts.
Yes, harrowing fasts, as I am feeling it right now. For I am writing these lines during Orthodox Lent, a forty-day period in which almost no animal product can be consumed, no sweets, and, for some sticklers, no olive oil. As there are several gradations, I try to stick to a semistrict level, and life is not very easy, as is meant to be. I just spent a long weekend in Amioun, my ancestral village in Northern Lebanon, in the Greek Orthodox area called the Koura valley. There traditional “ruse” foods are perfected, with great imagination: Levantine kibbeh made with herbs and beans in place of meat, meatballs made of matzoh-style small brown balls in a lentil soup. Remarkably, while fish is banned, most days, shellfish is allowed, probably as it was not considered a luxury item. The compensation for the absence of some nutrients from my daily diet will take place in lumps. I will make up my deprivation of what researchers (for now) call protein with fish on days when it is allowed, and of course I will ravenously eat lamb on Easter Day, then consume disproportionally high quantities of fatty red meat for a while thereafter. I dream of the red steak served in Fat Tony–patronized restaurants in unapologetically monstrous portions.
And there is this antifragility to the stressor of the fast, as it makes the wanted food taste better and can produce euphoria in one’s system. Breaking a fast feels like the exact opposite of a hangover.
6
How to Eat Yourself
I wonder how people can accept that the stressors of exercise are good for you, but do not transfer to the point that food deprivation can have the same effect. But scientists are in the process of discovering the effects of episodic deprivation of some, or all, foods. Somehow, evidence shows, we get sharper and fitter in response to the stress of the constraint.
We can look at biological studies not to generalize or use in the rationalistic sense, but to verify the existence of a human response to hunger: that biological mechanisms are activated by food deprivation. And we have experiments on cohorts showing the positive effect of hunger—or deprivation of a food group—on the human body. Researchers rationalize now with the mechanism of
autophagy
(eating oneself): when deprived of external sources, the theories are that your cells start eating themselves, or breaking down proteins and recombining amino acids to provide material for building other cells. It is assumed by some researchers (for now) that the “vacuum cleaner” effect of autophagy is the key to longevity—though my ideas of the natural are impervious to their theories: as I will show further down, occasional starvation produces some health benefits and that’s that.
The response to hunger, our antifragility, has been underestimated. We’ve been telling people to eat a good meal for breakfast so they can face the travails of the day. And it is not a new theory by empirically blind modern-day nutritionists—for instance I was struck by a dialogue in Stendhal’s monumental novel
Le rouge et le noir
in which the protagonist, Julien Sorel, is told “the work for the day will be long and rough, so let us
fortify
ourselves with a breakfast” (which in the French of the period was called “the first lunch”). Indeed, the idea of breakfast as a main meal with cereals and other such materials has been progressively shown to be harming humans—I wonder why it took so long before anyone realized that such an unnatural idea needs to be tested; further, the tests show that harm, or, at least, no benefits are derived from breakfast unless one has worked for it beforehand.
Let us remember that we are not designed to be receiving foods from the delivery person. In nature, we had to expend some energy to eat. Lions hunt to eat, they don’t eat their meal then hunt for pleasure. Giving people food before they expend energy would certainly confuse their signaling process. And we have ample evidence that intermittently (and
only intermittently) depriving organisms of food has been shown to engender beneficial effects on many functions—Valter Longo, for instance, noted that prisoners in concentration camps got less sick in the first phase of food restriction, then broke down later. He tried the result experimentally and found out that mice, in the initial phases of starvation, can withstand high doses of chemotherapy without visible side effects. Scientists use the narrative that starvation causes the expression of a gene coding a protein called SIRT, SIRT1, or sirtuin, which brings longevity and other effects. The antifragility of humans manifests itself in the response with up-regulation of some genes in response to hunger.
So once again, religions with ritual fasts have more answers than assumed by those who look at them too literally. In fact what these ritual fasts do is try to bring nonlinearities in consumption to match biological properties. The Appendix shows graphically the standard dose responses in biology: a little bit of anything seems to harbor positive convexity effects (whether beneficial or harmful); add to it and the effect weakens. Clearly at the upper end, the dose has no additional effect since one reaches saturation.
Walk-Deprived
Another source of harm from naive rationalism. Just as for a long time people tried to shorten their sleep, as it seemed useless to our earthling logic, many people think that walking is useless, so they use mechanical transportation (car, bicycle, etc.) and get their exercise working out at the gym. And when they walk, they do this ignominious “power walk,” sometimes with weights on their arms. They do not realize that for reasons still opaque to them, walking effortlessly, at a pace below the stress level, can have some benefits—or, as I speculate, is necessary for humans, perhaps as necessary as sleep, which at some point modernity could not rationalize and tried to reduce. Now it may or may not be true that walking effortlessly is as necessary as sleep, but since all my ancestors until the advent of the automobile spent much of their time walking around (and sleeping), I try to just follow the logic, even before some medical journal catches up to the idea and produces what referees of medical journals call “evidence.”
I Want to Live Forever
All I hear is how to live longer, richer, and, of course, more laden with electronic gadgets. We are not the first generation to believe that the worst possible thing to befall us is death. But for the ancients, the worst possible outcome was not death, but a dishonorable death, or even just a regular one. For a classical hero, dying in a retirement home with a rude nurse and a network of tubes coming into and out of your nose would not be the attractive
telos
for a life.
And, of course, we have this modern illusion that we should live as long as we can. As if we were each the end product. This idea of the “me” as a unit can be traced to the Enlightenment. And, with it, fragility.
Before that, we were part of the present collective and future progeny. Both present and the future tribes exploited the fragility of individuals to strengthen themselves. People engaged in sacrifices, sought martyrdom, died for the group, and derived pride from doing so; they worked hard for future generations.
Sadly, as I am writing these lines, the economic system is loading future generations with public governmental debt, causing depletion of resources, and environmental blight to satisfy the requirements of the security analysts and the banking establishment (once again, we cannot separate fragility from ethics).
As I wrote in
Chapter 4
, while the gene is antifragile, since it is information, the carrier of the gene is fragile, and needs to be so for the gene to get stronger. We live to produce information, or improve on it. Nietzsche had the Latin pun
aut liberi, aut libri
—either children or books, both information that carries through the centuries.
I was just reading in John Gray’s wonderful
The Immortalization Commission
about attempts to use science, in a postreligious world, to achieve immortality. I felt some deep disgust—as would any ancient—at the efforts of the “singularity” thinkers (such as Ray Kurzweil) who believe in humans’ potential to live forever. Note that if I had to find the anti-me, the person with diametrically opposite ideas and lifestyle on the planet, it would be that Ray Kurzweil fellow. It is not just neomania. While I propose removing offensive elements from people’s diets (and lives), he works by adding, popping close to two hundred pills daily. Beyond that, these attempts at immortality leave me with deep moral revulsion.
It is the same kind of deep internal disgust that takes hold of me
when I see a rich eighty-two-year-old man surrounded with “babes,” twentysomething mistresses (often Russian or Ukrainian). I am not here to live forever, as a sick animal. Recall that the antifragility of a system comes from the mortality of its components—and I am part of that larger population called humans. I am here to die a heroic death for the sake of the collective, to produce offspring (and prepare them for life and provide for them), or eventually, books—my information, that is, my genes, the antifragile in me, should be the ones seeking immortality, not me.
Then say goodbye, have a nice funeral in St. Sergius (Mar Sarkis) in Amioun, and, as the French say,
place aux autres
—make room for others.
1
While there are some controversies concerning conditional life expectancy, the numbers are quite revealing. For instance, on one extreme, Richard Lewontin estimates, “in the last 50 years, only four months have been added to the expected life span of a person who is already 60 years old.” Data from the Centers for Disease Control and Prevention (CDC) show a few more years (but we are still unsure how much of it came from medicine as compared to improvements in life conditions and social mores). Still, the CDC shows that life expectancy at age 20 only increased from 42.79 (additional years) in 1900–1902 to 51.2 in 1949–1951 and to 58.2 in 2002.
2
A technical comment: in the so-called Bayesian (or conditional probability) analysis, it would be equivalent to looking at
A
conditional on
B
rather than
B
conditional on
A
.
3
One example of lack of empirical wisdom in the use of “evidence”: in a
New York Times Magazine
article, a doctor who claimed that he stopped eating sugar because of its potential harm was apologetic for doing so “without full evidence.” The best test of empirical wisdom in someone is in where he puts the burden of evidence.
4
I am trying to avoid discussing the placebo effect; I am in the business of nonlinearities and it does not relate to the nonlinearities argument.
5
Some people claim that we need more fat than carbohydrates; others offer the opposite (they all tend to agree on protein, though few realize we need to randomize protein intake). Both sides still advocate nonrandomness in the mixing and ignore the nonlinearities from sequence and composition.
6
The principal disease of abundance can be seen in habituation and jadedness (what biologists currently call dulling of receptors); Seneca: “To a sick person, honey tastes better.”


================================================================================
CHAPTER/SECTION 113 (Item 116)
================================================================================

BOOK VII
The Ethics of Fragility and Antifragility
N
ow, ethics. Under opacity and in the newfound complexity of the world, people can hide risks and hurt others, with the law incapable of catching them. Iatrogenics has both delayed and invisible consequences. It is hard to see causal links, to fully understand what’s going on.
Under such epistemic limitations, skin in the game is the only true mitigator of fragility. Hammurabi’s code provided a simple solution—close to thirty-seven hundred years ago. This solution has been increasingly abandoned in modern times, as we have developed a fondness for neomanic complication over archaic simplicity. We need to understand the everlasting solidity of such a solution.


================================================================================
CHAPTER/SECTION 114 (Item 117)
================================================================================

CHAPTER 23
Skin in the Game: Antifragility and Optionality at the Expense of Others
Making talk less cheap—Looking at the spoils—Corporations with random acts of pity?—Predict and inverse predict
This chapter will look at what we are getting ourselves into when someone gets the upside, and a different person gets the downside.
The worst problem of modernity lies in the malignant transfer of fragility and antifragility from one party to the other, with one getting the benefits, the other one (unwittingly) getting the harm, with such transfer facilitated by the growing wedge between the ethical and the legal. This state of affairs has existed before, but is acute today—modernity hides it especially well.
It is, of course, an agency problem.
And the agency problem, is of course, an asymmetry.
We are witnessing a fundamental change. Consider older societies—those societies that have survived. The main difference between us and them is the disappearance of a sense of heroism; a shift away from a certain respect—and power—to those who take downside risks for others. For heroism is the exact inverse of the agency problem: someone elects to bear the disadvantage (risks his own life, or harm to himself, or, in milder forms, accepts to deprive himself of some benefits) for the sake of others. What we have currently is the opposite: power seems to go to
those, like bankers, corporate executives (nonentrepreneurs), and politicians, who steal a free option from society.
And heroism is not just about riots and wars. An example of an inverse agency problem: as a child I was most impressed with the story of a nanny who died in order to save a child from being hit by a car. I find nothing more honorable than accepting death in someone else’s place.
In other words, what is called sacrifice. And the word “sacrifice” is related to
sacred,
the domain of the holy that is separate from that of the profane.
In traditional societies, a person is only as respectable and as worthy as the downside he (or, more, a lot more, than expected,
she
) is willing to face for the sake of others. The most courageous, or valorous, occupy the highest rank in their society: knights, generals, commanders. Even mafia dons accept that such rank in the hierarchy makes them the most exposed to be whacked by competitors and the most penalized by the authorities. The same applies to saints, those who abdicate, devote their lives to serve others—to help the weak, the deprived, and the dispossessed.
So
Table 7
presents another Triad: there are those with no skin in the game but who benefit from others, those who neither benefit from nor harm others, and, finally, the grand category of those sacrificial ones who take the harm for the sake of others.
Click
here
for a larger image of this table.
Let me follow my emotions and start with the third column, on the far right, the one about heroes and people of courage. The robustness—even antifragility—of society depends on them; if we are here today, it is because someone, at some stage, took some risks for us. But courage and heroism do not mean blind risk taking—it is not necessarily recklessness. There is a pseudocourage that comes from risk blindness, in which people underestimate the odds of failure. We have ample evidence that the very same people become chicken and overreact in the face of real risks; the exact opposite. For the Stoics, prudence is connatural to courage—the courage to fight your own impulses (in an aphorism by—who else—Publilius Syrus, prudence was deemed the courage of the general).
Heroism has evolved through civilization from the martial arena to that of ideas. Initially, in preclassical times, the Homeric hero was someone principally endowed with physical courage—since everything was physical. In later classical times, for such people as the great Lacedaemonian king Agiselaus, a truly happy life was one crowned by the privilege of death in battle, little else, perhaps even nothing else. But for Agiselaus, courage had already evolved from purely martial prowess into something greater. Courage was often seen in acts of renunciation, as when one is ready to sacrifice himself for the benefit of others, of the collective, something altruistic.
Finally, a new form of courage was born, that of the Socratic Plato, which is the very definition of the modern man: the courage to stand up for an idea, and enjoy death in a state of thrill, simply because the privilege of dying for truth, or standing up for one’s values, had become the highest form of honor. And no one has had more prestige in history than two thinkers who overtly and defiantly sacrificed their lives for their ideas—two Eastern Mediterraneans; one Greek and one Semite.
We should pause a little when we hear
happiness
defined as an economic or otherwise puny materialistic condition. You can imagine how distraught I feel when I hear about the glorified heroism-free “middle class values,” which, thanks to globalization and the Internet, have spread to any place easily reached by British Air, enshrining the usual opiates of the deified classes: “hard work” for a bank or a tobacco company, diligent newspaper reading, obedience to most, but not all, traffic laws, captivity in some corporate structure, dependence on the opinion of a boss (with one’s job records filed in the personnel department), good legal compliance, reliance on stock market investments, tropical vacations, and a suburban life (under some mortgage) with a nice-looking
dog and Saturday night wine tasting. Those who meet with some success enter the gallery of the annual billionaire list, where they will hope to spend some time before their fertilizer sales are challenged by competitors from China. They will be called heroes—rather than lucky. Further, if success is random, a conscious act of heroism is nonrandom. And the “ethical” middle class may work for a tobacco company—and thanks to casuistry call themselves ethical.
I am even more distraught for the future of the human race when I see a nerd behind a computer in a D.C. suburb, walking distance from a Starbucks coffeehouse, or a shopping mall, capable of blowing up an entire battalion in a remote place, say Pakistan, and afterward going to the gym for a “workout” (compare his culture to that of knights or samurai). Cowardice enhanced by technology is all connected: society is fragilized by spineless politicians, draft dodgers afraid of polls, and journalists building narratives, who create explosive deficits and compound agency problems because they want to look good in the short term.
A disclaimer.
Table 7
does not imply that those with soul in the game are necessarily right or that dying for one’s ideas makes one necessarily good for the rest of us: many messianic utopians have caused quite a bit of harm. Nor is a grandiose death a necessity: many people fight evil in the patient grind of their daily lives without looking like heroes; they suffer society’s ingratitude even more—while media-friendly pseudoheroes rise in status. These people will not get a statue from future generations.
A half-man (or, rather, half-person) is not someone who does not have an opinion, just someone who does not take risks for it.
The great historian Paul Veyne has recently shown that it is a big myth that gladiators were forced labor. Most were volunteers who wanted the chance to become heroes by risking their lives and winning, or, when failing, to show in front of the largest crowd in the world how they were able to die honorably, without cowering—when a gladiator loses the fight the crowd decides whether he should be spared or put to death by the opponent. And spectators did not care for nonvolunteers, as these did not have their soul in the fight.
My greatest lesson in courage came from my father—as a child, I had admired him before for his erudition, but was not overly fazed since erudition on its own does not make a man. He had a large ego and immense dignity, and he demanded respect. He was once insulted by a militiaman
at a road check during the Lebanese war. He refused to comply, and got angry at the militiaman for being disrespectful. As he drove away, the gunman shot him in the back. The bullet stayed in his chest for the rest of his life so he had to carry an X-ray image through airport terminals. This set the bar very high for me: dignity is worth nothing unless you earn it, unless you are willing to pay a price for it.
A lesson I learned from this ancient culture is the notion of
megalopsychon
(a term expressed in Aristotle’s ethics), a sense of grandeur that was superseded by the Christian value of “humility.” There is no word for it in Romance languages; in Arabic it is called
Shhm
—best translated as
nonsmall
. If you take risks and face your fate with dignity, there is nothing you can do that makes you small; if you don’t take risks, there is nothing you can do that makes you grand, nothing. And when you take risks, insults by half-men (small men, those who don’t risk anything) are similar to barks by nonhuman animals: you can’t feel insulted by a dog.


================================================================================
CHAPTER/SECTION 115 (Item 118)
================================================================================

HAMMURABI
Let us now work with the elements of
Table 7
and bring the unifying foundational asymmetry (between upside and downside) into our central theme, ethics. Just as only business school professors and similar fragilistas separate robustness and growth, we cannot separate fragility and ethics.
Some people have options, or have optionality, at the expense of others. And the others don’t know it.
The effects of transfers of fragility are becoming more acute, as modernity is building up more and more people on the left column—inverse heroes, so to say. So many professions, most arising from modernity, are affected, becoming more antifragile at the expense of our fragility—tenured government employees, academic researchers, journalists (of the non-myth-busting variety), the medical establishment, Big Pharma, and many more. Now how do we solve the problem? As usual, with some great help from the ancients.
Hammurabi’s code—now about 3,800 years old—identifies the need to reestablish a symmetry of fragility, spelled out as follows:
If a builder builds a house and the house collapses and causes the death of the owner of the house—the builder shall be put to
death. If it causes the death of the son of the owner of the house, a son of that builder shall be put to death. If it causes the death of a slave of the owner of the house—he shall give to the owner of the house a slave of equal value.
It looks like they were much more advanced 3,800 years ago than we are today. The entire idea is that the builder knows more, a lot more, than any safety inspector, particularly about what lies hidden in the foundations—making it the best risk management rule ever, as the foundation, with delayed collapse, is the best place to hide risk. Hammurabi and his advisors understood small probabilities.
Now, clearly the object here is not to punish retrospectively, but to save lives by providing up-front disincentive in case of harm to others during the fulfillment of one’s profession.
These asymmetries are particularly severe when it comes to small-probability extreme events, that is, Black Swans—as these are the most misunderstood and their exposure is easiest to hide.
Fat Tony has two heuristics.
First,
never get on a plane if the pilot is not on board.
Second,
make sure there is also a copilot.
The first heuristic addresses the asymmetry in rewards and punishment, or transfer of fragility between individuals. Ralph Nader has a simple rule: people voting for war need to have at least one descendant (child or grandchild) exposed to combat. For the Romans, engineers needed to spend some time under the bridge they built—something that should be required of financial engineers today. The English went further and had the families of the engineers spend time with them under the bridge after it was built.
To me, every opinion maker needs to have “skin in the game” in the event of harm caused by reliance on his information or opinion (not having such persons as, say, the people who helped cause the criminal Iraq invasion come out of it completely unscathed). Further, anyone producing a forecast or making an economic analysis needs to have something to lose from it, given that others rely on those forecasts (to repeat, forecasts induce risk taking; they are more toxic to us than any other form of human pollution).
We can derive plenty of sub-heuristics from Fat Tony’s rules, particularly to mitigate the weaknesses of predictive systems. Predicting—any
prediction—without skin in the game can be as dangerous for others as unmanned nuclear plants without the engineer sleeping on the premises. Pilots should be on the plane.
The second heuristic is that we need to build redundancy, a margin of safety, avoiding optimization, mitigating (even removing) asymmetries in our sensitivity to risk.
The rest of this chapter will present a few syndromes, with, of course, some ancient remedies.


================================================================================
CHAPTER/SECTION 116 (Item 119)
================================================================================

THE TALKER’S FREE OPTION
We closed
Book I
by arguing that we need to put entrepreneurs and risk takers, “failed” or not, on top of the pyramid, and, unless they take personal risks when they expose others, academizing academics, talkers, and political politicians at the bottom. The problem is that society is currently doing the exact opposite, granting mere talkers a free option.
The idea that Fat Tony milked suckers when they ran to the exit door seemed at first quite inelegant to Nero. Benefiting from the misfortune of others—no matter how hideous these are and can be—is not the most graceful approach to life. But Tony had something at risk, and would have been personally harmed by an adverse outcome. Fat Tony had no agency problem. This makes it permissible. For there is an even worse problem associated with the opposite situation: people who just
talk,
prognosticate, theorize.
In fact, speculative risk taking is not just permissible; it is mandatory. No opinion without risk; and, of course, no risk without hope for return. If Fat Tony had an opinion, he felt he needed, for ethical reasons, to have a corresponding exposure. As they say in Bensonhurst, you got to do so if you have an opinion. Otherwise, you do not really have an opinion at all. You need to be earmarked as someone who has no downside for his opinion, with a special status in society, perhaps something below that of ordinary citizen. Commentators need to have a status
below
ordinary citizens. Regular citizens, at least, face the downside of their statements.
So counter to the entire idea of the intellectual and commentator as a detached and protected member of society, I am stating here that I find it profoundly unethical to talk without doing, without exposure to harm, without having one’s skin in the game, without having something
at risk. You express your opinion; it can hurt others (who rely on it), yet you incur no liability. Is this fair?
But this is the information age. This effect of transferring fragility might have been present throughout history, but it is much more acute now, under modernity’s connectivity, and the newfound invisibility of causal chains. The intellectual today is vastly more powerful and dangerous than before. The “knowledge world” causes separation of knowing and doing (within the same person) and leads to the fragility of society. How?
In the old days, privilege came with obligations—except for the small class of intellectuals who served a patron or, in some cases, the state. You want to be a feudal lord—you will be first to die. You want war? First in battle. Let us not forget something embedded in the U.S. Constitution: the president is commander in chief. Caesar, Alexander, and Hannibal were on the battlefield—the last, according to Livy, was first-in, last-out of combat zones. George Washington, too, went to battle, unlike Ronald Reagan and George W. Bush, who played video games while threatening the lives of others. Even Napoleon was personally exposed to risks; his showing up during a battle was the equivalent of adding twenty-five thousand troops. Churchill showed an impressive amount of physical courage. They were in it; they believed in it. Status implied you took physical risks.
Note that in traditional societies even those who fail—but have taken risks—have a higher status than those who are not exposed.
Now, again, the idiocy of predictive systems, making me emotional. We may have more social justice today than before the Enlightenment, but we also have more, a lot more transfers of optionality, more than ever—a patent setback. Let me explain. This knowledge shknowledge business necessarily means shifting to talk. Talk by academics, consultants, and journalists, when it comes to predictions, can be just
talk,
devoid of embodiment and stripped of true evidence. As in anything with words, it is not the victory of the most correct, but that of the most charming—or the one who can produce the most academic-sounding material.
We mentioned earlier how the political philosopher Raymond Aron sounded uninteresting in spite of his predictive abilities, while those who were wrong about Stalinism survived beautifully. Aron was about as
colorless as they come: in spite of his prophetic insights he looked, wrote, and lived like a tax accountant while his enemy, say, Jean-Paul Sartre, who led a flamboyant lifestyle, got just about everything wrong and even put up with the occupying Germans in an extremely cowardly manner. Sartre the coward looked radiant, impressive, and, alas, his books survived (please stop calling him a Voltaire; he was no Voltaire).
I got nauseous in Davos making eye contact with the fragilista journalist Thomas Friedman who, thanks to his influential newspaper op-eds, helped cause the Iraq war. He paid no price for the mistake. The real reason for my malaise was perhaps not just that I saw someone I consider vile and harmful. I just get disturbed when I see wrong and do nothing about it; it is biological. It is guilt, for Baal’s sake, and guilt is what I do not have to put up with. There is another central element of ancient Mediterranean ethics:
Factum tacendo, crimen facias acrius:
For Publilius Syrus, he who does not stop a crime is an accomplice. (I’ve stated my own version of this in the prologue, which needs to be reiterated: if you see fraud and don’t say fraud, you are a fraud.)
Thomas Friedman was a bit responsible for the Iraq invasion of 2003, and not only paid no penalty for it but continues to write for the op-ed page of
The New York Times,
confusing innocent people. He got—and kept—the upside, others get the downside. A writer with arguments can harm more people than any serial criminal. I am singling him out here because, at the core, the problem is his promotion of the misunderstanding of iatrogenics in complex systems. He promoted the “earth is flat” idea of globalization without realizing that globalization brings fragilities, causes more extreme events as a side effect, and requires a great deal of redundancies to operate properly. And the very same error holds with the Iraq invasion: in such a complex system, the predictability of the consequences is very low, so invading was epistemologically irresponsible.
Natural and ancestral systems work by penalties: no perpetual free option given to anyone. So does society in many things with visible effects. If someone drives a school bus blindfolded, and has an accident, he either exits the gene pool the old-fashioned way, or, if for some reason he is not harmed by the accident, he will incur enough penalties to be prevented from driving other people ever again. The problem is that the journalist Thomas Friedman is still driving the bus. There is no penalty for opinion makers who harm society. And this is a very bad practice.
The Obama administration was after the crisis of 2008 populated with people who drove the bus blindfolded. The iatrogenists got promoted.
Postdicting
Words are dangerous: postdictors, who explain things after the fact—because they are in the business of talking—always look smarter than predictors.
Because of the retrospective distortion, people who of course did not see an event coming will remember some thought to the effect that they did, and will manage to convince themselves that they predicted it, before proceeding to convince others. There will be after every event many more postdictors than true predictors, people who had an idea in the shower without taking it to its logical conclusion, and, given that many people take a lot of showers, say, nearly twice a day (if you include the gym or the episode with the mistress), they will have a large repertoire to draw from. They will not remember the numerous bath-generated ideas they had in the past that were either noise, or that contradicted the observed present—but as humans crave self-consistency, they will retain those elements of what they thought in the past that cohere with their perception of the present.
So opinion makers who were so proudly and professionally providing idle babble will eventually appear to win an argument, since they are the ones writing, and suckers who got in trouble from reading them will again look to them for future guidance, and will again get in trouble.
The past is fluid, marred with selection biases and constantly revised memories. It is a central property of suckers that they will never know they were the suckers because that’s how our minds work. (Even so, one is struck with the following fact: the fragilista crisis that started in 2007–2008 had many, many fewer
near-predictors
than random.)
The asymmetry (antifragility of postdictors): postdictors can cherry-pick and produce instances in which their opinions played out and discard mispredictions into the bowels of history. It is like a free option—to them; we pay for it.
Since they have the option, the fragilistas are personally antifragile: volatility tends to benefit them: the more volatility, the higher the illusion of intelligence.
But evidence of whether one has been a sucker or a nonsucker is easy to ferret out by looking at actual records, actions. Actions are symmetric, do not allow cherry-picking, remove the free option. When you look at the actual history of someone’s activities, instead of what thoughts he will deliver after the facts, things become crystal clear. The option is gone. Reality removes the uncertainty, the imprecision, the vagueness, the self-serving mental biases that make us appear more intelligent. Mistakes are costly, no longer free, but being right brings actual rewards. Of course, there are other checks one can do to assess the b***t component of life: investigate people’s decisions as expressed through their own investments. You would discover that many people who claim to have foreseen the collapse of the financial system had financial companies in their portfolios. Indeed, there was no need to “profit” from events like Tony and Nero to show nonsuckerness: just avoiding being hurt by them would have been sufficient.
I want predictors to have visible scars on their body from prediction errors, not distribute these errors to society.
You cannot sit and moan about the world. You need to come out on top. So Tony was right to insist that Nero take a ritual look at the physical embodiment of the spoils, like a bank account statement—as we said, it had nothing to do with financial value, nor purchasing power, just symbolic value. We saw in
Chapter 9
how Julius Caesar needed to incur the cost of having Vercingetorix brought to Rome and paraded. An intangible victory has no value.
Verba volent,
words fly. Never have people who talk and don’t do been more visible, and played a larger role, than in modern times. This is the product of modernism and division of tasks.
Recall that I said that America’s strength was risk taking and harboring risk takers (the right kind, the Thalesian king of high-failure, long-optionality type). Sorry, but we have been moving away from this model.
The Stiglitz Syndrome
There is something more severe than the problem with Thomas Friedman, which can be generalized to represent someone causing action while being completely unaccountable for his words.
The phenomenon I will call the Stiglitz syndrome, after an academic economist of the so-called “intelligent” variety called Joseph Stiglitz, is as follows.
Remember the fragility detection in
Chapter 19
and my obsession with Fannie Mae. Luckily, I had some skin in the game for my opinions, be it through exposure to a smear campaign. And, in 2008, no surprise, Fannie Mae went bust, I repeat, costing the U.S. taxpayer hundreds of billions (and counting)—generally, the financial system, with similar risks, exploded. The entire banking system had similar exposures.
But around the same period, Joseph Stiglitz, with two colleagues, the Orszag brothers (Peter and Jonathan), looked at the very same Fannie Mae. They assessed, in a report, that “on the basis of historical experience, the risk to the government from a potential default on GSE debt is effectively zero.”
1
Supposedly, they ran simulations—but didn’t see the obvious. They also said that the probability of a default was found to be “so small that it is difficult to detect.” It is statements like these and, to me, only statements like these (intellectual hubris and the illusion of understanding of rare events) that caused the buildup of these exposures to rare events in the economy. This is the Black Swan problem that I was fighting. This is Fukushima.
Now the culmination is that Stiglitz writes in 2010 in his
I-told-you-so
book that he claims to have “predicted” the crisis that started in 2007–2008.
Look at this aberrant case of antifragility provided to Stiglitz and his colleagues by society. It turns out that Stiglitz was not just a nonpredictor (by my standards) but was also part of the problem that caused the events, these accumulations of exposures to small probabilities. But he did not notice it! An academic is not designed to remember his opinions because he doesn’t have anything at risk from them.
At the core, people are dangerous when they have that strange skill that allows their papers to be published in journals but decreases their understanding of risk. So the very same economist who caused the problem then postdicted the crisis, and then became a theorist on what happened. No wonder we will have larger crises.
The central point: had Stiglitz been a businessman with his own money on the line, he would have blown up, terminated. Or had he been in nature, his genes would have been made extinct—so people with such
misunderstanding of probability would eventually disappear from our DNA. What I found nauseating was the government hiring one of his coauthors.
2
I am reluctantly calling the syndrome by Stiglitz’s name because I find him the smartest of economists, one with the most developed intellect for things
on paper
—except that he has no clue about the fragility of systems. And Stiglitz symbolizes harmful misunderstanding of small probabilities by the economics establishment. It is a severe disease, one that explains why economists will blow us up again.
The Stiglitz syndrome corresponds to a form of cherry-picking, the nastiest variety because the perpetrator is not aware of what he is doing. It is a situation in which someone doesn’t just fail to detect a hazard but contributes to its cause while ending up convincing himself—and sometimes others—of the opposite, namely, that he predicted it and warned against it. It corresponds to a combination of remarkable analytical skills, blindness to fragility, selective memory, and absence of skin in the game.
Stiglitz Syndrome = fragilista (with good intentions) + ex post cherry-picking
There are other lessons here, related to the absence of penalty. This is an illustration of the academics-who-write-papers-and-talk syndrome in its greatest severity (unless, as we will see, they have their soul in it). So many academics propose something in one paper, then the opposite in another paper, without penalty to themselves from having been wrong in the first paper since there is a need only for consistency
within
a single paper, not
across
one’s career. This would be fine, as someone may evolve and contradict earlier beliefs, but then the earlier “result” should be withdrawn from circulation and superseded with a new one—with books, the new edition supersedes the preceding one. This absence of penalty makes them antifragile at the expense of the society that accepts the “rigor” of their results. Further, I am not doubting Stiglitz’s sincerity, or some weak form of sincerity: I believe he genuinely thinks he predicted the financial crisis, so let me rephrase the problem: the problem
with people who do not incur harm is that they can cherry-pick from statements they’ve made in the past, many of them contradictory, and end up convincing themselves of their intellectual lucidity on the way to the World Economic Forum at Davos.
There is the iatrogenics of the medical charlatan and snake oil salesperson causing harm, but he sort of knows it and lies low after he is caught. And there is a far more vicious form of iatrogenics by experts who use their more acceptable status to claim later that they warned of harm. As these did not know they were causing iatrogenics, they cure iatrogenics with iatrogenics. Then things explode.
Finally, the cure to many ethical problems maps to the exact cure for the Stiglitz effect, which I state now.
Never ask anyone for their opinion, forecast, or recommendation. Just ask them what they have—or don’t have—in their portfolio.
We now know that many innocent retirees have been harmed by the incompetence of the rating agencies—it was a bit more than incompetence. Many subprime loans were toxic waste dressed as “AAA,” meaning near-government grade in safety. People were innocently led into putting their savings into them—and, further, regulators were forcing portfolio managers to use the assessment of the rating agencies. But rating agencies are protected: they present themselves as press—without the noble mission of the press to expose frauds. And they benefit from the protection of free speech—the “First Amendment” so ingrained in American habits. My humble proposal: one should say whatever he wants, but one’s portfolio needs to line up with it. And, of course, regulators should not be fragilistas by giving their stamp to predictive approaches—hence junk science.
The psychologist Gerd Gigerenzer has a simple heuristic. Never ask the doctor what
you
should do. Ask him what
he
would do if he were in your place. You would be surprised at the difference.
The Problem of Frequency, or How to Lose Arguments
Recall that Fat Tony was in favor of just “making a buck” as opposed to being “proven right.” The point has a statistical dimension. Let us return to the distinction between Thalesian and Aristotelian for a minute
and look at evolution from the following point of view. The frequency, i.e., how
often
someone is right is largely irrelevant in the real world, but alas, one needs to be a practitioner, not a talker, to figure it out. On paper, the frequency of being right matters, but only on paper—typically, fragile payoffs have little (sometimes no) upside, and antifragile payoffs have little downside. This means that one makes pennies to lose dollars in the fragile case; makes dollars to lose pennies in the antifragile one. So the antifragile can lose for a long time with impunity, so long as he happens to be right once; for the fragile, a single loss can be terminal.
Accordingly if you were betting on the downfall of, say, a portfolio of financial institutions because of their fragilities, it would have cost you pennies over the years preceding their eventual demise in 2008, as Nero and Tony did. (Note again that taking the other side of fragility makes you antifragile.) You were wrong for years, right for a moment, losing small, winning big, so vastly more successful than the other way (actually the other way would be bust). So you would have made the Thekels like Thales because betting against the fragile is antifragile. But someone who had merely “predicted” the event with just words would have been called by the journalists “wrong for years,” “wrong most of the time,” etc.
Should we keep tally of opinion makers’ “right” and “wrong,” the proportion does not matter, as we need to include consequences. And given that this is impossible, we are now in a quandary.
Look at it again, the way we looked at entrepreneurs. They are usually wrong and make “mistakes”—plenty of mistakes. They are convex. So what counts is the payoff from success.
Let me rephrase again. Decision making in the real world, that is, deeds, are Thalesian, while forecasting
in words
is Aristotelian. As we saw in the discussion in
Chapter 12
, one side of a decision has larger consequences than the other—we don’t have evidence that people are terrorists but we check them for weapons; we don’t believe the water is poisonous but we avoid drinking it; something that would be absurd for someone narrowly applying Aristotelian logic. To put in Fat Tony terms: suckers try to be right, nonsuckers try to make the buck, or:
Suckers try to win arguments, nonsuckers try to win.
To put it again in other words: it is rather a good thing to lose arguments.
The Right Decision for the Wrong Reason
More generally, for Mother Nature, opinions and predictions don’t count; surviving is what matters.
There is an evolutionary argument here. It appears to be the most underestimated argument in favor of free enterprise and a society driven by individual doers, what Adam Smith called “adventurers,” not central planners and bureaucratic apparatuses. We saw that bureaucrats (whether in government or large corporations) live in a system of rewards based on narratives, “tawk,” and the opinion of others, with job evaluation and peer reviews—in other words, what we call marketing. Aristotelian, that is. Yet the biological world evolves by survival, not opinions and “I predicted” and “I told you so.” Evolution dislikes the confirmation fallacy, endemic in society.
The economic world should, too, but institutions mess things up, as suckers may get bigger—institutions block evolution with bailouts and statism. Note that, in the long term, social and economic evolution nastily takes place by surprises, discontinuities, and jumps.
3
We mentioned earlier Karl Popper’s ideas on evolutionary epistemology; not being a decision maker, he was under the illusion that ideas compete with each other, with the least wrong surviving at any point in time. He missed the point that it is not ideas that survive, but people who have the right ones, or societies that have the correct heuristics, or the ones, right or wrong, that lead them to do the good thing. He missed the Thalesian effect, the fact that a wrong idea that is harmless can survive. Those who have wrong heuristics—but with a small harm in the event of error—will survive. Behavior called “irrational” can be good if it is harmless.
Let me give an example of a type of false belief that is helpful for survival. In your opinion, which is more dangerous, to mistake a bear for a stone, or mistake a stone for a bear? It is hard for humans to make the first mistake; our intuitions make us overreact at the smallest probability of harm and fall for a certain class of false patterns—those who
overreact upon seeing what may look like a bear have had a survival advantage, those who made the opposite mistake left the gene pool.
Our mission is to make talk less cheap.


================================================================================
CHAPTER/SECTION 117 (Item 120)
================================================================================

THE ANCIENTS AND THE STIGLITZ SYNDROME
We saw how the ancients understood the Stiglitz syndrome—and associated ones—rather well. In fact they had quite sophisticated mechanisms to counter most aspects of agency problems, whether individual or collective (the circular effect of hiding behind the collective). Earlier, I mentioned the Romans forcing engineers to spend time under the bridge they built. They would have had Stiglitz and Orszag sleep under the bridge of Fannie Mae and exit the gene pool (so they wouldn’t harm us again).
The Romans had even more powerful heuristics for situations few today have thought about, solving potent game-theoretic problems. Roman soldiers were forced to sign a
sacramentum
accepting punishment in the event of failure—a kind of pact between the soldier and the army spelling out commitment for upside and downside.
Assume that you and I are facing a small leopard or a wild animal in the jungle. The two of us can possibly overcome it by joining forces—but each one of us is individually weak. Now, if you run away, all you need to be is just faster than me, not faster than the animal. So it would be optimal for the one who can run away the fastest, that is, the most cowardly, to just be a coward and let the other one perish.
The Romans removed the soldiers’ incentive to be a coward and hurt others thanks to a process called
decimation
. If a legion loses a battle and there is suspicion of cowardice, 10 percent of the soldiers and commanders are put to death, usually by random lottery. Decimation—meaning eliminating one in ten—has been corrupted by modern language. The magic number is one in ten (or something equivalent): putting more than 10 per cent to death would lead to weakening of the army; too little, and cowardice would be a dominant strategy.
And the mechanism must have worked well as a deterrent against cowardice, since it was not commonly applied.
The English applied a version of it. Admiral John Byng was court-martialed and sentenced to death as he was found guilty of failing to “do his utmost” to prevent Minorca from falling to the French following the Battle of Minorca in 1757.
To Burn One’s Vessels
Playing on one’s inner agency problem can go beyond symmetry: give soldiers no options and see how antifragile they can get.
On April 29, 711, the armies of the Arab commander Tarek crossed the Strait of Gibraltar from Morocco into Spain with a small army (the name Gibraltar is derived from the Arabic
Jabal Tarek,
meaning “mount of Tarek”). Upon landing, Tarek had his ships put to the fire. He then made a famous speech every schoolchild memorized during my school days that I translate loosely: “Behind you is the sea, before you, the enemy. You are vastly outnumbered. All you have is sword and courage.”
And Tarek and his small army took control of Spain. The same heuristic seems to have played out throughout history, from Cortés in Mexico, eight hundred years later, to Agathocles of Syracuse, eight hundred years earlier—ironically, Agathocles was heading southward, in the opposite direction as Tarek, as he was fighting the Carthaginians and landed in Africa.
Never put your enemy’s back to the wall.
How Poetry Can Kill You
Ask a polyglot who knows Arabic who he considers the best poet—in any language—and odds are that he would answer Almutanabbi, who lived about a thousand years ago; his poetry in the original has a hypnotic effect on the reader (listener), rivaled only by the grip of Pushkin on Russian speakers. The problem is that Almutanabbi knew it; his name was literally “He who thinks of himself as a prophet,” on account of his perceived oversized ego. For a taste of his bombast, one of his poems informs us that his poetry is so potent “that blind people can read it” and “deaf people can listen to it.” Well, Almutanabbi was that rare case of a poet with skin in the game, dying for his poetry.
For in the same egotistical poem, Almutanabbi boasts, in a breathtaking display of linguistic magic, that he walks the walk, in addition to being the most imaginably potent poet—which I insist he was—he knew “the horse, the night, the desert, the pen, the book”—and thanks to his courage he got respect from the lion.
Well, the poem cost him his life. For Almutanabbi had—characteristically—vilified a desert tribe in one of his poems and they
were out to get him. They reached him as he was traveling. As he was outnumbered, he started to do the rational thing and run away, nothing shameful, except that one of his companions started reciting “the horse, the night …” back at him. He turned around and confronted the tribe to his certain death. Thus Almutanabbi remains, a thousand years later, the poet who died simply to avoid the dishonor of running away, and when we recite his verses we know they are genuine.
My childhood role model was the French adventurer and writer André Malraux. He imbued his writings with his own risk taking: Malraux was a school dropout—while extremely well read—who became an adventurer in Asia in his twenties. He was an active pilot during the Spanish Civil War and later an active member of the French underground resistance during the Second World War. He turned out to be a bit of a mythomaniac, unnecessarily glorifying his meetings with great men and statesmen. He just could not bear the idea of a writer being an intellectual. But unlike Hemingway, who was mostly into image building, he was the real thing. And he never engaged in small talk—his biographer reports that while other writers were discussing copyrights and royalties, he would steer the conversation to theology (he supposedly said
the twenty-first century will be religious or will not be
). One of my saddest days was when he died.
The Problem of Insulation
The system does not give researchers the incentive to be a Malraux. The great skeptic Hume was said to leave his skeptical angst in the philosophical cabinet, then go party with his friends in Edinburgh (though his idea of partying was rather too … Edinburgh). The philosopher Myles Burnyeat called this the “problem of insulation,” particularly with skeptics who are skeptics in one domain but not another. He provides the example of a philosopher who puzzles about the reality of time, but who nonetheless applies for a research grant to work on the philosophical problem of time during next year’s sabbatical—without doubting the reality of next year’s arrival. For Burnyeat, the philosopher “insulates his ordinary first order judgments from the effects of his philosophizing.” Sorry, Professor Doctor Burnyeat; I agree that philosophy is the only field (and its sibling, pure mathematics) that does not need to connect to reality. But then make it a parlor game and give it another name …
Likewise, Gerd Gigerenzer reports a more serious violation on the part of Harry Markowitz, who started a method called “portfolio selection” and received the same iatrogenic Swedish Riskbank prize (called “Nobel” in economics) for it, like other fragilistas such as Fragilista Merton and Fragilista Stiglitz. I spent part of my adult life calling it charlatanism, as it has no validity outside of academic endorsements and causes blowups (as explained in the Appendix). Well, Doctor Professor Fragilista Markowitz does not use his method for his own portfolio; he has recourse to more sophisticated (and simpler to implement) cabdrivers’ methodologies, closer to the one Mandelbrot and I have proposed.
I believe that forcing researchers to eat their own cooking whenever possible solves a serious problem in science. Take this simple heuristic—does the scientific researcher whose ideas are applicable to the real world apply his ideas to his daily life? If so, take him seriously. Otherwise, ignore him. (If the fellow is doing pure mathematics or theology, or teaching poetry, then there is no problem. But if he is doing something applicable, then: red flag.)
This brings us to Triffat-type fakeness compared to Seneca, the talker versus the doer. I applied this method of ignoring what an academic writes and focusing on what he does when I met a researcher on happiness who held that
anything one makes beyond $50,000 does not bring any additional happiness
—he was then earning more than twice that at a university, so according to his metric he was safe. The argument seen through his “experiments” published in “highly cited papers” (that is, by other academics) seemed convincing on paper—although I am not particularly crazy about the notion of “happiness” or the vulgarity of the modern interpretation of “seeking happiness.” So, like an idiot, I believed him. But a year or so later, I heard that he was particularly avid for dollars and spent his time on the road speaking for fees. That, to me, was more sufficient evidence than thousands of citations.
Champagne Socialism
Another blatant case of insulation. Sometimes the divorce between one’s “tawk” and one’s life can be overtly and convincingly visible: take people who want others to live a certain way but don’t really like it for themselves.
Never listen to a leftist who does not give away his fortune or does
not live the exact lifestyle he wants others to follow. What the French call “the caviar left,”
la gauche caviar,
or what Anglo-Saxons call champagne socialists, are people who advocate socialism, sometimes even communism, or some political system with sumptuary limitations, while overtly leading a lavish lifestyle, often financed by inheritance—not realizing the contradiction that they want others to avoid just such a lifestyle. It is not too different from the womanizing popes, such as John XII, or the Borgias. The contradiction can exceed the ludicrous as with French president François Mitterrand of France who, coming in on a socialist platform, emulated the pomp of French monarchs. Even more ironic, his traditional archenemy, the conservative General de Gaulle, led a life of old-style austerity and had his wife sew his socks.
I have witnessed even worse. A former client of mine, a rich fellow with what appeared to be a social mission, tried to pressure me to write a check to a candidate in an election on a platform of higher taxes. I resisted, on ethical grounds. But I thought that the fellow was heroic, for, should the candidate win, his own taxes would increase by a considerable amount. A year later I discovered that the client was being investigated for his involvement in a very large scheme to be shielded from taxes. He wanted to be sure that
others
paid more taxes.
I developed a friendship over the past few years with the activist Ralph Nader and saw contrasting attributes. Aside from an astonishing amount of personal courage and total indifference toward smear campaigns, he exhibits absolutely no divorce between what he preaches and his lifestyle, none. Just like saints who have soul in their game. The man is a secular saint.
Soul in the Game
There is a class of people who escape bureaucrato-journalistic “tawk”: those who have more than their skin in the game.
They have their soul in the game.
Consider prophets. Prophecy is a pledge of belief, little else. A prophet is not someone who first had an idea; he is the one to first believe in it—and take it to its conclusion.
Chapter 20
discussed prophecy, when done right, as subtraction, and detection of fragility. But if having skin in the game (and accepting downside) is what distinguishes the genuine thinker from ex post “tawk,” there is one step beyond needed to reach the rank of prophet. It
is a matter of commitment, or what philosophers call
doxastic commitment,
a type of belief-pledge that to Fat Tony and Nero needed to be translated into deeds (the reverse-Stiglitz).
Doxa
in Greek used to mean “belief,” but distinguished from “knowledge” (episteme); to see how it involves a commitment of sorts beyond just words, consider that in church Greek it took the meaning of
glorification
.
Incidentally, this notion also applies to all manner of ideas and theories: the main person behind a theory, the person to be called the originator, is someone who believed in it, in a doxastic way, with a costly commitment to take it to its natural conclusion; and not necessarily the first person to mention it over dessert wine or in a footnote.
Only he who has true beliefs will avoid eventually contradicting himself and falling into the errors of postdicting.


================================================================================
CHAPTER/SECTION 118 (Item 121)
================================================================================

OPTIONS, ANTIFRAGILITY, AND SOCIAL FAIRNESS
The stock market: the greatest, industrial-sized, transfer of antifragility in history—due to a vicious form of asymmetric skin in the game. I am not talking about investment here—but the current system of packaging investments into shares of “public” corporations, with managers allowed to game the system, and of course, getting more prestige than the real risk takers, the entrepreneurs.
A blatant manifestation of the agency problem is the following. There is a difference between a manager running a company that is not his own and an owner-operated business in which the manager does not need to report numbers to anyone but himself, and for which he has a downside. Corporate managers have incentives without disincentives—something the general public doesn’t quite get, as they have the illusion that managers are properly “incentivized.” Somehow these managers have been given free options by innocent savers and investors. I am concerned here with managers of businesses that are
not
owner-operated.
As I am writing these lines the United States stock market has cost retirees more than three trillion dollars in losses over the past dozen years compared to leaving money in government money market funds (I am being generous, the difference is even higher), while managers of the companies composing the stock market, thanks to the asymmetry of the stock option, are richer by close to four hundred billion dollars. They pulled a Thales on these poor savers. Even more outrageous is the fate of the banking industry: banks have lost more than they ever made in
their history, with their managers being paid billions in compensation—taxpayers take the downside, bankers get the upside. And the policies aiming at correcting the problem are hurting innocent people while bankers are sipping the Rosé de Provence brand of summer wine on their yachts in St. Tropez.
The asymmetry is visibly present: volatility benefits managers since they only get one side of the payoffs. The main point (alas, missed by almost everyone) is that they stand to gain from volatility—the more variations, the more value to this asymmetry. Hence they are antifragile.
To see how transfer of antifragility works, consider two scenarios, in which the market does the same thing on average but following different paths.
Path 1: market goes up 50 percent, then goes back down to erase all gains.
Path 2: market does not move at all.
Visibly Path 1, the more volatile, is more profitable to the managers, who can cash in their stock options. So the more jagged the route, the better it is for them.
And of course society—here the retirees—has the exact opposite payoff since they finance bankers and chief executives. Retirees get less upside than downside. Society pays for the losses of the bankers, but gets no bonuses from them. If you don’t see this transfer of antifragility as theft, you certainly have a problem.
What is worse, this system is called “incentive-based” and supposed to correspond to capitalism. Supposedly managers’ interests are aligned with those of the shareholders. What incentive? There is upside and no downside, no disincentive at all.
The Robert Rubin Free Option
Robert Rubin, former treasury secretary, earned $120 million from Citibank in bonuses over about a decade. The risks taken by the institution were hidden but the numbers looked good … until they didn’t look good (upon the turkey’s surprise). Citibank collapsed, but he kept his money—we taxpayers had to compensate him retrospectively since the government took over the banks’ losses and helped them stand on their feet. This type of payoff is very common, thousands of other executives had it.
This is the same story as the one of the architect hiding risks in the
basement for delayed collapse and cashing big checks while protected by the complexities of the legal system.
Some people suggest enforcing a “clawback provision” as a remedy, which consists of making people repay past bonuses in cases of subsequent failure. It would be done as follows: managers cannot cash their bonuses immediately, they can only do so three or five years later if there are no losses. But this does not solve the problem: the managers still have a net upside, and no net downside. At no point is their own net worth endangered. So the system still contains a high degree of optionality and transfer of fragility.
The same applies to the fund manager involved in managing a pension fund—he, too, has no downside.
But bankers used to be subjected to Hammurabi’s rule. The tradition in Catalonia was to behead bankers in front of their own banks (bankers tended to skip town before failure was apparent, but that was the fate of at least one banker, Francesco Castello, in 1360). In modern times, only the mafia executes these types of strategies to remove the free option. In 1980, the “Vatican banker” Roberto Calvi, the chief executive of Banco Ambrosiano that went bust, ran to take refuge in London. There, he supposedly committed suicide—as if Italy was no longer a good place for acts of drama such as taking one’s own life. It was recently discovered that it was not quite suicide; the mafia killed him for losing their money. The same fate befell the Las Vegas pioneer Bugsy Siegel, who ran an unprofitable casino in which the mafia had investments.
And in some countries such as Brazil, even today, top bankers are made unconditionally liable to the extent of their own assets.
Which Adam Smith?
Many right-wingers-in-love-with-large-corporations keep citing Adam Smith, famous patron saint of “capitalism,” a word he never uttered, without reading him, using his ideas in a self-serving selective manner—ideas that he most certainly did not endorse in the form they are presented.
4
In
Book IV
of
The Wealth of Nations,
Smith was extremely chary of the idea of giving someone upside without downside and had doubts about the limited liability of joint-stock companies (the ancestor of the modern limited liability corporation). He did not get the idea of transfer of antifragility, but he came close enough. And he detected—sort of—the problem that comes with managing other people’s business, the lack of a pilot on the plane:
The directors of such companies, however, being the managers rather of other people’s money than of their own, it cannot well be expected, that they should watch over it with the same anxious vigilance with which the partners in a private copartnery frequently watch over their own.
Further, Smith is even suspicious of their economic performance as he writes: “Joint-stock companies for foreign trade have seldom been able to maintain the competition against private adventurers.”
Let me make the point clearer: the version of “capitalism” or whatever economic system you need to have is with the minimum number of people in the left column of the Triad. Nobody realizes that the central problem of the Soviet system was that it put everyone in charge of economic life in that nasty fragilizing left column.


================================================================================
CHAPTER/SECTION 119 (Item 122)
================================================================================

THE ANTIFRAGILITY AND ETHICS OF (LARGE) CORPORATIONS
Have you noticed that while corporations sell you junk drinks, artisans sell you cheese and wine? And there is a transfer of antifragility from the small in favor of the large—until the large goes bust.
The problem of the commercial world is that it only works by addition (
via positiva
), not subtraction (
via negativa
): pharmaceutical companies don’t gain if you avoid sugar; the manufacturer of health club machines doesn’t benefit from your deciding to lift stones and walk on rocks (without a cell phone); your stockbroker doesn’t gain from your decision to limit your investments to what you see with your own eyes, say your cousin’s restaurant or an apartment building in your neighborhood; all these firms have to produce “growth in revenues” to satisfy the metric of some slow thinking or, at best, semi-slow thinking MBA analyst sitting in New York. Of course they will eventually self-destruct, but that’s another conversation.
Now consider companies like Coke or Pepsi, which I assume are, as the reader is poring over these lines, still in existence—which is unfortunate. What business are they in? Selling you sugary water or substitutes for sugar, putting into your body stuff that messes up your biological signaling system,
causing
diabetes and making diabetes vendors rich thanks to their compensatory drugs. Large corporations certainly can’t make money selling you tap water and cannot produce wine (wine seems to be the best argument in favor of the artisanal economy). But they dress their products up with a huge marketing apparatus, with images that fool the drinker and slogans such as “125 years of providing happiness” or some such. I fail to see why the arguments we’ve used against tobacco firms don’t apply—to some extent—to all other large companies that try to sell us things that may make us ill.
The historian Niall Ferguson and I once debated the chairperson of Pepsi-Cola as part of an event at the New York Public Library. It was a great lesson in antifragility, as neither Niall nor I cared about who she was (I did not even bother to know her name). Authors are antifragile. Both of us came totally unprepared (not even a single piece of paper) and she showed up with a staff of aides who, judging from their thick files, had probably studied us down to our shoe sizes (I saw in the speakers’ lounge an aide perusing a document with an ugly picture of yours truly in my pre-bone-obsession, pre-weight-lifting days). We could say anything we wanted with total impunity and she had to hew to her party line, lest the security analysts issue a bad report that would cause a drop of two dollars and thirty cents in the stock price before the year-end bonus. In addition, my experience of company executives, as evidenced by their appetite for spending thousands of hours in dull meetings or reading bad memos, is that they cannot possibly be remarkably bright. They are no entrepreneurs—just actors, slick actors (business schools are more like acting schools). Someone intelligent—or free—would likely implode under such a regimen. So Niall immediately detected her weak point and went straight for the jugular: her slogan was that she contributed to employment by having six hundred thousand persons on her staff. He immediately exposed her propaganda with the counterargument—actually developed by Marx and Engels—that large bureaucratic corporations seized control of the state just by being “big employers,” and can then extract benefits at the expense of small businesses. So a company that employs six hundred thousand persons is allowed
to wreck the health of citizens with impunity, and to benefit from the implied protection of bailouts (just like American car companies), whereas artisans like hairdressers and cobblers do not get such immunity.
A rule then hit me: with the exception of, say, drug dealers, small companies and artisans tend to sell us healthy products, ones that seem naturally and spontaneously needed; larger ones—including pharmaceutical giants—are likely to be in the business of producing wholesale iatrogenics, taking our money, and then, to add insult to injury, hijacking the state thanks to their army of lobbyists. Further, anything that requires marketing appears to carry such side effects. You certainly need an advertising apparatus to convince people that Coke brings them “happiness”—and it works.
There are, of course, exceptions: corporations with the soul of artisans, some with even the soul of artists. Rohan Silva once remarked that Steve Jobs wanted the inside of the Apple products to look aesthetically appealing, although they are designed to remain unseen by the customer. This is something only a true artisan would do—carpenters with personal pride feel fake when treating the inside of cabinets differently from the outside. Again, this is a form of redundancy, one with an aesthetic and ethical payoff. But Steve Jobs was one of the rare exceptions in the Highly Talked About Completely Misunderstood Said to Be Efficient Corporate Global Economy.
Artisans, Marketing, and the Cheapest to Deliver
Another attribute of the artisanal. There is no product that I particularly like that I have discovered through advertising and marketing: cheeses, wine, meats, eggs, tomatoes, basil leaves, apples, restaurants, barbers, art, books, hotels, shoes, shirts, eyeglasses, pants (my father and I have used three generations of Armenian tailors in Beirut), olives, olive oil, etc. The same applies to cities, museums, art, novels, music, painting, sculpture (I had at some point an obsession with ancient artifacts and Roman heads). These may have been “marketed” in some sense, by making people aware of their existence, but this isn’t how I came to use them—word of mouth is a potent naturalistic filter. Actually, the only filter.
The mechanism of
cheapest-to-deliver-for-a-given-specification
pervades whatever you see on the shelves. Corporations, when they sell
you what they call cheese, have an incentive to provide you with the cheapest-to-produce piece of rubber containing the appropriate ingredients that can still be called cheese—and do their homework by studying how to fool your taste buds. Actually, it is more than just an incentive: they are structurally designed and extremely expert at delivering the cheapest possible product that meets their specifications. The same with, say, business books: publishers and authors want to grab your attention and put in your hands the most perishable journalistic item available that still can be called a book. This is optimization at work, in maximizing (image and packaging) or minimizing (costs and efforts).
I said about marketing by soft drink companies that it is meant to maximally confuse the drinker. Anything one needs to market heavily is necessarily either an inferior product or an evil one. And it is highly unethical to portray something in a more favorable light than it actually is. One may make others aware of the existence of a product, say a new belly dancing belt, but I wonder why people don’t realize that, by definition, what is being marketed is necessarily inferior, otherwise it would not be advertised.
Marketing is bad manners—and I rely on my naturalistic and ecological instincts. Say you run into a person during a boat cruise. What would you do if he started boasting of his accomplishments, telling you how great, rich, tall, impressive, skilled, famous, muscular, well educated, efficient, and good in bed he is, plus other attributes? You would certainly run away (or put him in contact with another talkative bore to get rid of both of them). It is clearly much better if others (preferably someone other than his mother) are the ones saying good things about him, and it would be nice if he acted with some personal humility.
Actually this is not at all far-fetched. As I was writing this book, I overheard on a British Air flight a gentleman explain to the flight attendant less than two seconds into the conversation (meant to be about whether he liked cream and sugar in his coffee) that he won the Nobel Prize in Medicine “and Physiology” in addition to being the president of a famous monarchal academy. The flight attendant did not know what the Nobel was, but was polite, so he kept repeating “the Nobel Prize” hoping that she would wake up from her ignorance. I turned around and recognized him, and the character suddenly deflated. As the saying goes, it is hardest to be a great man to one’s chambermaid. And marketing beyond conveying information is insecurity.
We accept that people who boast are boastful and turn people off. How about companies? Why aren’t we turned off by companies that advertise how great they are? We have three layers of violations:
First layer, the mild violation: companies are shamelessly self-promotional, like the man on the British Air flight, and it only harms them. Second layer, the more serious violation: companies trying to represent themselves in the most favorable light possible, hiding the defects of their products—still harmless, as we tend to expect it and rely on the opinion of users. Third layer, the even more serious violation: companies trying to misrepresent the product they sell by playing with our cognitive biases, our unconscious associations, and that’s sneaky. The latter is done by, say, showing a poetic picture of a sunset with a cowboy smoking and forcing an association between great romantic moments and some given product that, logically, has no possible connection to it. You seek a romantic moment and what you get is cancer.
It seems that the corporate system pushes companies progressively into the third layer. At the core of the problem with capitalism—again, please do not invoke Adam Smith—lies the problem of units that are different from individuals. A corporation does not have natural ethics; it just obeys the balance sheet. The problem is that its sole mission is the satisfaction of some metric imposed by security analysts, themselves (very) prone to charlatanism.
A (publicly listed) corporation does not feel shame. We humans are restrained by some physical, natural inhibition.
A corporation does not feel pity.
A corporation does not have a sense of honor—while, alas, marketing documents mention “pride.”
A corporation does not have generosity. Only self-serving actions are acceptable. Just imagine what would happen to a corporation that decided to unilaterally cancel its receivables—just to be nice. Yet societies function thanks to random acts of generosity between people, even sometimes strangers.
All of these defects are the result of the absence of skin in the game, cultural or biological—an asymmetry that harms others for their benefit.
Now, such systems should tend to implode. And they do. As they say, you can’t fool too many people for too long a period of time. But the problem of implosion is that it does not matter to the managers—because of the agency problem, their allegiance is to their own personal cash flow. They will not be harmed by subsequent failures; they will keep
their bonuses, as there is currently no such thing as negative manager compensation.
In sum, corporations are so fragile, long-term, that they eventually collapse under the weight of the agency problem, while managers milk them for bonuses and ditch the bones to taxpayers. They would collapse sooner if not for the lobby machines: they start hijacking the state to help them inject sugary drinks into your esophagus. In the United States large corporations control some members of Congress. All this does is delay the corporation’s funeral at our expense.
5
Lawrence of Arabia or Meyer Lansky
Finally, if you ever have to choose between a mobster’s promise and a civil servant’s, go with the mobster. Any time. Institutions do not have a sense of honor, individuals do.
During the Great War, T. E. Lawrence, nicknamed Lawrence of Arabia, struck a deal with the Arab desert tribes to help the British against the Ottoman Empire. His promise: to deliver to them in return an Arab state. As the tribes did not know better, they made good on their side of the bargain. But, it turned out, the French and British governments had made a secret agreement, the Sykes-Picot Agreement, to divide the area in question between themselves. After the war, Lawrence went back to live in the U.K., supposedly in a state of frustration, but, of course, not much more. But he left us with a good lesson: never trust the words of a man who is not free.
Now on the other hand, a mobster’s greatest asset is that “his word is gold.” It was said that “a handshake from the famous mobster Meyer Lansky was worth more than the strongest contracts that a battery of lawyers could put together.” In fact he held in his mind the assets and liabilities of the Sicilian mafia, and was their bank account, without a single record. Just his honor.
As a trader I never trusted transactions with “representatives” of institutions; pit traders are bound by their bonds, and I’ve never known a single self-employed trader over a two-decade-long career who did not live up to his handshake.
Only a sense of honor can lead to commerce. Any commerce.
Next
We saw how, thanks to the misunderstanding of antifragility (and asymmetry or convexity), some classes of people use hidden options and harm the collective without anyone realizing. We also saw the solution in forcing skin in the game. Next, we will look at another form of optionality: how people can cherry-pick ethical rules to fit their actions. Or how they use public office as a means to satisfy personal greed.
1
GSE is Fannie Mae and Freddie Mac—they both blew up.
2
I find it truly disgusting that one of the Orszag brothers, Peter, after the crisis got a job with the Obama administration—another rehiring of blindfolded bus drivers. Then he became vice chairman of Citibank, which explains why Citibank will blow up again (and we taxpayers will end up subsidizing his high salary).
3
My suggestion to deter “too big to fail” and prevent employers from taking advantage of the public is as follows. A company that is classified as potentially
bailable out
should it fail should not be able to pay anyone more than a corresponding civil servant. Otherwise people should be free to pay each other what they want since it does not affect the taxpayer. Such limitation would force companies to stay small enough that they would not be considered for a bailout in the event of their failure.
4
I have had the same experience with journalists citing each other about my books without the smallest effort to go to my writings—my experience is that most journalists, professional academics, and other in similar phony professions don’t read original sources, but each other, largely because they need to figure out the consensus before making a pronouncement.
5
There seems to be a survival advantage to small or medium-sized owner-operated or family-owned companies.


================================================================================
CHAPTER/SECTION 120 (Item 123)
================================================================================

CHAPTER 24
Fitting Ethics to a Profession
How the slaves can snatch control—Squeezing the sissies—The tantalized class, permanently tantalized
At no time in the history of mankind has the following situation been seen in such an acute form. Say Mr. John Smith Jr., JD, is employed as lobbyist for the tobacco industry in Washington, D.C., which, as we all know, is engaged in the business of killing people for profit (we saw with the powers of subtraction that if we stopped such industries from existing by, say, banning cigarettes, then everything else done by medicine becomes a footnote). Ask any of his relatives (or friends) why they can tolerate it and don’t just ostracize him or harass him to tears, avoid him at the next family funeral. The answer is likely to be “everyone needs to make a living”—as they are hedging the possibility of their falling into the same situation some day.
We need to test the direction of the arrow (using the same logic as in our discussion of lecturing birds on flying):
Ethics (and Beliefs)
→
Profession
or
Profession
→
Ethics (and Beliefs)
Prior to Fat Tony’s debate with Socrates, Nero was curious about the first minute of encounter, since there is a gap of about twenty-five centuries. It is not a simple matter to identify the elements of our physical environment that would surprise Socrates the most. Questioned on the point by Fat Tony, who had some grudging respect for Nero’s knowledge of history, Nero’s speculative reply was “It would most certainly be the absence of slaves.”
“These people never did small domestic things themselves. So imagine Socrates’ sorry figure of a bulging belly, spindly legs, wondering
Opou oi douloi?
”
“But, Neeroh Toolip, there are still slaves around,” Fat Tony blurted out. “They often distinguish themselves by wearing this intricate device called a necktie.”
Nero: “Signore Ingeniere Tony, some of these tie-wearers are very rich, even richer than you.”
Tony: “Nero, you sucker. Don’t be fooled by money. These are just numbers. Being self-owned is a state of mind.”
Wealth Without Independence
There is a phenomenon called the
treadmill effect,
similar to what we saw with neomania: you need to make more and more to stay in the same place. Greed is antifragile—though not its victims.
Back to the sucker problem in believing that wealth makes people more independent. We need no more evidence for it than what is taking place now: recall that we have never been richer in the history of mankind. And we have never been more in debt (for the ancients, someone in debt was not free, he was in bondage). So much for “economic growth.”
At the local level, it looks like we get socialized in a certain milieu, hence exposed to a treadmill. You do better, move to Greenwich, Connecticut, then become a pauper next to a twenty-million-dollar mansion and million-dollar birthday parties. And you become more and more dependent on your job, particularly as your neighbors get big tax-sponsored Wall Street bonuses.
This class of persons is like Tantalus, who was subjected to an eternal punishment: he stood in a pool of water underneath a fruit tree and whenever he tried to grab the fruit it moved away and whenever he tried to drink, the water receded.
And such a permanently tantalized class is a modern condition. The Romans circumvented these social treadmill effects: much of social life took place between a patron and his less fortunate clients who benefited from his largesse and ate at his table—and relied on his assistance in times of trouble. There was no welfare at the time, and no church to distribute or recommend charity: everything was private (Seneca’s book
De beneficiis
I mentioned earlier was exactly about which obligations one had in such situations). There was little exposure to the other wealthy biggies, just as mafia dons don’t socialize with other mafia dons but with their constituents. To a large extent, that’s how my grandfather and great-grandfather lived, as they were local landowners and politicians; power was accompanied by a coterie of dependents. Provincial landowners were required to maintain an occasional “open house,” with an open table for people to come help themselves to the fruits of the wealth. Court life, on the other hand, leads to corruption—the nobleman comes from the provinces, where he is now brought down to size; he faces more flamboyant, wittier persons and feels pressure to prop up his self-esteem. People who would have lost their status in the cities conserve it in the provinces.
You cannot possibly trust someone on a treadmill.


================================================================================
CHAPTER/SECTION 121 (Item 124)
================================================================================

THE PROFESSIONALS AND THE COLLECTIVE
It is a fact that one can rapidly, after a phase of indoctrination, become enslaved to a profession, to the point of having one’s opinions on any subject become self-serving, hence unreliable for the collective. This is the bone the Greeks had to pick with professionals.
One of my first jobs was for a Wall Street firm. After I’d been employed for a few months, the managing director called us up and told us that we needed to contribute to a few politicians’ campaigns, with a “recommended” payment of a certain proportion of our income. These politicians were said to be “good.” By “good” was meant good for their business of investment banking, as these politicians would help with legislation that would protect their business. Had I done that, I would no longer have been eligible ethically to voice a political opinion “for the sake of the public.”
In a story well argued throughout the centuries, Demades the Athenian condemned a man who traded in funeral goods on the grounds that he could only derive profits by the death of the great many people. Montaigne,
rephrasing the argument made by Seneca in his
De beneficiis,
argued that we would then be obligated to condemn every single professional. According to him, the merchant only thrives by the debauchery of youth, the farmer by the dearness of grain, the architect by the ruin of buildings, lawyers and officers of justice by the suits and contentions of men. A physician takes no pleasure in the health of even his friends, a soldier does not wish for the peace of his country, etc. And, even worse, should we go into people’s inner and private thoughts and motivations, we would see that their wishes and hopes are almost invariably at someone else’s expense.
But Montaigne and Seneca were a bit too indulgent toward self-interest and missed something quite central. They clearly got the point that economic life does not necessarily depend on altruistic motives, and that the aggregate works differently from the individual. Remarkably, Seneca was born about eighteen centuries before Adam Smith, and Montaigne about three, so we should be quite impressed with their thinking while retaining a certain abhorrence of the fundamental dishonesty of men. We have known since Adam Smith that the collective does not require the benevolence of individuals, as self-interest can be the driver of growth. But all this does not make people less unreliable
in their personal opinions
about the collective. For they are involving the skin of others, so to speak.
What Montaigne and Seneca missed, in addition to the notion of skin in the game, was that one can draw the line with public affairs. They missed the agency problem—although the problem was known heuristically (Hammurabi, golden rules), it was not part of their consciousness.
The point isn’t that making a living in a profession is inherently bad; rather, it’s that such a person becomes automatically suspect when dealing with public affairs, matters that involve others. The definition of the
free man,
according to Aristotle, is one who is free with his opinions—as a side effect of being free with his time.
Freedom in this sense is only a matter of sincerity in political opinions.
The Greeks saw the world in three professions. The
banausikai technai
, the artisans; the craft of war,
polemike techne;
and that of farming,
georgia
. The last two professions, war and farming, were worthy of a gentleman—mainly because they were not self-serving and were free of conflicts of interest with the collective. But the Athenians despised the
banausoi,
the artisans who worked for a living in dark rooms making
objects—generally sitting down. For Xenophon, such crafts degraded the craftsmen’s bodily strength, softened his spirit, and left him no time for his friends and city. The illiberal arts confine one to the workshop and narrow one’s interests
to his own welfare;
the crafts of war and farming give one a wider scope so that he can attend to his friends and city. To Xenophon, farming is the mother and nurse of the other
technai
. (The ancients did not have corporations; if Xenophon were alive today he would transfer his distrust from artisans to corporate employees.)
There are Arabic and Hebrew sayings,
Yad el hurr mizan / Yad ben horin moznayim
—“the hand of the free is a scale.” It is just that the definition of the free is not well understood: he is free who owns his own opinion.
For Metternich, humanity started at the rank of baron; for Aristotle, as well as, though in a separate form, the English up until the twentieth century, it started at the rank of idle freeman, unpreoccupied with work. It never meant
not
working; it just meant not deriving your personal and emotional identity from your work, and viewing work as something optional, more like a hobby. In a way your profession does not identify you so much as other attributes, here your birth (but it could be something else). This is the
f*** you money
that allowed Thales of Miletus to gauge his own sincerity. For the Spartans, it was all about courage. For Fat Tony, humanity started at the level of “self-ownership.”
Now self-ownership for our horizontal friend was vastly more democratic than for his thinking predecessors. It simply meant being the owner of your opinion. And it has nothing to do with wealth, birth, intelligence, looks, shoe size, rather with personal courage.
In other words, for Fat Tony, it was a very, very specific definition of a free person: someone who cannot be squeezed into doing something he would otherwise never do.
Consider this leap in sophistication from Athens to Brooklyn: if for the Greeks, only he who is free with his time is free with his opinion, for our horizontal friend and advisor, only he who has courage is free with his opinion.
Sissies are born, not made. They stay sissies no matter how much independence you give them, no matter how rich they get.
Another facet of the difference between abstract modernistic nation-states and local government. In an antique city-state, or a modern municipality, shame is the penalty for the violation of ethics—making things more symmetric. Banishment and exile, or, worse, ostracism were severe
penalties—people did not move around voluntarily and considered up-rooting a horrible calamity. In larger organisms like the mega holy nation-state, with a smaller role for face-to-face encounters, and social roots, shame ceases to fulfill its duty of disciplinarian. We need to reestablish it.
And aside from shame, there is friendship, socialization in a certain milieu, being part of a group of people that have diverging interests from the collective. Cleon, the hero of the Peloponnesian War, advocated the public renouncement of friends upon taking up public affairs—he paid for it with some revilement by historians.
A simple solution, but quite drastic: anyone who goes into public service should not be allowed to
subsequently
earn more from any commercial activity than the income of the highest paid civil servant. It is like a voluntary cap (it would prevent people from using public office as a credential-building temporary accommodation, then going to Wall Street to earn several million dollars). This would get priestly people into office.
Just as Cleon was reviled, in the modern world, there seems to be an inverse agency problem for those who do the right thing: you pay for your service to the public with smear campaigns and harassment. The activist and advocate Ralph Nader suffered numerous smear campaigns as the auto industry went after him.


================================================================================
CHAPTER/SECTION 122 (Item 125)
================================================================================

THE ETHICAL AND THE LEGAL
I felt ashamed not having exposed the following scam for a long time. (As I said,
if you see fraud
…) Let us call it the Alan Blinder problem.
The story is as follows. At Davos, during a private coffee conversation that I thought aimed at saving the world from, among other things, moral hazard and agency problems, I was interrupted by Alan Blinder, a former vice chairman of the Federal Reserve Bank of the United States, who tried to sell me a peculiar investment product that aims at legally hoodwinking taxpayers. It allowed the high net worth investor to get around the regulations limiting deposit insurance (at the time, $100,000) and benefit from coverage for near-unlimited amounts. The investor would deposit funds in any amount and Prof. Blinder’s company would break it up into smaller accounts and invest in banks, thus escaping the limit; it would look like a single account but would be insured in full. In
other words, it would allow the super-rich to scam taxpayers by getting free government-sponsored insurance. Yes,
scam
taxpayers. Legally. With the help of former civil servants who have an insider edge.
I blurted out: “Isn’t this unethical?” I was then told in response “It is perfectly legal,” adding the even more incriminating “we have plenty of former regulators on the staff,” (a) implying that what was legal was ethical and (b) asserting that former regulators have an edge over citizens.
It took a long time, a couple of years, before I reacted to the event and did my public
J’accuse
. Alan Blinder is certainly not the worst violator of my sense of ethics; he probably irritated me because of the prominence of his previous public position, while the Davos conversation was meant to save the world from evil (I was presenting to him my idea of how bankers take risks at the expense of taxpayers). But what we have here is a model of how people use public office to, at some point, legally profit from the public.
Tell me if you understand the problem in its full simplicity: former regulators and public officials who were employed by the citizens to represent their best interests can use the expertise and contacts acquired on the job to benefit from glitches in the system upon joining private employment—law firms, etc.
Think about it a bit further: the more complex the regulation, the more bureaucratic the network, the more a regulator who knows the loops and glitches would benefit from it later, as his regulator edge would be a convex function of his differential knowledge. This is a franchise, an asymmetry one has at the expense of others. (Note that this franchise is spread across the economy; the car company Toyota hired former U.S. regulators and used their “expertise” to handle investigations of its car defects.)
Now stage two—things get worse. Blinder and the dean of Columbia University Business School wrote an op-ed opposing the government’s raising the insurance limit on individuals. The article argued that the public should not have the unlimited insurance that Blinder’s clients benefit from.
A few remarks.
First, the more complicated the regulation, the more prone to arbitrages by insiders. This is another argument in favor of heuristics. Twenty-three hundred pages of regulation—something I can replace
with Hammurabi’s rule—will be a gold mine for former regulators. The incentive of a regulator is to have complex regulation. Again, the insiders are the enemies of the
less-is-more
rule.
Second, the difference between the letter and the spirit of regulation is harder to detect in a complex system. The point is technical, but complex environments with nonlinearities are easier to game than linear ones with a small number of variables. The same applies to the gap between the legal and the ethical.
Third, in African countries, government officials get explicit bribes. In the United States they have the implicit, never mentioned, promise to go work for a bank at a later date with a sinecure offering, say $5 million a year, if they are seen favorably by the industry. And the “regulations” of such activities are easily skirted.
What upset me the most about the Alan Blinder problem is the reactions by those with whom I discussed it: people found it natural that a former official would try to “make money” thanks to his former position—at our expense.
Don’t people like to make money?
goes the argument.
Casuistry as Optionality
You can always find an argument or an ethical reason to defend an opinion ex post. This is a dicey point, but, as with cherry-picking, one should propose an ethical rule before an action, not after. You want to prevent fitting a narrative to what you are doing—and for a long time “casuistry,” the art of arguing the nuances of decisions, was just that, fitting narratives.
Let me first define a fraudulent opinion. It is simply one with vested interests generalized to the public good—in which, say a hairdresser recommends haircuts “for the health of people,” or a gun lobbyist claims gun ownership is “good for America,” simply making statements that benefit him personally, while the statements are dressed up to look as if they were made for the benefit of the collective. In other words, is he in the left column of
Table 7
? Likewise, Alan Blinder wrote that he opposed generalized deposit insurance, not because his company would lose business, but
because of the public good
.
But the heuristic is easy to implement, with a simple question. I was in Cyprus at a conference dinner in which another speaker, a Cypriot
professor of petrochemical engineering in an American university, was ranting against the climate activist Lord Nicholas Stern. Stern was part of the conference but absent from the dinner. The Cypriot was extremely animated. I had no idea what the issues were, but saw the notion of “absence of evidence” mixed with “evidence of absence” and pounced on him in defense of Stern, whom I had never met. The petrochemical engineer was saying that we had
no evidence
that fossil fuels caused harm to the planet, turning his point semantically into something equivalent in decision making to the statement that that we had
evidence that fossil fuels did not harm
. He made the mistake of saying that Stern was recommending useless insurance, causing me to jump to ask him if he had car, health, and other insurance for events that did not take place, that sort of argument. I started bringing up the idea that we are doing something new to the planet, that the burden of evidence is on those who disturb natural systems, that Mother Nature knows more than he will ever know, not the other way around. But it was like talking to a defense lawyer—sophistry, and absence of convergence to truth.
Then a heuristic came to mind. I surreptitiously asked a host sitting next to me if the fellow had anything to gain from his argument: it turned out that he was deep into oil companies, as an advisor, an investor, and a consultant. I immediately lost interest in what he had to say and the energy to debate him in front of others—his words were nugatory, just babble.
Note how this fits into the idea of skin in the game. If someone has an opinion, like, say, the banking system is fragile and should collapse, I want him invested in it so he is harmed if the audience for his opinion are harmed—as a token that he is not an empty suit. But when general statements about the collective welfare are made, instead,
absence
of investment is what is required.
Via negativa.
I have just presented the mechanism of ethical optionality by which
people fit their beliefs to actions rather than fit their actions to their beliefs
.
Table 8
compares professions with respect to such ethical backfitting.
Click
here
for a larger image of this table.
There exists an inverse Alan Blinder problem, called “evidence against one’s interest.” One should give more weight to witnesses and opinions when they present the opposite of a conflict of interest. A pharmacist or an executive of Big Pharma who advocates starvation and
via negativa
methods to cure diabetes would be more credible than another one who favors the ingestion of drugs.


================================================================================
CHAPTER/SECTION 123 (Item 126)
================================================================================

BIG DATA AND THE RESEARCHER’S OPTION
This is a bit technical, so the reader can skip this section with no loss. But optionality is everywhere, and here is a place to discuss a version of cherry-picking that destroys the entire spirit of research and makes the abundance of data extremely harmful to knowledge. More data means more information, perhaps, but it also means more false information. We are discovering that fewer and fewer papers replicate—textbooks in, say, psychology need to be revised. As to economics, fuhgetaboudit. You can hardly trust many statistically oriented sciences—especially when the researcher is under pressure to publish for his career. Yet the claim will be “to advance knowledge.”
Recall the notion of epiphenomenon as a distinction between real life and libraries. Someone looking at history from the vantage point of a library will necessarily find many more spurious relationships than
one who sees matters in the making, in the usual sequences one observes in real life. He will be duped by more epiphenomena, one of which is the direct result of the excess of data as compared to real signals.
We discussed the rise of noise in
Chapter 7
. Here it becomes a worse problem, because there is an optionality on the part of the researcher, no different from that of a banker. The researcher gets the upside, truth gets the downside. The researcher’s free option is in his ability to pick whatever statistics can confirm his belief—or show a good result—and ditch the rest. He has the
option
to stop once he has the right result. But beyond that, he can find statistical relationships—the spurious rises to the surface. There is a certain property of data: in large data sets, large deviations are vastly more attributable to noise (or variance) than to information (or signal).
1
FIGURE 18.
The Tragedy of Big Data. The more variables, the more correlations that can show significance in the hands of a “skilled” researcher. Falsity grows faster than information; it is nonlinear (convex) with respect to data.
There is a difference in medical research between (a) observational studies, in which the researcher looks at statistical relationships on his computer, and (b) the double-blind cohort experiments that extract information in a realistic way that mimics real life.
The former, that is, observation from a computer, produces all manner
of results that tend to be, as last computed by John Ioannides, now more than eight times out of ten, spurious—yet these observational studies get reported in the papers and in
some
scientific journals. Thankfully, these observational studies are not accepted by the Food and Drug Administration, as the agency’s scientists know better. The great Stan Young, an activist against spurious statistics, and I found a genetics-based study in
The New England Journal of Medicine
claiming significance from statistical data—while the results to us were no better than random. We wrote to the journal, to no avail.
Figure 18
shows the swelling number of potential spurious relationships. The idea is as follows. If I have a set of 200 random variables, completely unrelated to each other, then it would be near impossible not to find in it a high correlation of sorts, say 30 percent, but that is entirely spurious. There are techniques to control the cherry-picking (one of which is known as the Bonferoni adjustment), but even then they don’t catch the culprits—much as regulation doesn’t stop insiders from gaming the system. This explains why in the twelve years or so since we’ve decoded the human genome, not much of significance has been found. I am not saying that there is no information in the data: the problem is that the needle comes in a haystack.
Even experiments can be marred with bias: the researcher has the incentive to select the experiment that corresponds to what he was looking for, hiding the failed attempts. He can also formulate a hypothesis after the results of the experiment—thus fitting the hypothesis to the experiment. The bias is smaller, though, than in the previous case.
The fooled-by-data effect is accelerating. There is a nasty phenomenon called “Big Data” in which researchers have brought cherry-picking to an industrial level. Modernity provides too many variables (but too little data per variable), and the spurious relationships grow much, much faster than real information, as noise is convex and information is concave.
Increasingly, data can only truly deliver
via negativa
–style knowledge—it can be effectively used to debunk, not confirm.
The tragedy is that it is very hard to get funding to replicate—and reject—existing studies. And even if there were money for it, it would be hard to find takers: trying to replicate studies will not make anyone a hero. So we are crippled with a distrust of empirical results, except for those that are negative. To return to my romantic idea of the amateur and tea-drinking English clergyman: the professional researcher competes
to “find” relationships. Science must not be a competition; it must not have rankings—we can see how such a system will end up blowing up. Knowledge must not have an agency problem.


================================================================================
CHAPTER/SECTION 124 (Item 127)
================================================================================

THE TYRANNY OF THE COLLECTIVE
Mistakes made collectively, not individually, are the hallmark of organized knowledge—and the best argument against it. The argument “because everyone is doing it” or “that’s how others do it” abounds. It is not trivial: people who on their own would not do something because they find it silly now engage in the same thing but in groups. And this is where academia in its institutional structure tends to violate science.
One doctoral student at the University of Massachusetts, Chris S., once came to tell me that he believed in my ideas of “fat tails” and my skepticism of current methods of risk management, but that it would not help him get an academic job. “It’s what everybody teaches and uses in papers,” he said. Another student explained that he wanted a job at a good university so he could make money testifying as an expert witness—they would not buy my ideas on robust risk management because “everyone uses these textbooks.” Likewise, I was asked by the administration of a university to teach standard risk methods that I believe are pure charlatanism (I refused). Is my duty as a professor to get students a job at the expense of society, or to fulfill my civic obligations? Well, if the former is the case, then economics and business schools have a severe ethical problem. For the point is generalized and that’s why economics hasn’t collapsed yet in spite of the obvious nonsense in it—and
scientifically proven
nonsense in it. (In my “fourth quadrant” paper—see discussion in the Appendix—I show how these methods are empirically invalid, in addition to being severely mathematically inconsistent, in other words, a scientific swindle). Recall that professors are not penalized when they teach you something that blows up the financial system, which perpetuates the fraud. Departments need to teach
something
so students get jobs, even if they are teaching snake oil—this got us trapped in a circular system in which everyone knows that the material is wrong but nobody is free enough or has enough courage to do anything about it.
The problem is that the last place on the planet where the “other people think so” argument can be used is science: science is precisely about arguments standing on their own legs, and something proven to
be wrong empirically or mathematically is plain wrong, whether a hundred “experts” or three trillion disagree with the statement. And the very use of “other people” to back up one’s claims is indicative that the person—or the entire collective that composes the “other”—is a wimp. The appendix shows what has been busted in economics, and what people keep using because they are not harmed by error, and that’s the optimal strategy for keeping a job or getting a promotion.
But the good news is that I am convinced that a single person with courage can bring down a collective composed of wimps.
And here, once again, we need to go back into history for the cure. The scriptures were quite aware of the problem of the diffusion of responsibility and made it a sin to follow the crowd in doing evil—as well as to give false testimony in order to conform to the multitude.
I close
Book VII
with a thought. Whenever I hear the phrase “I am ethical” uttered, I get tense. When I hear about classes in ethics, I get even more tense. All I want is to remove the optionality, reduce the antifragility of some at the expense of others. It is simple
via negativa
. The rest will take care of itself.
1
It is a property of sampling. In real life, if you are observing things in real time, then large deviations matter a lot. But when a researcher looks for them, then they are likely to be bogus—in real life there is no cherry-picking, but on the researcher’s computer, there is.


================================================================================
CHAPTER/SECTION 125 (Item 128)
================================================================================

CHAPTER 25
Conclusion
As usual at the end of the journey, while I was looking at the entire manuscript on a restaurant table, someone from a Semitic culture asked me to explain my book standing on one leg. This time it was Shaiy Pilpel, a probabilist with whom I’ve had a two-decades-long calm conversation without a single episode of small talk. It is hard to find people knowledgeable and confident enough to like to extract the essence of things, instead of nitpicking.
With the previous book, one of his compatriots asked me the same question, but I had to think about it. This time I did not even have to make an effort.
It was so obvious that Shaiy summed it up it himself in the same breath. He actually believes that all real ideas can be distilled down to a central issue that the great majority of people in a given field, by dint of specialization and empty-suitedness, completely miss. Everything in religious law comes down to the refinements, applications, and interpretations of the Golden Rule, “Don’t do unto others what you don’t want them to do to you.” This we saw was the logic behind Hammurabi’s rule. And the Golden Rule was a true distillation, not a Procrustean bed. A central argument is never a summary—it is more like a generator.
Shaiy’s extraction was:
Everything gains or loses from volatility
.
Fragility is what loses from volatility and uncertainty
. The glass on the table is short volatility.
In the novel
The Plague
by Albert Camus, a character spends part of his life searching for the perfect opening sentence for a novel. Once he
had that sentence, he had the full book as a derivation of the opening. But the reader, to understand and appreciate the first sentence, will have to read the entire book.
I glanced at the manuscript with a feeling of calm elation. Every sentence in the book was a derivation, an application, or an interpretation of the short maxim. Some details and extensions can be counterintuitive and elaborate, particularly when it comes to decision making under opacity, but at the end everything flows from it.
The reader is invited to do the same. Look around you, at your life, at objects, at relationships, at entities. You may replace
volatility
with other members of the disorder cluster here and there for clarity, but it is not even necessary—when formally expressed, it is all the same symbol. Time is volatility. Education, in the sense of the formation of character, personality, and acquisition of true knowledge, likes disorder; label-driven education and educators abhor disorder. Some things break because of error, others don’t. Some theories fall apart, not others. Innovation is precisely something that gains from uncertainty: and some people sit around waiting for uncertainty and using it as raw material, just like our ancestral hunters.
Prometheus is long disorder; Epimetheus is short disorder. We can separate people and the quality of their experiences based on exposure to disorder and appetite for it: Spartan hoplites contra bloggers, adventurers contra copy editors, Phoenician traders contra Latin grammarians, and pirates contra tango instructors.
It so happens that everything nonlinear is convex or concave, or both, depending on the intensity of the stressor. We saw the link between convexity and liking volatility. So everything likes or hates volatility up to a point. Everything.
We can detect what likes volatility thanks to convexity or acceleration and higher orders, since convexity is the response by a thing that likes disorder. We can build Black Swan–protected systems thanks to detection of concavity. We can take medical decisions by understanding the convexity of harm and the logic of Mother Nature’s tinkering, on which side we face opacity, which error we should risk. Ethics is largely about stolen convexities and optionality.
More technically, we may never get to know
x,
but we can play with the exposure to
x,
barbell things to defang them; we can control a function of
x, f
(
x
), even if
x
remains vastly beyond our understanding. We
can keep changing
f
(
x
) until we are comfortable with it by a mechanism called
convex transformation,
the fancier name for the barbell.
This short maxim also tells you where fragility supersedes truth, why we lie to children, and why we humans got a bit ahead of ourselves in this large enterprise called modernity.
Distributed randomness (as opposed to the concentrated type) is a necessity, not an option: everything big is short volatility. So is everything fast. Big and fast are abominations. Modern times don’t like volatility.
And the Triad gives us some indication of what should be done to live in a world that does not want us to understand it, a world whose charm comes from our inability to truly understand it.
The glass is dead; living things are long volatility. The best way to verify that you are alive is by checking if you like variations. Remember that food would not have a taste if it weren’t for hunger; results are meaningless without effort, joy without sadness, convictions without uncertainty, and an ethical life isn’t so when stripped of personal risks.
And once again, reader, thank you for reading my book.


================================================================================
CHAPTER/SECTION 126 (Item 129)
================================================================================

EPILOGUE
From Resurrection to Resurrection
It was an aortic aneurism.
Nero was in the Levant for his annual celebration of the death and rebirth of Adonis. It was a period of mourning with wailing women, followed by a celebration of resurrection. He watched nature waking up from the mild Mediterranean winter, when the rivers are full of reddish water, the blood of the Phoenician god wounded by the boar, as the melted snow from the mountains swelled the rivers and rivulets.
Things in nature move ahead from resurrection to resurrection.
That was when Tony’s driver called. His name was also Tony, and while identified as Tony-the-driver he pretended he was a bodyguard (when in fact it looked like, given the comparative size, he was the one bodyguarded by Tony). Nero never liked him, always had that strange feeling of distrust, so the moment of sharing the news was odd. During his silence on the line, he felt sympathy for Tony-the-driver.
Nero was designated as the executor of Tony’s will, which made him initially nervous. He had somehow a fear that Tony’s wisdom would have a gigantic Achilles’ heel somewhere. But, it turned out, there was nothing serious, a flawless estate, of course debt-free, conservative, fairly distributed. There were some funds to discreetly provide to a woman likely to be a prostitute, for whom Tony had some antifragile obsessive love, of course helped by the fact that she was both older and much less attractive than Tony’s wife, that sort of thing. So nothing serious.
Except for the posthumous prank. Tony bequeathed to Nero a sum of twenty million dollars to spend at his discretion on … It was to be a secret mission; noble of course, but secret. And, of course, vague. And dangerous. It was the best compliment Nero ever got from Tony: trusting that Nero would be able to read his mind.
Which he did.


================================================================================
CHAPTER/SECTION 127 (Item 130)
================================================================================

GLOSSARY
Triad:
The triplet Antifragility, Robustness, Fragility.
Fundamental Asymmetry
(also
Seneca’s Asymmetry
): When someone has
more upside than downside
in a certain situation, he is antifragile and tends to gain from (a) volatility, (b) randomness, (c) errors, (d) uncertainty, (e) stressors, (f) time. And the reverse.
Procrustean bed
: Procrustes got people to fit perfectly into his bed by cutting or stretching their limbs. Corresponds to situations in which simplifications are not simplifications.
Fragilista
: Someone who causes fragility because he thinks he understands what’s going on. Also usually lacks sense of humor. See
Iatrogenics.
Often Fragilistas fragilize by depriving variability-loving systems of variability and error-loving systems of errors. They tend to mistake organisms for machines and engineering projects.
Lecturing-Birds-How-to-Fly Effect
: Inverting the arrow of knowledge to read academia → practice, or education → wealth, to make it look as though technology owes more to institutional science than it actually does.
Touristification
: The attempt to suck randomness out of life. Applies to soccer moms, Washington civil servants, strategic planners, social engineers, “nudge” manipulators, etc. Opposite:
rational flâneur.
Rational flâneur
(or just
flâneur
): Someone who, unlike a tourist, makes a decision opportunistically at every step to revise his schedule (or his
destination) so he can imbibe things based on new information obtained. In research and entrepreneurship, being a flâneur is called “looking for optionality.” A non-narrative approach to life.
Barbell Strategy
: A dual strategy, a combination of two extremes, one safe and one speculative, deemed more robust than a “monomodal” strategy; often a necessary condition for antifragility. For instance, in biological systems, the equivalent of marrying an accountant and having an occasional fling with a rock star; for a writer, getting a stable sinecure and writing without the pressures of the market during spare time. Even trial and error are a form of barbell.
Iatrogenics
: Harm done by the healer, as when the doctor’s interventions do more harm than good.
Generalized Iatrogenics
: By extension, applies to the harmful side effects of actions by policy makers and activities of academics.
Tantalized Class
: An economic condition of making more than minimum wage
and
wishing for more wealth. Workers, monks, hippies, some artists, and English aristocrats escape it. The middle class tends to fall into it; so do Russian billionaires, lobbyists, most bankers, and bureaucrats. Members are bribable provided they are given an adequate narrative, mostly with the use of casuistry.
Black Swan Errors
Nonpredictive Approach
: Building stuff in a manner immune to perturbations—hence robust to changes in future outcomes.
Thalesian versus Aristotelian
: The Thalesian focuses on exposure, payoff from decision; the Aristotelian focuses on logic, the True-False distinction. For Fat Tony, the problem is all about sucker-nonsucker, or risks and rewards. (Also see
nonlinearities
,
convexity effects
.)
Conflation of Event and Exposure
: Mistaking a function of a variable for the variable itself.
Naturalistic Risk Management
: The belief that, when it comes to risk management, Mother Nature has a much, much more significant track record than rationalistic humans. It is imperfect, but much better.
Burden of evidence
: The burden of evidence falls on those who disrupt the natural, or those who propose
via positiva
policies.
Ludic Fallacy
: Mistaking the well-posed problems of mathematics and laboratory experiments for the ecologically complex real world. Includes mistaking the randomness in casinos for that in real life.
Antifragile Tinkering, Bricolage
: A certain class of trial and error, with small errors being “the right” kind of mistakes. All equivalent to
rational flâneur.
Hormesis
: A bit of a harmful substance, or stressor, in the right dose or with the right intensity, stimulates the organism and makes it better, stronger, healthier, and prepared for a stronger dose the next exposure. (Think of bones and karate.)
Naive Interventionism
: Intervention with disregard to
iatrogenics.
The preference, even obligation, to “do something” over doing nothing. While this instinct can be beneficial in emergency rooms or ancestral environments, it hurts in others in which there is an “expert problem.”
Naive Rationalism
: Thinking that the reasons for things are, by default, accessible to university buildings. Also called the
Soviet-Harvard illusion.
Turkey and Inverse Turkey
: The turkey is fed by the butcher for a thousand days, and every day the turkey pronounces with increased statistical confidence that the butcher “will never hurt it”—until Thanksgiving, which brings a Black Swan revision of belief for the turkey. The
inverse turkey
error is the mirror confusion, not seeing opportunities—pronouncing that one has evidence that someone digging for gold or searching for cures will “never find” anything.
Doxastic Commitment
, or
“Soul in the Game”
: You must only believe predictions and opinions by those who committed themselves to a certain
belief, and had something to lose, in a way to pay a cost in being wrong.
Heuristics
: Simple, practical, easy-to-apply rules of thumb that make life easy. These are necessary (we do not have the mental power to absorb all information and tend to be confused by details) but they can get us in trouble as we do not know we are using them when forming judgments.
Opaque Heuristic
: Routine performed by societies that does not seem to make sense yet has been done for a long time and sticks for unknown reasons.
Dionysian
: Opaque heuristic seemingly irrational, named after Dionysos (or Bacchus for Romans), the god of wine and revelling. Is contrasted to the Apollonian, which represents order.
Agency Problem
: Situation in which the manager of a business is not the true owner, so he follows a strategy that cosmetically seems to be sound, but in a hidden way benefits him and makes him antifragile at the expense (fragility) of the true owners or society. When he is right, he collects large benefits; when he is wrong, others pay the price. Typically this problem leads to fragility, as it is easy to hide risks. It also affects politicians and academics. A major source of fragility.
Hammurabi Risk Management
: The idea that a builder has more knowledge than the inspector and can hide risks in the foundations where they can be most invisible; the remedy is to remove the incentive in favor of delayed risk.
Green Lumber Fallacy
: Mistaking the source of important or even necessary knowledge—the greenness of lumber—for another, less visible from the outside, less tractable one. How theoreticians impute wrong weights to what one should know in a certain business or, more generally, how many things we call “relevant knowledge” aren’t so much so.
Skin in the Game / Captain and Ship Rule
: Every captain goes down with every ship. This removes the
agency problem
and the lack of
doxastic commitment.
Empedocles’ Tile
: A dog sleeps on the same tile because of a natural, biological, explainable or nonexplainable match, confirmed by long series of recurrent frequentation. We may never know the reason, but the match is there. Example: why we read books.
Cherry-picking
: Selecting from the data what serves to prove one’s point and ignoring disconfirming elements.
Ethical Problems as Transfers of Asymmetry (fragility)
: Someone steals antifragility and optionality from others, getting the upside and sticking others with the downside. “Others’ skin in the game.”
The Robert Rubin violation
: Stolen optionality. Getting upside from a strategy without downside for oneself, leaving the harm to society. Rubin got $120 million in compensation from Citibank; taxpayers are retrospectively paying for his errors.
The Alan Blinder problem
: (1) Using privileges of office retrospectively at the expense of citizens. (2) Violating moral rules while complying perfectly with the law; confusion of ethical and legal. (3) The regulator’s incentive to make complicated regulations in order to subsequently sell his “expertise” to the private sector.
The Joseph Stiglitz problem
: Lack of penalty from bad recommendation causing harm to others. Mental
cherry-picking,
leading to contributing to the cause of a crisis while being convinced of the opposite—and thinking he predicted it. Applies to people with opinions without skin in the game.
Rational Optionality
: Not being locked into a given program, so one can change his mind as he goes along based on discovery or new information. Also applies to
rational flâneur.
Ethical Inversion
: Fitting one’s ethics to actions (or profession) rather than the reverse.
Narrative Fallacy
: Our need to fit a story, or pattern, to a series of connected or disconnected facts. The statistical application is data mining.
Narrative Discipline
: Discipline that consists of fitting a convincing and good-sounding story to the past. Opposed to experimental discipline. A great way to fool people is to use statistics as part of the narrative, by ferreting out “good stories” from the data thanks to cherry picking; in medicine, epidemiological studies tend to be marred with the narrative fallacy, less so controlled experiments. Controlled experiments are more rigorous, less subjected to
cherry-picking.
Non-narrative action
: Does not depend on a narrative for the action to be right—the narrative is just there to motivate, entertain, or prompt action. See
flâneur.
Robust Narrative
: When the narrative does not produce opposite conclusions or recommendations for action under change of assumption or environment. The narrative is otherwise fragile. Similarly, a robust model or mathematical tool does not lead to different policies when you change some parts of the model.
Subtractive Knowledge
: You know what is wrong with more certainty than you know anything else. An application of
via negativa.
Via negativa:
In theology and philosophy, the focus on what something is not, an indirect definition. In action, it is a recipe for what to avoid, what not to do—subtraction, not addition, say, in medicine.
Subtractive Prophecy
: Predicting the future by removing what is fragile from it rather than naively adding to it. An application of
via negativa.
Lindy Effect
: A technology, or anything nonperishable, increases in life expectancy with every day of its life—unlike perishable items (such as humans, cats, dogs, and tomatoes). So a book that has been a hundred years in print is likely to stay in print another hundred years.
Neomania
: A love of change for its own sake, a form of philistinism that does not comply with the
Lindy effect
and understands fragility. Forecasts the future by adding, not subtracting.
Opacity
: You do not see the barrel when someone is playing Russian roulette. More generally, some things remain opaque to us, leading to illusions of understanding.
Mediocristan
: A process dominated by the mediocre, with few extreme successes or failures (say, income for a dentist). No single observation can meaningfully affect the aggregate. Also called “thin-tailed,” or member of the Gaussian family of distributions.
Extremistan
: A process where the total can be conceivably impacted by a single observation (say, income for a writer). Also called “fat-tailed.” Includes the fractal, or power-law, family of distributions.
Nonlinearities, Convexity Effects (smiles and frowns)
: Nonlinearities can be concave or convex, or a mix of both. The term
convexity effects
is an extension and generalization of the fundamental asymmetry. The technical name for fragility is negative convexity effects and for antifragility is positive convexity effects. Convex is good (a smiley), concave is bad (a frowny).
Philosopher’s Stone
, also called
Convexity Bias
(very technical): The exact measure of benefits derived from nonlinearity or optionality (or, even more technically, the difference between
x
and a convex function of
x
). For instance, such bias can quantify the health benefits of variable intensity of pulmonary ventilation over steady pressure, or compute the gains from infrequent feeding. The
Procrustean bed
from the neglect of nonlinearity (to “simplify”) lies in assuming such convexity bias does not exist.


================================================================================
CHAPTER/SECTION 128 (Item 131)
================================================================================

Appendix I:
A GRAPHICAL TOUR OF THE BOOK
For those nonliterary folks who like to see things in graphs, rather than words, and those only.


================================================================================
CHAPTER/SECTION 129 (Item 132)
================================================================================

NONLINEARITY AND LESS IS MORE (& PROCRUSTEAN BED)
FIGURE 19
.
This graph explains both the nonlinear response and the “less is more” idea. As the dose increases beyond a certain point, benefits reverse. We saw that everything nonlinear is either convex, concave, or, as in this graph, mixed. Also shows how under nonlinearities, reductions fail: the Procrustean bed of words “good for you” or “bad” is severely distorting.
Also shows why tinkering-derived heuristics matter because they don’t take you into the danger zone—words and narratives do. Note how the “more is more” zone is convex, meaning accelerated initial benefits. (In Levantine Arabic, the zone beyond the saturation has a name:
“more of it is like less of it.”)
Finally, it shows why competitive “sophistication” (rather, complication masked as sophistication) is harmful, as compared to the practitioner’s craving for optimal simplicity.
Fragility Transfer Theorem:
Note that by the Fragility Transfer Theorem,


================================================================================
CHAPTER/SECTION 130 (Item 133)
================================================================================

CONVEX EXPOSURE [OVER SOME RANGE] ↔ LIKES VOLATILITY [UP TO SOME POINT]
(volatility and other members of the disorder cluster), and
CONCAVE EXPOSURE ↔ DISLIKES VOLATILITY


================================================================================
CHAPTER/SECTION 131 (Item 134)
================================================================================

MAPPING OF FRAGILITIES
In Time Series Space
FIGURE 20
.
Fragile variations through time, two types of fragilities.
A representative series. The horizontal axis shows time, the vertical one shows variations. This can apply to anything: a health indicator, changes in wealth, your happiness, etc. We can see small (or no) benefits and variations most of the time and occasional large adverse outcomes. Uncertainty can hit in a rather hard way. Notice that the loss can occur at any time and exceed the previous cumulative gains. Type 2 (top) and Type 1 (bottom) differ in that Type 2 does not experience large positive effects from uncertainty while Type 1 does.
FIGURE 21
.
The Just Robust
(but not antifragile) (top): It experiences small or no variations through time. Never large ones.
The Antifragile
system (bottom): Uncertainty benefits a lot more than it hurts—the exact opposite of the first graph in
Figure 20
.
Seen in Probabilities
FIGURE 22
.
The horizontal axis represents outcomes, the vertical their probability (i.e., their frequency).
The Robust:
Small positive and negative outcomes.
The Fragile
(
Type 1
, very rare): Can deliver both large negative and large positive outcomes. Why is it rare? Symmetry is very, very rare empirically yet all statistical distributions tend to simplify by using it.
The Fragile (Type 2):
We see large improbable downside (often hidden and ignored), small upside. There is a possibility of a severe unfavorable outcome (left), much more than a hugely favorable one, as the left side is thicker than the right one.
The Antifragile:
Large upside, small downside. Large favorable outcomes are possible, large unfavorable ones less so (if not impossible). The right “tail,” for favorable outcomes, is larger than the left one.
Click
here
for a larger image of this table.
Fragility has a left tail and, what is crucial, is therefore sensitive to perturbations of the left side of the probability distribution.
FIGURE 23
.
Definition of Fragility
(top graph): Fragility is the shaded area, the increase in the mass in left tail below a certain level K of the target variable in response to any change in parameter of the source variable—mostly the “volatility” or something a bit more tuned. We subsume all these changes in s
–
, about which later in the notes section (where I managed to hide equations).
For a
definition of antifragility
(bottom graph), which is not exactly symmetric, the
same mirror image for right tail plus robustness in left tail. The parameter perturbated is s
+
.
It is key that while we may not be able to specify the probability distribution with any precision, we can probe the response through heuristics thanks to the “transfer theorem” in Taleb and Douady (2012). In other words, we do not need to understand the future probability of events, but we can figure out the fragility to these events.


================================================================================
CHAPTER/SECTION 132 (Item 135)
================================================================================

BARBELL TRANSFORMATION IN TIME SERIES
FIGURE 24
.
Barbell seen in time series space. Flooring payoffs while keeping upside.


================================================================================
CHAPTER/SECTION 133 (Item 136)
================================================================================

BARBELLS (CONVEX TRANSFORMATIONS) AND THEIR PROPERTIES IN PROBABILITY SPACE
A graphical expression of the barbell idea.
FIGURE 25
.
Case 1,
the Symmetric Case.
Injecting uncertainty into the system makes us move from one bell shape—the first, with narrow possible spate of outcomes—to the second, a lower peak but more spread out. So it causes an increase of both positive and negative surprises, both positive and negative Black Swans.
FIGURE 26
.
Case 2 (top):
Fragile.
Limited gains, larger losses. Increasing uncertainty in the system causes an augmentation of mostly (sometimes only) negative outcomes, just negative Black Swans. Case 3 (bottom):
Antifragile.
Increasing randomness and uncertainty in the system raises the probability of very favorable outcomes, and accordingly expand the expected payoff. It shows how discovery is, mathematically, exactly like an anti–airplane delay.


================================================================================
CHAPTER/SECTION 134 (Item 137)
================================================================================

TECHNICAL VERSION OF FAT TONY’S “NOT THE SAME ‘TING,’ ” OR THE CONFLATION OF EVENTS AND EXPOSURE TO EVENTS
This note will also explain a “convex transformation.”
f
(
x
) is
exposure
to the variable
x. f
(
x
) can equivalently be called “payoff from
x,
” “exposure to
x,
” even “utility of payoff from
x
” where we introduce in
f
a utility function.
x
can be anything.
Example
:
x
is the intensity of an earthquake on some scale in some specific area,
f
(
x
) is the number of persons dying from it. We can easily see that
f
(
x
) can be made more predictable than
x
(if we force people to stay away from a specific area or build to some standards, etc.).
Example
:
x
is the number of meters of my fall to the ground when someone pushes me from height
x, f
(
x
) is a measure of my physical condition from the effect of the fall. Clearly I cannot predict
x
(who will push me, rather
f
(
x
)).
Example
:
x
is the number of cars in NYC at noon tomorrow,
f
(
x
) is travel time from point A to point B for a certain agent.
f
(
x
) can be made more predictable than
x
(take the subway, or, even better, walk).
Some people talk about
f
(
x
) thinking they are talking about
x.
This is the problem of the
conflation
of
event
and
exposure
. This error present in Aristotle is virtually ubiquitous in the philosophy of probability (say, Hacking).
One can become antifragile to
x
without understanding x, through convexity of
f
(
x
).
The answer to the question “what do you do in a world you don’t understand?” is, simply, work on the undesirable states of
f
(
x
).
It is often easier to modify
f
(
x
) than to get better knowledge of
x.
(In other words, robustification rather than forecasting Black Swans.)
Example
: If I buy an insurance on the market, here
x,
dropping more than 20 percent,
f
(
x
) will be independent of the part of the probability distribution of
x
that is below 20 percent and impervious to changes in its scale parameter. (This is an example of a barbell.)
FIGURE 27
.
Convex Transformation (f(x) is a convex function of x).
The difference between x and exposure to x. There is no downside risk in the second graph. The key is to modify f(x) in order to make knowledge of the properties of x on the left side of the distribution as irrelevant as possible. This operation is called convex transformation, nicknamed “barbell” here.
Green lumber fallacy:
When one confuses
f
(
x
) for another function
g
(
x
), one that has different nonlinearities.
More technically
: If one is antifragile to
x,
then the variance (or volatility, or other measures of variation) of
x
benefit
f
(
x
), since distributions that are skewed have their mean depend on the variance and when skewed right, their expectation increases with variance (the lognormal, for instance, has for mean a term that includes +½ σ
2
).
Further, the probability distribution of
f
(
x
) is markedly different from that of
x
, particularly in the presence of nonlinearities.
When
f
(
x
) is convex (concave) monotonically,
f
(
x
) is right (left) skewed.
When
f
(
x
) is increasing and convex on the left then concave to the right, the probability distribution of
f
(
x
) is thinner-tailed than that of
x
. For instance, in Kahneman-Tversky’s prospect theory, the so-called utility of changes in wealth is more “robust” than that of wealth.
Why payoff matters more than probability (technical):
Where
p
(
x
) is the density, the expectation, that is ∫
f
(
x
)
p
(
x
)
dx,
will depend increasingly on
f
rather than
p,
and the more nonlinear
f,
the more it will depend on
f
rather than
p
.


================================================================================
CHAPTER/SECTION 135 (Item 138)
================================================================================

THE FOURTH QUADRANT (TALEB, 2009)
The idea is that tail events are not computable (in fat-tailed domains), but we can assess our exposure to the problem. Assume
f
(
x
) is an increasing function,
Table 10
connects the idea to the notion of the Fourth Quadrant.
Click
here
for a larger image of this table.


================================================================================
CHAPTER/SECTION 136 (Item 139)
================================================================================

LOCAL AND GLOBAL CONVEXITIES (TECHNICAL)
Nothing is open-ended in nature—death is a maximum outcome for a unit. So things end up convex on one end, concave on the other.
In fact, there is maximum harm at some point in things biological. Let us revisit the concave figure of the stone and pebbles in
Chapter 18
: by widening the range we see that boundedness of harm brings convexities somewhere. Concavity was dominant, but local.
Figure 28
looks at the continuation of the story of the stone and pebbles.
FIGURE 28
.
The top graph shows a broader range in the story of the stone and pebbles in
Chapter 18
. At some point, the concave turns convex as we hit maximum harm. The bottom graph shows strong antifragility, with no known upper limit (leading to Extremistan). These payoffs are only available in economic variables, say, sales of books, or matters unbounded or near-unbounded. I am unable to find such an effect in nature.
FIGURE 29
.
Weak Antifragility (Mediocristan), with bounded maximum.
Typical in nature.


================================================================================
CHAPTER/SECTION 137 (Item 140)
================================================================================

FREAK NONLINEARITIES (VERY TECHNICAL)
The next two types of nonlinearities are almost never seen outside of economic variables; they are particularly limited to those caused by derivatives.
FIGURE 30
.
The top graph shows a convex-concave increasing function, the opposite of the bounded dose-response functions we see in nature. It leads to Type 2, Fragile (very, very fat tails). The bottom graph shows the most dangerous of all: pseudoconvexity. Local antifragility, global fragility.


================================================================================
CHAPTER/SECTION 138 (Item 141)
================================================================================

MEDICAL NONLINEARITIES AND THEIR PROBABILITY CORRESPONDENCE (
CHAPTERS 21
&
22
)
FIGURE 31
.
Medical Iatrogenics:
Case of small benefits and large Black Swan–style losses seen in probability space. Iatrogenics occurs when we have small identifiable gains (say, avoidance of small discomfort or a minor infection) and exposure to Black Swans with delayed invisible large side effects (say, death). These concave benefits from medicine are just like selling a financial option (plenty of risk) against small tiny immediate gains while claiming “evidence of no harm.”
In short, for a healthy person, there is a small probability of disastrous outcomes (discounted because unseen and not taken into account), and a high probability of mild benefits.
FIGURE 32
.
Nonlinearities in biology.
The shape convex-concave necessarily flows from anything increasing (monotone, i.e., never decreasing) and bounded, with maximum and minimum values, i.e., does not reach infinity from either side. At low levels, the dose response is convex (gradually more and more effective). Additional doses tend to become gradually ineffective or start hurting. The same can apply to anything consumed in too much regularity. This type of graph necessarily applies to any situation bounded on both sides, with a known minimum and maximum (saturation), which includes happiness.
For instance, if one considers that there exists a maximum level of happiness and unhappiness, then the general shape of this curve with convexity on the left and concavity on the right has to hold for happiness (replace “dose” with “wealth” and “response” with “happiness”). Kahneman-Tversky prospect theory models a similar shape for “utility” of changes in wealth, which they discovered empirically.
FIGURE 33
.
Recall the hypertension example. On the vertical axis, we have the benefits of a treatment, on the horizontal, the severity of the condition. The arrow points at the level where probabilistic gains match probabilistic harm. Iatrogenics disappears nonlinearly as a function of the severity of the condition. This implies that when the patient is very ill, the distribution shifts to antifragile (thicker right tail), with large benefits from the treatment over possible iatrogenics, little to lose.
Note that if you increase the treatment you hit concavity from maximum benefits, a zone not covered in the graph—seen more broadly, it would look like the preceding graph.
FIGURE 34
.
The top graph shows hormesis for an organism (similar to
Figure 19
): we can see a stage of benefits as the dose increases (initially convex) slowing down into a phase of harm as we increase the dose a bit further (initially concave); then we see things flattening out at the level of maximum harm (beyond a certain point, the organism is dead so there is such a thing as a bounded and known worst case scenario in biology). To the right, a wrong graph of hormesis in medical textbooks showing initial concavity, with a beginning that looks linear or slightly concave.


================================================================================
CHAPTER/SECTION 139 (Item 142)
================================================================================

THE INVERSE TURKEY PROBLEM
FIGURE 35
.
Antifragile, Inverse Turkey Problem:
The unseen rare event is positive. When you look at a positively skewed (antifragile) time series and make inferences about the unseen, you miss the good stuff and underestimate the benefits (the Pisano, 2006a, 2006b, mistake). On the bottom, the other Harvard problem, that of Froot (2001). The filled area corresponds to what we do not tend to see in small samples, from insufficiency of points. Interestingly the shaded area increases with model error. The more technical sections call this zone ω
B
(turkey) and ω
C
(inverse turkey).


================================================================================
CHAPTER/SECTION 140 (Item 143)
================================================================================

DIFFERENCE BETWEEN POINT ESTIMATES AND DISTRIBUTIONS
Let us apply this analysis to how planners make the mistakes they make, and why deficits tend to be worse than planned:
FIGURE 36
.
The gap between predictions and reality:
probability distribution of outcomes from costs of projects in the minds of planners (top) and in reality (bottom). In the first graph they assume that the costs will be both low and quite certain. The graph on the bottom shows outcomes to be both worse and more spread out, particularly with higher possibility of unfavorable outcomes. Note the fragility increase owing to the swelling left tail.
This misunderstanding of the effect of uncertainty applies to government deficits, plans that have IT components, travel time (to a lesser degree), and many more. We will use the same graph to show model error from underestimating fragility by assuming that a parameter is constant when it is random. This is what plagues bureaucrat-driven economics (next discussion).


================================================================================
CHAPTER/SECTION 141 (Item 144)
================================================================================

Appendix II (Very Technical):
WHERE MOST ECONOMIC MODELS FRAGILIZE AND BLOW PEOPLE UP
When I said “technical” in the main text, I may have been fibbing. Here I am not.
The Markowitz incoherence:
Assume that someone tells you that the probability of an event is exactly zero. You ask him where he got this from. “Baal told me” is the answer. In such case, the person is coherent, but would be deemed unrealistic by non-Baalists. But if on the other hand, the person tells you “I
estimated
it to be zero,” we have a problem. The person is both unrealistic and inconsistent. Something estimated needs to have an estimation error. So probability cannot be zero if it is estimated, its lower bound is linked to the estimation error; the higher the estimation error, the higher the probability, up to a point. As with Laplace’s argument of total ignorance, an infinite estimation error pushes the probability toward ½.
We will return to the implication of the mistake; take for now that anything estimating a parameter and then putting it into an equation is different from estimating the equation across parameters (same story as the health of the grandmother, the average temperature, here “estimated” is irrelevant, what we need is average health across temperatures). And Markowitz showed his incoherence by starting his “semi-nal” paper with “Assume you know
E
and
V
” (that is, the expectation and the variance). At the end of the paper he accepts that they need to be estimated, and what is worse, with a combination of statistical techniques and the “judgment of practical men.” Well, if these parameters need to be estimated, with an error, then the derivations need to be written differently and, of course, we would have no paper—and no Markowitz paper, no blowups, no modern finance, no fragilistas teaching junk to students.… Economic models are extremely fragile to assumptions, in the sense that a slight alteration in these assumptions can, as we will see, lead to extremely consequential differences in the results. And, to make matters worse, many of these models are “back-fit” to assumptions, in the sense that the hypotheses are selected to make the math work, which makes them ultrafragile and ultrafragilizing.
Simple example:
Government deficits.
We use the following deficit example owing to the way calculations by governments and government agencies currently miss convexity terms (and have a hard time accepting it). Really, they don’t take them into account. The example illustrates:
(a) missing the stochastic character of a variable known to affect the model but deemed deterministic (and fixed), and
(b)
F,
the function of such variable, is convex or concave with respect to the variable.
Say a government estimates unemployment for the next three years as averaging 9 percent; it uses its econometric models to issue a forecast balance
B
of a two-hundred-billion deficit in the local currency. But it misses (like almost everything in economics) that unemployment is a stochastic variable. Employment over a three-year period has fluctuated by 1 percent on average. We can calculate the effect of the error with the following:
Unemployment at 8%, Balance
B
(8%) = −75 bn (improvement of 125 bn)
Unemployment at 9%, Balance
B
(9%)= −200 bn
Unemployment at 10%, Balance
B
(10%)= −550 bn (worsening of 350 bn)
The concavity bias, or negative convexity bias, from underestimation of the deficit is −112.5 bn, since ½ {
B
(8%) +
B
(10%)} = −312 bn, not −200 bn. This is the exact case of the
inverse philosopher’s stone
.
FIGURE 37.
Nonlinear transformations allow the detection of both model convexity bias and fragility.
Illustration of the example: histogram from Monte Carlo simulation of government deficit as a left-tailed random variable simply as a result of randomizing unemployment, of which it is a concave function. The method of point estimate would assume a Dirac stick at −200, thus underestimating both the
expected
deficit (−312) and the tail fragility of it. (From Taleb and Douady, 2012).
Application: Ricardian Model and Left Tail—The Price of Wine Happens to Vary
For almost two hundred years, we’ve been talking about an idea by the economist David Ricardo called “comparative advantage.” In short, it says that a country should have a certain policy based on its comparative advantage in wine or clothes. Say a country is good at both wine and clothes, better than its neighbors with whom it can trade freely. Then the visible
optimal
strategy would be to specialize in either wine or clothes, whichever fits the best and minimizes opportunity costs. Everyone would then be happy. The analogy by the economist Paul Samuelson is that if someone happens to be the best doctor in town and, at the same time, the best secretary,
then it would be preferable to be the higher-earning doctor—as it would minimize opportunity losses—and let someone else be the secretary and buy secretarial services from him.
I agree that there are benefits in
some
form of specialization, but not from the models used to prove it. The flaw with such reasoning is as follows. True, it would be inconceivable for a doctor to become a part-time secretary just because he is good at it. But, at the same time, we can safely assume that being a doctor insures some professional stability: People will not cease to get sick and there is a higher social status associated with the profession than that of secretary, making the profession more desirable. But assume now that in a two-country world, a country specialized in wine, hoping to sell its specialty in the market to the other country, and that
suddenly the price of wine drops precipitously
. Some change in taste caused the price to change. Ricardo’s analysis assumes that both the market price of wine and the costs of production remain constant, and there is no “second order” part of the story.
Click
here
for a larger image of this table.
The logic:
The table above shows the cost of production, normalized to a selling price of one unit each, that is, assuming that these trade at equal price (1 unit of cloth for 1 unit of wine). What looks like the paradox is as follows: that Portugal produces cloth cheaper than Britain, but should buy cloth from there instead, using the gains from the sales of wine. In the absence of transaction and transportation costs, it is efficient for Britain to produce just cloth, and Portugal to only produce wine.
The idea has always attracted economists because of its paradoxical and counterintuitive aspect. For instance, in an article “Why Intellectuals Don’t Understand Comparative Advantage” (Krugman, 1998), Paul Krugman, who fails to understand the concept himself, as this essay and his technical work show him to be completely innocent of tail events and risk management, makes fun of other intellectuals such as S. J. Gould who understand tail events albeit intuitively rather than analytically. (Clearly one cannot talk about returns and gains without discounting these benefits by the offsetting risks.) The article shows Krugman falling into the critical and dangerous mistake of confusing function of average and average of function. (Traditional Ricardian analysis assumes the variables are endogenous, but does not add a layer of stochasticity.)
Now consider the price of wine and clothes
variable
—which Ricardo did not assume—with the numbers above the unbiased average long-term value. Further assume that they follow a fat-tailed distribution. Or consider that their costs of production vary according to a fat-tailed distribution.
If the price of wine in the international markets rises by, say, 40 percent, then there are clear benefits. But should the price drop by an equal percentage, −40 percent, then massive harm would ensue, in magnitude larger than the benefits should there be an equal rise. There are concavities to the exposure—severe concavities.
And clearly, should the price drop by 90 percent, the effect would be disastrous. Just imagine what would happen to your household should you get an instant and unpredicted 40 percent pay cut. Indeed, we have had problems in history with countries specializing in some goods, commodities, and crops that happen to be not just volatile, but extremely volatile. And disaster does not necessarily come from variation in price, but problems in production: suddenly, you can’t produce the crop because of a germ, bad weather, or some other hindrance.
A bad crop, such as the one that caused the Irish potato famine in the decade around 1850, caused the death of a million and the emigration of a million more (Ireland’s entire population at the time of this writing is only about six million, if one includes the northern part). It is very hard to reconvert resources—unlike the case in the doctor-typist story, countries don’t have the ability to change. Indeed, monoculture (focus on a single crop) has turned out to be lethal in history—one bad crop leads to devastating famines.
The other part missed in the doctor-secretary analogy is that countries don’t have family and friends. A doctor has a support community, a circle of friends, a collective that takes care of him, a father-in-law to borrow from in the event that he needs to reconvert into some other profession, a state above him to help. Countries don’t. Further, a doctor has savings; countries tend to be borrowers.
So here again we have fragility to second-order effects.
Probability Matching:
The idea of comparative advantage has an analog in probability: if you sample from an urn (with replacement) and get a black ball 60 percent of the time, and a white one the remaining 40 percent, the optimal strategy, according to textbooks, is to bet 100 percent of the time on black. The strategy of betting 60 percent of the time on black and 40 percent on white is called “probability matching” and considered to be an error in the decision-science literature (which I remind the reader is what was used by Triffat in
Chapter 10
). People’s instinct to engage in probability matching appears to be sound, not a mistake. In nature, probabilities are unstable (or unknown), and probability matching is similar to redundancy, as a buffer. So if the probabilities change, in other words if there is another layer of randomness, then the optimal strategy is probability matching.
How specialization works:
The reader should not interpret what I am saying to mean that specialization is not a good thing—only that one should establish such specialization after addressing fragility and second-order effects. Now I do believe that Ricardo is ultimately right, but not from the models shown. Organically, systems without top-down controls would specialize progressively, slowly, and over a long time, through trial and error, get the right amount of specialization—not through some bureaucrat using a model. To repeat, systems make small errors, design makes large ones.
So the imposition of Ricardo’s insight-turned-model by some social planner would lead to a blowup; letting tinkering work slowly would lead to efficiency—true efficiency. The role of policy makers should be to,
via negativa
style, allow the emergence of specialization by preventing what hinders the process.
A More General Methodology to Spot Model Error
Model second-order effects and fragility:
Assume we have the right model (which is a very generous assumption) but are uncertain about the parameters. As a generalization of the deficit/employment example used in the previous section, say we are using
f,
a simple function:
f
(
x
|
ᾱ
), where
ᾱ
is supposed to be the average expected
input variable, where we take
φ
as the distribution of
α
over its domain
,
.
The philosopher’s stone
: The mere fact that
α
is uncertain (since it is estimated) might lead to a bias if we perturbate from the
inside
(of the integral), i.e., stochasticize the parameter deemed fixed. Accordingly, the convexity bias is easily measured as the difference between (a) the function
f
integrated across values of potential
α,
and (b)
f
estimated for a single value of
α
deemed to be its average. The convexity bias (philosopher’s stone)
ω
A
becomes:
1
The central equation:
Fragility is a partial philosopher’s stone below
K,
hence
ω
B
the missed fragility is assessed by comparing the two integrals below
K
in order to capture the effect on the left tail:
which can be approximated by an interpolated estimate obtained with two values of
α
separated from a midpoint by ∆
α
its mean deviation of
α
and estimating
Note that antifragility
ω
C
is integrating from
K
to infinity. We can probe
ω
B
by point estimates of
f
at a level of
X
≤
K
so that
which leads us to the fragility detection heuristic (Taleb, Canetti, et al., 2012). In particular, if we assume that
ω
´
B
(
X
) has a constant sign for
X
≤
K
, then
ω
B
(
K
) has the same sign. The detection heuristic is a perturbation in the tails to probe fragility, by checking the function
ω
´
B
(
X
) at any level
X
.
Click
here
for a larger image of this table.
Portfolio fallacies:
Note one fallacy promoted by Markowitz users:
portfolio theory entices people to diversify, hence it is better than nothing
. Wrong, you finance fools: it pushes them to optimize, hence overallocate. It does not drive people to take less risk based on diversification, but causes them to take more open positions owing to perception of offsetting statistical properties—making them vulnerable to model error, and especially vulnerable to the underestimation of tail events. To see how, consider two investors facing a choice of allocation across three items: cash, and securities
A
and
B
. The investor who does not know the statistical properties of
A
and
B
and knows he doesn’t know will allocate, say, the portion he does not want to lose to cash, the rest into
A
and
B
—according to whatever heuristic has been in traditional use. The investor who thinks he knows the statistical properties, with parameters σ
A
, σ
B
, ρ
A
,
B
, will allocate
ω
A
,
ω
B
in a way to put the total risk at some target level (let us ignore the expected return for this). The lower his perception of the correlation ρ
A
,
B
, the worse his exposure to model error. Assuming he thinks that the correlation ρ
A
,
B
, is 0, he will be overallocated by
1
⁄
3
for extreme events. But if the poor investor has the illusion that the correlation is −1, he will be maximally overallocated to his
A
and
B
investments. If the investor uses leverage, we end up with the story of Long-Term Capital Management, which turned out to be fooled by the parameters. (In real life, unlike in economic papers, things tend to change; for Baal’s sake, they change!) We can repeat the idea for each parameter σ and see how lower perception of this σ leads to overallocation.
I noticed as a trader—and obsessed over the idea—that correlations were never the same in different measurements. Unstable would be a mild word for them: 0.8 over a long period becomes −0.2 over another long period. A pure sucker game. At times of stress, correlations experience even more abrupt changes—without any reliable regularity, in spite of attempts to model “stress correlations.” Taleb (1997) deals with the effects of stochastic correlations: One is only safe shorting a correlation at 1, and buying it at −1—which seems to correspond to what the 1
/n
heuristic does.
Kelly Criterion vs. Markowitz:
In order to implement a full Markowitz-style optimization, one needs to know the entire joint probability distribution of all assets for the entire future, plus the exact utility function for wealth at all future times. And without errors! (We saw that estimation errors make the system explode.) Kelly’s method, developed around the same period, requires no joint distribution or utility function. In practice one needs the ratio of expected profit to worst-case return—dynamically adjusted to avoid ruin. In the case of barbell transformations, the worst case is guaranteed. And model error is much, much milder under Kelly criterion. Thorp (1971, 1998), Haigh (2000).
The formidable Aaron Brown holds that Kelly’s ideas were rejected by economists—in spite of the practical appeal—because of their love of general theories for all asset prices.
Note that bounded trial and error is compatible with the Kelly criterion when one has an idea of the potential return—even when one is ignorant of the returns, if losses are bounded, the payoff will be robust and the method should outperform that of Fragilista Markowitz.
Corporate Finance:
In short, corporate finance seems to be based on point projections, not distributional projections; thus if one perturbates cash flow projections, say, in the Gordon valuation model, replacing the fixed—and known—growth (and other parameters) by continuously varying jumps (particularly under fat-tailed distributions), companies deemed “expensive,” or those with high growth, but low earnings, could markedly increase in expected value, something the market prices heuristically but without explicit reason.
Conclusion and summary:
Something the economics establishment has been missing is that having the right model (which is a very generous assumption), but being uncertain about the parameters will invariably lead to an increase in fragility in the presence of convexity and nonlinearities.


================================================================================
CHAPTER/SECTION 142 (Item 145)
================================================================================

FUHGETABOUD SMALL PROBABILITIES
Now the meat, beyond economics, the more general problem with probability and its mismeasurement.
How Fat Tails (Extremistan) Come from
Nonlinear Responses to Model Parameters
Rare events have a certain property—missed so far at the time of this writing. We deal with them using a model, a mathematical contraption that takes input parameters and outputs the probability. The more parameter uncertainty there is in a model designed to compute probabilities, the more small probabilities tend to be underestimated. Simply, small probabilities are convex to errors of computation, as an airplane ride is concave to errors and disturbances (remember, it gets longer, not shorter). The more sources of disturbance one forgets to take into account, the longer the airplane ride compared to the naive estimation.
We all know that to compute probability using a standard Normal statistical distribution, one needs a parameter called
standard deviation
—or something similar that characterizes the scale or dispersion of outcomes. But uncertainty about such standard deviation has the effect of making the small probabilities rise. For instance, for a deviation that is called “three sigma,” events that should take place no more than one in 740 observations, the probability rises by 60% if one moves the standard deviation up by 5%, and drops by 40% if we move the standard deviation down by 5%. So if your error is on average a tiny 5%, the underestimation from a naive model is about 20%. Great asymmetry, but nothing yet. It gets worse as one looks for more deviations, the “six sigma” ones (alas, chronically frequent in economics): a rise of five times more. The rarer the event (i.e., the higher the “sigma”), the worse the effect from small uncertainty about what to put in the equation. With events such as ten sigma, the difference is more than a billion times. We can use the argument to show how smaller and smaller probabilities require more precision in computation. The smaller the probability, the more a small, very small rounding in the computation makes the asymmetry massively insignificant. For tiny, very small probabilities, you need near-infinite precision in the parameters; the slightest uncertainty there causes mayhem. They are very convex to perturbations. This in a way is the argument I’ve used to show that small probabilities are incomputable, even if one has the right model—which we of course don’t.
The same argument relates to deriving probabilities nonparametrically, from past frequencies. If the probability gets close to 1/ sample size, the error explodes.
This of course explains the error of Fukushima. Similar to Fannie Mae. To summarize, small probabilities increase in an accelerated manner as one changes the parameter that enters their computation.
FIGURE 38.
The probability is convex to standard deviation in a Gaussian model. The plot shows the STD effect on P>x, and compares P>6 with an STD of 1.5 compared to P>6 assuming a linear combination of 1.2 and 1.8 (here a(1)=1/5).
The worrisome fact is that a perturbation in σ extends well into the tail of the distribution in a convex way; the risks of a portfolio that is sensitive to the tails
would explode. That is, we are still here in the Gaussian world! Such explosive uncertainty isn’t the result of natural fat tails in the distribution, merely small imprecision about a future parameter. It is just epistemic! So those who use these models while admitting parameters uncertainty are necessarily committing a severe inconsistency.
2
Of course, uncertainty explodes even more when we replicate conditions of the non-Gaussian real world upon perturbating tail exponents. Even with a powerlaw distribution, the results are severe, particularly under variations of the tail exponent as these have massive consequences. Really, fat tails mean incomputability of tail events, little else.
Compounding Uncertainty (Fukushima)
Using the earlier statement that
estimation implies error,
let us extend the logic: errors have errors; these in turn have errors. Taking into account the effect makes all small probabilities rise regardless of model—even in the Gaussian—to the point of reaching fat tails and powerlaw effects (even the so-called infinite variance) when higher orders of uncertainty are large. Even taking a Gaussian with σ the standard deviation having a proportional error
a
(1);
a
(1) has an error rate
a
(2), etc. Now it depends on the higher order error rate
a
(
n
) related to
a
(
n
−1); if these are in constant proportion, then we converge to a very thick-tailed distribution. If proportional errors decline, we still have fat tails. In all cases mere error is not a good thing for small probability.
The sad part is that getting people to accept that every measure has an error has been nearly impossible—the event in Fukushima held to happen once per million years would turn into one per 30 if one percolates the different layers of uncertainty in the adequate manner.
1
The difference between the two sides of Jensen’s inequality corresponds to a notion in information theory, the Bregman divergence. Briys, Magdalou, and Nock, 2012.
2
This further shows the defects of the notion of “Knightian uncertainty,” since
all tails
are uncertain under the slightest perturbation and their effect is severe in fat-tailed domains, that is, economic life.


================================================================================
CHAPTER/SECTION 143 (Item 146)
================================================================================

To Sarah Josephine Taleb


================================================================================
CHAPTER/SECTION 144 (Item 147)
================================================================================

ACKNOWLEDGMENTS
Peter Bevelin, Jazi Zilber, and Peter Tanous read the entire manuscript several times in several different versions in great detail and provided generous comments or hints on relevant research. I had exceptional and enthusiastic contributions from Will Murphy, Evan Camfield, Alexis Kirshbaum, Cynthia Taleb, Will Goodlad, Stefan McGrath, and Asim Samiuddin, who witnessed the progress of the book and contributed to its development.
Generous comments and help: Peter Nielsen, Rory Sutherland, Saifedean Ammous, Michael Kraland, Ron Kennett (for, among other things, the prints concave/convex of the Metropolitan Museum), Max Brockman, John Brockman, Marcos Carreira, Nathan Myhrvold, Aaron Brown, Terry Burnham, Peter Boettke, Russ Roberts, Kevin Horgan, Farid Karkaby, Michael Schrague, Dan Goldstein, Marie-Christine Riachi, Ed Frankel, Mika Kasuga, Eric Weinstein, Emanuel Derman, Alberto Mingardi, Constantine Sandis, Guy Deutscher, Bruno Dupire, George Martin, Joelle Weiss, Rohan Silva, Janan Ganesh, Dan Ariely, Gur Huberman, Cameron Williams, Jacques Merab, Lorenzo Savorelli, Andres Velasco, Eleni Panagiotarakou, Conrad Young, Melik Keylan, Seth Roberts, John McDonald, Yaneer Bar-Yam, David Shaywitz, Nouriel Roubini, Philippe Asseily, Ghassan Bejjani, Alexis Grégoire Saint-Marie, Charles Tapiero, Barry Blecherman, Art De Vany, Guy Riviere, Bernard Oppetit, Brendon Yarkin, and Mark Spitznagel; and my online helpers Jean-Louis Reault, Ben Lambert, Marko Costa, Satiyaki Den, Kenneth Lamont, Vergil Den, Karen Brennan, Ban Kanj, Lea McKay, Ricardo Medina, Marco Alves, Pierre Madani, Greg Linster, Oliver Mayor, Satyaki Roy, Daniel Hogendoorn, Phillip Crenshaw, Walter Marsh, John Aziz, Graeme Blake, Greg Linster, Sujit Kapadia, Alvaro De La Paz, Apoorv Bajpai, Louis Shickle, Ben Brady, Alfonso Payno de las Cuevas, “Guru Anaerobic,” Alexander Boland, David Boxenhorn, Dru Stevenson, and Michal Kolano. I am certain I have forgotten many more.


================================================================================
CHAPTER/SECTION 145 (Item 148)
================================================================================

ADDITIONAL NOTES, AFTERTHOUGHTS, AND FURTHER READING
These are both additional readings and ideas that came to me after the composition of the book, like whether God is considered robust or antifragile by theologians or the history of measurement as a sucker problem in the probability domain. As to further reading, I am avoiding the duplication of those mentioned in earlier books, particularly those concerning the philosophical problem of induction, Black Swan problems, and the psychology of uncertainty. I managed to bury some mathematical material in the text without Alexis K., the math-phobic London editor, catching me (particularly my definition of fragility in the notes for
Book V
and my summary derivation of “small is beautiful”). Note that there are more involved technical discussions on the Web.
Seclusion:
Since
The Black Swan,
I’ve spent 1,150 days in physical seclusion, a soothing state of more than three hundred days a year with minimal contact with the outside world—plus twenty years of thinking about the problem of nonlinearities and nonlinear exposures. So I’ve sort of lost patience with institutional and cosmetic knowledge. Science and knowledge are convincing and deepened rigorous argument taken to its conclusion, not naive (
via positiva
) empiricism or fluff, which is why I refuse the commoditized (and highly gamed) journalistic idea of “reference”—rather, “further reading.” My results should not depend, and do not depend on a single paper or result, except for
via negativa
debunking—these are illustrative.
Charlatans:
In the “fourth quadrant” paper published in
International Journal of Forecasting
(one of the backup documents for
The Black Swan
that had been sitting on the Web) I showed
empirically
using all economic data available that fat tails are both severe and intractable—hence all methods with “squares” don’t work with socioeconomic variables: regression, standard deviation, correlation, etc. (technically 80% of the Kurtosis in 10,000 pieces of data can come from
one single
observation, meaning all measures of fat tails are just sampling errors). This is a very strong
via negativa
statement: it means we can’t use covariance matrices—they are unreliable and uninformative. Actually just accepting fat tails would have led us to such result—no need for empiricism; I processed the data nevertheless. Now any honest scientific profession would say: “what do we do
with such evidence?”—the economics and finance establishment just ignored it. A bunch of charlatans, by any scientific norm and ethical metric. Many “Nobels” (Engle, Merton, Scholes, Markowitz, Miller, Samuelson, Sharpe, and a few more) have their results grounded in such central assumptions, and all their works would evaporate otherwise. Charlatans (and fragilistas) do well in institutions. It is a matter of ethics; see notes on
Book VII
.
For our purpose here, I ignore any economic paper that uses regression in fat-tailed domains—as just hot air—except in some cases, such as Pritchet (2001), where the result is not impacted by fat tails.


================================================================================
CHAPTER/SECTION 146 (Item 149)
================================================================================

PROLOGUE & BOOK I:
The Antifragile: An Introduction
Wind energizes fire:
Resembles La Rochefoucauld’s comment on love.
Antifragility and complexity:
Bar-Yam and Epstein (2004) define sensitivity, the possibility of large response to small stimuli, and robustness, the possibility of small response to large stimuli. In fact this sensitivity, when the response is positive, resembles antifragility.
Private Correspondence with Bar-Yam:
Yaneer Bar-Yam, generously in his comments: “If we take a step back and more generally consider the issue of partitioned versus connected systems, partitioned systems are more stable, and connected systems are both more vulnerable and have more opportunities for collective action. Vulnerability (fragility) is connectivity without responsiveness. Responsiveness enables connectivity to lead to opportunity. If collective action can be employed to address threats, or to take advantage of opportunities, then the vulnerability can be mitigated and outweighed by the benefits. This is the basic relationship between the idea of sensitivity as we described it and your concept of antifragility.” (With permission.)
Damocles and complexification:
Tainter (1988) argues that sophistication leads to fragility—but following a very different line of reasoning.
Post-Traumatic Growth:
Bonanno (2004), Tedeschi and Calhoun (1996), Calhoun and Tedeschi (2006), Alter et al. (2007), Shah et al. (2007), Pat-Horenczyk and Brom (2007).
Pilots abdicate responsibility to the system:
FAA report: John Lowy, AP, Aug. 29, 2011.
Lucretius Effect:
Fourth Quadran
t
discussion in the Postscript of
The Black Swan
and empirical evidence in associated papers.
High-water mark:
Kahneman (2011), using as backup the works of the very insightful Howard Kunreuther, that “protective actions, whether by individuals or by governments, are usually designed to be adequate to the worst disaster actually experienced.… Images of even worse disaster do not come easily to mind.”
Psychologists and “resilience”:
Seery 2011, courtesy Peter Bevelin. “However, some theory and empirical evidence suggest that the experience of facing difficulties can also promote benefits in the form of greater propensity for resilience when dealing with subsequent stressful situations.” They use resilience! Once again
itsnotresilience
.
Danchin’s paper:
Danchin et al. (2011).
Engineering errors and sequential effect on safety:
Petroski (2006).
Noise and effort:
Mehta et al. (2012).
Effort and fluency:
Shan and Oppenheimer (2007), Alter et al. (2007).
Barricades:
Idea communicated by Saifedean Ammous.
Buzzati:
Una felice sintesi di quell’ultimo capitolo della vita di Buzzati è contenuto nel libro di Lucia Bellaspiga «Dio che non esisti, ti prego. Dino Buzzati, la fatica di credere»
Self-knowledge:
Daniel Wegner’s illusion of conscious will, in
Fooled by Randomness
.
Book sales and bad reviews:
For Ayn Rand: Michael Shermer, “The Unlikeliest Cult in History,”
Skeptic
vol. 2, no. 2, 1993, pp. 74–81. This is an example; please do not mistake this author for a fan of Ayn Rand.
Smear campaigns:
Note that the German philosopher Brentano waged an anonymous attack on Marx. Initially it was the accusation of covering up some sub-minor fact completely irrelevant to the ideas of
Das Kapital;
Brentano got the discussion completely diverted away from the central theme, even posthumously, with Engels vigorously continuing the debate defending Marx in the preface of the third volume of the treatise.
How to run a smear campaign from Louis XIV to Napoleon:
Darnton (2010).
Wolff’s law and bones, exercise, bone mineral density in swimmers:
Wolff (1892), Carbuhn (2010), Guadaluppe-Grau (2009), Hallström et al. (2010), Mudd (2007), Velez (2008).
Aesthetics of disorder:
Arnheim (1971).
Nanocomposites:
Carey et al. (2011).
Karsenty and Bones:
I thank Jacques Merab for discussion and introduction to Karsenty; Karsenty (2003, 2012a), Fukumoto and Martin (2009); for male fertility and bones, Karsenty (2011, 2012b).
Mistaking the Economy for a Clock:
A typical, infuriating error in Grant (2001): “Society is conceived as a huge and intricate clockwork that functions automatically and predictably once it has been set in motion. The whole system is governed by mechanical laws that organize the relations of each part. Just as Newton discovered the laws of gravity that govern motion in the natural world, Adam Smith discovered the laws of supply and demand that govern the motion of the economy. Smith used the metaphor of the watch and the machine in describing social systems.”
Selfish gene:
The “selfish gene” is (convincingly) an idea of Robert Trivers often attributed to Richard Dawkins—private communication with Robert Trivers. A sad story.
Danchin’s systemic antifragility and redefinition of hormesis:
Danchin and I wrote our papers in feedback mode. Danchin et al. (2011): “The idea behind is that in the fate of a collection of entities, exposed to serious challenges, it may be possible to obtain a positive overall outcome. Within the collection, one of the entities would fare extremely well, compensating for the collapse of all the others and even doing much better than the bulk if unchallenged. With this view, hormesis is just a holistic description of underlying scenarios acting at the level of a population of processes, structures or molecules, just noting the positive outcome for the whole. For living organisms this could act at the level of the population of organisms, the population of cells, or the population of intracellular molecules. We explore here how antifragility could operate at the latter level, noting that its implementation has features highly reminiscent of what we name natural selection. In particular, if antifragility is a built-in process that permits some individual entities to stand out from the bulk in a challenging situation, thereby improving the fate of the whole, it would illustrate the implementation of a process that gathers and utilises information.”
Steve Jobs:
“Death is the most wonderful invention of life. It purges the system of these old models that are obsolete.” Beahm (2011).
Swiss cuckoo clock:
Orson Welles,
The Third Man.
Bruno Leoni:
I thank Alberto Mingardi for making me aware of the idea of legal robustness—and for the privilege of being invited to give the Leoni lecture in Milan in 2009. Leoni (1957, 1991).
Great Moderation:
A turkey problem. Before the turmoil that started in 2008, a gentleman called Benjamin Bernanke, then a Princeton professor, later to be chairman of the Federal Reserve Bank of the United States and the most powerful person in the world of economics and finance, dubbed the period we witnessed the “great moderation”—putting me in a very difficult position to argue for increase of fragility. This is like pronouncing that someone who has just spent a decade in a sterilized room is in “great health”—when he is the most vulnerable.
Note that the turkey problem is an evolution of Russell’s chicken (
The Black Swan
).
Rousseau:
In
Contrat Social
. See also Joseph de Maistre,
Oeuvres,
Éditions Robert Laffont.


================================================================================
CHAPTER/SECTION 147 (Item 150)
================================================================================

BOOK II:
Modernity and the Denial of Antifragility
City-states:
Great arguments in support of the movement toward semiautonomous cities. Benjamin Barber, Long Now Foundation Lecture (2012), Khanna (2010), Glaeser (2011). Mayors are better than presidents at dealing with trash collection—and less likely to drag us into war. Also Mansel (2012) for the Levant.
Austro-Hungarian Empire:
Fejtö (1989). Counterfactual history: Fejtö holds that the first war would have been avoided.
Random search and oil exploration:
Menard and Sharman (1976), controversy White et al. (1976), Singer et al. (1981).
Randomizing politicians:
Pluchino et al. (2011).
Switzerland:
Exposition in Fossedal and Berkeley (2005).
Modern State:
Scott (1998) provides a critique of the high modernistic state.
Levantine economies:
Mansel (2012) on city-states. Economic history, Pamuk (2006), Issawi (1966, 1988), von Heyd (1886). Insights in Edmond About (About, 1855).
City-States in history:
Stasavage (2012) is critical of the oligarchic city-state as an engine of long-term growth (though initially high growth rate). However, the paper is totally unconvincing econometrically owing to missing fat tails. The issue is fragility and risk management, not cosmetic growth. Aside from Weber and Pirenne, advocates of the model, Delong and Schleifer (1993). See Ogilvie (2011).
Tonsillectomies:
Bakwin (1945), cited by Bornstein and Emler (2001), discussion in Freidson (1970). Redone by Avanian and Berwick (1991).
Orlov:
Orlov (2011).
Naive interventionism in development:
Easterly (2006) reports a green lumber problem: “The fallacy is to assume that because I have studied and lived in a society that somehow wound up with prosperity and peace, I know enough to plan for other societies to have prosperity and peace. As my friend April once said, this is like thinking the racehorses can be put in charge of building the racetracks.”
Also luck in development, Easterly et al. (1993), Easterly and Levine (2003), Easterly (2001).
China famine:
Meng et al. (2010).
Washington’s death:
Morens (1999); Wallenborn (1997).
Koran and Iatrogenics:
Semmelweiss:
Of the most unlikely references, see Louis-Ferdinand Céline’s doctoral thesis, reprinted in Gallimard (1999), courtesy Gloria Origgi.
Fake stabilization:
Some of the arguments in
Chapter 7
were co-developed with Mark Blyth in
Foreign Affairs,
Taleb and Blyth (2011).
Sweden:
“Economic elites had more autonomy than in any successful democracy,” Steinmo (2011).
Traffic and removal of signs:
Vanderbilt (2008).
History of China:
Eberhard (reprint, 2006).
Nudge:
They call it the
status quo bias
and some people want to get the government to manipulate people into breaking out of it. Good idea, except when the “expert” nudging us is not an expert.
Procrastination and the priority heuristic:
Brandstetter and Gigerenzer (2006).
France’s variety:
Robb (2007). French riots as a national sport, Nicolas (2008). Nation-state in France, between 1680 and 1800, Bell (2001).
Complexity:
We are more interested here in the effect on fat tails than other attributes. See Kaufman (1995), Hilland (1995), Bar-Yam (2001), Miller and Page (2007), Sornette (2004).
Complexity and fat tails:
There is no need to load the math here (left to the technical companion); simple rigorous arguments can prove with minimal words how fat tails emerge from some attributes of complex systems. The important mathematical effect comes from lack of independence of random variables which prevents convergence to the Gaussian basin.
Let us examine the effect from dynamic hedging and portfolio revisions.
A—Why fat tails emerge from leverage and feedback loops, single agent simplified case.
A1 [leverage]—If an agent with some leverage L buys securities in response to increase in his wealth (from the increase of the value of these securities held), and sells them in response to decrease in their value, in an attempt to maintain a certain level of leverage L (he is concave in exposure), and
A2 [feedback effects]—If securities rise nonlinearly in value in response to purchasers and decline in value in response to sales, then, by the violation of the independence between the variations of securities, CLT (the central limit theorem) no longer holds (no convergence to the Gaussian basin). So fat tails are an immediate result of feedback and leverage, exacerbated by the concavity from the level of leverage L.
A3—If feedback effects are concave to size (it costs more per unit to sell 10 than to sell 1), then negative skewness of the security and the wealth process will emerge. (Simply, like the “negative gamma” of portfolio insurance, the agent has an option in buying, but no option in selling, hence negative skewness. The forced selling is exactly like the hedging of a short option.)
Note on path dependence exacerbating skewness:
More specifically, if wealth increases first, this causes more risk and skew. Squeezes and forced selling on the way down: the market drops more (but less frequently) than it rises on the way up.
B—Multiagents: if, furthermore, more than one agent is involved, then the effect is compounded by the dynamic adjustment (hedging) of one agent causing the adjustment of another, something commonly called “contagion.”
C—One can generalize to anything, such as home prices rising in response to home purchases from excess liquidity, etc.
The same general idea of forced execution plus concavity of costs leads to the superiority of systems with distributed randomness.
Increase of risk upon being provided numbers:
See the literature on anchoring (reviewed in
The Black Swan
). Also Mary Kate Stimmler’s doctoral thesis at Berkeley (2012), courtesy Phil Tetlock.
Stimmler’s experiment is as follows. In the simple condition, subjects were told:
For your reference, you have been provided with the following formula for calculating the total amount of money (
T
) the investment will make three months after the initial investment (
I
) given the rate of return (
R
):
T=I*R
In the complex condition, subjects were told:
For your reference, you have been provided with the following formula for calculating the total amount of money
A
n
the investment will make three months after the initial investment
A
n-1
given the rate of return
r
.
Needless to mention that the simple condition and the complex one produced the same output. But those who had the complex condition took more risks.
The delusion of probabilistic measurement:
Something that is obvious to cabdrivers and grandmothers disappears inside university hallways. In his book
The Measure of Reality
(Crosby, 1997), the historian Alfred Crosby presented the following thesis: what distinguished Western Europe from the rest of the world is obsession with measurement, the transformation of the qualitative into the quantitative. (This is not strictly true, the ancients were also obsessed with measurements, but they did not have the Arabic numerals to do proper calculations.) His idea was that we learned to be precise about things—and that was the precursor of the scientific revolution. He cites the first mechanical clock (which quantized time), marine charts and perspective painting (which quantized space), and double-entry bookkeeping (which quantized financial accounts). The obsession with measurement started with the right places, and progressively invaded the wrong ones.
Now our problem is that such measurement started to be applied to elements that have a high measurement error—in some case infinitely high. (Recall Fukushima in the previous section.) Errors from Mediocristan are inconsequential, those from Extremistan are acute. When measurement errors are prohibitively large, we should not be using the word “measure.” Clearly I can “measure” the table on which I am writing these lines. I can “measure” the temperature. But I cannot “measure” future risks. Nor can I “measure” probability—unlike this table it cannot lend itself to our investigation. This is at best a speculative estimation of something that
can
happen.
Note that Hacking (2006) does not for a single second consider fat tails! Same with Hald (1998, 2003), von Plato (1994), Salsburg (2001), and from one who should know better, Stigler (1990). A book that promoted bad risk models, Bernstein (1996). Daston (1988) links probabilistic measurement to the Enlightenment.
The idea of probability as a quantitative not a qualitative construct has indeed been plaguing us. And the notion that science
equals
measurement free of error—it is, largely but not in everything—can lead us to all manner of fictions, delusions, and dreams.
An excellent understanding of probability linked to skepticism: Franklin (2001). Few other philosophers go back to the real problem of probability.
Fourth Quadrant:
See the discussion in
The Black Swan
or paper Taleb (1999).
Nuclear, new risk management:
Private communication, Atlanta, INPO, Nov. 2011.
Anecdotal knowledge and power of evidence:
A reader, Karl Schluze, wrote: “An old teacher and colleague told me (between his sips of bourbon) ‘If you cut off the head of a dog and it barks, you don’t have to repeat the experiment.’ ” Easy to get examples: no lawyer would invoke an “N=1” argument in defense of a person, saying “he only killed once”; nobody considers a plane crash as “anecdotal.”
I would go further and map disconfirmation as exactly where N=1 is sufficient.
Sometimes researchers call a result “anecdotal” as a knee-jerk reaction when the result is exactly the reverse. Steven Pinker called John Gray’s pointing out the two world wars as counterevidence to his story of great moderation “anecdotal.” My experience is that social science people rarely know what they are talking about when they talk about “evidence.”


================================================================================
CHAPTER/SECTION 148 (Item 151)
================================================================================

BOOK III:
A Nonpredictive View of the World
Decision theorists teaching practitioners:
To add more insults to us, decision scientists use the notion of “practical,” an inverse designation. See Hammond, Keeney, and Raiffa (1999) trying to teach us how to make decisions. For a book describing exactly how practitioners don’t act, but how academics think practitioners act: Schon (1983).
The asymmetry between good and bad:
Segnius homines bona quam mala sentiunt
in Livy’s
Annals
(XXX, 21).
Stoics and emotions:
Contradicts common beliefs that Stoicism is about being a vegetable, Graver (2007).
Economic growth was not so fast:
Crafts (1985), Crafts and Harley (1992).
Cheating with the rock star:
Arnavist and Kirkpatrick (2005), Griffith et al. (2002), Townsend et al. (2010).
Simenon:
“Georges Simenon, profession: rentier,” Nicole de Jassy
Le Soir illustré
9 janvier 1958, N° 1333, pp. 8–9, 12.
Dalio:
Bridgewater-Associates-Ray-Dalio-Principles.


================================================================================
CHAPTER/SECTION 149 (Item 152)
================================================================================

BOOK IV:
Optionality, Technology, and the Intelligence of Antifragility
The Teleological
Aristotle and his influence:
Rashed (2007), both an Arabist and a Hellenist.
The nobility of failure:
Morris (1975).
Optionality
Bricolage:
Jacob (1977a, 1977b), Esnault (2001).
Rich getting richer:
On the total wealth for HNWI (High Net Worth Individuals) increasing, see Merrill Lynch data in “World’s wealthiest people now richer than
before the credit crunch,” Jill Treanor,
The Guardian,
June 2012. The next graph shows why it has nothing to do with growth and total wealth formation.
FIGURE 39
.
Luxury goods and optionality. On the vertical the probability, on the horizontal the integral of wealth. Antifragility city: the effect of change in inequality on the pool of very rich increases nonlinearly in the tails: the money of the superrich reacts to inequality rather than total wealth in the world. Their share of wealth multiplies by close to 50 times in response to a change of 25% in dispersion of wealth. A small change of 0.01 in the GINI coefficient (0 when perfect inequality, 1.00 when one person has all) equivalent to 8% rise in real Gross Domestic Product—the effect is stark regardless of the probability distribution.
Camel in Arabia:
Lindsay (2005).
Obliquity:
Kay (2010).
Real options literature:
Trigeorgis (1993), review in Dixit and Pindyck (1994), Trigeorgis (1996), Luehrman (1998), McGrath (1999)—the focus is on reversible and irreversible investments.
Translational gap:
Wooton (2007); Arikha (2008b); modern Contopoulos-Ioannidis et al. (2003, 2008), commentary Bosco and Watts (2007).
Criticism of Wootton:
Brosco and Watts (2007).
Epiphenomena and Granger-causality:
See Granger (1999) for a review.
Lecturing birds how to fly:
There are antecedents in Erasmus, “teaching fish how to swim.”
Adages,
2519, III, VI, 19.
“Piscem nature doces
I’χθὺν νήχεσθαι διδάσκεις
,
id est piscem nature doces. Perinde est ac si dicas : Doctum doces. Confine illi, quod alibi retulimus :
Δελφἶνα νήχεσθαι διδάσκεις
,
id est Delphinum natare doces.”
The expression was first coined in Haug and Taleb (2010), posted in 2006, leading to a book, Triana (2009). We weren’t aware of the Erasmus imagery, which we would have selected instead.
Education and its effect on growth and wealth:
Pritchett (2001), Wolf (2002), Chang (2011).
Schumpeter’s ideas on destruction for advancement:
Schumpeter (1942). Criticism by Harvard economists about lack of technical approach in McCraw (2007).
Amateurs:
Bryson (2010), Kealey (1996).
Scientific misattribution of the works of Bachelier, Thorpe, and others:
Haug and Taleb (2010). Discussion in Triana (2009, 2011).
Ex cura theoria nascitur:
In Coulter (2000), attributed to Paracelsus.
Jet engine:
Scranton (2006, 2007, 2009), Gibbert and Scranton (2009).
Busting the episteme theory of cybernetics:
Mindell, 2002. I thank David Edgerton for introducing me to his works.
Cathedrals and theoretical and axiomatic geometry:
Beaujoan (1973, 1991), Portet (2002). Ball (2008) for the history of the construction of Chartres cathedral.
Epistemic base and conflation:
The epistemic base is sort of the
x,
not
f
(
x
). A great way
to see the difference between
x
and
f
(
x
) in technology, offered by Michael Polanyi: one can patent
f
(
x
), a technique, but not
x,
scientific knowledge. In Mokyr (2005).
Epistemic Base:
Mokyr (1999, 2002, 2005, 2009). The biggest problem with Mokyr: not getting
ω
C
. Further, this notion of the East missing trial and error (also see argument about China): see Tetlock in Tetlock et al. (2009). Mokyr and Meisenzahl have a different spin, with microinventions feeding macroinventions. Still intellectually weak.
Techne-Episteme in economics:
Marglin (1996), but the tradition did not go very far.
Needham’s works on China:
Winchester (2008).
Tenure:
Kealey (1996): “Adam Smith attributed the English professors’ decay to their guaranteed salaries and tenured jobs. (As compared to Scottish Universities.)”
Fideism:
Popkin (2003).
Linear Model:
Edgerton (1996a, 1996b, 2004). Edgerton showed that it was a backward-fit idea, that is, fit to the past. Edgerton also writes: “This profoundly academic-research-oriented model of twentieth-century science is all the more surprising in view of the long tradition of
stressing the non-academic origins of modern science
[emphasis mine], particularly the craft traditions, and the insistence of much history of science, strengthened in the last 20 years, on the significance of industrial contexts for science, from dyeing to brewing to engine making.”
Convexity bias:
It was discovered early in commodity and financial futures; Burghardt and Hoskins (1994), Taleb (1997), Burghardt and Liu (2002), Burghardt and Panos (2001), Kirikos and Novak (1997), Pieterbarg and Renedo (2004). Many people blew up on misunderstanding the effect.
Example of detection and mapping of convexity bias (
ω
A
), from author’s doctoral thesis:
The method is to find what needs dynamic hedging and dynamic revisions. Among the members of the class of instruments considered that are not options
stricto-sensu
but require dynamic hedging can be rapidly mentioned a broad class of convex instruments: (1) Low coupon long dated bonds. Assume a discrete time framework. Take
B
(
r
,
T
,
C
) the bond maturing period
T,
paying a coupon
C
where
rt
= ∫
rs ds.
We have the convexity
д
2
B
/
дr
2
increasing with
T
and decreasing with
C
. (2) Contracts where the financing is extremely correlated with the price of the Future. (3) Baskets with a geometric feature in its computation. (4) A largely neglected class of assets is the “quanto-defined” contracts (in which the payoff is not in the native currency of the contract), such as the Japanese NIKEI Future where the payoff is in U.S. currency. In short, while a Japanese yen denominated NIKEI contract is linear, a U.S. dollars denominated one is nonlinear and requires dynamic hedging.
Take at initial time
t
0
, the final condition
V
(
S,T
)
= S
T
where
T
is the expiration date. More simply, the security just described is a plain forward, assumed to be linear. There appears to be no Ito term there yet. However should there be an intermediate payoff such that, having an accounting period
i/T,
the variation margin is paid in cash disbursement, some complexity would arise. Assume ∆
(t
i
)
the changes in the value of the portfolio during period
(t
i
,t
i-1
)
, ∆(t
i
)= (V(S,t
i
)-V(S, t
i-1
)). If the variation is to be paid at period
t
i
, then the operator would have to borrow at the forward rate between periods
t
i
and
T,
here
r
(
t
i
,T
). This financing is necessary to make
V
(
S,T
) and
S
T
comparable in present value. In expectation, we will have to discount the variation using forward cash flow method for the accounting period between
t
i-1
and
t
i
. Seen from period
T,
the value of the variation becomes
E
t
[
exp
[
-r
(
t
i
,T
)(
T-t
i
)] ∆(t
i
)], where
E
t
is the expectation operator at
time
t
(under, say, the risk-neutral probability measure). Therefore we are delivering at period
T,
in expectation, as seen from period
t
0
, the expected value of a stream of future variation
E
t0
[Σ
exp
[-
r
(
t
i
,
T
)(
T
-
t
i
)] ∆(
t
i
)]. However we need to discount to the present using the term rate
r
(
T
). The previous equation becomes
V
(
S,T
)
|
t=t0
= V
[
S,t
0
]
+ exp
[
r
(
T
)]
E
to
[Σ
exp
[-
r
(
t
i
,
T
)(
T
-
t
i
)] ∆(
t
i
)], which will be different from
S
T
when any of the interest rate forwards is stochastic.
Result
(a polite way to say “theorem”):
When the variances of the forward discount rate r
(
t
i
,
T
)
and the underlying security S
T
are strictly positive and the correlation between the two is lower than 1, V
(
S,T
)
|
t=t0
≠ S
T
. Proof: by examining the properties of the expectation operator. Therefore:
F
(
S, t
0
)
= F
(
S,t
0
+
∆
t
), while a nonlinear instrument will merely satisfy:
E
[
V
(
S,t
0
)]
=E
[
V
(
S,t
0
+
∆
t
)].
Critique of Kealey:
Posner (1996).
General History of Technology:
Missing convexity biases, Basalla (1988), Stokes (1997), Geison (1995).
Ideas of innovation:
Berkun (2007), Latour and Woolfar (1996), Khosla (2009), Johnson (2010).
Medical discoveries and absence of causative knowledge:
Morton (2007), Li (2006), Le Fanu (2002), Bohuon and Monneret (2009). Le Fanu (2002): “It is perhaps predictable that doctors and scientists should assume the credit for the ascendency of modern medicine without acknowledging, or indeed recognizing, the mysteries of nature that have played so important a part. Not surprisingly, they came to believe their intellectual contribution to be greater than it really was, and that they understood more than they really did. They failed to acknowledge the overwhelmingly empirical nature of technological and drug innovation, which made possible spectacular breakthroughs in the treatment of disease without the requirement of any profound understanding of its causation or natural history.”
Commerce as convex:
Ridley (2010) has comments on Phoenicians; Aubet (2001).
Pharma’s insider:
La Matina (2009).
Multiplicative side effects:
Underestimation of interactions in Tatonetti et al. (2012): they simply uncovered the side effects of people taking joint drugs together, which effectively swells the side effects (they show something as large as a multiplication of the effect by 4).
Strategic planning:
Starbuck et al. (1992, 2008), Abrahamson and Freedman (2007). The latter is a beautiful ode to disorder and “mess.”
Entrepreneurship:
Elkington and Hartigan (2008).
Harvard Business School professors’ pathological misunderstanding of small probabilities:
This is not an empirical statement, but just to have fun: for an illustrative example of a sucker who misses
ω
B
and
ω
C
, always start looking in Harvard. Froot (2001), Pisano (2006a, 2006b). Froot: “Because managers of insurance companies purchase reinsurance at far above the fair price, they must believe that risk management adds considerable value.” He thinks
he
knows the fair price.
Le Goff:
Le Goff (1985):
“L’un est un professeur, saisi dans son enseignement, entouré d’élèves, assiégé par les bans, où se presse l’auditoire. L’autre est un savant solitaire, dans son cabinet tranquille, à l’aise au milieu de la pièce où se meuvent librement ses pensées. Ici c’est le tumulte des écoles, la poussière des salles, l’indifférence au décor du labeur collectif,” “Là tout n’est qu’ordre et beauté / Luxe, calme, et volupté.”
Martignon:
Geschlechtsspezifische Unterschiede im Gehirn und mögliche Auswirkungen auf den Mathematikunterricht.
Wissenschaftliche Hausarbeit zur Ersten
Staatsprüfung für das Lehramt an Realschulen nach der RPO I v. 16.12.1999. Vorgelegt von: Ulmer, Birgit. Erste Staatsprüfung im Anschluss an das Wintersemester 2004/05, Pädagogische Hochschule Ludwigsburg. Studienfach: Mathematik. Dozenten: Prof. Dr. Laura Martignon, Prof. Dr. Otto Ungerer.
Renan:
Averroès et l’averroïsme,
p. 323 (1852).
Socrates:
Conversation with Mark Vernon (Vernon, 2009), who believes that Socrates was more like Fat Tony. Wakefield (2009) a great context. Calder et al. (2002) presents portraits more or less hagiographic.
Socratic Fallacy:
Geach (1966).
Episteme
-
Techne
:
Alexander of Aphrodisias,
On Aristotle’s Metaphysics, On Aristotle’s Prior Analytics
1.1–7,
On Aristotle’s Topics
1,
Quaestiones
2.16–3.15.
Tacit-Explicit knowledge:
Colins (2010), Polanyi (1958), Mitchell (2006).
Click
here
for a larger image of this table.
All the terms on the left seem to be connected. We can easily explain how
rationalism, explicit,
and
literal
fit together. But the terms on the right do not appear to be logically connected. What connects
customs, bricolage, myths, knowhow,
and
figurative
? What is the connection between religious dogma and tinkering? There is
something,
but I can’t explain it in a compressed form, but there is the Wittgenstein family resemblance.
Lévi-Strauss:
Lévi-Strauss (1962) on different forms of intelligence. However, in Charbonnier (2010), in interviews in the 1980s, he seems to believe that some day in the future, science will allow us to predict with acceptable precision very soon, “once we get the theory of things.” Wilken (2010) for bio. See also Bourdieu (1972) for a similar problem seen from a sociologist.
Evolutionary heuristics:
This is central but I hide it here. To summarize the view—a merger of what it is in the literature and the ideas of this book: an evolutionary heuristic in a given activity has the following attributes: (a) you don’t know you are using it, (b) it has been done for a long time in the very same, or rather similar environment, by generations of practitioners, and reflects some evolutionary collective wisdom, (c) it is free of the agency problem and those who use it survived (this excludes medical heuristics used by doctors since the patient might not have survived, and is in favor of collective heuristics used by society), (d) it replaces complex problems that require a mathematical solution, (e) you can only learn it by practicing and watching others, (f) you can always do “better” on a computer, as these do better on a computer than in real life. For some reason, these heuristics that are second best do better than those that seem to be best, (g) the field in which it was developed allows for rapid feedback, in the sense that those who make mistakes are penalized and don’t stick around for too long. Finally, as the psychologists Kahneman and Tversky have shown, outside the domains in which they were formed, these can go awfully wrong.
Argumentation and the green lumber problem:
In Mercier and Sperber (2011). The post-Socratic idea of reasoning as an instrument for seeking the truth has been recently devalued further—though it appears that the Socratic method of discussion might be beneficial, but only in a dialogue form. Mercier and Sperber have debunked the notion that we use reasoning in order to search for the truth. They showed in a remarkable study that the purpose of arguments is not to make decisions but to convince others—since decisions we arrive at by reasoning are fraught with massive distortions. They showed it experimentally, producing evidence that individuals are better at forging arguments in a social setting (when there are others to convince) than when they are alone.
Anti-Enlightenment:
For a review, Sternhell (2010), McMahon (2001), Delon (1997). Horkheimer and Adorno provide a powerful critique of the cosmeticism and sucker-traps in the ideas of modernity. And of course the works of John Gray, particularly Gray (1998) and
Straw Dogs,
Gray (2002).
Wittgenstein and tacit knowledge:
Pears (2006).
On Joseph de Maistre:
Companion (2005).
Ecological, non-soccer-mom economics:
Smith (2008), also Nobel lecture given along with Kahneman’s. Gigerenzer further down.
Wisdom of the ages:
Oakeshott (1962, 1975, 1991). Note that Oakeshott conservatism means accepting the necessity of a certain rate of change. It seems to me that what he wanted was organic, not rationalistic change.


================================================================================
CHAPTER/SECTION 150 (Item 153)
================================================================================

BOOK V:
The Nonlinear and the Nonlinear
More formally, to complement the graphical exposition, from Taleb and Douady (2012), the
local fragility
of a random variable
X
λ depending on parameter
λ
, at stress level
K
and semi-deviation level
s
–
(
λ
) with pdf
f
λ
is its
K-left-tailed semi-vega sensitivity
(“vega” being sensitivity to some measure of volatility),
V
(
X
,
fλ
,
K
,
s
–
) to
s
–
, the mean absolute semi-deviation below Ω, here
,
. The
inherited fragility
of
Y
with respect to
X
at stress level
L
=
φ
(
K
) and left-semi-deviation level
s
–
(
λ
) of
X
is the partial derivative
. Note that the stress level and the pdf are defined for the variable
Y,
but the parameter used for differentiation is the left-semi-absolute deviation of
X
. For antifragility, the flip above Ω, in addition to robustness below the same stress level
K
. The
transfer theorems
relate the fragility of
Y
to the second derivative
φ
(
K
) and show the effect of convex (concave or mixed nonlinear) transformations on the tails via the
transfer function
H
K
. For the antifragile, use
s
+
, the integral above
K
.
Fragility is not psychological:
We start from the definition of fragility as tail vega sensitivity and end up with nonlinearity as a necessary attribute of the source of such fragility in the inherited case—a cause of the disease rather than the disease itself. However, there is a long literature by economists and decision scientists embedding risk into psychological preferences—historically, risk has been described as derived from risk aversion as a result of the structure of choices under uncertainty with a concavity of the muddled concept of “utility” of payoff; see Pratt (1964), Arrow (1965), Rothschild and Stiglitz (1970, 1971). But this “utility” business never led anywhere except the circularity, expressed by Machina and Rothschild (2008), “risk is what risk-averters hate.” Indeed limiting risk to aversion to concavity of choices is a quite unhappy result.
The porcelain cup and its concavity:
Clearly, a coffee cup, a house, or a bridge doesn’t have psychological preferences, subjective utility, etc. Yet each is concave in its reaction to harm: simply, taking
z
as a stress level and Π(
z
) the harm function, it suffices to see that, with
n
>1, Π(
n z
) <
n
Π(
z
) for all 0
< n z<Z*
, where
Z*
is the level (not necessarily specified) at which the item is broken. Such inequality leads to Π(
z
) having a negative second derivative at the initial value
z
. So if a coffee cup is less harmed by
n
times a stressor of intensity
Z
than once a stressor of
n Z,
then harm (as a negative function) needs to be concave to stressors up to the point of breaking; such stricture is imposed by the structure of survival probabilities and the distribution of harmful events, nothing to do with subjective utility or some other figments.
Scaling in a positive way, convexity of cities:
Bettencourt and West (2010, 2011), West (2011). Cities are 3-D items like animals, and these beneficial nonlinearities correspond to efficiencies. But consider traffic!
“More Is Different”:
Anderson (1972).
Comparative fragility of animals:
Diamond (1988).
Flyvbjerg and colleagues on delays:
Flyvbjerg (2009), Flyvbjerg and Buzier (2011).
Small Is Beautiful, the romantic views:
Dahl and Tufte (1973), Schumacher (1973) for the soundbite. Kohr (1957) for the first manifesto against the size of the governing unit.
Size of government:
I can’t find people thinking in terms of convexity effects, not even libertarians—take Kahn (2011).
Small states do better:
A long research tradition on governance of city-states. It looks like what we interpret as political systems might come from size. Evidence in Easterly and Kraay (2000).
The age of increasing fragility:
Zajdenwebber, see the discussion in
The Black Swan
. Numbers redone recently in
The Economist,
“Counting the Cost of Calamities,” Jan. 14, 2012.
Convexity effect on mean:
Jensen (1906), Van Zwet (1966). While Jensen deals with monotone functions, Van Zwet deals with concave-convex and other mixtures—but these remain simple nonlinearities. Taleb and Douady (2012) applies it to all forms of local nonlinearities.
Empirical record of bigger:
Mergers and hubris hypothesis: in Roll (1986); since then Cartwright and Schoenberg (2006).
Debt in ancient history:
Babylonian jubilees, Hudson et al. (2002). Athens, Harrison (1998), Finley (1953). History of debt, Barty-King (1997), Muldrew (1993), Glaeser (2001). The latter has an anarchist view. He actually believes that debt precedes barter exchange.
Food networks:
Dunne et al. (2002), Perchey and Dunne (2012), Valdovinos and Ramos-Jiliberto (2010). Fragility and resources, Nasr (2008, 2009).
Fannie Mae:
They were concave across all meaningful variables. Some probability-and-nonlinearity-challenged fellow in the Obama commission investigating the cause of the crisis spread the rumor that I only detected interest rate risk of Fannie Mae: not true.
Costs of execution:
“Price impact,” that is, execution costs, increase with size; they tend to follow the square root—meaning the total price is convex and grows at exponent 3/2 (meaning costs are concave). But the problem is that for large deviations, such as the Société Générale case, it is a lot worse; transaction costs accelerate, in a less and less precise manner—all these papers on price impact by the new research tradition are meaningless when you need them. Remarkably, Bent Flyvbjerg found a similar effect, but slightly less concave in total, for bridges and tunnels with proportional costs growing at 10 Log[
x
] of size.
Small Is Beautiful, a technical approach:
To explain how city-states, small firms, etc. are more robust to harmful events, take
X,
a random variable for the “unintended exposure,” the source of uncertainty (for Soc Gen it was the position that it did not see, for a corporation it might be an emergency need to some inventory, etc.). Assume the size of this unintended harm is proportional to the size of the unit—for smaller entities engage in smaller transactions than larger ones. We use for probability distribution the variable of all unintended exposures ∑
X
i
where
X
i
are independent random variables, simply scaled as
X
i
= X/N
. With
k
the tail amplitude and
α
the tail exponent, π(
k
,
α
,
X
) =
α k
α
x
-1-
α
. The
N
-convoluted Pareto distribution for the unintended total position
N
∑
X
i
: π(
k/N
,
α
,
X
)
N
where
N
is the number of convolutions for the distribution. The mean of the distribution, invariant with respect to
N
, is
α k
/α−
1
).
Losses from squeezes and overruns:
for the loss function, take
C
[
X
]= -
b X
β
, where costs of harm is a concave function of
X
. Note that for small deviations, β = 3/2 in the microstructure and execution literature.
Resulting probability distribution of harm:
As we are interested in the distribution of
y,
we make a transformation of stochastic variable. The harm
y=C
[
X
] has for distribution: π[
C
-1
[
x
]]/
C
’[
C
-1
[
x
]]. Consider that it follows a Pareto distribution with tail amplitude
k
β
and tail exponent
α
/β,
which has for mean
. Now the sum: for the convoluted sum of
N
entities, the asymptotic distribution becomes:
with mean (owing to additivity) as a function of the variables which include
N:
. If we check the ratio of expected
losses in the tails for
N
=1 to
N
=10 at different values of the ratio of β over
α
, the ratio of the expectation for 1 unit over 10 units
reveals the “small is beautiful” effect across different levels of concavity.


================================================================================
CHAPTER/SECTION 151 (Item 154)
================================================================================

BOOK VI:
Via Negativa
Subtractive Knowledge
Maps:
A reader, Jean-Louis, a mapmaker, writes to me: “As a mapmaker, I learned a long time ago that the key to good mapmaking is precisely the info you choose to leave out. I have made numerous clients notice that if a map is too literal and precise, it confuses people.”
Imam Ali:
Nahj-el-Balagha, Letter. 31.
The mosaic god is not antifragile:
For God—the Abrahamic-Mosaic God (of Jews, Christians, and Moslems)—is the representation of total robustness and infallibility. Note that counter to initial impressions, the essence of perfection is robustness, not antifragility. I’ve received many messages suggesting that the (Levantine) God should be put in the antifragile category. This would be a severe mistake according to Eastern Mediterranean religions. Antifragility for a deity may apply to Babylonian, Greek, Syrian, and Egyptian mythologies. But Levantine monotheistic theology, from the ancient Semitic El (or Al) to the modern Allah or, to a lesser extent, what people call “the Lord” in the Bible Belt, from Genesis to the Koran, progressed into a definition of an increasingly abstract God—hence closest to the definition of pure robustness. The monotheistic God is certainly not fragile; but he is not antifragile. By definition, thanks to his maximally abstract quality, he is what cannot be improved, which is the very property of perfection—only imperfect mortals can improve, therefore need antifragility to try to improve. In the Koran, one of the properties of God is
Smd,
a word that has no synonym even in Arabic, hence cannot be translated; its meaning can only be conveyed through the iteration of partial descriptions.
Smd
is that which has reached such degree of completeness that it does not depend on external circumstances, anything or anyone; a bulwark against all manner of attacks; He transcends the notion of time. The idea is also present in other Levantine systems. Orthodox theology, through
theosis,
seeks merger with God, the aspiration to a level of completeness, hence independence from anything else.
Interdicts in religion:
Fourest and Venner (2010) presents a list across all persuasions.
Steve Jobs:
Beahm (2011).
Gladwell:
“If you totted up all his hospital bills for the ten years that he had been on the streets—as well as substance-abuse-treatment costs, doctors’ fees, and other expenses—Murray Barr probably ran up a medical bill as large as anyone in the state of Nevada. ‘It cost us one million dollars not to do something about Murray,’ O’Bryan said.” Gladwell (2009).
Falsification and problems of induction:
See references in
The Black Swan
.
Smoking and overall medical effect:
Burch (2009).
Fractality:
Mandelbrot (1983).
Edgerton’s shock of the old:
Edgerton (2007).
Less Is More in Decision Theory
Simplicity and Steve Jobs:
“That’s been one of my mantras—focus and simplicity. Simple can be harder than complex: You have to work hard to get your thinking
clean to make it simple. But it’s worth it in the end because once you get there, you can move mountains.”
BusinessWeek,
May 25, 1998.
Heuristics as powerful—and necessary—shortcuts:
Gigerenzer and Brighton (2009) bust the following myth, as presented in
The Selfish Gene
by Richard Dawkins, in which we find the following about how a baseball outfielder catches a ball: “[H]e behaves as if he had solved a set of differential equations in predicting the trajectory of the ball.… At some subconscious level, something functionally equivalent to the mathematical calculations is going on.”
Not quite, Professor Dawkins. Gerd Gigerenzer et al. counter by saying that none of that is done. They write the following:
Instead, experiments have shown that players rely on several heuristics. The gaze heuristic is the simplest one and works if the ball is already high up in the air: Fix your gaze on the ball, start running, and adjust your running speed so that the angle of gaze remains constant. A player who relies on the gaze heuristic can ignore all causal variables necessary to compute the trajectory of the ball—the initial distance, velocity, angle, air resistance, speed and direction of wind, and spin, among others. By paying attention to only one variable, the player will end up where the ball comes down without computing the exact spot.
The same heuristic is also used by animal species for catching prey and for intercepting potential mates. In pursuit and predation, bats, birds, and dragonflies maintain a constant optical angle between themselves and their prey, as do dogs when catching a Frisbee.
Additional examples:
To choose a mate, a peahen uses a heuristic: Rather than investigating all peacocks posing and displaying in a lek eager to get her attention or weighting and adding all male features to calculate the one with the highest expected utility, she investigates only three or four, and chooses the one with the largest number of eyespots.
Just like humans. Another example:
To measure the area of a nest cavity, a narrow crack in a rock, an ant has no yardstick but a rule of thumb: Run around on an irregular path for a fixed period while laying down a pheromone trail, and then leave. Return, move around on a different irregular path, and estimate the size of the cavity by the frequency of encountering the old trail. This heuristic is remarkably precise.
Other: Czerlinski and Gigerenzer et al. (1999), Goldstein and Gigerenzer (1999), Gigerenzer (2008).
Makridakis, forecasting, and less is more:
Makridakis et al. (1982, 1993), Makridakis and Hibon (2000), Makridakis and Taleb (2009).
Heuristic to measure risks:
Taleb, Canetti et al. (2012)—with IMF staff.
Lindy Effects and Associated Topics
The Lindy effect was demonstrated in Mandelbrot (1997). Initially he used it for the artistic production, bounded by the life of the producer. In our conversations toward the end of his life, I suggested the boundary perishable/nonperishable and he agreed that the nonperishable would be powerlaw distributed while the perishable (the initial Lindy story) worked as a mere metaphor. Depending on
whether we condition for knowledge of the initial time, the remaining lifetime for the exponential remains constant regardless of future condition, for powerlaw increases with time since inception, by a factor of (
α
/1-
α
), where
α
is the tail exponent; for Gaussian or semi-Gaussian it decreases.
Gott:
Gott (1993, 1994) presented the Copernican idea but did not properly condition the probability; corrected in Caves (2000). See discussion in Rees (2003), a treatment of the paradox in Bostrom (2002).
Survival papers and distributional properties:
Often powerlaws are mistaken for exponential distributions, owing to lack of data in the tails. So I assume a priori that an exponential is likely to be powerlaw, but not the reverse, as the error in the opposite direction is vastly less likely. Pigolotti et al. (2005). For empires, Arbesman (2011), Khmaladze et al. (2007, 2010), Taagepera (1978, 1979). For firms: Fujiwara. Also Turchin (2003, 2009).
Conditional expected time of survival across distributions:
Sornette and Knopoff (1997). They show how, paradoxically, the longer one waits for an earthquake, the longer he would be expected to wait.
Other Neomania
Le Corbusier:
Christopher Caldwell, “Revolting High Rises,”
New York Times,
November 27, 2005.
Cairns and ancient measures:
Cairns (2007). His work was brought to my attention by Yoav Brand, who graciously offered me his book after a lecture.
Nonteleological design:
How buildings mutate and change, Brand (1995).
The Dog:
Moral,
ii. 11; 1208 b 11. “And he says that when a dog was accustomed always to sleep on the same tile, Empedokles was asked why the dog always sleeps on the same tile, and he answered that the dog had some likeness to the tile, so that the likeness is the reason for its frequenting it.”
General and Philosophical Discussions of Medicine
Medicina soror philosophiae:
For reflective histories of medicine, Mudry (2006), Pigeaud (2006); Camguillem (1995) discussion of iatrogenics. For the spirit, Pager (1996), Bates (1995).
Islamic medicine:
Porman and Savage-Smith (2007), Djebbar (2001).
De motu animali
and attempts to mathematize medicine:
In Wear (1995). Let me reiterate: math is good, the wrong math is not good.
Ancient medicine:
Edelstein (1987), Lonrig (1998). Vivian Nutton’s
Ancient Medicine
(Nutton [2004]) is informative, but near-silent about the empiricists, and not too detailed about ancient practices outside of a few standard treatises. More on medicine (skeptics and methodists) in the monumental Zeller (1905) or even better the superb
Les Sceptiques Grecs
by Brochard.
Oranges:
As they are named in Modern Greek,
portokali,
a corruption of “Portuguese”—further corrupted in Levantine Arabic into
burduqan,
and present under that name in the Sicilian dialect.
Medical heuristics:
Palmieri (2003).
Medieval and Renaissance:
French (2003).
General history:
Conrad et al. (1995), Porter (2002, 2003), Meslin et al. (2006), Kennedy (2004).
Iatrogenics:
Sharpe and Faden (1998), most complete; Illich (1995) the first movement; Hadler (2009) for the back, Duffin (1999), Welsh et al. (2011) on overdiagnosis (though no argument about noise/signal and filtering), Lebrun (1995).
Agency and iatrogenics:
Just a random example: “Surgeons do more operations if they’re on the board of surgery centers,” June 22, 2012, “The Daily Stat,”
Harvard Business Review
.
More amusing historical perspective of iatrogenics:
Gustave Jules A. Witkowski, 1889,
Le mal qu’on a dit des médecins.
Rationalism/Galenism:
Garicia-Ballester (1995).
Montaigne:
“Mais ils ont cet heur, selon Nicocles, que le soleil esclaire leur succez, et la terre cache leur faute; et, outre-cela, ils ont une façon bien avantageuse de se servir de toutes sortes d’evenemens, car ce que la fortune, ce que la nature, ou quelque autre cause estrangere (desquelles le nombre est infini) produit en nous de bon et de salutaire, c’est le privilege de la medecine de se l’attribuer. Tous les heureux succez qui arrivent au patient qui est soubs son regime, c’est d’elle qu’il les tient. Les occasions qui m’ont guery, moy, et qui guerissent mille autres qui n’appellent point les medecins à leurs secours, ils les usurpent en leurs subjects; et, quant aux mauvais accidents, ou ils les desavouent tout à fait, en attribuant la coulpe au patient par des raisons si vaines qu’ils n’ont garde de faillir d’en trouver tousjours assez bon nombre de telles.
…
”
[Note the detection of the attribution problem.]
On demandoit à un Lacedemonien qui l’avoit fait vivre sain si long temps: L’ignorance de la medecine, respondit il.
Et Adrian l’Empereur crioit sans cesse, en mourant, que la presse des medecins l’avoit tué.
Modern alternative medicine:
Singh and Edzard (2008)—they had their skin in the game, as they were sued for it.
Homeopathy and empirical evidence:
Goldacre (2007). See also the highly readable
Bad Science,
Goldacre (2009).
Modern evidence-based medicine:
Manual in Sacket et al. (1998). Flaws of rationalistic methods, Silverman (1999), Gauch (2009), Sestini and Irving (2009).
Icing:
Collins (2008): “There is insufficient evidence to suggest that cryotherapy improves clinical outcome in the management of soft tissue injuries.” I could not find papers saying the opposite. What benefits are proffered seem so marginal it is not even funny.
Convexity of blood pressure:
Numbers from Welch et al. (2011).
Jensen’s inequality and pulmonary ventilators:
Brewster et al. (2005), Graham et al. (2005), Mutch et al. (2007).
Paracelsus:
Interesting character as a rebel; alas, seems to have been hijacked by homeopathy advocates such as Coulter (2000). Biographies in Ball (2006), Bechtel (1970), Alendy (1937).
Immortalization:
Gray (2011).
Stendhal:
Le Rouge et le noir: “La besogne de cette journée sera longue et rude, fortifions-nous par un premier déjeuner; le second viendra à dix heures pendant la grand’messe
.
”
Chapitre XXVIII.
Specific Medical Topics
Note that the concern of this author is not evidence, but rather absence of it and how researchers manage such a problem. The focus is in detecting missed convexities.
Effectiveness of low-calorie sweeteners:
One gets plenty of information by looking at studies by defenders with vested interests. De la Hunty et al. (2006) shows “advantages” to aspartame, with a meta-analysis, but focusing on the calorie-in calorie-out method, not overall weight gains. But reading it closely uncovers that the core is missing: “Some compensation for the substituted energy occurs but this is only about one-third of the energy replaced and is
probably
[emphasis mine]
less than when using soft drinks sweetened with aspartame. Nevertheless these compensation values are derived from short-term studies.” Obviously, the paper was financed by a maker of aspartame. A better study, Anderson et al. (2012), though marred with conflict of interest (authors’ support from food companies), concludes: “there is no evidence that LCS (low calorie sweeteners) can be claimed to be a cause of higher body weight in adults. Similarly evidence supporting a role in weight management is lacking.” The last sentence is the only one that I can pay attention to as it is evidence “against interest.” Had there been benefits, we would have known about them. In other words, we are incurring iatrogenics of these sweets-without-calories without evidence, as of 2012, that they even work!
Mithridatization and hormesis:
In Pliny, Kaiser (2003), Rattan (2008), Calabrese and Baldwin (2002, 2003a, 2003b). Note that they miss the convexity argument or the insight about the departure from the norm—hormesis might just be reinstatement of normalcy.
Fasting and hormesis:
Martin, Mattson et al. (2006). Cancer treatment and fasting, Longo et al. (2008), Safdie et al. (2009), Raffaghelo et al. (2010)); on yeast and longevity under restriction, Fabrizio et al. (2001); SIRT1, Longo et al. (2006), Michan et al. (2010); review work in Blagosklonny et al. (2010).
Definition of hormesis:
Mattson (2008) for local definition, Danchin et al. (2011) for more complex-systems approach.
Aging, longevity, and hormesis:
An extremely rich research; Radak et al. (2005), Rattan (2008), Cypster and Johnson (2002) for the C-elegans; Gems and Partridge (2008), Haylick (2001), Masoro (1998), Parsons (2000); for inflammation and Alzheimer’s, Finch et al. (2001).
Bone density and load:
Dook (1997) for females, Andreoli et al. (2001) for more general athletes; Scott, Khan, et al. (2008) for general exercise. Aging for females: Solomon (1997), Rautava et al. (2007); Conroy et al. (1993) for young females.
Bone density and bicycle riding:
Nichols et al. (2003), Barry et al. (2008).
Bone density and Olympic-style weightlifting:
Some “weightlifting” studies mistake the resistance exercise on machines for real naturalistic weightlifting that stresses the skeleton. Conroy et al. (1993) is a more ecologically robust study because it focuses on weight.
Thyroid:
Earle (1975).
Cholesterol:
Non-naive look, Scanu and Edelstein (2008).
Lewontin and life expectancy:
Lewontin (1993). Got idea for the potential unreliability of the Lewontin estimation and was directed to the CDC data from some article on the Web I can’t remember.
Outdoors not sports:
Rose et al. (2008). Higher levels of total time spent outdoors, rather than at sports per se, were associated with less myopia and a more hyperopic mean refraction, after adjusting for near work, parental myopia, and ethnicity.
“Neurobabble,” “brain porn” studies:
Weisberg (2008), McCabe (2008), also “neuroscience and the law,” report by the U.K. Royal Society. Note that the writer Jonah Lehrer used brain porn quite effectively, building a narrative using some loose brain story, playing the narrative fallacy to the hilt—until he was caught creating both narrative and data to back it up.
The pressure on dentists to generate revenues:
“Dental Abuse Seen Driven by Private Equity Investments,” Sydney P. Freedberg, Bloomberg News, May 17, 2012.
Significance:
Simply, people in social science should not be using statistics any more than an accountant should be given a surgeon’s knife. The problem of misunderstanding significance affects professionals. See McCloskey and Ziliak (1996),
Ziliak and McCloskey (2008), Soyer and Hogarth (2011), Kahneman and Tversky (1971), Taleb and Goldstein (2012).
Practitioners and theoreticians in mathematical finance failing to understand an elementary notion in statistics in spite of all the hype:
Evidence in Taleb and Goldstein (2007).
Missing nonlinearities of dose response:
The case of radiation is rather stark, Neumaier et al. (2012). “The standard model currently in use applies a linear scale, extrapolating cancer risk from high doses to low doses of ionizing radiation. However, our discovery of DSB clustering over such large distances casts considerable doubts on the general assumption that risk to ionizing radiation is proportional to dose, and instead provides a mechanism that could more accurately address risk dose dependency of ionizing radiation.” Radiation hormesis is the idea that low-level radiation causes hormetic overreaction with protective effects. Also see Aurengo (2005).
Statins and convexity:
For instance, with statin drugs routinely prescribed to lower blood lipids, although the result is statistically significant for a certain class of people, the effect is minor. “High-risk men aged 30–69 years should be advised that about 50 patients need to be treated for 5 years to prevent one [cardiovascular] event” (Abramson and Wright, 2007).
Statins side effects and (more or less) hidden risks:
Side effects in musculoskeletal harm or just pain, Women, Speed et al. (2012). General assessment, Hilton-Jones (2009), Hu Chung et al. (2012). Roberts (2012) shows another aspect of convexity of benefits, hence harm in marginal cases. Fernandez et al. (2011) shows where clinical trials do not reflect myopathy risks. Blaha et al. (2012) shows “increased risks for healthy patients.” Also, Reedberg and Katz (2012); Hamazaki et al.: “The absolute effect of statins on all-cause mortality is rather small, if any.”
Harlan Krumholz,
Forbes,
April 29, 2011:
Problem is that drugs that improve blood test results may not lower risk. For example, many drugs that reduce LDL or raise HDL or lower blood sugar or blood pressure, do not, against all expectations, lower risk—and in some cases they increase risk.
This is particularly true when considering treatment options to prevent a future event such as a heart attack. Unfortunately, for many drugs that affect risk factors, studies that investigate whether patients benefit are either not done or delayed. This is the case with ezetimibe, a Merck agent that reduces LDL. Because the study that will include information about patient outcomes will only be completed when ezetimibe comes off patent, we will not know how it actually affects risk for a few more years. This billion dollar drug’s approval and sales have been solely based on its effect on a blood test.
For the fibrates, though, we are more fortunate. There are studies of patient outcomes, and fenofibrate, the Abbott drug, has been tested twice in large studies. In both, the drug failed to reduce the risk of the patients taking it even as it very effectively lowered their triglyceride levels. Most recently, in a $300 million trial by the National Institutes of Health, no benefit was shown for the Abbott drug when it was combined with a statin—compounded by a suggested harm for women. The former concern is sufficiently high to have prompted the FDA to convene an advisory committee to review the findings.
Back:
McGill (2007); iatrogenics surgery or epidural, Hadler (2009), Sayre (2010).
Doctor’s strikes:
There have been a few episodes of hospital strikes, leading to the cancellation of elective surgeries but not emergency-related services. The data
are not ample, but can give us insights if interpreted in
via negativa
mode. Extracting the effect of elective surgery, Argeseanu et al. (2008). See also Allebeck (1985), Gruber and Kleiner (2010), Siegel-Itzkovich (2000).
Diabetes and pharmacological treatments (ACCORD study):
The ACCORD study (Action to Control Cardiovascular Risk in Diabetes) found no gain from lowering blood glucose, or other metrics—it may be more opaque than a simple glucose problem remedied by pharmacological means. Synthesis, Skyler et al. (2009), old methods, Westman and Vernon (2008).
Discussions of diabetes and diet:
Taylor (2008), reversal in Lim et al. (2011), Boucher et al. (2004), Shimakuru et al. (2010); diabetes management by diet alone, early insights in Wilson et al. (1980). Couzin, “Deaths in Diabetes Trial Challenge a Long-Held Theory,”
Science
15 (February 2008): 884–885. Diabetes reversal and bariatric (or other) surgery: Pories (1995), Guidone et al. (2006), Rubino et al. 2006.
Autophagy for cancer:
Kondo et al. (2005).
Autophagy (general):
Danchin et al. (2011), Congcong et al. (2012).
Jensen’s inequality in medicine and workout:
Many such as Schnohr and Marott (2011) got close to dealing with the fact that extreme sprinting and nothing (as a barbell) outperforms steady exercise, but missed the convexity bias part.
Art De Vany and Jensen’s inequality:
Art De Vany, private correspondence: “Tissue gains are increasing but convex with nutrient intake (the curve is rising, but at a diminishing rate). This has to be the case for the point of origin to be a steady state solution. This implies that weight gain, including fat, is higher at the average intake than it is on a varying intake of the same calories and nutrients. Muscle and fat compete for substrate, so a fatter person will shift nutrient partitioning toward muscle because body fat induces insulin resistance in muscle. Insulin operates in a pulsate release and is far more effective with that pattern than with the chronic elevation induced by six meals a day. On the downside, where fat and muscle are lost, the curve is negatively sloped but declines at a diminishing rate (concave). This means you lose more fat feeding intermittently than continuously. The loss at the average intake (six per day keeps the variation of the average small) is less than the loss at the same intake but one that varies between a small intake and a large one. A more subtle point: you lose more weight when you eat at the average than intermittently, but that is because you lose more muscle in chronic deprivation than intermittent deprivation. Intermittent eating yields a superior body composition.”
Starvation, intermittent fasting, and aging:
For the neuronal resistance and brain aging, Anson, Guo, et al. (2003), Mattson et al. (2005), Martin, Mattson et al. (2006), Halagappa, Guo, et al. (2007), Stranahan and Mattson (2012).
Caloric restriction:
Harrison (1984), Wiendruch (1996), Pischon (2008).
Intense exercise:
Synthesis of the literature on the effect of episodic energy imbalance, in De Vany (2011), who also, as a bonus, examines powerlaw effects.
Missing the point that pills are more speculative:
Stip (2010) spends time on
via positiva
methods to extend life with complicated pharma stories.
Glucose and willpower:
Note the effect of glucose making people sharper and helping willpower from experiments by Baumeister, see Kahneman (2011), might only apply to metabolically unfit persons. See Kurzban (2011) for a look at the statistical tools.
Cluster of ailments from lack of randomness, as presented in prologue:
Yaffe and Blackwell (2004), Razay and Wilcock (1994); Alzheimer and hyperinsulenemia, Luchsinger, Tang, et al. (2004), Janson, Laedtke, et al. (2004).
Starvation and the brain:
Stranahan and Mattson (2012). Long-held belief that the
brain needed glucose, not ketones, and that the brain does not go through autophagy, progressively corrected.
Ramadan and effect of fasting:
Ramadan is not interesting because people fast for only about 12 hours, depending on the season (someone who fasts from dinner to lunch can get 17 hours without food, which is practiced by this author). Further, they gorge themselves at dawn, and load on carbohydrates with, in my experience, the sweets of Tripoli (Lebanon). Nevertheless, some significance. Trabelsi et al. (2012), Akanji et al. (2012).
Benefits of stress:
For the different effects of the two types of stressors, short and chronic, Dhabar (2009); for the benefits of stress on boosting immunity and cancer resistance, Dhabhar et al. (2010), Dhabhar et al. (2012).
Iatrogenics of hygiene and systematic elimination of germs:
Rook (2011), Garner et al. (2006), Mégraud and Lamouliatte (1992) for Helyobacter.
The Paleo crowd, De Vany, Gary Taubes, and friends:
Taubes (2008, 2011), De Vany (2011); evolutionary anthropology, Carrera-Bastos et al. (2011), Kaplan et al. (2000).


================================================================================
CHAPTER/SECTION 152 (Item 155)
================================================================================

BOOK VII:
The Ethics of Fragility and Antifragility
Modern philosophical discussions on capitalism:
No interest in such a simple heuristic as skin in the game, even in insightful discourses such as Cuillerai (2009).
Courage in history:
Berns et al. (2010).
Gladiators:
Veyne (1999).
Treadmill:
Lucretius,
Nimirum quia non bene norat quæ esset habendi / Finis, et omnino quoad crescat vera voluptas.
Group and collective:
Haidt (2012).
Adam Smith on capitalism:
“A word he never uttered”: Simon Schama, private communication.
Stiglitz et al. dangerous report:
Joseph E. Stiglitz, Jonathan M. Orszag, and Peter R. Orszag, “Implications of the New Fannie Mae and Freddie Mac Risk-based Capital Standard,”
Fannie Mae Papers,
Volume I, Issue 2, March 2002.
Meyer Lansky:
Attributed to Ralph Salerno, retired NYPD mob investigator, in Ferrante (2011).
Unsavory activities by pharma finding patients rather than treatments:
Stories of direct and indirect corruption, particularly in the psychiatric domain. A professor of psychiatry at Harvard Medical School received $1.6 million from pharma. “Thanks to him, children as young as two years old are now being diagnosed with bipolar disorder …” Marcia Angell,
The New York Review of Books
. Angell used to be the editor of
The New England Journal of Medicine
and distrusts a large number of clinical studies. Further, how money is not spent on speculative research, but on “safe” bets with regular drugs, Light and Lexchin (2012).
Contradicting studies:
Kahneman brought to my attention studies such as Malmendier and Tate (2008, 2009) showing managers investing more than needed in their companies, hence excess skin in the game as a result of overconfidence. Myron Scholes and Robert Merton had investments in LTCM. Indeed—but overall the free option dominates (just measure the aggregate payment of managers relative to gains by shareholders). There are “fools of randomness” and “crooks of randomness”; we often observe a combination. (Credit: Nicolas Tabardel.)
Asymmetries and extractive:
Acemoglu and Robinson (2012) discusses an asymmetry with their notion of extractive economic institutions and environment, in which someone gets rich at the expense of someone else, the opposite of the convex
collaborative framework in which one’s wealth leads to a compounding pie. Role of institutions, North (1990).
Caviar socialism and Burnyeat’s problem:
Riffard (2004), Burnyeat (1984), Wai-Hung (2002).
Collective blindness and diffusion of responsibility:
In the animal domain (ants), Deneubourg, Goss et al. (1983), Deneubourg, Pasteels et al. (1983).
Life and socialization in Rome:
Veyne (2001).
Elephant in the room:
Things that everyone knows but remain undiscussed. Zerubavel (2006).
Mortality of large firms:
Higher than expected, Greenwood and Suddaby (2006), comment Stubbart and Knight (2006). The best test is to take the S&P 100 or S&P 500 and look at its composition through time. The other one of course is in the literature on mergers.
Information cascades:
The mechanism by which the crowd exacerbates fallacies, illusions, and rumors, Sunstein (2009) for a synthesis.
Alan Blinder problem:
Wall Street Journal
article with undisclosed conflict of interest: “Blanket Deposit Insurance Is a Bad Idea,” Oct. 15, 2008, coauthored with R. Glenn Hubbard, dean of Columbia University Business School.
Comparative performance of family businesses:
McConaughy and Fialco (2001), Le Breton–Miller and Miller (2006), Mackie (2001).
Skin in the game:
Taleb and Martin (2012a).
Data Mining, Big Data, and the Researcher’s Option, etc.
Misunderstanding in social science literature:
Typical mistake, consider the ignorance of the problem by hyperactive promoters of the idea such as Ayres (2007): “Want to hedge a large purchase of Euros? Turns out you should sell a carefully balanced portfolio of twenty-six other stocks and commodities that might include Wal-Mart stock,” p. 11.
Stan Young’s crusade:
Young and Carr (2011). Also Ioannides (2005, 2007).
Doxastic commitment:
Levi (1980).
Salt:
Very convincing Freedman and Petitti (2001), relies on visualization of data rather than metrics. Note “neither author consults for the salt industry,” the kind of thing I read
first
.
Graph on Big Data:
By Monte Carlo simulation; used >0.1, or beyond what correlations are loved in social science (it is hard to analytically do the analysis because of the need for large matrices to remain positive-definite). The convexity is invariant to the correlation threshold.
Solution to the researcher’s bias in clinical trials:
Goldacre (2009) suggests the establishment of a database of trials, forcing researchers to record their failures. Anything is better than what we got.
The collective and fragility:
The power of the collective rests on benefits from efficiency, hence fragility: people start substituting collective judgment for individual judgment. This works fine—it is faster and cheaper (hence more
efficient
) than having to reinvent the wheel individually. But like everything that is a shortcut, it ends blowing up in our faces. In the world in which we live the effect is compounded—the scale is larger and larger; the collective is planetary.
Jobs and artisan ethics:
This makes me worry: “Playboy: ‘Are you saying that the people who made PCjr don’t have that kind of pride in the product?’ Jobs: ‘If they did, they wouldn’t have made the PCjr.’ ”
Playboy
[
sic
], Feb. 1, 1985.
Busting the hypothesis of hyperbolic discounting:
Read and Airoldi (2012).
Other discussions of Big Data and researchers gaming the system:
Baumeister et al. (2007) about self-reporting in psychology. Kerr (1998) about hypothesis following the results, and post hoc in Yauan and Maxwell; Yarkoni for the large
M
(dimension) low
N
(data) problem.


================================================================================
CHAPTER/SECTION 153 (Item 156)
================================================================================

BIBLIOGRAPHY
About, Edmond, 1855,
La Grèce contemporaine
.
Abrahamson, Eric, and David H. Freedman, 2007,
A Perfect Mess: The Hidden Benefits of Disorder: How Crammed Closets, Cluttered Offices, and On-the-Fly Planning Make the World a Better Place
. Little, Brown.
Abramson, J., and J. Wright, 2007, “Are Lipid-Lowering Guidelines Evidence-Based?”
Lancet
369(9557): 168–169.
Acemoglu, Daron, and James A. Robinson, 2012,
Why Nations Fail: The Origins of Power, Prosperity and Poverty.
New York: Crown Books.
ACCORD Study Group, 2007, “Action to Control Cardiovascular Risk in Diabetes (ACCORD) Trial: Design and Methods.”
American Journal of Cardiology
99 (suppl): 21i–33i.
Akanji, A. O., O. A. Mojiminiyi, and N. Abdella, 2000, “Beneficial Changes in Serum Apo A-1 and Its Ratio to Apo B and HDL in Stable Hyperlipidaemic Subjects After Ramadan Fasting in Kuwait.”
European Journal of Clinical Nutrition
54(6): 508–13.
Allebeck, P., 1985, “The General Labour Conflict in Sweden 1980: Effects on the Mortality in Stockholm County.” Public Health 99(1): 10–17.
Allendy, René, 1937,
Paracelse; le médecin maudit
. Gallimard.
Alter, A. L., D. M. Oppenheimer, et al., 2007, “Overcoming Intuition: Metacognitive Difficulty Activates Analytic Reasoning.”
Journal of Experimental Psychology: General
136(4): 569.
Anderson, G., J. Foreyt, M. Sigman-Grant, and D. Allison, 2012, “The Use of Low-Calorie Sweeteners by Adults: Impact on Weight Management.”
Journal of Nutrition
142(6): 1163s–1169s.
Anderson, P. W., 1972,
Science,
New Series, Vol. 177, No. 4047 (Aug. 4), pp. 393–396.
Anderson, R. C., and D. M. Reeb, 2004, “Board Composition: Balancing Family Influence in S&P 500 Firms.”
Administrative Science Quarterly
209–237.
Andreoli, A., M. Monteleone, M. Van Loan, L. Promenzio, U. Tarantino, and A. De Lorenzo, 2001, “Effects of Different Sports on Bone Density and Muscle Mass in Highly Trained Athletes.”
Medicine & Science in Sports & Exercise
33(4): 507–511.
Anson, R. M., Z. Guo, et al., 2003, “Intermittent Fasting Dissociates Beneficial Effects of Dietary Restriction on Glucose Metabolism and Neuronal Resistance to Injury from Calorie Intake.”
Proceedings of the National Academy of Sciences of the United States of America
100(10): 6216.
Arbesman, S., 2011, “The Life-Spans of Empires.”
Historical Methods: A Journal of Quantitative and Interdisciplinary History
44(3): 127–129.
Arikha, Noga, 2008a,
Passions and Tempers: A History of the Humours
. Harper Perennial.
Arikha, Noga, 2008b, “Just Life in a Nutshell: Humours as Common Sense,”
Philosophical Forum Quarterly
XXXIX: 3.
Arnheim, Rudolf, 1971,
Entropy and Art: An Essay on Disorder and Order.
Berkeley: University of California Press.
Arnqvist, G., and M. Kirkpatrick, 2005, “The Evolution of Infidelity in Socially Monogamous Passerines: The Strength of Direct and Indirect Selection on Extrapair Copulation Behavior in Females.”
American Naturalist
165 (s5).
Aron, Raymond, 1964,
Dimensions de la conscience historique
. Agora/Librairie Plon.
Arrow, Kenneth, 1971, “Aspects of the Theory of Risk-Bearing,” Yrj¨o Jahnsson Lectures (1965), reprinted in
Essays in the Theory of Risk Bearing,
edited by Kenneth Arrow. Chicago: Markum.
Atamas, S. P., and J. Bell, 2009, “Degeneracy-Driven Self-Structuring Dynamics in Selective Repertoires.”
Bulletin of Mathematical Biology
71(6): 1349–1365.
Athavale, Y., P. Hosseinizadeh, et al., 2009, “Identifying the Potential for Failure of Businesses in the Technology, Pharmaceutical, and Banking Sectors Using Kernel-Based Machine Learning Methods.” IEEE.
Aubet, Maria Eugenia, 2001,
The Phoenicians and the West: Politics, Colonies and Trade,
Cambridge: Cambridge University Press.
Audard, Catherine, ed., 1993,
Le respect: De l’estime à la déférence: une question de limite
. Paris: Éditions Autrement.
Aurengo, André, 2005, “Dose-Effect Relationships and Estimation of the Carcinogenic Effects of Low Doses of Ionizing Radiation.” Académie des Sciences et Académie Nationale de Médecine.
Ayanian, J. Z., and D. M. Berwick 1991, “Do Physicans Have a Bias Toward Action?”
Medical Decision Making
11(3): 154–158.
Ayres, Ian, 2007,
Super Crunchers: Why Thinking-by-Numbers Is the New Way to Be Smart.
New York: Bantam.
Bakwin, H., 1945, “Pseudodoxia Pediatrica.”
New England Journal of Medicine
232(24): 692.
Ball, Philip, 2006,
The Devil’s Doctor: Paracelsus and the World of Renaissance Magic and Science
. New York: Farrar, Straus and Giroux.
Ball, Philip, 2008,
Universe of Stone: A Biography of Chartres Cathedral
. New York: Harper.
Bar-Yam, Yaneer, and I. Epstein, 2004. “Response of Complex Networks to Stimuli.”
Proceedings of the National Academy of Sciences of the United States of America
101(13): 4341.
Bar-Yam, Yaneer, 2001,
Introducing Complex Systems
. Cambridge, Mass.: New England Complex Systems Institute, 57.
Barkan, I., 1936, “Imprisonment as a Penalty in Ancient Athens.”
Classical Philology
31(4): 338–341.
Barry, D. W., and W. M. Kohrt, 2008, “BMD Decreases over the Course of a Year in Competitive Male Cyclists.”
Journal of Bone and Mineral Research
23(4): 484–491.
Barty-King, H., 1997,
The Worst Poverty: A History of Debt and Debtors
. Budding Books.
Basalla, George, 1988,
The Evolution of Technology
. Cambridge: Cambridge University Press.
Bates, Don, ed., 1995,
Knowledge and the Scholarly Medical Traditions
. Cambridge: Cambridge University Press.
Baumeister, R. F., K. D. Vohs, and D. C. Funder, 2007, “Psychology as the Science of Self-Reports and Finger Movements: Whatever Happened to Actual Behavior?”
Perspectives on Psychological Science
2: 396–403.
Beahm, George, 2011,
I, Steve: Steve Jobs in His Own Words
. Perseus Books Group.
Beaujouan, G., 1991,
Par raison de nombres: L’art du calcul et les savoirs scientifiques médiévaux
. Variorum Publishing.
Beaujouan, G., 1973,
Réflexions sur les rapports entre théorie et pratique au moyen age
. D. Reidel Publ. Co.
Bechtel, Guy, 1970,
Paracelse et la naissance de la médecine alchimique
. Culture, Art, Loisirs.
Bell, David A., 2001,
The Cult of the Nation in France: Inventing Nationalism 1680–1800
. Cambridge, Mass.: Harvard University Press.
Bennett, G., N. Gilman, et al., 2009, “From Synthetic Biology to Biohacking: Are We Prepared?”
Nature Biotechnology
27(12): 1109–1111.
Berkun, Scott, 2007,
The Myths of Innovation
. Sebastol, Calif.: O’Reilly.
Berlin, Isaiah, 1990,
The Crooked Timber of Humanity
. Princeton, N.J.: Princeton University Press.
Berns, Thomas, Laurence Blésin, and Gaelle Jeanmart, 2010,
Du courage: une histoire philosophique
. Encre Marine.
Bernstein, Peter L., 1996,
Against the Gods: The Remarkable Story of Risk
. New York: Wiley.
Bettencourt, L., and G. West, 2010, “A unified theory of urban living,”
Nature
467(7318): 912–913.
Bettencourt, L., and G. West, 2011, “Bigger Cities Do More with Less.”
Scientific American
305(3): 52–53.
Beunza, D., and D. Stark, 2010, “Models, Reflexivity, and Systemic Risk: A Critique of Behavioral Finance.” Preprint.
Biezunski, Michel, ed., 1983,
La recherche en histoire des sciences
. Paris: Éditions du Seuil.
Blagosklonny, M., J. Campisi, D. Sinclair, A. Bartke, M. Blasco, W. Bonner, V. Bohr, R. Brosh Jr., A. Brunet, and R. DePinho, 2010, “Impact Papers on Aging in 2009.”
Aging
(Albany, N.Y.), 2(3): 111.
Blaha, M. J., K. Nasir, R. S. Blumenthal, 2012, “Statin Therapy for Healthy Men Identified as ‘Increased Risk.’ ” JAMA 307(14): 1489–90.
Bliss, Michael, 2007,
The Discovery of Insulin
. Chicago: University of Chicago Press.
Blundell-Wignall, A., G. Wehinger, et al., 2009, “The Elephant in the Room: The Need to Deal with What Banks Do.”
OECD Journal: Financial Market Trends
(2).
Boehlje, M., 1999, “Structural Changes in the Agricultural Industries: How Do We Measure, Analyze and Understand Them?”
American Journal of Agricultural Economics
81(5): 1028–1041.
Bohuon, Claude, and Claude Monneret, 2009,
Fabuleux hasards: histoire de la découverte des médicaments
. EDP Sciences.
Bonanno, G. A., 2004, “Loss, Trauma, and Human Resilience: Have We Underestimated the Human Capacity to Thrive After Extremely Aversive Events?”
American Psychologist
59: 20–28.
Borkowski, M., B. Podaima, et al., 2009, “Epidemic Modeling with Discrete-Space
Scheduled Walkers: Extensions and Research Opportunities.”
BMC Public Health
9 (Suppl 1): S14.
Bostrom, Nick, 2002,
Anthropic Bias: Observation Selection Effects in Science and Philosophy.
London: Routledge.
Boucher, A., et al., 2004, “Biochemical Mechanism of Lipid-Induced Impairment of Glucose-Stimulated Insulin Secretion and Reversal with a Malate Analogue.”
Journal of Biological Chemistry
279: 27263–27271.
Bourdieu, Pierre, 1972,
Esquisse d’une théorie de la pratique
. Paris: Éditions du Seuil.
Brand, Stewart, 1995,
How Buildings Learn: What Happens After They’re Built
. Penguin.
Brandstätter, E., G. Gigerenzer, et al., 2006, “The Priority Heuristic: Making Choices Without Trade-offs.”
Psychological Review
113(2): 409.
Brewster, J. F., M. R. Graham, et al., 2005, “Convexity, Jensen’s Inequality and Benefits of Noisy Mechanical Ventilation.”
Journal of the Royal Society
2(4): 393–396.
Brosco, J., and S. Watts, 2007, “Two Views: ‘Bad Medicine: Doctors Doing Harm Since Hippocrates.’ By David Wootton.”
Journal of Social History
41(2): 481.
Bryson, Bill, 2010,
At Home: A Short History of Private Life
. New York: Doubleday.
Burch, Druin, 2009,
Taking the Medicine: A Short History of Medicine’s Beautiful Idea, and Our Difficulty Swallowing It
. Chatto and Windus.
Burghardt, G., and W. Hoskins, 1994, “The Convexity Bias in Eurodollar Futures.”
Carr Futures Research Note,
September.
Burghardt, G., and G. Panos, 2001, “Hedging Convexity Bias.”
Carr Futures Research Note,
August.
Burnyeat, F., 1984, “The Sceptic in His Place and Time.” In R. Rorty, J. B. Schneewind, and Q. Skinner, eds.,
Philosophy in History.
Cambridge: Cambridge University Press, p. 225.
Cairns, Warwick, 2007,
About the Size of It: The Common Sense Approach to Measuring Things.
London: Pan Books.
Calabrese, E. J., 2005, “Paradigm Lost, Paradigm Found: The Re-emergence of Hormesis as a Fundamental Dose Response Model in the Toxicological Sciences.”
Environmental Pollution
138(3): 378–411.
Calabrese, E. J., and L. Baldwin, 2002, “Defining Hormesis.”
Human & Experimental Toxicology
21(2): 91.
Calabrese, E. J., and L. A. Baldwin, 2003a, “Toxicology Rethinks Its Central Belief.”
Nature
421(6924): 691–692.
Calabrese, E. J., and L. A. Baldwin, 2003b, “Hormesis: The Dose-Response Revolution.”
Annual Review of Pharmacology and Toxicology
43(1): 175–197.
Calder, William M. III, Bernhard Huss, Marc Mastrangelo, R. Scott Smith, and Stephen M. Trzaskoma, 2002,
The Unknown Socrates
. Wauconda, Ill: Bolchazy-Carducci Publishers.
Calhoun, L. G., and R. G. Tedeschi, 2006,
Expert Companions: Post-Traumatic Growth in Clinical Practice
. Lawrence Erlbaum Associates Publishers.
Canguilhem, Georges, 1966,
Le normal et le pathologique
. Presses Universitaires de France.
Canguilhem, Georges, 1995,
Études d’histoire et de philosophie des sciences
. Librairie Philosophique J. Vrin.
Carbuhn, A., T. Fernandez, A. Bragg, J. Green, and S. Crouse, 2010, “Sport and Training Influence Bone and Body Composition in Women Collegiate Athletes.”
Journal of Strength and Conditioning Research
24(7): 1710–1717.
Carey, B., P. K. Patra, et al., 2011, “Observation of Dynamic Strain Hardening in Polymer Nanocomposites.”
ACS Nano.
5(4): 2715–2722.
Carrera-Bastos, P., M. Fontes Villalba, et al., 2011, “The Western Diet and Lifestyle and Diseases of Civilization.”
Research Reports in Clinical Cardiology
2: 215–235.
Cartwright, S., and R. Schoenberg, 2006, “Thirty Years of Mergers and Acquisitions Research: Recent Advances and Future Opportunities.”
British Journal of Management
17(S1): S1–S5.
Caves, Carlton M., 2000, “Predicting Future Duration from Present Age: A Critical Assessment,”
Contemporary Physics
41: 143–153.
Chang, H. J., 2011,
23 Things They Don’t Tell You About Capitalism
. London: Bloomsbury Press.
Charbonnier, Georges, 2010,
Entretiens avec Claude Lévi-Strass
. Les Belles Lettres.
Collins, Harry, 2010,
Tacit and Explicit Knowledge
. Chicago: University of Chicago Press.
Collins, N. C., 2008, “Is Ice Right? Does Cryotherapy Improve Outcome for Acute Soft Tissue Injury?”
Emergency Medicine Journal
25: 65–68.
Compagnon, Antoine, 2005,
Les antimodernes de Joseph de Maistre à Roland Barthes
. Paris: Gallimard.
Congcong, He, et al., 2012, “Exercise-Induced BCL2-Regulated Autophagy Is Required for Muscle Glucose Homeostasis.”
Nature
, 2012.
Conrad, Lawrence I., Michael Neve, Vivian Nutton, Roy Porter, and Andrew Wear, 1995,
The Western Medical Tradition: 800 BC to AD 1800
. Cambridge: Cambridge University Press.
Conroy, B. P., W. J. Kraemer, et al., 1993, “Bone Mineral Density in Elite Junior Olympic Weightlifters.”
Medicine and Science in Sports and Exercise
25(10): 1103.
Contopoulos-Ioannidis, D. G., E. E. Ntzani, et al., 2003, “Translation of Highly Promising Basic Science Research into Clinical Applications.”
American Journal of Medicine
114(6): 477–484.
Contopoulos-Ioannidis, D. G., G. A. Alexiou, et al., 2008, “Life Cycle of Translational Research for Medical Interventions.”
Science
321(5894): 1298–1299.
Convery, F. J., C. Di Maria, et al., 2010, “ESRI Discussion Paper Series No. 230.”
Coulter, Harris L., 1994,
Divided Legacy: A History of the Schism in Medical Thought,
Vol. I. Center for Empirical Medicine.
Coulter, Harris L., 2000,
Divided Legacy: A History of Schism in Medical Thought,
Vol. II. North Atlantic Books.
Cowan, R., P. A. David, et al., 2000, “The Explicit Economics of Knowledge Codification and Tacitness.”
Industrial and Corporate Change
9(2): 211.
Coy, P., 2009, “What Good Are Economists Anyway?”
BusinessWeek
27: 26–29.
Crafts, Nicholas F. R., 1985,
British Economic Growth During the Industrial Revolution.
New York: Oxford University Press.
Crafts, Nicholas F. R., and C. Knick Harley. “Output Growth and the British Industrial Revolution: A Restatement of the Crafts-Harley View.”
Economic History Review
45 (1992): 703–730.
Cretu, O., R. B. Stewart, et al., 2011,
Risk Management for Design and Construction.
Crosby, Alfred W., 1997,
The Measure of Reality: Quantification and Western Society, 1250–1600
. Cambridge: Cambridge University Press.
Cuillerai, Marie, 2009,
Spéculation, éthique, confiance: Essai sur le capitalisme vertueux
. Éditions Payots-Rivages.
Cunningham, Solveig Argeseanu, Kristina Mitchell, K.M. Venkat Narayan, Salim Yusuf, 2008, “Doctors’ Strikes and Mortality: A Review.”
Social Science & Medicine
67(11), 1784–1788.
Cypser, J. R., and T. E. Johnson, 2002, “Multiple Stressors in
Caenorhabditis Elegans
Induce Stress Hormesis and Extended Longevity.”
Journals of Gerontology: Series A: Biological Sciences and Medical Sciences
57(3): B109.
Czerlinski, J., G. Gigerenzer, et al., 1999, “How Good Are Simple Heuristics?”
Dahl, Robert A., and Edward R. Tufte, 1973,
Size and Democracy.
Stanford: Stanford University Press.
Danchin, A., P. M. Binder, et al., 2011, “Antifragility and Tinkering in Biology (and in Business) Flexibility Provides an Efficient Epigenetic Way to Manage Risk.”
Genes
2(4): 998–1016.
Darnton, Robert, 2010,
The Devil in the Holy Water, or The Art of Slander from Louis XIV to Napoleon
. University of Pennsylvania Press.
Daston, Lorraine, 1988,
Classical Probability in the Enlightenment
. Princeton, N.J.: Princeton University Press.
Davidson, P., 2010, “Black Swans and Knight’s Epistemological Uncertainty: Are These Concepts Also Underlying Behavioral and Post-Walrasian Theory?”
Journal of Post Keynesian Economics
32(4): 567–570.
Davis, Devra, 2007,
The Secret History of the War on Cancer
. Basic Books.
Dawes, Robyn M., 2001,
Everyday Irrationality: How Pseudo-Scientists, Lunatics, and the Rest of Us Systematically Fail to Think Rationally
. Westview.
De Finetti, B., 1937,
La prévision: ses lois logiques, ses sources subjectives.
Institut Henri Poincaré.
De Finetti, B., 1974,
Theory of Probability,
Vol. 1. London: John.
De Finetti, B., 1989, “Probabilism.”
Erkenntnis
31(2): 169–223.
De la Hunty, A., S. Gibson, and M. Ashwell, 2006, “A Review of the Effectiveness of Aspartame in Helping with Weight Control.”
Nutrition Bulletin
31(2):115–128.
De Long, J. Bradford, and Andrei Shleifer, 1993, “Princes and Merchants: European City Growth Before the Industrial Revolution.”
Journal of Law and Economics
36: 671–702.
De Soto, H., 2000,
The Mystery of Capital: Why Capitalism Triumphs in the West and Fails Everywhere Else
. Basic Books.
De Vany, A., 2011,
The New Evolution Diet
. Vermilion.
Delon, Michel, ed., 1997,
Dictionnaire européen des lumières
. Presses Universitaires de France.
Deneubourg, J. L., S. Goss, N. Franks, and J. M. Pasteels, 1989, “The Blind Leading the Blind: Modelling Chemically Mediated Army Ant Raid Patterns.”
Journal of Insect Behavior
2: 719–725.
Deneubourg, J. L., J. M. Pasteels, and J. C. Verhaeghe, 1983, “Probabilistic Behavior in Ants: A Strategy of Errors?”
Journal of Theoretical Biology
105: 259–271.
Derman, E., and N. N. Taleb, 2005, “The Illusions of Dynamic Replication.”
Quantitative Finance
5: 4.
Dhabhar, F. S., 2009, “Enhancing Versus Suppressive Effects of Stress on Immune Function: Implications for Immunoprotection and Immunopathology.”
Neuroimmunomodulation
16(5): 300–317.
Dhabhar, F. S., A. N. Saul, C. Daugherty, T. H. Holmes, D. M. Bouley, T. M. Oberyszyn, 2010, “Short-term Stress Enhances Cellular Immunity and Increases Early Resistance to Squamous Cell carcinoma.”
Brain, Behavior and Immunity
24(1): 127–137.
Dhabhar, F. S., A. N. Saul, T. H. Holmes, C. Daugherty, E. Neri, J. M. Tillie, D. Kusewitt, T. M. Oberyszyn, 2012, “High-Anxious Individuals Show Increased Chronic Stress Burden, Decreased Protective Immunity, and Increased Cancer Progression in a Mouse Model of Squamous Cell Carcinoma.”
PLOS ONE
7(4): e33069.
Diamond, Jared, 1988, “Why Cats Have Nine Lives.”
Nature,
Vol. 332, April 14.
Dixit, A. K. and R. S. Pindyck, 1994,
Investment Under Uncertainty
. Princeton, N.J.: Princeton University Press.
Djebbar, Ahmed, 2001,
Une histoire de la science arabe.
Éditions du Seuil.
Dook, J. E., C. James, N. K. Henderson, and R. I. Price, 1997, “Exercise and Bone Mineral Density in Mature Female Athletes.”
Medicine and Science in Sports and Exercise
29(3): 291–296.
Douady, R. and N. N. Taleb, 2011, “Statistical Undecidability,” preprint.
Driver, P. M., and D. A. Humphries, 1988,
Protean Behaviour: The Biology of Unpredictability
. Oxford: Oxford University Press.
Duffin, Jacalyn, 1999,
History of Medicine: A Scandalously Short Introduction
. Toronto: University of Toronto Press.
Dunne, J. A., R. J. Williams, et al., 2002, “Network Topology and Biodiversity Loss in Food Webs: Robustness Increases with Connectance.”
Ecology Letters
5(4): 558–567.
Earle, J., 1975, “Thyroid Cancer. Delayed Effects of Head and Neck Irradiation in Children (Medical Information).”
Western Journal of Medicine
123:340, October.
Easterly, W., 2001,
The Elusive Quest for Growth: Economists’ Adventures and Misadventures in the Tropics.
Cambridge, Mass.: The MIT Press.
Easterly, W., and A. Kraay, 2000, “Small States, Small Problems? Income, Growth, and Volatility in Small States.”
World Development
28(11): 2013–2027.
Easterly, W., M. Kremer, L. Pritchett, and L. Summers, 1993, “Good Policy or Good Luck? Country Growth Performance and Temporary Shocks”
Journal of Monetary Economics
32(3): 459–483.
Easterly, William, 2006,
The White Man’s Burden: Why the West’s Efforts to Aid the Rest Have Done So Much Ill and So Little Good
. Penguin Group.
Eberhard, Wolfram, 1950, 1977,
A History of China
. University of California Press.
Edelstein, Ludwig, 1987,
Ancient Medicine
. Johns Hopkins University Press.
Edgerton, David, 1996a, “The ‘White Heat’ Revisited: British Government and Technology in the 1960s.”
Twentieth Century British History
7(1): 53–82.
Edgerton, David, 1996b,
Science, Technology, and the British Industrial ‘Decline,’ 1870–1970
. Cambridge: Cambridge University Press.
Edgerton, David, 2004, “The ‘Linear Model’ Did Not Exist: Reflections on the History and Historiography of Science and Research in Industry in the Twentieth Century.” In Karl Grandin and Nina Wormbs, eds.,
The Science–Industry Nexus: History, Policy, Implications.
New York: Watson.
Edgerton, David, 2007,
The Shock of the Old: Technology and Global History Since 1900
, Oxford.
Ekern, S., 1980, “Increasing Nth Degree Risk.”
Economics Letters
6(4): 329–333.
Elkington, John, and Pamela Hartigan, 2008,
The Power of Unreasonable People: How Social Entrepreneurs Create Markets That Change the World
. Cambridge, Mass.: Harvard Business Press.
Emer, J., 2009, “An Evolution of General Purpose Processing: Reconfigurable Logic Computing.”
Proceedings of the 7th Annual IEEE/ACM International Symposium.
Esnault, Y., 2001, “Francois Jacob, l’éloge du bricolage.”
Biofutur
(213).
Fabrizio, P., F. Pozza, S. Pletcher, C. Gendron, and V. Longo, 2001, “Regulation of Longevity and Stress Resistance by Sch9 in Yeast.”
Science’s STKE
292(5515): 288.
Fejtö, François, 1989,
Requiem pour un Empire défunt. Histoire de la destruction de l’Autriche-Hongrie
. Paris: Lieu Commun.
Ferguson, Niall, 2011,
Civilization: The West and the Rest
. Penguin.
Fernandez, G., E. S. Spatz, C. Jablecki, P. S. Phillips, 2011, “Statin Myopathy: A Common Dilemma Not Reflected in Clinical Trials.”
Cleveland Clinic Journal of Medicine
78(6): 393–403.
Ferrante, Louis, 2011,
Mob Rules: What the Mafia Can Teach the Legitimate Businessman
. Penguin.
Finch, C., V. Longo, A. Miyao, T. Morgan, I. Rozovsky, Y. Soong, M. Wei, Z. Xie, and H. Zanjani, 2001, “Inflammation in Alzheimer’s Disease.” In M.-F. Chesselet, ed.,
Molecular Mechanisms of Neurodegenerative Diseases
, pp. 87–110.
Fink, W., V. Lipatov, et al., 2009, “Diagnoses by General Practitioners: Accuracy and Reliability.”
International Journal of Forecasting
25(4): 784–793.
Finley, M. I., 1953, “Land, Debt, and the Man of Property in Classical Athens.”
Political Science Quarterly
68(2): 249–268.
Flyvbjerg, Bent, 2001,
Making Social Science Matter: Why Social Inquiry Fails and How It Can Succeed Again
. Cambridge: Cambridge University Press.
Flyvbjerg, Bent, and Alexander Budzier, 2011, “Are You Sitting on a Ticking Time Bomb?”
Harvard Business Review
, September.
Flyvbjerg, Bent, 2009, “Survival of the Unfittest: Why the Worst Infrastructure Gets Built—and What We Can Do About It.”
Oxford Review of Economic Policy,
Vol. 25, No. 3, 344–367.
Fossedal, G. A., and A. R. Berkeley III, 2005,
Direct Democracy in Switzerland
. Transaction Pub.
Fourest, Caroline, and Fiametta Venner, 2010,
Les interdits religieux
. Éditions Dalloz.
Franklin, James, 2001,
The Science of Conjecture: Evidence and Probability Before Pascal
. Baltimore: Johns Hopkins University Press.
Freedman, D. A., and D. B. Petitti, 2001, “Salt and Blood Pressure: Conventional Wisdom Reconsidered.”
Evaluation Review
25(3): 267–287.
Freedman, D., D. Collier, et al., 2010,
Statistical Models and Causal Inference: A Dialogue with the Social Sciences
. Cambridge: Cambridge University Press.
Freeman, C., and L. Soete, 1997,
The Economics of Industrial Innovation
. London: Routledge.
Freidson, Eliot, 1970,
Profession of Medicine: A Study of the Sociology of Applied Knowledge
. Chicago: University of Chicago Press.
French, Roger, 2003,
Medicine Before Science: The Rational and Learned Doctor from the Middle Ages to the Enlightenment
. Cambridge: Cambridge University Press.
Froot, K. A., 2001, “The Market for Catastrophe Risk: A Clinical Examination,”
Journal of Financial Economics
60(2–3): 529–571.
Fujiwara, Y., 2004, “Zipf Law in Firms Bankruptcy.”
Physica A: Statistical and Theoretical Physics
337: 219–30.
Fukumoto, S., and T. J. Martin, 2009, “Bone as an Endocrine Organ.”
Trends in Endocrinology and Metabolism
20: 230–236.
Fuller, Steve, 2005,
The Intellectual
. Icon Books.
García-Ballester, Luis, 1995, “Health and Medical Care in Medieval Galenism.” In Don Bates, ed.,
Knowledge and the Scholarly Medical Traditions
. Cambridge: Cambridge University Press.
Garland, Robert, 1998,
Daily Life of the Ancient Greeks
. Indianapolis: Hackett.
Gauch, Ronald R., 2009,
It’s Great! Oops, No It Isn’t: Why Clinical Research Can’t Guarantee the Right Medical Answers
. Springer.
Gawande, Atul, 2002,
Complications: A Surgeon’s Note on an Imperfect Science
. Picador.
Geach, Peter, 1966, “Plato’s Euthyphro,”
The Monist
50: 369–382.
Geison, Gerald L., 1995,
The Private Science of Louis Pasteur
. Princeton, N.J.: Princeton University Press.
Gems, D., and L. Partridge, 2008, “Stress-Response Hormesis and Aging: That Which Does Not Kill Us Makes Us Stronger.”
Cell Metabolism
7(3): 200–203.
Gibbert, M. and P. Scranton, 2009, “Constraints as Sources of Radical Innovation? Insights from Jet Propulsion Development.”
Management & Organizational History
4(4): 385.
Gigerenzer, Gerd, 2008, “Why Heuristics Work.”
Perspectives on Psychological Science
3(1): 20–29.
Gigerenzer, Gerd, and H. Brighton, 2009, “
Homo heuristicus:
Why Biased Minds Make Better Inferences.”
Topics in Cognitive Science
1(1): 107–143.
Gigerenzer, Gerd, and W. Gaissmaier, 2011, “Heuristic Decision Making.”
Annual Review of Psychology
62: 451–482.
Gladwell, Malcolm, 2009,
What the Dog Saw: And Other Adventures
. Hachette Group.
Glaeser, E., 2011,
Triumph of the City: How Our Greatest Invention Makes Us Richer, Smarter, Greener, Healthier, and Happier.
New York: Penguin
Glaser, Scott, and Rinoo Shah, 2010, “Root Cause Analysis of Paraplegia Following Transforaminal Epidural Steroid Injections.”
Pain Physician
13: 237–244.
Gold, Rich, 2007,
The Plenitude: Creativity, Innovation, and Making Stuff
. Cambridge, Mass.: The MIT Press.
Goldacre, B., 2007, “Benefits and Risks of Homoeopathy.”
Lancet
370(9600): 1672–1673.
Goldacre, B., 2009,
Bad Science: Quacks, Hacks, and Big Pharme Flacks.
London: Harper Perennial.
Goldstein, D. G., and G. Gigerenzer, 1999, “The Recognition Heuristic: How Ignorance Makes Us Smart.”
Goldstein, D. G., and G. Gigerenzer, 2002, “Models of Ecological Rationality: The Recognition Heuristic.”
Psychological Review
109(1): 75.
Goldstein, D. G., and N. N. Taleb, 2007, “We Don’t Quite Know What We Are Talking About When We Talk About Volatility,”
Journal of Portfolio Management,
Summer.
Gott, J. Richard III, 1993, “Implications of the Copernican Principle for Our Future Prospects.”
Nature
363(6427): 315–319.
Gott, J. Richard III, 1994, “Future Prospects Discussed.”
Nature
368: 108.
Graeber, David, 2011,
Debt: The First 5000 Years
. Melville House Publishing.
Graham, M. R., C. J. Haberman, et al., 2005, “Mathematical Modelling to Centre Low Tidal Volumes Following Acute Lung Injury: A Study with Biologically Variable Ventilation.”
Respiratory Research
6(1): 64.
Granger, Clive W. J., 1999,
Empirical Modeling in Economics: Specification and Evaluation
. Cambridge: Cambridge University Press.
Grant, Ruth W., 2011,
Strings Attached: Untangling the Ethics of Incentives
. Princeton, N.J.: Princeton University Press.
Graver, M., 2007,
Stoicism and Emotion
. Chicago: University of Chicago Press.
Gray, John, 1998,
Hayek on Liberty
. Psychology Press.
Gray, John, 2002,
Straw Dogs: Thoughts on Humans and Other Animals.
London: Granta Books.
Gray, John, 2011,
The Immortalization Commission: Science and the Strange Quest to Cheat Death
. Allen Lane.
Greenwood, R., and R. Suddaby, 2006, “The Case of Disappearing Firms: Death or Deliverance?”
Journal of Organizational Behavior
27(1): 101–108.
Grice, E. A., and J. A. Segre, 2011, “The Skin Microbiome.”
Nature Reviews Microbiology
9(4): 244–253.
Griffith, S. C., I.P.F. Owens, and K. A. Thuman, 2002, “Extrapair Paternity in Birds: A Review of Interspecific Variation and Adaptive Function.”
Molecular Ecology
11: 2195–212.
Grob, Gerald N., 2002,
The Deadly Truth: A History of Disease in America
. Cambridge, Mass.: Harvard University Press.
Gruber, Jonathan, and Samuel A. Kleiner, 2010,
Do Strikes Kill? Evidence from New York State
(NBER Working Paper No. 15855). National Bureau of Economic Research.
Guadalupe-Grau, A., T. Fuentes, B. Guerra, and J. Calbet, 2009, “Exercise and Bone Mass in Adults.”
Sports Medicine
39(6): 439–468.
Guarner, F., R. Bourdet-Sicard, et al., 2006, “Mechanisms of Disease: the Hygiene Hypothesis Revisited.”
Nature Clinical Practice Gastroenterology & Hepatology
3(5): 275–284.
Guidone, C., et al., 2006, “Mechanisms of Recovery from Type 2 Diabetes After Malabsorptive Bariatric Surgery.”
Diabetes
55: 2025–2031.
Hacking, Ian, 1984,
The Emergence of Probability: A Philosophical Study of Early Ideas About Probability, Induction and Statistical Inference
. Cambridge: Cambridge University Press.
Hacking, Ian, 1990,
The Taming of Chance
. Cambridge: Cambridge University Press.
Hacking, Ian, 2006,
The Emergence of Probability,
2nd ed. New York: Cambridge University Press.
Hadler, Nortin M., M.D., 2008,
Worried Sick: A Prescription for Health in an Overtreated America
. Chapel Hill: University of North Carolina Press.
Hadler, Nortin M., M.D., 2009,
Stabbed in the Back
. Chapel Hill: University of North Carolina Press.
Haidt, J., 2012,
The Righteous Mind: Why Good People Are Divided by Politics and Religion
. New York: Pantheon.
Haigh, J., 2000, “The Kelly Criterion and Bet Comparisons in Spread Betting.”
Journal of the Royal Statistical Society: Series D (The Statistician)
49(4): 531–539.
Hajek, A., 2003,
Interpretations of Probability
. Citeseer.
Halagappa, V.K.M., Z. Guo, et al., 2007, “Intermittent Fasting and Caloric Restriction Ameliorate Age-Related Behavioral Deficits in the Triple-Transgenic Mouse Model of Alzheimer’s Disease.”
Neurobiology of Disease
26(1):
Hald, Anders, 1998,
A History of Mathematical Statistics from 1750 to 1930
. New York: Wiley.
Hald, Anders, 2003,
A History of Probability and Statistics and Their Applications Before 1750
. Hoboken, N.J.: Wiley.
Haleblian, J., C. E. Devers, et al., 2009, “Taking Stock of What We Know About Mergers and Acquisitions: A Review and Research Agenda.”
Journal of Management
35(3): 469–502.
Hallström, H., H. Melhus, A. Glynn, L. Lind, A. Syvänen, and K. Michaëlsson, 2010, “Coffee Consumption and CYP1A2 Genotype in Relation to Bone Mineral Density of the Proximal Femur in Elderly Men and Women: A Cohort Study.”
Nutrition and Metabolism
7:12.
Hamazaki, T., et al, 2012, “Rethinking Cholesterol Issues,”
Journal of Lipid Nutrition
21.
Hammond, John S., Ralph L. Keeney, and Howard Raïffa, 1999,
Smart Choices: A Practical Guide to Making Better Life Decisions.
Cambridge, Mass.: Harvard Business Press.
Harrison, A.R.W., 1998,
The Law of Athens: The Family and Property
. Indianapolis: Hackett.
Harrison, D. E., J. R. Archer, and C. M. Astle, 1984, “Effects of Food Restriction on Aging: Separation of Food Intake and Adiposity.”
Proceedings of the National Academy of Sciences USA
81: 1835–1838.
Haug, E. G., 1998,
The Complete Guide to Option Pricing Formulas
. McGraw-Hill Companies.
Haug, E. G., and N. N. Taleb, 2010, “Option Traders Use Heuristics, Never the Formula Known as Black-Scholes-Merton Equation,”
Journal of Economic Behavior and Organizations
27.
Hayek, F. A., 1945, “The Use of Knowledge in Society.”
American Economic Review
35(4): 519–530.
Hayek, F. A., 1991,
The Fatal Conceit: The Errors of Socialism
. Chicago: University of Chicago Press.
Hayflick, L., 2001, “Hormesis, Aging and Longevity Determination.”
Human & Experimental Toxicology
20(6): 289.
Heyde, C. C., and E. Seneta, eds., 2001,
Statisticians of the Centuries
. New York: Springer.
Hilton-Jones, D., 2009, “I-7. Statins and Muscle Disease.”
Acta Myologica
28(1): 37.
Hind, K. and M. Burrows, 2007, “Weight-Bearing Exercise and Bone Mineral Accrual in Children and Adolescents: A Review of Controlled Trials.”
Bone
40: 14–27.
Holland, John H., 1995,
Hidden Order: How Adaptation Builds Complexity
. Basic Books.
Hollis, Martin, 1994,
The Philosophy of Social Science: An Introduction
. Cambridge: Cambridge University Press.
Horkheimer, Max, and Theodor W. Adorno, 2002,
Dialectic of Enlightenment
. Stanford: Stanford University Press.
Hu, M., B.M.Y. Cheung, et al., 2012, “Safety of Statins: An Update.”
Therapeutic Advances in Drug Safety
3(3): 133–144.
Huang, Chi-fu, and Robert H. Litzenberger, 1988,
Foundations of Financial Economics.
Prentice-Hall, Inc.
Hudson, M., M. Van de Mieroop, et al., 2002,
Debt and Economic Renewal in the Ancient Near East: A Colloquium Held at Columbia University.
Potomac: CDL Press.
Illich, Ivan, 1995,
Limits to Medicine: Medical Nemesis, the Expropriation of Health.
London: Marion Boyars.
Ioannidis, J.P.A., 2005, “Why Most Published Research Findings Are False.”
PLoS Medicine
2(8), 696–701, doi:10.1371/journal.pmed.0020124.
Ioannidis, J.P.A., and T. A. Trikalinos, 2007, “An Exploratory Test for an Excess of Significant Findings.”
Clinical Trials
4: 245–253, doi:10.1177/174077450707944.
Issawi, Charles, 1988,
The Fertile Crescent, 1800–1914: A Documentary Economic History
. Oxford: Oxford University Press.
Issawi, Charles, 1966, in Charles Issawi, ed.,
The Economic History of the Middle East
,
1800–1914
. Chicago: University of Chicago Press.
Jacob, François, 1977a, “Evolution et bricolage.”
Le Monde
6(7): 8.
Jacob, François, 1977b, “Evolution and Tinkering,”
Science
196(4295): 1161–1166.
Janson, J., T. Laedtke, et al., 2004, “Increased Risk of Type 2 Diabetes in Alzheimer Disease.”
Diabetes
53(2): 474–481.
Jaynes, E. T., 2003, 2004,
Probability Theory: The Logic of Science
. Cambridge: Cambridge University Press.
Jensen, J.L.W.V., 1906, “Sur les fonctions convexes et les inégalités entre les valeurs moyennes.”
Acta Mathematica
30.
Johnsgard, P. A., 2010, “Ducks, Geese, and Swans of the World: Tribe Stictonettini (Freckled Duck).” In Paul A. Johnsgard,
Ducks, Geese, and Swans of the World.
University of Nebraska Press.
Johnson, P.D.R., 2011, “Extensively Resistant Tuberculosis in the Lands Down Under.”
Medical Journal of Australia
194(11): 565.
Johnson, Steven, 2010,
Where Good Ideas Come From: The Natural History of Innovation
. Riverhead Books.
Josipovici, Gabriel, 2010,
What Ever Happened to Modernism?
New Haven: Yale University Press.
Kahn, James, 2011, “Can We Determine the Optimal Size of Government?”
Cato Institute
No. 7, September.
Kahneman, D., 2011,
Thinking, Fast and Slow
. New York: Farrar, Straus and Giroux.
Kahneman, D., 1982, “On the Study of Statistical Intuitions.” In D. Kahneman, P. Slovic, and A. Tversky, eds.,
Judgment Under Uncertainty: Heuristics and Biases.
Cambridge: Cambridge University Press.
Kahneman, D., and Amos Tversky, 1979, “Prospect Theory: An Analysis of Decision Under Risk.”
Econometrica
46(2): 171–185.
Kaiser, Jocelyn, 2003, “Hormesis: Sipping from a Poisoned Chalice.”
Science
302 (5644): 376–379.
Kantorovich, Aharon, 1993,
Scientific Discovery: Logic and Tinkering
. State University of New York Press.
Kaplan, H., K. Hill, J. Lancaster, and A. M. Hurtado, 2000, “A Theory of Human Life History Evolution: Diet, Intelligence, and Longevity.”
Evolutionary Anthropology
9:156–185.
Karsenty, G., 2003, “The Complexities of Skeletal Biology.”
Nature
423 (6937): 316–318.
Karsenty, G., 2011,
Regulation of Male Fertility by Bone
. Cold Spring Harbor Laboratory Press.
Karsenty, G., 2012a, “Bone as an endocrine tissue.”
Annual Review of Physiology
74(1).
Karsenty, G., 2012b, “The Mutual Dependence Between Bone and Gonads.”
Journal of Endocrinology
213(2): 107–114.
Kauffman, Stuart, 1995,
At Home in the Universe: The Search for Laws of Self-Organization and Complexity
. Oxford: Oxford University Press.
Kay, John, 2010,
Obliquity
. Penguin.
Kealey, T., 1996,
The Economic Laws of Scientific Research
. London: Macmillan.
Kennedy, Michael T., 2004,
A Brief History of Disease, Science and Medicine: From the Ice Age to the Genome Project
. Mission Viejo, Calif.: Asklepiad Press.
Kerr, N. L., 1998, “HARKing: Hypothezising After the Results Are Known.”
Personality and Social Psychology Review
2: 196–217, doi:10.1207/s15327957pspr0203_4.
Khanna, P., 2010, “Beyond City Limits.”
Foreign Policy
181: 120–128.
Khmaladze, E. V., R. Brownrigg, and J. Haywood, 2010, “Memoryless Reigns of the ‘Sons of Heaven.’ ”
International Statistical Review
78: 348–62.
Khmaladze, E., R. Brownrigg, and J. Haywood, 2007, “Brittle Power: On Roman Emperors and Exponential Lengths of Rule.”
Statistics & Probability Letters
77: 1248–1257.
Khosla, V., 2009, “Whose Rules? Terms of Discussions Around a Global Cap-and-Trade System.”
Innovations: Technology, Governance, Globalization
4(4): 23–40.
Kirikos, G., and D. Novak, 1997, “Convexity Conundrums.”
Risk Magazine,
March: 60–61.
Kohr, Leopold, 1957,
The Breakdown of Nations
. Rinehart.
Kondo, Y., T. Kanzawa, and R. Sawaya, 2005, “The Role of Autophagy in Cancer Development and Response to Therapy.”
Nature Reviews Cancer
5: 726–734.
Krugman, P., 1998, “Why Intellectuals Don’t Understand Comparative Advantage.”
Freedom and Trade: The Economics and Politics of International Trade
2: 22.
Kurzban, R., 2010, “Does the Brain Consume Additional Glucose During Self-Control Tasks?”
Evolutionary Psychology
8: 244–259. Retrieved from
http://www.epjournal.net/wp-content/uploads/ep08244259.pdf
.
La Mattina, John L., 2009,
Drug Truths: Dispelling the Myths About Pharma R&D
. Wiley.
Latour, Bruno, and Steve Woolgar, 1996,
La vie de laboratoire: La production des faits scientifiques
. La Découverte.
Laumakis, M., C. Graham, et al., 2009, “The Sloan-C Pillars and Boundary Objects as a Framework for Evaluating Blended Learning.”
Journal of Asynchronous Learning Networks
13(1): 75–87.
Lavery, J. V., 2011, “How Can Institutional Review Boards Best Interpret Preclinical Data?”
PLoS Medicine
8(3): e1001011.
Le Bourg, Eric, 2009, “Hormesis, Aging and Longevity.”
Biochimica et Biophysica Acta (BBA): General Subjects
1790(10): 1030–1039.
Le Breton–Miller, I., and D. Miller, 2006, “Why Do Some Family Businesses Out-Compete? Governance, Long-Term Orientations, and Sustainable Capability.”
Entrepreneurship Theory and Practice
30(6): 731–746.
Le Fanu, James, M.D., 2002,
The Rise and Fall of Modern Medicine
. Carroll and Graf.
Le Goff, Jacques, 1985,
Les intellectuals au moyen age
. Éditions du Seuil.
Le Goff, Jacques, 1999,
Un autre moyen age
. Gallimard.
Lebrun, François, 1995,
Se soigner: Médicins, saints et sorciers aux XVII et XVIII siècles
. Éditions du Seuil.
Leoni, B., 1957, “The Meaning of ‘Political’ in Political Decisions.”
Political Studies
5(3): 225–239.
Leoni, B., and A. Kemp, 1991,
Freedom and the Law
. Indianapolis: Liberty Fund.
Levi, Isaac, 1980,
The Enterprise of Knowledge.
Cambridge, Mass.: The MIT Press.
Lévi-Strauss, Claude, 1962,
La pensée sauvage
. Plon.
Lewis, Ben, 2008,
Hammer and Tickle
. London: Weidenfeld & Nicolson.
Lewontin, Richard, 1993,
Biology as Ideology
:
The Doctrine of DNA,
Harper Perennial.
Li, Jie Jack, 2006,
Laughing Gas, Viagra, and Lipitor: The Human Stories Behind the Drugs We Use
. Oxford: Oxford University Press.
Light, D. and J. Lexchin, 2012, “Pharmaceutical Research and Development: What Do We Get for All That Money?”
British Medical Journal,
345.
Lim, E. L., et al., 2011, “Reversal of Type 2 Diabetes: Normalisation of Beta Cell Function in Association with Decreased Pancreas and Liver Triacylglycerol.”
Diabetologia
54: 2506–2514.
Lindsay, James E., 2005,
Daily Life in the Medieval Islamic World
. Indianapolis: Hackett.
Lloyd, R., K. Hind, et al., 2010, “A Pilot Investigation of Load-Carrying on the Head and Bone Mineral Density in Premenopausal, Black African Women.”
Journal of Bone and Mineral Metabolism
28(2): 185–190.
Longo, V., and B. Kennedy, 2006, “Sirtuins in Aging and Age-Related Disease.”
Cell
126(2): 257–268.
Longo, V., M. Lieber, and J. Vijg, 2008, “Turning Anti-Ageing Genes Against Cancer.”
National Review of Molecular Cell Biology
9(11): 903–910, 1471–1472.
Longrigg, James, 1998,
Greek Medicine from the Heroic to the Hellenistic Age: A Source Book
. London: Routledge.
Luchsinger, J. A., M. X. Tang, et al., 2004, “Hyperinsulinemia and Risk of Alzheimer Disease.”
Neurology
63(7): 1187–1192.
Luehrman, T. A., 1998, “Strategy as a Portfolio of Real Options.”
Harvard Business Review
76: 89–101.
Lustick, I., B. Alcorn, et al., 2010, “From Theory to Simulation: The Dynamic Political Hierarchy in Country Virtualization Models.”
American Political Science Association.
Machina, Mark, and Michael Rothschild, 2008, “Risk.” In Steven N. Durlauf and Lawrence E. Blume, eds.,
The New Palgrave Dictionary of Economics,
2nd ed. London: Macmillan.
Mackie, R., 2001, “Family Ownership and Business Survival: Kirkcaldy, 1870–1970.”
Business History
43: 1–32.
Makridakis, S., and N. N. Taleb, 2009, “Decision Making and Planning Under Low Levels of Predictability,”
International Journal of Forecasting
25 (4): 716–733.
Makridakis, S., A. Andersen, R. Carbone, R. Fildes, M. Hibon, R. Lewandowski, J. Newton, R. Parzen, and R. Winkler, 1982, “The Accuracy of Extrapolation (Time Series) Methods: Results of a Forecasting Competition.”
Journal of Forecasting
1: 111–153.
Makridakis, S., and M. Hibon, 2000, “The M3–Competition: Results, Conclusions and Implications.”
International Journal of Forecasting
16: 451–476.
Makridakis, S., C. Chatfield, M. Hibon, M. Lawrence, T. Mills, K. Ord, and L. F. Simmons, 1993, “The M2–Competition: A Real-Time Judgmentally Based Forecasting Study” (with commentary).
International Journal of Forecasting
5: 29.
Malhotra, Y., 2000, “Knowledge Assets in the Global Economy: Assessment of National Intellectual Capital.”
Journal of Global Information Management
8(3): 5.
Malmendier, U., and G. Tate, 2008, “Who Makes Acquisitions? CEO Overconfidence and the Market’s Reaction.”
Journal of Financial Economics
89(1): 20–43.
Malmendier, U., and G. Tate, 2009, “Superstar CEOs.”
Quarterly Journal of Economics
124(4): 1593–1638.
Mandelbrot, Benoît B., 1983,
The Fractal Geometry of Nature
. W. H. Freeman.
Mandelbrot, Benoît B., 1997,
Fractals and Scaling in Finance: Discontinuity, Concentration, Risk
. New York: Springer-Verlag.
Mandelbrot, Benoît B., and N. N. Taleb, 2010, “Random Jump, Not Random Walk.” In Richard Herring, ed.,
The Known, the Unknown, and the Unknowable
. Princeton, N.J.: Princeton University Press.
Mansel, P., 2012,
Levant.
Hachette.
Marglin, S. A., 1996, “Farmers, Seedsmen, and Scientists: Systems of Agriculture and Systems of Knowledge.” In Frédérique Apffel-Marglin and Stephen A. Marglin,
Decolonizing Knowledge: From Development to Dialogue
. Oxford University Press, 185–248.
Martin, B., M. P. Mattson, et al., 2006, “Caloric Restriction and Intermittent Fasting: Two Potential Diets for Successful Brain Aging.”
Ageing Research Reviews
5(3): 332–353.
Masoro, E. J., 1998, “Hormesis and the Antiaging Action of Dietary Restriction.”
Experimental Gerontology
33(1–2): 61–66.
Mattson, M. P., 2008, “Hormesis Defined.”
Ageing Research Reviews
7(1): 1–7.
Mattson, M. P., and R. Wan, 2005, “Beneficial Effects of Intermittent Fasting and Caloric Restriction on the Cardiovascular and Cerebrovascular Systems.”
Journal of Nutritional Biochemistry
16(3): 129–137.
Matz, David, 2002,
Daily Life of the Ancient Romans
. Indianapolis: Hackett.
McAleer, M., A. Pagan, and P. Volker, 1985, “What Will Take the Con Out of Econometrics?”
American Economic Review
75(3): 293–307.
McCabe, D. P., and A. D. Castel, 2008, “Seeing Is Believing: The Effect of Brain Images on Judgments of Scientific Reasoning.”
Cognition
107: 343–352.
McCloskey, D., and S. Ziliak, 1996, “The Standard Error of Regressions.”
Journal of Economic Literature
34(1): 97–114.
McConaugby, D., C. Matthews, and A. Fialko, 2001, “Founding Family Controlled Firms: Performance, Risk and Value.”
Journal of Small Business Management
39: 31–49.
McCraw, Thomas 2007,
Prophet of Innovation: Joseph Schumpeter and Creative Destruction
. Cambridge, Mass.: The Belknap Press of Harvard University.
McGill, S., 2007,
Low Back Disorders: Evidence-Based Prevention and Rehabilitation
. Human Kinetics Publishers.
McGrath, R. G., 1999, “Falling Forward: Real Options Reasoning and Entrepreneurial Failure.”
Academy of Management Review
: 13–30.
McKnight, Scot, 2009,
Fasting
. Thomas Nelson.
McMahon, Darrin M., 2001,
Enemies of the Enlightenment: The French Counter-Enlightenment and the Making of Modernity
. Oxford: Oxford University Press.
Mégraud, F., and H. Lamouliatte, 1992, “
Helicobacter pylori
and Duodenal Ulcer.”
Digestive Diseases and Sciences
37(5): 769–772.
Mehta, R., R. J. Zhu, et al., 2012, “Is Noise Always Bad? Exploring the Effects of Ambient Noise on Creative Cognition.”
Meisenzahl, R., and J. Mokyr, 2011,
The Rate and Direction of Invention in the British Industrial Revolution: Incentives and Institutions
. National Bureau of Economic Research.
Menard, W., and G. Sharman, 1976, “Random Drilling.”
Science
192(4236): 206–208.
Meng, X., N. Qian, and P. Yared, 2010,
The Institutional Causes of China’s Great Famine, 1959–61
. National Bureau of Economic Research.
Mercier, H., and D. Sperber, 2011, “Why Do Humans Reason? Arguments for an Argumentative Theory.”
Behavioral and Brain Sciences
34(2) 57–74.
Meslin, Michel, Alain Proust, and Ysé Tardan-Masquelier, eds., 2006,
La quête de guérison
:
Médicine et religions face à la souffrance
. Paris: Bayard.
Meyers, Morton A., M.D., 2007,
Happy Accidents: Serendipity in Modern Medical Breakthroughs
. New York: Arcade.
Michán, S., Y. Li, M. Chou, E. Parrella, H. Ge, J. Long, J. Allard, K. Lewis, M. Miller, and W. Xu, 2010, “SIRT1 Is Essential for Normal Cognitive Function and Synaptic Plasticity.”
Journal of Neuroscience
30(29): 9695–9707.
Micklesfield, L., L. Rosenberg, D. Cooper, M. Hoffman, A. Kalla, I. Stander, and E. Lambert, 2003, “Bone Mineral Density and Lifetime Physical Activity in South African Women.”
Calcified Tissue International
73(5): 463–469.
Miller, John H., and Scott E. Page, 2007,
Complex Adaptive Systems: An Introduction to Computational Models of Social Life
. Princeton, N.J.: Princeton University Press.
Mindell, D. A., 2002,
Between Human and Machine: Feedback, Control, and Computing Before Cybernetics
. Baltimore: Johns Hopkins University Press.
Mitchell, Mark T., 2006,
Michael Polanyi: The Art of Knowing
. ISI Books.
Mokyr, Joel, 1990,
The Lever of Riches: Technological Creativity and Economic Progress
. Oxford: Oxford University Press.
Mokyr, Joel, ed., 1999,
The British Industrial Revolution: An Economic Perspective.
Westview Press.
Mokyr, Joel, 2002,
The Gifts of Athena: Historical Origins of the Knowledge Economy
. Princeton, N.J.: Princeton University Press.
Mokyr, Joel, 2005, “Long-Term Economic Growth and the History of Technology.” In Philippe Aghion and Steven N. Durlauf, eds.,
Handbook of Economic Growth,
Vol. 1B. Elsevier.
Mokyr, Joel, 2009,
The Enlightened Economy: An Economic History of Britain, 1700–1850
. New Haven: Yale University Press.
Morens, David M., 1999, “Death of a President.”
New England Journal of Medicine
342: 1222.
Morris, Ivan I., 1975,
The Nobility of Failure: Tragic Heroes in the History of Japan.
Farrar, Strauss and Giroux.
Mudd, L., W. Fornetti, and J. Pivarnik, 2007, “Bone Mineral Density in Collegiate Female Athletes: Comparisons Among Sports.”
Journal of Athletic Training,
Jul-Sep 42(3): 403–408.
Mudry, Philippe, 2006,
Medicina, soror philosophiae
. Éditions BHMS.
Muldrew, C., 1993, “Credit and the Courts: Debt Litigation in a Seventeenth-Century Urban Community.”
Economic History Review
46(1): 23–38.
Mutch, W.A.C., T. G. Buchman, et al., 2007, “Biologically Variable Ventilation Improves Gas Exchange and Respiratory Mechanics in a Model of Severe Bronchospasm.”
Critical Care Medicine
35(7): 1749.
Nasr, G., 2008, “Applying Environmental Performance Indices Towards an Objective Measure of Sustainability in the Levant.”
International Journal of Sustainable Development
11(1): 61–73.
Nasr, G., 2009, “Limitations of the Hydraulic Imperative: The Case of the Golan Heights.”
Water Resources Development
25(1): 107–122.
Nelson, R. R., 2005,
Technology, Institutions, and Economic Growth
. Cambridge, Mass.: Harvard University Press.
Neumaier, T., J. Swenson, et al., 2012, “Evidence for Formation of DNA Repair Centers and Dose-Response Nonlinearity in Human Cells.”
Proceedings of the National Academy of Sciences
109(2): 443–448.
Nicholas, Jean, 2008,
La rebellion française: Mouvements populaires et conscience sociale 1661–1789
. Gallimard.
Nichols, J. F., J. E. Palmer, et al., 2003, “Low Bone Mineral Density in Highly Trained Male Master Cyclists.”
Osteoporosis International
14(8): 644–649.
North, Douglass C., 1990,
Institutions, Institutional Change and Economic Performance.
Cambridge: Cambridge University Press.
Nowak, Martin A., 2006,
Evolutionary Dynamics: Exploring the Equations of Life
. Cambridge, Mass.: The Belknap Press of Harvard University.
Nutton, Vivian, 2004,
Ancient Medicine
. Psychology Press.
O’Hara, Kieron, 2004,
Trust: From Socrates to Spin
. Icon Books.
Oakeshott, Michael, 1975,
On Human Conduct
. Oxford: Clarendon Press.
Oakeshott, Michael, 1991, “The Rationalist.”
Quadrant
35(3): 87.
Oakeshott, Michael, 1962, 1991,
Rationalism in Politics and Other Essays.
Liberty Fund.
Ober, J., 2010,
Wealthy Hellas,
Vol. 140. Baltimore: Johns Hopkins University Press.
Ogilvie, Sheilagh, 2011,
Institutions and European Trade: Merchant Guilds 1000–1800.
Cambridge: Cambridge University Press.
Orlov, Dmitry, 2011,
Reinventing Collapse: The Soviet Experience and American Prospects
. New Society Publishers.
Palmieri, Nicoletta, ed., 2003,
Rationnel et irrationnel dans la médecine ancienne et médiévale
. Saint-Étienne: Université de Saint-Étienne.
Pamuk, Sevket, 2006, “Estimating Economic Growth in the Middle East Since 1820.”
Journal of Economic History
66(3).
Parsons, P. A., 2000, “Hormesis: An Adaptive Expectation with Emphasis on Ionizing Radiation.”
Journal of Applied Toxicology
20(2): 103–112.
Pat-Horenczyk, R., and D. Brom, 2007, “The Multiple Faces of Post-Traumatic Growth.”
Applied Psychology
56(3): 379–385.
Pautler, P. A., 2003, “Evidence on Mergers and Acquisitions.”
Antitrust Bulletin
48: 119.
Pavitt, K., 1998a, “The Inevitable Limits of EU R&D Funding.”
Research Policy
27(6): 559–568.
Pavitt, K., 1998b, “The Social Shaping of the National Science Base.”
Research Policy
27(8): 793–805.
Payer, Lynn, 1996,
Medicine and Culture
. New York: Henry Holt.
Pears, David, 2006,
Paradox and Platitude in Wittgenstein’s Philosophy
. Oxford: Oxford University Press.
Pérez-Jean, Brigitte, 2005,
Dogmatisme et scepticisme
. Presses Universitaires du Septentrion.
Petchey, O. L., and J. A. Dunne, 2012, “Predator-Prey Relations and Food Webs.”
Metabolic Ecology: A Scaling Approach
. Wiley, p. 86.
Petroski, Henry, 2006,
Success Through Failure: The Paradox of Design
. Princeton, N.J.: Princeton University Press.
Pigeaud, Jackie, 2006,
La maladie de l’âme
. Les Belles Lettres.
Pigolotti, S., A. Flammini, et al., 2005, “Species Lifetime Distribution for Simple Models of Ecologies.”
Proceedings of the National Academy of Sciences of the United States of America
102(44): 15747.
Pirenne, Henri, 2005,
Mahomet et Charlemagne
. Presses Universitaires de France.
Pisano, G. P., 2006a, “Can Science Be a Business?”
Harvard Business Review
10: 1–12.
Pisano, G. P., 2006b,
Science Business: The Promise, The Reality, and the Future of Biotech
. Cambridge, Mass.: Harvard Business Press.
Pischon, T., et al., 2008, “General and Abdominal Adiposity and Risk of Death in Europe.”
New England Journal of Medicine
359: 2105–2120.
Pi-Sunyer, X., et al., 2007, “Reduction in Weight and Cardiovascular Disease Risk Factors in Individuals with Type 2 Diabetes: One-Year Results of the Look AHEAD Trial.”
Diabetes Care
30: 1374–1383.
Piterbarg, V. V., and M. A. Renedo, 2004, “Eurodollar Futures Convexity Adjustments in Stochastic Volatility Models.” Working Paper.
Pluchino, A., C. Garofalo, et al., 2011, “Accidental Politicians: How Randomly Selected Legislators Can Improve Parliament Efficiency.”
Physica A: Statistical Mechanics and Its Applications.
Polanyi, M., 1958,
Personal Knowledge: Towards a Post-Critical Philosophy
. London: Routledge and Kegan Paul.
Pomata, Gianna, and Nancy G. Siraisi, eds., 2005,
Historia: Empiricism and Erudition in Early Modern Europe
. Cambridge, Mass.: The MIT Press.
Popkin, Richard, 2003,
The History of Scepticism: From Savonarola to Bayle
. Oxford: Oxford University Press.
Popper, Karl, 1961,
The Poverty of Historicism
. London: Routledge.
Pories, W. J., et al., 1995, “Who Would Have Thought It? An Operation Proves to Be the Most Effective Therapy for Adult-Onset Diabetes Mellitus.”
Annals of Surgery
222: 339–350; discussion 350–352.
Pormann, Peter E., and Emilie Savage-Smith, 2007,
Medieval Islamic Medicine
. Georgetown University Press.
Porter, Roy, 2002,
Blood and Guts: A Short History of Medicine
. Penguin.
Porter, Roy, 2003,
Flesh in the Age of Reason
. W. W. Norton.
Portet, P., 2002,
La mesure géométrique des champs au moyen âge
. Librairie Droz.
Posner, M. V., 1996, “Corrupted by Money?”
Nature
382: 123–124.
Pratt, John W., 1964, “Risk Aversion in the Small and in the Large,”
Econometrica
32 (January–April), 122–136.
Pritchard, James B., ed., 2011,
The Ancient Near East: An Anthology of Texts and Pictures
. Princeton, N.J.: Princeton University Press.
Pritchett, L., 2001, “Where Has All the Education Gone?”
World Bank Economic Review
15(3): 367.
Radak, Z., H. Y. Chung, et al., 2005, “Exercise and Hormesis: Oxidative Stress-Related Adaptation for Successful Aging.”
Biogerontology
6(1): 71–75.
Raffaghello, L., F. Safdie, G. Bianchi, T. Dorff, L. Fontana, and V. Longo, 2010, “Fasting and Differential Chemotherapy Protection in Patients.”
Cell Cycle
9(22): 4474.
Rashed, Marwan, 2007,
L’héritage aristotélien
. Les Belles Lettres.
Rattan, S.I.S., 2008, “Hormesis in aging.”
Ageing Research Reviews
7(1): 63–78.
Rautava, E., M. Lehtonen-Veromaa, H. Kautiainen, S. Kajander, and O. J. Heinonen, 2007, “The Reduction of Physical Activity Reflects on the Bone Mass Among Young Females: A Follow-Up Study of 143 Adolescent Girls.”
Osteoporosis International
(18)7: 915–922.
Razay, G. and G. K. Wilcock, 1994, “Hyperinsulinaemia and Alzheimer’s Disease.”
Age and Ageing
23(5): 396–399.
Read, D., S. Frederick, and M. Airoldi, 2012, “Four Days Later in Cincinnati: Longitudinal Tests of Hyperbolic Discounting.”
Acta Psychologica
140(2): 177–185, PMID: 22634266.
Redberg, R. F., and M. H. Katz, 2012, “Healthy Men Should Not Take Statins.” JAMA 307(14): 1491–1492.
Rees, Martin, 2003,
Our Final Century: Will Civilisation Survive the Twenty-First Century?
Arrow Books.
Rein, R., K. Davids, et al., 2010, “Adaptive and Phase Transition Behavior in Performance of Discrete Multi-Articular Actions by Degenerate Neurobiological Systems.”
Experimental Brain Research
201(2): 307–322.
Ridley, Matt, 2010,
The Rational Optimist: How Prosperity Evolves
. 4th Estate.
Riffard, Pierre, 2004,
Les philosophes: Vie intime
. Presses Universitaires de France.
Robb, Graham, 2007,
The Discovery of France
. Picador.
Roberts, B. H., 2012,
The Truth About Statins: Risks and Alternatives to Cholesterol-Lowering Drugs
. New York: Simon and Schuster.
Roberts, Royston M., 1989,
Serendipity: Accidental Discoveries in Science
. Wiley.
Roll, R., 1986, “The Hubris Hypothesis of Corporate Takeovers.”
Journal of Business
59:197–216.
Rook, G.A.W., 2011, “Hygiene and Other Early Childhood Influences on the Subsequent Function of the Immune System.”
Digestive Diseases
29(2): 144–153.
Rose, K. A., I. G. Morgan, et al., 2008, “Outdoor Activity Reduces the Prevalence of Myopia in Children.”
Ophthalmology
115(8): 1279–1285.
Rothschild, M., and J. E. Stiglitz, 1970, “Increasing Risk: I. A Definition.”
Journal of Economic Theory
2(3): 225–243.
Rothschild, M., and J. E. Stiglitz, 1971, “Increasing Risk: II. Its Economic Consequences.”
Journal of Economic Theory
3(1): 66–84.
Rubino, F., et al., 2006, “The Mechanism of Diabetes Control After Gastrointestinal Bypass Surgery Reveals a Role of the Proximal Small Intestine in the Pathophysiology of Type 2 Diabetes.”
Annals of Surgery
244: 741–749.
Sackett, David L., W. Scott Richardson, William Rosenberg, and R. Brian Haynes, 1998,
Evidence-Based Medicine: How to Practice and Teach EBM
. Churchill Livingstone.
Safdie, F., T. Dorff, D. Quinn, L. Fontana, M. Wei, C. Lee, P. Cohen, and V. Longo, 2009, “Fasting and Cancer Treatment in Humans: A Case Series Report.”
Aging
(Albany, N.Y.), 1(12): 988.
Salsburg, David, 2001,
The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century.
Freemen.
Sandis, Constantine, 2012,
The Things We Do and Why We Do Them
. London: Palgrave Macmillan.
Scanu, A. M., and C. Edelstein, 2008, “HDL: Bridging Past and Present with a Look at the Future.”
FASEB Journal
22(12): 4044–4054.
Schlumberger, M. J., 1998, “Papillary and Follicular Thyroid Carcinoma,”
New England Journal of Medicine
338(5) 297–306.
Schnohr, P., J. L. Marott, et al., 2011, “Intensity Versus Duration of Cycling: Impact on All-Cause and Coronary Heart Disease Mortality: The Copenhagen City Heart Study.”
European Journal of Cardiovascular Prevention & Rehabilitation
.
Schon, Donald, 1983,
The Reflective Practitioner: How Professionals Think in Action
. Basic Books.
Schumacher, E. F., 1973,
Small Is Beautiful: A Study of Economics as if People Mattered.
London: Blond & Briggs.
Schumpeter, Joseph A., 1942,
Capitalism, Socialism and Democracy.
New York: Harper and Brothers. 5th ed., London: George Allen and Unwin, 1976.
Schumpeter, Joseph A., 1994,
History of Economic Analysis
. Oxford: Oxford University Press.
Scott, A., K. M. Khan, V. Duronio, and D. A. Hart, 2008, “Mechanotransduction in Human Bone: In Vitro Cellular Physiology That Underpins Bone Changes with Exercise.”
Sports Medicine
38(2): 139–160.
Scott, James C., 1998,
Seeing like a State: How Certain Schemes to Improve the Human Condition Have Failed
. New Haven: Yale University Press.
Scranton, P., 2006, “Urgency, Uncertainty, and Innovation: Building Jet Engines in Postwar America.”
Management & Organizational History
1(2): 127.
Scranton, P., 2007, “Turbulence and Redesign: Dynamic Innovation and the Dilemmas of US Military Jet Propulsion Development.”
European Management Journal
25(3): 235–248.
Scranton, P., 2009, “The Challenge of Technological Uncertainty.”
Technology and Culture
50(2): 513–518.
Seery, M. D., 2011, “Resilience.”
Current Directions in Psychological Science
20(6): 390–394.
Sestini, P., and L. B. Irving, 2009. “The Need for Expertise and the Scientific Base of Evidence-Based Medicine.”
Chest
135(1): 245.
Shackle, G.L.S., 1992,
Epistemics and Economics: A Critique of Economic Doctrines
. Transaction Publishers.
Shah, A. K., and D. M. Oppenheimer, 2007, “Easy Does It: The Role of Fluency in Cue Weighting.”
Judgment and Decision Making
2(6): 371–379.
Sharpe, Virginia A., and Alan I. Faden, 1998,
Medical Harm: Historical, Conceptual, and Ethical Dimensions of Iatrogenic Illness.
Cambridge: Cambridge University Press.
Shelford, April G., 2007,
Transforming the Republic of Letters: Pierre-Daniel Huet and European Intellectual Life, 1650–1720.
Rochester, N.Y.: University of Rochester Press.
Shimabukuro, M., et al., 1998, “Lipoapoptosis in Beta-Cells of Obese Prediabetic Fa/Fa Rats. Role of Serine Palmitoyltransferase Overexpression.”
Journal of Biological Chemistry
273: 32487–32490.
Siegel-Itzkovich, Judy, 2000, “Doctors’ Strike in Israel May Be Good for Health.”
BMJ
320(7249): 1561.
Silverman, William A., 1999,
Where’s the Evidence: Debates in Modern Medicine
. Oxford: Oxford University Press.
Singer, S. Fred Charles A. S. Hall, Cutler J., 1981, Cleveland: Science, New Series, Vol. 213, No. 4515 (Sep. 25, 1981).
Singh, Simon, and Ernst Edzard, M.D., 2008,
Trick or Treatment: The Undeniable Facts About Alternative Medicine
. New York: W. W. Norton.
Skyler, J., R. Bergenstal, R. Bonow, J. Buse, P. Deedwania, E. Gale, B. Howard, M. Kirkman, M. Kosiborod, and P. Reaven (2009), “Intensive Glycemic Control and the Prevention of Cardiovascular Events: Implications of the ACCORD, ADVANCE, and VA Diabetes Trials.”
Circulation
119(2): 351–357.
Smith, V. L., 2008,
Rationality in Economics: Constructivist and Ecological Forms
. Cambridge: Cambridge University Press.
Sober, Elliott, 2008,
Evidence and Evolution: The Logic Behind Science
. Cambridge: Cambridge University Press.
Solomon, L., 1979, “Bone Density in Ageing Caucasian and African Populations.”
Lancet
2: 1326–1330.
Sorabji, Richard, 2000,
Emotion and Peace of Mind: From Stoic Agitation to Christian Temptation
. Oxford: Oxford University Press.
Sornette, Didier, and L. Knopoff, 1997, “The Paradox of the Expected Time Until the Next Earthquake.”
Bulletin of the Seismological Society of America
87(4): 789–798.
Sornette, Didier, and D. Zajdenweber, 1999, “Economic Returns of Research: The Pareto Law and Its Implications.”
The European Physical Journal, B: Condensed Matter and Complex Systems
8(4): 653–664.
Sornette, Didier, 2003,
Why Stock Markets Crash: Critical Events in Complex Financial Systems
. Princeton, N.J.: Princeton University Press.
Sornette, Didier, 2004,
Critical Phenomena in Natural Sciences: Chaos, Fractals, Self-organization and Disorder: Concepts and Tools,
2nd ed. Berlin and Heidelberg: Springer.
Stanley, J., 2010, “Knowing (How).”
Noûs.
Starbuck, W. H., 1992, “Strategizing in the Real World,” in “Technological Foundations of Strategic Management.” Special issue,
International Journal of Technology Management
8, no. 1/2.
Starbuck, W. H., 2004, “Why I Stopped Trying to Understand the Real World.”
Organizational Studies
25(7).
Starbuck, W. H., M. L. Barnett, et al., 2008, “Payoffs and Pitfalls of Strategic Learning.”
Journal of Economic Behavior & Organization
66(1): 7–21.
Stasavage, D., 2012, “Was Weber Right? City Autonomy, Political Oligarchy, and the Rise of Europe.” Preprint.
Steinmo, S., 2010,
The Evolution of Modern States: Sweden, Japan, and the United States (Cambridge Studies in Comparative Politics).
Cambridge University Press
Steinmo, S., 2012, “Considering Swedish Exceptionalism,” draft, European University Institute.
Sternberg, Robert J., 2003,
Wisdom, Intelligence and Creativity Synthesized.
Cambridge: Cambridge University Press.
Sternhell, Zeev, 2010,
The Anti-Enlightenment Tradition
. New Haven: Yale University Press.
Steven, S., et al., 2010, “Dietary Reversal of Type 2 Diabetes Motivated by Research Knowledge.”
Diabetic Medicine
27: 724–725.
Stigler, Stephen M., 1990,
The History of Statistics: The Measurement of Uncertainty Before 1900
. Cambridge, Mass.: The Belknap Press of Harvard University.
Stipp, David, 2010,
The Youth Pill
. Current.
Stokes, Donald E., 1997,
Pasteur’s Quadrant: Basic Science and Techonological Innovation
. Brookings Institution Press.
Stranahan, A. M., and M. P. Mattson, 2012, “Recruiting Adaptive Cellular Stress Responses for Successful Brain Ageing.”
Nature Reviews Neuroscience
.
Stroud, Barry, 1984,
The Significance of Philosophical Scepticism
. Oxford: Oxford University Press.
Stubbart, C. I., and M. B. Knight, 2006, “The Case of the Disappearing Firms: Empirical Evidence and Implications.”
Journal of Organizational Behavior
27(1): 79–100.
Sunstein, Cass, 2009,
On Rumors: How Falsehoods Spread, Why We Believe Them, What Can Be Done
. Allen Lane.
Taagepera, R., 1978, “Size and Duration of Empires: Growth-Decline Curves, 3000 to 600 B.C.”
Social Science Research
7: 180–196.
Tainter, J., 1988,
The Collapse of Complex Societies: New Studies in Archaeology.
Cambridge: Cambridge University Press.
Taleb, N. N., and M. Blyth, 2011, “The Black Swan of Cairo.”
Foreign Affairs
90(3).
Taleb, N. N., and A. Pilpel, 2007, “Epistemology and Risk Management.”
Risk and Regulation
13, Summer.
Taleb, N. N., and C. Tapiero, 2010, “The Risk Externalities of Too Big to Fail.”
Physica A: Statistical Physics and Applications
.
Taleb, N. N., D. G. Goldstein, and M. Spitznagel, 2009, “The Six Mistakes Executives Make in Risk Management,”
Harvard Business Review
(October).
Taleb, N. N., 2008, “Infinite Variance and the Problems of Practice.”
Complexity
14(2).
Taleb, N. N., 2009, “Errors, Robustness, and the Fourth Quadrant.”
International Journal of Forecasting
25.
Taleb, N. N., 2011, “The Future Has Thicker Tails than the Past: Model Error as Branching Counterfactuals.”
Benoît Mandelbrot’s Scientific Memorial,
Preprint (see Companion Volume).
Taleb, N. N., and R. Douady, 2012, “A Map and Simple Heuristic to Detect Fragility, Antifragility, and Model Error,” arXiv Preprint.
Taleb, N. N., and G. Martin, 2012a, “How to Avoid Another Crisis,”
SAIS Review of International Affairs
.
Taleb, N. N., and G. Martin, 2012b, “The Illusion of Thin Tails Under Aggregation (A Reply to Jack Treynor).”
Journal of Investment Management.
Taleb, N. N., and D. Goldstein, 2012, “The Problem Is Beyond Psychology: The Real World Is More Random Than Regression Analyses,”
International Journal of Forecasting
28(3), 715–716.
Taleb, N. N., Elie Canetti, Elena Loukoianova, Tidiane Kinda, and Christian Schmieder, 2012, “A New Heuristic Measure of Fragility and Tail Risks: Application to Stress Testing,” IMF Working Paper.
Tatonetti, Nicholas P., et al., 2012, “Data-Driven Prediction of Drug Effects and Interactions.”
Science Translational Medicine
4, 125ra31, doi: 10.1126/scitranslmed.3003377.
Taubes, G., 2008,
Good Calories, Bad Calories: Fats, Carbs, and the Controversial Science of Diet and Health
. New York: Anchor Books.
Taubes, G., 2011,
Why We Get Fat: And What to Do About It
. New York: Anchor Books.
Taylor, R., 2008, “Pathogenesis of Type 2 Diabetes: Tracing the Reverse Route from Cure to Cause.”
Diabetologia
51: 1781–1789.
Tedeschi, R. G., and L. G. Calhoun, 1996, “The Posttraumatic Growth Inventory: Measuring the Positive Legacy of Trauma.”
Journal of Traumatic Stress
9(3): 455–471.
Tetlock, Philip E., Richard Ned Lebow, and Geoffrey Parker, eds., 2009,
Unmaking the West: “What-If?” Scenarios That Rewrite World History
. Ann Arbor: University of Michigan Press.
Thomas, Keith, 1997,
Religion and the Decline of Magic
. Oxford: Oxford University Press.
Thompson, M. R., 2010, “Reformism vs. Populism in the Philippines.”
Journal of Democracy
21(4): 154–168.
Thorp, E., 1971, “Portfolio Choice and the Kelly Criterion.”
Stochastic Models in Finance,
599–619.
Thorp, E., 1998, “The Kelly Criterion in Blackjack, Sports Betting, and the Stock Market.”
Finding the Edge: Mathematical Analysis of Casino Games
.
Thorsrud, Harald, 2009,
Ancient Scepticism
. Acumen.
Todd, E., 2010, “The International Risk Governance Council Framework and Its Application to
Listeria monocytogenes
in Soft Cheese Made from Unpasteurised Milk.” Food Control.
Townsend, A., A. Clark, and K. McGowan, 2010, “Direct Benefits and Genetic Costs of Extrapair Paternity for Female American Crows (
Corvus brachyrhynchos
).”
American Naturalist
175 (1).
Trabelsi, K., K. El Abed, S. R. Stannard, K. Jammoussi, K. M. Zeghal, and A. Hakim, 2012, “Effects of Fed- Versus Fasted-State Aerobic Training During Ramadan on Body Composition and Some Metabolic Parameters in Physically Active Men.”
International Journal of Sport Nutrition and Exercise.
Triana, P., 2009,
Lecturing Birds on Flying: Can Mathematical Theories Destroy the Financial Markets?
Wiley.
Triana, P., 2011,
The Number That Killed Us: A Story of Modern Banking, Flawed Mathematics, and a Big Financial Crisis
. Wiley.
Trigeorgis, L., 1993, “Real Options and Interactions with Financial Flexibility.”
Financial Management,
202–224.
Trigeorgis, L., 1996,
Real Options: Managerial Flexibility and Strategy in Resource Allocation.
Cambridge, Mass.: The MIT Press.
Trivers, Robert, 2011,
The Folly of Fools: The Logic of Deceit and Self-Deception in Human Life
. Basic Books.
Turchin, P., 2003,
Historical Dynamics: Why States Rise and Fall
. Princeton, N.J.: Princeton University Press.
Turchin, P., 2009, “A Theory for Formation of Large Empires.”
Journal of Global History
4(02): 191–217.
Urvoy, Dominique, 1996,
Les penseurs libres dans l’Islam classique
. Champs Flammarion.
Valdovinos, F., R. Ramos-Jiliberto, et al., 2010, “Consequences of Adaptive Foraging for the Structure and Dynamics of Food Webs.”
Ecology Letters
13: 1546–1559.
Vanderbilt, T., 2008a, “The Traffic Guru.”
Wilson Quarterly
(1976), 32(3): 26–32.
Vanderbilt, T., 2008b,
Traffic: Why We Drive the Way We Do (and What It Says About Us).
New York: Knopf.
Van Zwet, W. R., 1964,
Convex Transformations of Random Variables.
Mathematical Center Amsterdam, 7.
Velez, N., A. Zhang, B. Stone, S. Perera, M. Miller, and S. Greenspan, “The Effect of Moderate Impact Exercise on Skeletal Integrity in Master Athletes.”
Osteoporosis International
(October 2008), 19(10): 1457–1464.
Vermeij, Geerat J., 2004,
Nature: An Economic History
. Princeton, N.J.: Princeton University Press.
Vernon, Mark, 2009,
Plato’s Podcasts: The Ancient’s Guide to Modern Living
. London: Oneworld.
Veyne, Paul, 1999, “Païens et chrétiens devant la gladiature.”
Mélanges de l’École française de Rome. Antiquité,
vol. 111, issue 111–2, 883–917.
Veyne, Paul, 2001,
La société romaine.
Paris: Éditions du Seuil.
Vigarello, Georges, 1998,
Histoire des pratiques de santé
. Paris: Éditions du Seuil.
von Heyd, Wilhelm, 1886,
Histoire du commerce du Levant au moyen-âge
(French translation). Éd. fr., refondue et augmentée, Leipzig.
von Plato, Jan, 1994,
Creating Modern Probability: Its Mathematics, Physics and Philosophy in Historical Perspective
. New York: Cambridge University Press.
Wagner, Andreas, 2005,
Robustness and Evolvability in Living Systems
. Princeton, N.J.: Princeton University Press.
Wai-Hung, Wong, 2002, “The Problem of Insulation,”
Philosophy,
vol. 77, no. 301 (July 2002), 349–373.
Wales, J. K., 1982, “Treatment of Type 2 (Non-Insulin-Dependent) Diabetic Patients with Diet Alone.”
Diabetologia
23: 240–245.
Wallenborn, White McKenzie, 1997, “George Washington’s Terminal Illness: A Modern Medical Analysis of the Last Illness and Death of George Washington.” The Papers of George Washington, University of Virginia.
Waller, John, 2002,
Fabulous Science: Fact and Fiction in the History of Scientific Discovery
. Oxford: Oxford University Press.
Waterfield, Robin, 2009,
Why Socrates Died: Dispelling the Myths
. London: Faber and Faber.
Wear, Andrew, 1995, “Anatomy.” In Lawrence Conrad et al., eds.,
The Western Medical Tradition,
Vol. 1, Cambridge: Cambridge University Press.
Weber, Max, 1905, 2000,
L’éthique protestante et l’esprit du capitalisme
. Flammarion.
Weindruch, R., 1996, “The Retardation of Aging by Caloric Restriction: Studies in Rodents and Primates.”
Toxicologic Pathology
24: 742–745.
Weisberg, D., F. Keil, J. Goodstein, E. Rawson, and J. R. Gray, 2008, “The Seductive Allure of Neuroscience Explanations.”
Journal of Cognitive Neuroscience
20: 470–477.
Welch, H. Gilbert, Lisa M. Schwartz, and Steven Woloshin, 2011,
Overdiagnosed: Making People Sick in the Pursuit of Health
. Boston: Beacon Press.
West, G. B., 2011, “Can There Be a Quantitative Theory for the History of Life and Society?”
Cliodynamics
2(1).
Westman, E. and Vernon, M., 2008, “Has Carbohydrate Restriction Been Forgotten as a Treatment for Diabetes Mellitus? A Perspective on the ACCORD Study Design.”
Nutrition and Metabolism
(Lond), 5:10.
Whitacre, J. M., 2010, “Degeneracy: A Link Between Evolvability, Robustness and Complexity in Biological Systems.”
Theoretical Biology and Medical Modelling
7(1): 6.
White, David A., and Thomas A. Fitzgerald, “On Menard and Sharman Random Drilling.”
Science,
New Series, Vol. 192, No. 4236 (Apr. 16, 1976).
Whitehead, Alfred North, 1967,
Science and the Modern World
. The Free Press.
Wilcken, Patrick, 2010,
Claude Lévi-Strauss: The Poet in the Laboratory
. Penguin.
Wilson, E. A., et al., 1980, “Dietary Management of Maturity-Onset Diabetes.”
BMJ
280: 1367–1369.
Wilson, Emily, 2007,
The Death of Socrates: Hero, Villain, Chatterbox, Saint
. London: Profile Books.
Wilson, Stephen, 2003,
The Bloomsbury Book of the Mind
. London: Bloomsbury.
Winchester, Simon, 2008,
Bomb, Book and Compass: Joseph Needham and the Great Secrets of China
. New York: Viking.
Wolf, Alison, 2002,
Does Education Matter? Myths About Education and Economic Growth
. London: Penguin UK.
Wolff, J., 1892,
Das Gesetz der Transformation der Knochen.
Reprint: Pro Business, Berlin 2010.
Women, P., W. Speed, et al., 2012, “Statins and Musculoskeletal Pain.”
Wootton, David, 2006,
Bad Medicine: Doctors Doing Harm Since Hippocrates
. Oxford: Oxford University Press.
Yaffe, K., T. Blackwell, et al., 2004. “Diabetes, Impaired Fasting Glucose, and Development of Cognitive Impairment in Older Women.”
Neurology
63(4): 658–663.
Yarkoni, T., 2009, “Big Correlations in Little Studies: Inflated Fmri Correlations Reflect Low Statistical Power,” commentary on Vul et al., 2009,
Perspectives on Psychological Science
4(3), 294–298, doi:10.1111/j.1745–6924.2009.01127.x.
Young, S. S., and A. Karr, 2011, “Deming, Data and Observational Studies.”
Significance
8(3): 116–120.
Yuan, K. H., and S. Maxwell, 2005, “On the Post Hoc Power in Testing Mean Differences.”
Journal of Educational and Behavioral Statistics
30(2), 141–167.
Zeller, Eduard, 1905 (reprint),
Outlines of History of Greek Philosophy
. Whitefish, Mont.: Kessinger Publishing.
Zerubavel, Eviatar, 2006,
The Elephant in the Room: Silence and Denial in Everyday Life
. Oxford: Oxford University Press.
Ziliak, S., and D. McCloskey, 2008,
The Cult of Statistical Significance: How the Standard Error Costs Us Jobs, Justice, and Lives
. Ann Arbor: University of Michigan Press.


================================================================================
CHAPTER/SECTION 154 (Item 157)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 155 (Item 158)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 156 (Item 159)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 157 (Item 160)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 158 (Item 161)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 159 (Item 162)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 160 (Item 163)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 161 (Item 164)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 162 (Item 165)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 163 (Item 166)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 164 (Item 167)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 165 (Item 168)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 166 (Item 169)
================================================================================

Double-tap or move your cursor over the table and click to zoom.
Click
here
to return to the text.


================================================================================
CHAPTER/SECTION 167 (Item 172)
================================================================================

2010 Random House Trade Paperback Edition
Copyright © 2007, 2010 by Nassim Nicholas Taleb
All rights reserved.
Published in the United States by Random House Trade Paperbacks, an imprint of The Random House Publishing Group, a division of Random House, Inc., New York.
R
ANDOM
H
OUSE
T
RADE
P
APERBACKS
and colophon are trademarks of Random House, Inc.
Originally published in hardcover and in slightly different form in the United States by Random House, an imprint of The Random House Publishing Group, a division of Random House, Inc., in 2007.
LIBRARY OF CONGRESS CATALOGING-IN-PUBLICATION DATA
Taleb, Nassim.
The black swan: the impact of the highly improbable /
Nassim Nicholas Taleb.
p. cm.
Contents: Part one—Umberto Eco’s antilibrary, or how we seek
validation—Part two—We just can’t predict—Part three—
Those gray swans of extremistan—Part four—The end.
eISBN: 978-0-679-60418-1
1. Uncertainty (Information theory)—Social aspects.
2. Forecasting. I. Title.
Q375.T35 2007
003′.54—dc22   2006051093
www.atrandom.com
v3.0_r7


================================================================================
CHAPTER/SECTION 168 (Item 173)
================================================================================

CONTENTS
Master - Table of Contents
The Black Swan
Title Page
Copyright
Note to the Second Edition
Prologue
On the Plumage of Birds
What You Do Not Know
Experts and “Empty Suits”
Learning to Learn
A New Kind of Ingratitude
Life Is Very Unusual
Plato and the Nerd
Too Dull to Write About
The Bottom Line
Chapters Map
PART 1:
UMBERTO ECO’S ANTILIBRARY, OR HOW WE SEEK VALIDATION
Chapter 1:
The Apprenticeship of an Empirical Skeptic
Anatomy of a Black Swan
On Walking Walks
“Paradise” Evaporated
The Starred Night
History and the Triplet of Opacity
Nobody Knows What’s Going On
History Does Not Crawl, It Jumps
Dear Diary: On History Running Backward
Education in a Taxicab
Clusters
Where Is the Show?
8¾ Lbs Later
The Four-Letter Word of Independence
Limousine Philosopher
Chapter 2:
Yevgenia’s Black Swan
Chapter 3:
The Speculator and the Prostitute
The Best (Worst) Advice
Beware the Scalable
The Advent of Scalability
Scalability and Globalization
Travels Inside Mediocristan
The Strange Country of Extremistan
Extremistan and Knowledge
Wild and Mild
The Tyranny of the Accident
Chapter 4:
One Thousand and One Days, or How Not to Be a Sucker
How to Learn from the Turkey
Trained to Be Dull
A Black Swan Is Relative to Knowledge
A Brief History of the Black Swan Problem
Sextus the (Alas) Empirical
Algazel
The Skeptic, Friend of Religion
I Don’t Want to Be a Turkey
They Want to Live in Mediocristan
Chapter 5:
Confirmation Shmonfirmation!
Zoogles Are Not All Boogles
Evidence
Negative Empiricism
Counting to Three
Saw Another Red Mini!
Not Everything
Back to Mediocristan
Chapter 6:
The Narrative Fallacy
On the Causes of My Rejection of Causes
Splitting Brains
A Little More Dopamine
Andrey Nikolayevich’s Rule
A Better Way to Die
Remembrance of Things Not Quite Past
The Madman’s Narrative
Narrative and Therapy
To Be Wrong with Infinite Precision
Dispassionate Science
The Sensational and the Black Swan
Black Swan Blindness
The Pull of the Sensational
The Shortcuts
Beware the Brain
How to Avert the Narrative Fallacy
Chapter 7:
Living in the Antechamber of Hope
Peer Cruelty
Where the Relevant Is the Sensational
Nonlinearities
Process over Results
Human Nature, Happiness, and Lumpy Rewards
The Antechamber of Hope
Inebriated by Hope
The Sweet Trap of Anticipation
When You Need the Bastiani Fortress
El desierto de los tártaros
Bleed or Blowup
Chapter 8:
Giacomo Casanova’s Unfailing Luck: The Problem of Silent Evidence
The Story of the Drowned Worshippers
The Cemetery of Letters
How to Become a Millionaire in Ten Steps
A Health Club for Rats
Vicious Bias
More Hidden Applications
The Evolution of the Swimmer’s Body
What You See and What You Don’t See
Doctors
The Teflon-style Protection of Giacomo Casanova
“I Am a Risk Taker”
I Am a Black Swan: The Anthropic Bias
The Cosmetic Because
Chapter 9:
The Ludic Fallacy, or The Uncertainty of the Nerd
Fat Tony
Non-Brooklyn John
Lunch at Lake Como
The Uncertainty of the Nerd
Gambling with the Wrong Dice
Wrapping Up Part One
The Cosmetic Rises to the Surface
Distance from Primates
PART 2:
WE JUST CAN’T PREDICT
From Yogi Berra to Henri Poincaré
Chapter 10:
The Scandal of Prediction
On the Vagueness of Catherine’s Lover Count
Black Swan Blindness Redux
Guessing and Predicting
Information Is Bad for Knowledge
The Expert Problem, or the Tragedy of the Empty Suit
What Moves and What Does Not Move
How to Have the Last Laugh
Events Are Outlandish
Herding Like Cattle
I Was “Almost” Right
Reality? What For?
“Other Than That,” It Was Okay
The Beauty of Technology: Excel Spreadsheets
The Character of Prediction Errors
Don’t Cross a River if It Is (on Average) Four Feet Deep
Get Another Job
At JFK
Chapter 11:
How to Look for Bird Poop
How to Look for Bird Poop
Inadvertent Discoveries
A Solution Waiting for a Problem
Keep Searching
How to Predict Your Predictions!
The Nth Billiard Ball
Third Republic–Style Decorum
The Three Body Problem
They Still Ignore Hayek
How Not to Be a Nerd
Academic Libertarianism
Prediction and Free Will
The Grueness of Emerald
That Great Anticipation Machine
Chapter 12:
Epistemocracy, a Dream
Monsieur de Montaigne, Epistemocrat
Epistemocracy
The Past’s Past, and the Past’s Future
Prediction, Misprediction, and Happiness
Helenus and the Reverse Prophecies
The Melting Ice Cube
Once Again, Incomplete Information
What They Call Knowledge
Chapter 13:
Appelles the Painter, or What Do You Do if You Cannot Predict?
Advice Is Cheap, Very Cheap
Being a Fool in the Right Places
Be Prepared
The Idea of Positive Accident
Volatility and Risk of Black Swan
Barbell Strategy
“Nobody Knows Anything”
The Great Asymmetry
PART 3:
THOSE GRAY SWANS OF EXTREMISTAN
Chapter 14:
From Mediocristan to Extremistan, and Back
The World Is Unfair
The Matthew Effect
Lingua Franca
Ideas and Contagions
Nobody Is Safe in Extremistan
A Brooklyn Frenchman
The Long Tail
Naïve Globalization
Reversals Away from Extremistan
Chapter 15:
The Bell Curve, That Great Intellectual Fraud
The Gaussian and the Mandelbrotian
The Increase in the Decrease
The Mandelbrotian
What to Remember
Inequality
Extremistan and the 80/20 Rule
Grass and Trees
How Coffee Drinking Can Be Safe
Love of Certainties
How to Cause Catastrophes
Quételet’s Average Monster
Golden Mediocrity
God’s Error
Poincaré to the Rescue
Eliminating Unfair Influence
“The Greeks Would Have Deified It”
“Yes/No” Only Please
A (Literary) Thought Experiment on Where the Bell Curve Comes From
Those Comforting Assumptions
“The Ubiquity of the Gaussian”
Chapter 16:
The Aesthetics of Randomness
The Poet of Randomness
The Platonicity of Triangles
The Geometry of Nature
Fractality
A Visual Approach to Extremistan/Mediocristan
Pearls to Swine
The Logic of Fractal Randomness (with a Warning)
The Problem of the Upper Bound
Beware the Precision
The Water Puddle Revisited
From Representation to Reality
Once Again, Beware the Forecasters
Once Again, a Happy Solution
Where Is the Gray Swan?
Chapter 17:
Locke’s Madmen, or Bell Curves in the Wrong Places
Only Fifty Years
The Clerks’ Betrayal
Anyone Can Become President
More Horror
Confirmation
It Was Just a Black Swan
How to “Prove” Things
Chapter 18:
The Uncertainty of the Phony
Ludic Fallacy Redux
Find the Phony
Can Philosophers Be Dangerous to Society?
The Problem of Practice
How Many Wittgensteins Can Dance on the Head of a Pin?
Where Is Popper When You Need Him?
The Bishop and the Analyst
Easier Than You Think: The Problem of Decision Under Skepticism
PART 4:
THE END
Chapter 19:
Half and Half, or How to Get Even with the Black Swan
When Missing a Train Is Painless
The End
EPILOGUE: YEVGENIA’S WHITE SWANS
POSTSCRIPT ESSAY: ON ROBUSTNESS AND FRAGILITY, DEEPER PHILOSOPHICAL AND EMPIRICAL REFLECTIONS
I—Learning from Mother Nature, the Oldest and the Wisest
On Slow but Long Walks
My Mistakes
Robustness and Fragility
Redundancy as Insurance
Big is Ugly—and Fragile
Climate Change and “Too Big” Polluters
Species Density
The Other Types of Redundancy
Distinctions Without a Difference, Differences Without a Distinction
A Society Robust to Error
II—Why I Do All This Walking, or How Systems Become Fragile
Another Few Barbells
Beware Manufactured Stability
III—Margaritas Ante Porcos
Main Errors in Understanding the Message
How to Expunge One’s Crimes
A Desert Crossing
IV—Asperger and the Ontological Black Swan
Asperger Probability
Future Blindness Redux
Probability has to be Subjective
Probability on a Thermometer
V—(Perhaps) the Most Useful Problem in the History of Modern Philosophy
Living in Two Dimensions
The Dependence on Theory for Rare Events
Epimenides the Cretan
An Undecidability Theorem
It’s the Consequences …
From Reality to Representation
Proof in the Flesh
Fallacy of the Single Event Probability
Psychology of Perception of Deviations
The Problem of Induction and Causation in the Complex Domain
Induction
Driving the School Bus Blindfolded
VI—The Fourth Quadrant, the Solution to that Most Useful of Problems
David Freedman, RIP
Decisions
The Fourth Quadrant, a Map
VII—What to Do with the Fourth Quadrant
Not Using the Wrong Map: The Notion of Iatrogenics
Negative Advice
Iatrogenics and The Nihilism Label
Phronetic Rules: What is Wise to do (or not do) in Real Life to Mitigate the Fourth Quadrant if you can’t Barbell?
VIII—The Ten Principles for a Black-Swan-Robust Society
IX—Amor Fati: How to Become Indestructible
Nihil Perditi
Glossary
Dedication
Acknowledgments for the First Edition
Notes
Bibliography


================================================================================
CHAPTER/SECTION 169 (Item 174)
================================================================================

NOTE TO THE SECOND EDITION
In order to preserve the integrity of the original text, I have limited the updating of the current edition to a small number of footnotes. I added a long Postscript essay, going deeper into philosophical and empirical discussions of the subject and addressing some misunderstandings of the concept of the Black Swan that cropped up after the initial publication of the book.


================================================================================
CHAPTER/SECTION 170 (Item 175)
================================================================================

PROLOGUE
ON THE PLUMAGE OF BIRDS
Before the discovery of Australia, people in the Old World were convinced that
all
swans were white, an unassailable belief as it seemed completely confirmed by empirical evidence. The sighting of the first black swan might have been an interesting surprise for a few ornithologists (and others extremely concerned with the coloring of birds), but that is not where the significance of the story lies. It illustrates a severe limitation to our learning from observations or experience and the fragility of our knowledge. One single observation can invalidate a general statement derived from millennia of confirmatory sightings of millions of white swans. All you need is one single (and, I am told, quite ugly) black bird.
*
I push one step beyond this philosophical-logical question into an empirical reality, and one that has obsessed me since childhood.
†
What we call here a Black Swan (and capitalize it) is an event with the following three attributes.
First, it is an
outlier
, as it lies outside the realm of regular expectations, because nothing in the past can convincingly point to its possibility. Second, it carries an extreme impact (unlike the bird). Third, in spite of its outlier status, human nature makes us concoct explanations for its occurrence
after
the fact, making it explainable and predictable.
I stop and summarize the triplet: rarity, extreme impact, and retrospective (though not prospective) predictability.
*
A small number of Black Swans explain almost everything in our world, from the success of ideas and religions, to the dynamics of historical events, to elements of our own personal lives. Ever since we left the Pleistocene, some ten millennia ago, the effect of these Black Swans has been increasing. It started accelerating during the industrial revolution, as the world started getting more complicated, while ordinary events, the ones we study and discuss and try to predict from reading the newspapers, have become increasingly inconsequential.
Just imagine how little your understanding of the world on the eve of the events of 1914 would have helped you guess what was to happen next. (Don’t cheat by using the explanations drilled into your cranium by your dull high school teacher.) How about the rise of Hitler and the subsequent war? How about the precipitous demise of the Soviet bloc? How about the consequences of the rise of Islamic fundamentalism? How about the effect of the spread of the Internet? How about the market crash of 1987 (and the more unexpected recovery)? Fads, epidemics, fashion, ideas, the emergence of art genres and schools. All follow these Black Swan dynamics. Literally, just about everything of significance around you might qualify.
This combination of low predictability and large impact makes the Black Swan a great puzzle; but that is not yet the core concern of this book. Add to this phenomenon the fact that we tend to act as if it does not exist! I don’t mean just you, your cousin Joey, and me, but almost all “social scientists” who, for over a century, have operated under the false belief that their tools could measure uncertainty. For the applications of the sciences of uncertainty to real-world problems has had ridiculous effects; I have been privileged to see it in finance and economics. Go ask your
portfolio manager for his definition of “risk,” and odds are that he will supply you with a
measure
that
excludes
the possibility of the Black Swan—hence one that has no better predictive value for assessing the total risks than astrology (we will see how they dress up the intellectual fraud with mathematics). This problem is endemic in social matters.
The central idea of this book concerns our blindness with respect to randomness, particularly the large deviations: Why do we, scientists or nonscientists, hotshots or regular Joes, tend to see the pennies instead of the dollars? Why do we keep focusing on the minutiae, not the possible significant large events, in spite of the obvious evidence of their huge influence? And, if you follow my argument, why does reading the newspaper actually
decrease
your knowledge of the world?
It is easy to see that life is the cumulative effect of a handful of significant shocks. It is not so hard to identify the role of Black Swans, from your armchair (or bar stool). Go through the following exercise. Look into your own existence. Count the significant events, the technological changes, and the inventions that have taken place in our environment since you were born and compare them to what was expected before their advent. How many of them came on a schedule? Look into your own personal life, to your choice of profession, say, or meeting your mate, your exile from your country of origin, the betrayals you faced, your sudden enrichment or impoverishment. How often did these things occur according to plan?
What You Do Not Know
Black Swan logic makes
what you don’t know
far more relevant than what you do know.
*
Consider that many Black Swans can be caused and exacerbated
by their being unexpected
.
Think of the terrorist attack of September 11, 2001: had the risk been reasonably
conceivable
on September 10, it would not have happened. If such a possibility were deemed worthy of attention, fighter planes would have circled the sky above the twin towers, airplanes would have had
locked bulletproof doors, and the attack would not have taken place, period. Something else might have taken place. What? I don’t know.
Isn’t it strange to see an event happening precisely because it was not supposed to happen? What kind of defense do we have against that? Whatever you come to know (that New York is an easy terrorist target, for instance) may become inconsequential if your enemy knows that you know it. It may be odd that, in such a strategic game, what you know can be truly inconsequential.
*
This extends to all businesses. Think about the “secret recipe” to making a killing in the restaurant business. If it were known and obvious, then someone next door would have already come up with the idea and it would have become generic. The next killing in the restaurant industry needs to be an idea that is not easily conceived of by the current population of restaurateurs. It has to be at some distance from expectations. The more unexpected the success of such a venture, the smaller the number of competitors, and the more successful the entrepreneur who implements the idea. The same applies to the shoe and the book businesses—or any kind of entrepreneurship. The same applies to scientific theories—nobody has interest in listening to trivialities. The payoff of a human venture is, in general, inversely proportional to what it is expected to be.
Consider the Indian Ocean tsunami of December 2004. Had it been expected, it would not have caused the damage it did—the areas affected would have been less populated, an early warning system would have been put in place. What you know cannot really hurt you.
Experts and “Empty Suits”
The inability to predict outliers implies the inability to predict the course of history
, given the share of these events in the dynamics of events.
But we act as though we are able to predict historical events, or, even worse, as if we are able to change the course of history. We produce thirty-year projections of social security deficits and oil prices without realizing that we cannot even predict these for next summer—our cumulative prediction errors for political and economic events are so monstrous that every time I look at the empirical record I have to pinch myself to verify
that I am not dreaming. What is surprising is not the magnitude of our forecast errors, but our absence of awareness of it. This is all the more worrisome when we engage in deadly conflicts: wars are fundamentally unpredictable (and we do not know it). Owing to this misunderstanding of the causal chains between policy and actions, we can easily trigger Black Swans thanks to aggressive ignorance—like a child playing with a chemistry kit.
Our inability to predict in environments subjected to the Black Swan, coupled with a general lack of the awareness of this state of affairs, means that certain professionals, while believing they are experts, are in fact not. Based on their empirical record, they do not know more about their subject matter than the general population, but they are much better at narrating—or, worse, at smoking you with complicated mathematical models. They are also more likely to wear a tie.
Black Swans being unpredictable, we need to adjust to their existence (rather than naïvely try to predict them). There are so many things we can do if we focus on antiknowledge, or what we do not know. Among many other benefits, you can set yourself up to collect serendipitous Black Swans (of the positive kind) by maximizing your exposure to them. Indeed, in some domains—such as scientific discovery and venture capital investments—there is a disproportionate payoff from the unknown, since you typically have little to lose and plenty to gain from a rare event. We will see that, contrary to social-science wisdom, almost no discovery, no technologies of note, came from design and planning—they were just Black Swans. The strategy for the discoverers and entrepreneurs is to rely less on top-down planning and focus on maximum tinkering and recognizing opportunities when they present themselves. So I disagree with the followers of Marx and those of Adam Smith: the reason free markets work is because they allow people to be lucky, thanks to aggressive trial and error, not by giving rewards or “incentives” for skill. The strategy is, then, to tinker as much as possible and try to collect as many Black Swan opportunities as you can.
Learning to Learn
Another related human impediment comes from excessive focus on what we do know: we tend to learn the precise, not the general.
What did people learn from the 9/11 episode? Did they learn that some events, owing to their dynamics, stand largely outside the realm of the predictable?
No. Did they learn the built-in defect of conventional wisdom? No. What did they figure out? They learned precise rules for avoiding Islamic prototerrorists and tall buildings. Many keep reminding me that it is important for us to be practical and take tangible steps rather than to “theorize” about knowledge. The story of the Maginot Line shows how we are conditioned to be specific. The French, after the Great War, built a wall along the previous German invasion route to prevent reinvasion—Hitler just (almost) effortlessly went around it. The French had been excellent students of history; they just learned with too much precision. They were too practical and exceedingly focused for their own safety.
We do not spontaneously learn that
we don’t learn that we don’t learn
. The problem lies in the structure of our minds: we don’t learn rules, just facts, and only facts. Metarules (such as the rule that we have a tendency to not learn rules) we don’t seem to be good at getting. We scorn the abstract; we scorn it with passion.
Why? It is necessary here, as it is my agenda in the rest of this book, both to stand conventional wisdom on its head and to show how inapplicable it is to our modern, complex, and increasingly
recursive
environment.
*
But there is a deeper question: What are our minds made for? It looks as if we have the wrong user’s manual. Our minds do not seem made to think and introspect; if they were, things would be easier for us today, but then we would not be here today and I would not have been here to talk about it—my counterfactual, introspective, and hard-thinking ancestor would have been eaten by a lion while his nonthinking but faster-reacting cousin would have run for cover. Consider that thinking is time-consuming and generally a great waste of energy, that our predecessors spent more than a hundred million years as nonthinking mammals and that in the blip in our history during which we have used our brain we have used it on subjects too peripheral to matter. Evidence shows that we do much
less thinking than we believe we do—except, of course, when we think about it.


================================================================================
CHAPTER/SECTION 171 (Item 176)
================================================================================

A NEW KIND OF INGRATITUDE
It is quite saddening to think of those people who have been mistreated by history. There were the
poètes maudits
, like Edgar Allan Poe or Arthur Rimbaud, scorned by society and later worshipped and force-fed to schoolchildren. (There are even schools named after high school dropouts.) Alas, this recognition came a little too late for the poet to get a serotonin kick out of it, or to prop up his romantic life on earth. But there are even more mistreated heroes—the very sad category of those who we do not know were heroes, who saved our lives, who helped us avoid disasters. They left no traces and did not even know that they were making a contribution. We remember the martyrs who died for a cause that we knew about, never those no less effective in their contribution but whose cause we were never aware of—precisely because they were successful. Our ingratitude toward the
poètes maudits
fades completely in front of this other type of thanklessness. This is a far more vicious kind of ingratitude: the feeling of uselessness on the part of the silent hero. I will illustrate with the following thought experiment.
Assume that a legislator with courage, influence, intellect, vision, and perseverance manages to enact a law that goes into universal effect and employment on September 10, 2001; it imposes the continuously locked bulletproof doors in every cockpit (at high costs to the struggling airlines)—just in case terrorists decide to use planes to attack the World Trade Center in New York City. I know this is lunacy, but it is just a thought experiment (I am aware that there may be no such thing as a legislator with intellect, courage, vision, and perseverance; this is the point of the thought experiment). The legislation is not a popular measure among the airline personnel, as it complicates their lives. But it would certainly have prevented 9/11.
The person who imposed locks on cockpit doors gets no statues in public squares, not so much as a quick mention of his contribution in his obituary. “Joe Smith, who helped avoid the disaster of 9/11, died of complications of liver disease.” Seeing how superfluous his measure was, and how it squandered resources, the public, with great help from airline pilots, might well boot him out of office.
Vox clamantis in deserto
. He will
retire depressed, with a great sense of failure. He will die with the impression of having done nothing useful. I wish I could go attend his funeral, but, reader, I can’t find him. And yet, recognition can be quite a pump. Believe me, even those who genuinely claim that they do not believe in recognition, and that they separate labor from the fruits of labor, actually get a serotonin kick from it. See how the silent hero is rewarded: even his own hormonal system will conspire to offer no reward.
Now consider again the events of 9/11. In their aftermath, who got the recognition? Those you saw in the media, on television performing heroic acts, and those whom you saw trying to give you the impression that they were performing heroic acts. The latter category includes someone like the New York Stock Exchange chairman Richard Grasso, who “saved the stock exchange” and received a huge bonus for his contribution (the equivalent of several
thousand
average salaries). All he had to do was be there to ring the opening bell on television—the television that, we will see, is the carrier of unfairness and a major cause of Black Swan blindness.
Who gets rewarded, the central banker who avoids a recession or the one who comes to “correct” his predecessors’ faults and happens to be there during some economic recovery? Who is more valuable, the politician who avoids a war or the one who starts a new one (and is lucky enough to win)?
It is the same logic reversal we saw earlier with the value of what we don’t know; everybody knows that you need more prevention than treatment, but few reward acts of prevention. We glorify those who left their names in history books at the expense of those contributors about whom our books are silent. We humans are not just a superficial race (this may be curable to some extent); we are a very unfair one.


================================================================================
CHAPTER/SECTION 172 (Item 177)
================================================================================

LIFE IS VERY UNUSUAL
This is a book about uncertainty; to this author, the rare event
equals
uncertainty. This may seem like a strong statement—that we need to principally study the rare and extreme events in order to figure out common ones—but I will make myself clear as follows. There are two possible ways to approach phenomena. The first is to rule out the extraordinary and focus on the “normal.” The examiner leaves aside “outliers” and studies ordinary cases. The second approach is to consider that in order to understand a phenomenon, one needs first to consider the extremes—particularly
if, like the Black Swan, they carry an extraordinary cumulative effect.
I don’t particularly care about the usual. If you want to get an idea of a friend’s temperament, ethics, and personal elegance, you need to look at him under the tests of severe circumstances, not under the regular rosy glow of daily life. Can you assess the danger a criminal poses by examining only what he does on an
ordinary
day? Can we understand health without considering wild diseases and epidemics? Indeed the normal is often irrelevant.
Almost everything in social life is produced by rare but consequential shocks and jumps; all the while almost everything studied about social life focuses on the “normal,” particularly with “bell curve” methods of inference that tell you close to nothing. Why? Because the bell curve ignores large deviations, cannot handle them, yet makes us confident that we have tamed uncertainty. Its nickname in this book is GIF, Great Intellectual Fraud.


================================================================================
CHAPTER/SECTION 173 (Item 178)
================================================================================

PLATO AND THE NERD
At the start of the Jewish revolt in the first century of our era, much of the Jews’ anger was caused by the Romans’ insistence on putting a statue of Caligula in their temple in Jerusalem in exchange for placing a statue of the Jewish god Yahweh in Roman temples. The Romans did not realize that what the Jews (and the subsequent Levantine monotheists) meant by
god
was abstract, all embracing, and had nothing to do with the anthropomorphic, too human representation that Romans had in mind when they said
deus
. Critically, the Jewish god did not lend himself to symbolic representation. Likewise, what many people commoditize and label as “unknown,” “improbable,” or “uncertain” is not the same thing to me; it is not a concrete and precise category of knowledge, a
nerdified
field, but its opposite; it is the lack (and limitations) of knowledge. It is the exact contrary of knowledge; one should learn to avoid using terms made for knowledge to describe its opposite.
What I call
Platonicity
, after the ideas (and personality) of the philosopher Plato, is our tendency to mistake the map for the territory, to focus on pure and well-defined “forms,” whether objects, like triangles, or social notions, like utopias (societies built according to some blueprint of what “makes sense”), even nationalities. When these ideas and crisp constructs
inhabit our minds, we privilege them over other less elegant objects, those with messier and less tractable structures (an idea that I will elaborate progressively throughout this book).
Platonicity is what makes us think that we understand more than we actually do. But this does not happen everywhere. I am not saying that Platonic forms don’t exist. Models and constructions, these intellectual maps of reality, are not always wrong; they are wrong only in some specific applications. The difficulty is that a) you do not know beforehand (only after the fact)
where
the map will be wrong, and b) the mistakes can lead to severe consequences. These models are like potentially helpful medicines that carry random but very severe side effects.
The
Platonic fold
is the explosive boundary where the Platonic mind-set enters in contact with messy reality, where the gap between what you know and what you think you know becomes dangerously wide. It is here that the Black Swan is produced.


================================================================================
CHAPTER/SECTION 174 (Item 179)
================================================================================

TOO DULL TO WRITE ABOUT
It was said that the artistic filmmaker Luchino Visconti made sure that when actors pointed at a closed box meant to contain jewels, there were real jewels inside. It could be an effective way to make actors live their part. I think that Visconti’s gesture may also come out of a plain sense of aesthetics and a desire for authenticity—somehow it may not feel right to fool the viewer.
This is an essay expressing a primary idea; it is neither the recycling nor repackaging of other people’s thoughts. An essay is an impulsive meditation, not science reporting. I apologize if I skip a few obvious topics in this book out of the conviction that what is too dull for me to write about might be too dull for the reader to read. (Also, to avoid dullness may help to filter out the nonessential.)
Talk is cheap
. Someone who took too many philosophy classes in college (or perhaps not enough) might object that the sighting of a Black Swan does not invalidate the theory that
all swans are white
since such a black bird is not technically a swan since whiteness to him may be the essential property of a swan. Indeed those who read too much Wittgenstein (and writings about comments about Wittgenstein) may be under the impression that language problems are important. They may certainly be important to attain prominence in philosophy departments, but they are
something we, practitioners and decision makers in the real world,
leave for the weekend
. As I explain in the chapter called “The Uncertainty of the Phony,” for all of their intellectual appeal, these niceties have no serious implications Monday to Friday as opposed to more substantial (but neglected) matters. People in the classroom, not having faced many true situations of decision making under uncertainty, do not realize what is important and what is not—even those who are scholars of uncertainty (or
particularly
those who are scholars of uncertainty). What I call the practice of uncertainty can be piracy, commodity speculation, professional gambling, working in some branches of the Mafia, or just plain serial entrepreneurship. Thus I rail against “sterile skepticism,” the kind we can do nothing about, and against the exceedingly theoretical language problems that have made much of modern philosophy largely irrelevant to what is derisively called the “general public.” (In the past, for better or worse, those rare philosophers and thinkers who were not self-standing depended on a patron’s support. Today academics in abstract disciplines depend on one another’s opinion, without external checks, with the severe occasional pathological result of turning their pursuits into insular prowess-showing contests. Whatever the shortcomings of the old system, at least it enforced
some
standard of relevance.)
The philosopher Edna Ullmann-Margalit detected an inconsistency in this book and asked me to justify the use of the precise metaphor of a Black Swan to describe the unknown, the abstract, and imprecise uncertain—white ravens, pink elephants, or evaporating denizens of a remote planet orbiting Tau Ceti. Indeed, she caught me red handed. There is a contradiction; this book is a story, and I prefer to use stories and vignettes to illustrate our gullibility about stories and our preference for the dangerous compression of narratives.
*
You need a story to displace a story. Metaphors and stories are far more potent (alas) than ideas; they are also easier to remember and more fun to read. If I have to go after what I call the narrative disciplines, my best tool is a narrative.
Ideas come and go, stories stay.


================================================================================
CHAPTER/SECTION 175 (Item 180)
================================================================================

THE BOTTOM LINE
The beast in this book is not just the bell curve and the self-deceiving statistician, nor the Platonified scholar who needs theories to fool himself with. It is the drive to “focus” on what makes sense to us. Living on our planet, today, requires a lot more imagination than we are made to have. We lack imagination and repress it in others.
Note that I am not relying in this book on the beastly method of collecting selective “corroborating evidence.” For reasons I explain in
Chapter 5
, I call this overload of examples naïve empiricism—successions of anecdotes selected to fit a story do not constitute evidence. Anyone looking for confirmation will find enough of it to deceive himself—and no doubt his peers.
*
The Black Swan idea is based on the structure of randomness in empirical reality.
To summarize: in this (personal) essay, I stick my neck out and make a claim, against many of our habits of thought, that our world is dominated by the extreme, the unknown, and the very improbable (improbable according our current knowledge)—and all the while we spend our time engaged in small talk, focusing on the known, and the repeated. This implies the need to use the extreme event as a starting point and not treat it as an exception to be pushed under the rug. I also make the bolder (and more annoying) claim that in spite of our progress and the growth in knowledge, or perhaps
because
of such progress and growth, the future will be increasingly less predictable, while both human nature and social “science” seem to conspire to hide the idea from us.
Chapters Map
The sequence of this book follows a simple logic; it flows from what can be labeled purely literary (in subject and treatment) to what can be deemed entirely scientific (in subject, though not in treatment). Psychology will be mostly present in Part One and in the early part of Part Two; business and natural science will be dealt with mostly in the second half of Part Two and in Part Three. Part One, “Umberto Eco’s Antilibrary,” is mostly
about how we perceive historical and current events and what distortions are present in such perception. Part Two, “We Just Can’t Predict,” is about our errors in dealing with the future and the unadvertised limitations of some “sciences”—and what to do about these limitations. Part Three, “Those Gray Swans of Extremistan,” goes deeper into the topic of extreme events, explains how the bell curve (that great intellectual fraud) is generated, and reviews the ideas in the natural and social sciences loosely lumped under the label “complexity.” Part Four, “The End,” will be very short.
I derived an unexpected amount of enjoyment writing this book—in fact, it just wrote itself—and I hope that the reader will experience the same. I confess that I got hooked on this withdrawal into pure ideas after the constraints of an active and transactional life. After this book is published, my aim is to spend time away from the clutter of public activities in order to think about my philosophical-scientific idea in total tranquillity.
*
The spread of camera cell phones has afforded me a large collection of pictures of black swans sent by traveling readers. Last Christmas I also got a case of Black Swan Wine (not my favorite), a videotape (I don’t watch videos), and two books. I prefer the pictures.
†
I used the logical metaphor of the black swan (not capitalized) for Black Swan Events (capitalized), but this problem should not be confused with the logical problem raised by many philosophers. This is not so much about exceptions as it is about the oversize role of extreme events in many domains in life. Furthermore, the logical problem is about the possibility of the exception (black swan); mine is about the
role
of the exceptional event (Black Swan) leading to the degradation of predictability and the need to be robust to negative Black Swans and exposed to positive ones.
*
The highly expected
not happening
is also a Black Swan. Note that, by symmetry, the occurrence of a highly improbable event is the equivalent of the nonoccurrence of a highly probable one.
*
The Black Swan is the result of collective and individual epistemic limitations (or distortions), mostly confidence in knowledge; it is not an objective phenomenon. The most severe mistake made in the interpretation of my Black Swan is to try to define an “objective Black Swan” that would be invariant in the eyes of all observers. The events of September 11, 2001, were a Black Swan for the victims, but certainly not to the perpetrators. The Postscript provides an additional discussion of the point.
*
The Idea of Robustness: Why do we formulate theories leading to projections and forecasts without focusing on the robustness of these theories and the consequences of the errors? It is much easier to deal with the Black Swan problem if we focus on robustness to errors rather than improving predictions.
*
Recursive
here means that the world in which we live has an increasing number of feedback loops, causing events to be the cause of more events (say, people buy a book
because
other people bought it), thus generating snowballs and arbitrary and unpredictable planet-wide winner-take-all effects. We live in an environment where information flows too rapidly, accelerating such epidemics. Likewise, events can happen
because
they are not supposed to happen. (Our intuitions are made for an environment with simpler causes and effects and slowly moving information.) This type of randomness did not prevail during the Pleistocene, as socioeconomic life was far simpler then.
*
The metaphor of the black swan is not at all a modern one—contrary to its usual attribution to Popper, Mill, Hume, and others. I selected it because it corresponds to the ancient idea of a “rare bird.” The Latin poet Juvenal refers to a “bird as rare as the black swan”—
rara avis in terris nigroque simillima cygno
.
*
It is also naïve empiricism to provide, in support of some argument, series of eloquent confirmatory quotes by dead authorities. By searching, you can always find someone who made a well-sounding statement that confirms your point of view—and, on every topic, it is possible to find another dead thinker who said the exact opposite. Almost all of my non–Yogi Berra quotes are from people I disagree with.


================================================================================
CHAPTER/SECTION 176 (Item 181)
================================================================================

T
he writer Umberto Eco belongs to that small class of scholars who are encyclopedic, insightful, and nondull. He is the owner of a large personal library (containing thirty thousand books), and separates visitors into two categories: those who react with “Wow! Signore
professore dottore
Eco, what a library you have! How many of these books have you read?” and the others—a very small minority—who get the point that a private library is not an ego-boosting appendage but a research tool. Read books are far less valuable than unread ones. The library should contain as much of
what you do not know
as your financial means, mortgage rates, and the currently tight real-estate market allow you to put there. You will accumulate more knowledge and more books as you grow older, and the growing number of unread books on the shelves will look at you menacingly. Indeed, the more you know, the larger the rows of unread books. Let us call this collection of unread books an
antilibrary
.
We tend to treat our knowledge as personal property to be protected and defended. It is an ornament that allows us to rise in the pecking order. So this tendency to offend Eco’s library sensibility by focusing on the known is a human bias that extends to our mental operations. People don’t walk around with anti-résumés telling you what they have not studied or experienced (it’s the job of their competitors to do that), but it would be nice if they did. Just as we need to stand library logic on its head, we will work on standing knowledge itself on its head. Note that the Black
Swan comes from our misunderstanding of the likelihood of surprises, those unread books, because we take what we know a little too seriously.
Let us call an antischolar—someone who focuses on the unread books, and makes an attempt not to treat his knowledge as a treasure, or even a possession, or even a self-esteem enhancement device—a skeptical empiricist.
The chapters in this section address the question of how we humans deal with knowledge—and our preference for the anecdotal over the empirical.
Chapter 1
presents the Black Swan as grounded in the story of my own obsession. I will make a central distinction between the two varieties of randomness in
Chapter 3
. After that,
Chapter 4
briefly returns to the Black Swan problem in its original form: how we tend to generalize from what we see. Then I present the three facets of the same Black Swan problem: a)
The error of confirmation
, or how we are likely to undeservedly scorn the virgin part of the library (the tendency to look at what confirms our knowledge, not our ignorance), in
Chapter 5
; b)
the narrative fallacy
, or how we fool ourselves with stories and anecdotes (
Chapter 6
); c) how emotions get in the way of our inference (
Chapter 7
); and d)
the problem of silent evidence
, or the tricks history uses to hide Black Swans from us (
Chapter 8
).
Chapter 9
discusses the lethal fallacy of building knowledge from the world of games.


================================================================================
CHAPTER/SECTION 177 (Item 182)
================================================================================

Chapter One
THE APPRENTICESHIP OF AN EMPIRICAL SKEPTIC
Anatomy of a Black Swan—The triplet of opacity—Reading books backward—The rearview mirror—Everything becomes explainable—Always talk to the driver (with caution)—History doesn’t crawl; it jumps—“It was so unexpected”—Sleeping for twelve hours
This is not an autobiography, so I will skip the scenes of war. Actually, even if it were an autobiography, I would still skip the scenes of war. I cannot compete with action movies or memoirs of adventurers more accomplished than myself, so I will stick to my specialties of chance and uncertainty.


================================================================================
CHAPTER/SECTION 178 (Item 183)
================================================================================

ANATOMY OF A BLACK SWAN
For more than a millennium the eastern Mediterranean seaboard called Syria Libanensis, or Mount Lebanon, had been able to accommodate at least a dozen different sects, ethnicities, and beliefs—it worked like magic. The place resembled major cities of the eastern Mediterranean (called the Levant) more than it did the other parts in the interior of the Near East (it was easier to move by ship than by land through the mountainous terrain). The Levantine cities were mercantile in nature; people dealt with one another according to a clear protocol, preserving a peace conducive
to commerce, and they socialized quite a bit across communities. This millennium of peace was interrupted only by small occasional friction
within
Moslem and Christian communities, rarely between Christians and Moslems. While the cities were mercantile and mostly Hellenistic, the mountains had been settled by all manner of religious minorities who claimed to have fled both the Byzantine and Moslem orthodoxies. A mountainous terrain is an ideal refuge from the mainstream, except that your enemy is the other refugee competing for the same type of rugged real estate. The mosaic of cultures and religions there was deemed an example of coexistence: Christians of all varieties (Maronites, Armenians, Greco-Syrian Byzantine Orthodox, even Byzantine Catholic, in addition to the few Roman Catholics left over from the Crusades); Moslems (Shiite and Sunni); Druzes; and a few Jews. It was taken for granted that people learned to be tolerant there; I recall how we were taught in school how far more civilized and wiser we were than those in the Balkan communities, where not only did the locals refrain from bathing but also fell prey to fractious fighting. Things appeared to be in a state of stable equilibrium, evolving out of a historical tendency for betterment and tolerance. The terms
balance
and
equilibrium
were often used.
Both sides of my family came from the Greco-Syrian community, the last Byzantine outpost in northern Syria, which included what is now called Lebanon. Note that the Byzantines called themselves “Romans”—
Roumi
(plural
Roum)
in the local languages. We originate from the olive-growing area at the base of Mount Lebanon—we chased the Maronite Christians into the mountains in the famous battle of Amioun, my ancestral village. Since the Arab invasion in the seventh century, we had been living in mercantile peace with the Moslems, with only some occasional harassment by the Lebanese Maronite Christians from the mountains. By some (literally) Byzantine arrangement between the Arab rulers and the Byzantine emperors, we managed to pay taxes to both sides and get protection from both. We thus managed to live in peace for more than a millennium almost devoid of bloodshed: our last true problem was the later troublemaking crusaders, not the Moslem Arabs. The Arabs, who seemed interested only in warfare (and poetry) and, later, the Ottoman Turks, who seemed only concerned with warfare (and pleasure), left to us the uninteresting pursuit of commerce and the less dangerous one of scholarship (like the translation of Aramaic and Greek texts).
By any standard the country called Lebanon, to which we found ourselves suddenly incorporated after the fall of the Ottoman Empire, in the
early twentieth century, appeared to be a stable paradise; it was also cut in a way to be predominantly Christian. People were suddenly brainwashed to believe in the nation-state as an entity.
*
The Christians convinced themselves that they were at the origin and center of what is loosely called Western culture yet with a window on the East. In a classical case of static thinking, nobody took into account the differentials in birthrate between communities and it was assumed that a slight Christian majority would remain permanent. Levantines had been granted Roman citizenship, which allowed Saint Paul, a Syrian, to travel freely through the ancient world. People felt connected to everything they felt was worth connecting to; the place was exceedingly open to the world, with a vastly sophisticated lifestyle, a prosperous economy, and temperate weather just like California, with snow-covered mountains jutting above the Mediterranean. It attracted a collection of spies (both Soviet and Western), prostitutes (blondes), writers, poets, drug dealers, adventurers, compulsive gamblers, tennis players, après-skiers, and merchants—all professions that complement one another. Many people acted as if they were in an old James Bond movie, or the days when playboys smoked, drank, and, instead of going to the gym, cultivated relationships with good tailors.
The main attribute of paradise was there: cabdrivers were said to be polite (though, from what I remember, they were not polite to me). True, with hindsight, the place may appear more Elysian in the memory of people than it actually was.
I was too young to taste the pleasures of the place, as I became a rebellious idealist and, very early on, developed an ascetic taste, averse to the ostentatious signaling of wealth, allergic to Levantine culture’s overt pursuit of luxury and its obsession with things monetary.
As a teenager, I could not wait to go settle in a metropolis with fewer James Bond types around. Yet I recall something that felt special in the intellectual air. I attended the French lycée that had one of the highest success rates for the French
baccalauréat
(the high school degree), even in the subject of the French language. French was spoken there with some purity: as in prerevolutionary Russia, the Levantine Christian and Jewish patrician class (from Istanbul to Alexandria) spoke and wrote formal French as a language of distinction. The most privileged were sent to school in
France, as both my grandfathers were—my paternal namesake in 1912 and my mother’s father in 1929. Two thousand years earlier, by the same instinct of linguistic distinction, the snobbish Levantine patricians wrote in Greek, not the vernacular Aramaic. (The New Testament was written in the bad local patrician Greek of our capital, Antioch, prompting Nietzsche to shout that “God spoke bad Greek.”) And, after Hellenism declined, they took up Arabic. So in addition to being called a “paradise,” the place was also said to be a miraculous crossroads of what are superficially tagged “Eastern” and “Western” cultures.
On Walking Walks
My ethos was shaped when, at fifteen, I was put in jail for (allegedly) attacking a policeman with a slab of concrete during a student riot—an incident with strange ramifications since my grandfather was then the minister of the interior, and the person who signed the order to crush our revolt. One of the rioters was shot dead when a policeman who had been hit on the head with a stone panicked and randomly opened fire on us. I recall being at the center of the riot, and feeling a huge satisfaction upon my capture while my friends were scared of both prison and their parents. We frightened the government so much that we were granted amnesty.
There were some obvious benefits in showing one’s ability to act on one’s opinions, and not compromising an inch to avoid “offending” or bothering others. I was in a state of rage and didn’t care what my parents (and grandfather) thought of me. This made them quite scared of
me
, so I could not afford to back down, or even blink. Had I concealed my participation in the riot (as many friends did) and been discovered, instead of being openly defiant, I am certain that I would have been treated as a black sheep. It is one thing to be cosmetically defiant of authority by wearing unconventional clothes—what social scientists and economists call “cheap signaling”—and another to prove willingness to translate belief into action.
My paternal uncle was not too bothered by my political ideas (these come and go); he was outraged that I used them as an excuse to dress sloppily. To him, inelegance on the part of a close family member was the mortal offense.
Public knowledge of my capture had another major benefit: it allowed me to avoid the usual outward signs of teenage rebellion. I discovered that
it is much more effective to act like a nice guy and be “reasonable” if you prove willing to go beyond just verbiage. You can afford to be compassionate, lax, and courteous if, once in a while, when it is least expected of you, but completely justified, you sue someone, or savage an enemy, just to show that you can walk the walk.
“Paradise” Evaporated
The Lebanese “paradise” suddenly evaporated, after a few bullets and mortar shells. A few months after my jail episode, after close to thirteen centuries of remarkable ethnic coexistence, a Black Swan, coming out of nowhere, transformed the place from heaven to hell. A fierce civil war began between Christians and Moslems, including the Palestinian refugees who took the Moslem side. It was brutal, since the combat zones were in the center of the town and most of the fighting took place in residential areas (my high school was only a few hundred feet from the war zone). The conflict lasted more than a decade and a half. I will not get too descriptive. It may be that the invention of gunfire and powerful weapons turned what, in the age of the sword, would have been just tense conditions into a spiral of uncontrollable tit-for-tat warfare.
Aside from the physical destruction (which turned out to be easy to reverse with a few motivated contractors, bribed politicians, and naïve bondholders), the war removed much of the crust of sophistication that had made the Levantine cities a continuous center of great intellectual refinement for three thousand years. Christians had been leaving the area since Ottoman times—those who moved to the West took Western first names and melded in. Their exodus accelerated. The number of cultured people dropped below some critical level. Suddenly the place became a vacuum. Brain drain is hard to reverse, and some of the old refinement may be lost forever.
The Starred Night
The next time you experience a blackout, take some solace by looking at the sky. You will not recognize it. Beirut had frequent power shutdowns during the war. Before people bought their own generators, one side of the sky was clear at night, owing to the absence of light pollution. That was the side of town farthest from the combat zone. People deprived of television
drove to watch the erupting lights of nighttime battles. They appeared to prefer the risk of being blown up by mortar shells to the boredom of a dull evening.
So you could see the stars with great clarity. I had been told in high school that the planets are in something called
equilibrium
, so we did not have to worry about the stars hitting us unexpectedly. To me, that eerily resembled the stories we were also told about the “unique historical stability” of Lebanon. The very idea of assumed equilibrium bothered me. I looked at the constellations in the sky and did not know what to believe.


================================================================================
CHAPTER/SECTION 179 (Item 184)
================================================================================

HISTORY AND THE TRIPLET OF OPACITY
History is opaque. You see what comes out, not the script that produces events, the generator of history. There is a fundamental incompleteness in your grasp of such events, since you do not see what’s inside the box, how the mechanisms work. What I call the generator of historical events is different from the events themselves, much as the minds of the gods cannot be read just by witnessing their deeds. You are very likely to be fooled about their intentions.
This disconnect is similar to the difference between the food you see on the table at the restaurant and the process you can observe in the kitchen. (The last time I brunched at a certain Chinese restaurant on Canal Street in downtown Manhattan, I saw a rat coming out of the kitchen.)
The human mind suffers from three ailments as it comes into contact with history, what I call the
triplet of opacity
. They are:
the illusion of understanding, or how everyone thinks he knows what is going on in a world that is more complicated (or random) than they realize;
the retrospective distortion, or how we can assess matters only after the fact, as if they were in a rearview mirror (history seems clearer and more organized in history books than in empirical reality); and
the overvaluation of factual information and the handicap of authoritative and learned people, particularly when they create categories—when they “Platonify.”
Nobody Knows What’s Going On
The first leg of the triplet is the pathology of thinking that the world in which we live is more understandable, more explainable, and therefore more predictable than it actually is.
I was constantly told by adults that the war, which ended up lasting close to seventeen years, was going to end in “only a matter of days.” They seemed quite confident in their forecasts of duration, as can be evidenced by the number of people who sat waiting in hotel rooms and other temporary quarters in Cyprus, Greece, France, and elsewhere for the war to finish. One uncle kept telling me how, some thirty years earlier, when the rich Palestinians fled to Lebanon, they considered it a
very temporary
solution (most of those still alive are still there, six decades later). Yet when I asked him if it was going to be the same with our conflict, he replied, “No, of course not. This place is different; it has always been different.” Somehow what he detected in others did not seem to apply to him.
This duration blindness in the middle-aged exile is quite a widespread disease. Later, when I decided to avoid the exile’s obsession with his roots (exiles’ roots penetrate their personalities a bit too deeply), I studied exile literature precisely to avoid the traps of a consuming and obsessive nostalgia. These exiles seemed to have become prisoners of their memory of idyllic origin—they sat together with other prisoners of the past and spoke about the old country, and ate their traditional food while some of their folk music played in the background. They continuously ran counterfactuals in their minds, generating alternative scenarios that could have happened and prevented these historical ruptures, such as “if the Shah had not named this incompetent man as prime minister, we would still be there.” It was as if the historical rupture had a specific cause, and that the catastrophe could have been averted by removing
that
specific cause. So I pumped every displaced person I could find for information on their behavior during exile. Almost all act in the same way.
One hears endless stories of Cuban refugees with suitcases still half packed who came to Miami in the 1960s for “a matter of a few days” after the installation of the Castro regime. And of Iranian refugees in Paris and London who fled the Islamic Republic in 1978 thinking that their absence would be a brief vacation. A few are still waiting, more than a quarter century later, for the return. Many Russians who left in 1917, such as
the writer Vladimir Nabokov, settled in Berlin, perhaps to be close enough for a quick return. Nabokov himself lived all his life in temporary housing, in both indigence and luxury, ending his days at the Montreux Palace hotel on Lake Geneva.
There was, of course, some wishful thinking in all of these forecasting errors, the blindness of hope, but there was a knowledge problem as well. The dynamics of the Lebanese conflict had been patently unpredictable, yet people’s reasoning as they examined the events showed a constant: almost all those who cared seemed convinced that they understood what was going on. Every single day brought occurrences that lay completely outside their forecast, but they could not figure out that they had not forecast them. Much of what took place would have been deemed completely crazy with respect to the past. Yet it did not seem that crazy
after
the events. This retrospective plausibility causes a discounting of the rarity and conceivability of the event. I later saw the exact same illusion of understanding in business success and the financial markets.
History Does Not Crawl, It Jumps
Later, upon replaying the wartime events in my memory as I formulated my ideas on the perception of random events, I developed the governing impression that our minds are wonderful explanation machines, capable of making sense out of almost anything, capable of mounting explanations for all manner of phenomena, and generally incapable of accepting the idea of unpredictability. These events were unexplainable, but intelligent people thought they were capable of providing convincing explanations for them—after the fact. Furthermore, the more intelligent the person, the better sounding the explanation. What’s more worrisome is that all these beliefs and accounts appeared to be logically coherent and devoid of inconsistencies.
So I left the place called Lebanon as a teenager, but, since a large number of my relatives and friends remained there, I kept coming back to visit, especially during the hostilities. The war was not continuous: there were periods of fighting interrupted by “permanent” solutions. I felt closer to my roots during times of trouble and experienced the urge to come back and show support to those left behind who were often demoralized by the departures—and envious of the fair-weather friends who could seek economic and personal safety only to return for vacations during these occasional lulls in the conflict. I was unable to work or read when I was
outside Lebanon while people were dying, but, paradoxically, I was less concerned by the events and able to pursue my intellectual interests guilt-free when I was
inside
Lebanon. Interestingly, people partied quite heavily during the war and developed an even bigger taste for luxuries, making the visits quite attractive in spite of the fighting.
There were a few difficult questions. How could one have predicted that people who seemed a model of tolerance could become the purest of barbarians overnight? Why was the change so abrupt? I initially thought that perhaps the Lebanese war was truly not possible to predict, unlike other conflicts, and that the Levantines were too complicated a race to figure out. Later I slowly realized, as I started to consider all the big events in history, that their irregularity was not a local property.
The Levant has been something of a mass producer of consequential events nobody saw coming. Who predicted the rise of Christianity as a dominant religion in the Mediterranean basin, and later in the Western world? The Roman chroniclers of that period did not even take note of the new religion—historians of Christianity are baffled by the absence of contemporary mentions. Apparently, few of the big guns took the ideas of a seemingly heretical Jew seriously enough to think that he would leave traces for posterity. We only have a single contemporary reference to Jesus of Nazareth—in
The Jewish Wars
of Josephus—which itself may have been added later by a devout copyist. How about the competing religion that emerged seven centuries later; who forecast that a collection of horsemen would spread their empire and Islamic law from the Indian subcontinent to Spain in just a few years? Even more than the rise of Christianity, it was the spread of Islam (the third edition, so to speak) that carried full unpredictability; many historians looking at the record have been taken aback by the swiftness of the change. Georges Duby, for one, expressed his amazement about how quickly close to ten centuries of Levantine Hellenism were blotted out “with a strike of a sword.” A later holder of the same history chair at the Collège de France, Paul Veyne, aptly talked about religions spreading “like bestsellers”—a comparison that indicates unpredictability. These kinds of discontinuities in the chronology of events did not make the historian’s profession too easy: the studious examination of the past in the greatest of detail does not teach you much about the mind of History; it only gives you the illusion of understanding it.
History and societies do not crawl. They make jumps. They go from fracture to fracture, with a few vibrations in between. Yet we (and historians) like to believe in the predictable, small incremental progression.
It struck me, a belief that has never left me since, that we are just a great machine for looking backward, and that humans are great at self-delusion. Every year that goes by increases my belief in this distortion.
Dear Diary: On History Running Backward
Events present themselves to us in a distorted way. Consider the nature of information: of the millions, maybe even trillions, of small facts that prevail before an event occurs, only a few will turn out to be relevant later to your understanding of what happened. Because your memory is limited and filtered, you will be inclined to remember those data that subsequently match the facts, unless you are like the eponymous Funes in the short story by Jorge Luis Borges, “Funes, the Memorious,” who forgets nothing and seems condemned to live with the burden of the accumulation of unprocessed information. (He does not manage to live too long.)
I had my first exposure to the retrospective distortion as follows. During my childhood I had been a voracious, if unsteady, reader, but I spent the first phase of the war in a basement, diving body and soul into all manner of books. School was closed and it was raining mortar shells. It is dreadfully boring to be in basements. My initial worries were mostly about how to fight boredom and what to read next
*
—though being forced to read for lack of other activities is not as enjoyable as reading out of one’s own volition. I wanted to be a philosopher (I still do), so I felt that I needed to make an investment by forcibly studying others’ ideas. Circumstances motivated me to study theoretical and general accounts of wars and conflicts, trying to get into the guts of History, to get into the workings of that big machine that generates events.
Surprisingly, the book that influenced me was not written by someone in the thinking business but by a journalist: William Shirer’s
Berlin Diary: The Journal of a Foreign Correspondent, 1934–1941
. Shirer was a radio correspondent, famous for his book
The Rise and Fall of the Third Reich
. It occurred to me that the
Journal
offered an unusual perspective. I had already read (or read about) the works of Hegel, Marx, Toynbee, Aron, and Fichte on the philosophy of history and its properties and thought that I had a vague idea of the notions of dialectics, to the extent that there was
something to understand in these theories. I did not grasp much, except that history had some logic and that things developed through contradiction (or opposites) in a way that elevated mankind into higher forms of society—that kind of thing. This sounded awfully similar to the theorizing around me about the war in Lebanon. To this day I surprise people who put the ludicrous question to me about what books “shaped my thinking” by telling them that this book taught me (albeit inadvertently) the most about philosophy and theoretical history—and, we will see, about science as well, since I learned the difference between forward and backward processes.
How? Simply, the diary purported to describe the events
as they were taking place
, not after. I was in a basement with history audibly unfolding above me (the sound of mortar shells kept me up all night). I was a teenager attending the funerals of classmates. I was experiencing a nontheoretical unfolding of History and I was reading about someone apparently experiencing history as it went along. I made efforts to mentally produce a movielike representation of the future and realized it was not so obvious. I realized that if I were to start writing about the events later they would seem more …
historical
. There was a difference between the
before
and the
after
.
The journal was purportedly written without Shirer knowing what was going to happen next, when the information available to him was not corrupted by the subsequent outcomes. Some comments here and there were quite illuminating, particularly those concerning the French belief that Hitler was a transitory phenomenon, which explained their lack of preparation and subsequent rapid capitulation. At no time was the extent of the ultimate devastation deemed possible.
While we have a highly unstable memory, a diary provides indelible facts recorded more or less immediately; it thus allows the fixation of an unrevised perception and enables us to later study events in their own context. Again, it is the purported method of description of the event, not its execution, that was important. In fact, it is likely that Shirer and his editors did some cheating, since the book was published in 1941 and publishers, I am told, are in the business of delivering texts to the general public instead of providing faithful depictions of the authors’ mind-sets stripped of retrospective distortions. (By “cheating,” I mean removing at the time of publication elements that did not turn out to be relevant to what happened, thus enhancing those that may interest the public. Indeed the editing process can be severely distorting, particularly
when the author is assigned what is called a “good editor.”) Still, encountering Shirer’s book provided me with an intuition about the workings of history. One would suppose that people living through the beginning of WWII had an inkling that something momentous was taking place. Not at all.
*
Shirer’s diary turned out to be a training program in the dynamics of uncertainty. I wanted to be a philosopher, not knowing at the time what most professional philosophers did for a living. The idea led me to adventure (rather to the adventurous practice of uncertainty) and also to mathematical and scientific pursuits instead.
Education in a Taxicab
I will introduce the third element of the triplet, the curse of learning, as follows. I closely watched my grandfather, who was minister of defense, and later minister of the interior and deputy prime minister in the early days of the war, before the fading of his political role. In spite of his position he did not seem to know what was going to happen any more than did his driver, Mikhail. But unlike my grandfather, Mikhail used to repeat “God knows” as his main commentary on events, transferring the task of understanding higher up.
I noticed that very intelligent and informed persons were at no advantage over cabdrivers in their predictions, but there was a crucial difference. Cabdrivers did not believe that they understood as much as learned people—really, they were not the experts and they knew it. Nobody knew anything, but elite thinkers thought that they knew more than the rest because they were elite thinkers, and if you’re a member of the elite, you automatically know more than the nonelite.
It is not just knowledge but information that can be of dubious value. It came to my notice that almost everybody was acquainted with current events in their smallest details. The overlap between newspapers was so
large that you would get less and less information the more you read. Yet everyone was so eager to become familiar with every fact that they read every freshly printed document and listened to every radio station as if the great answer was going to be revealed to them in the next bulletin. People became encyclopedias of who had met with whom and which politician said what to which other politician (and with what tone of voice: “Was he more friendly than usual?”). Yet to no avail.


================================================================================
CHAPTER/SECTION 180 (Item 185)
================================================================================

CLUSTERS
I also noticed during the Lebanese war that journalists tended to cluster not necessarily around the same opinions but frequently around the same framework of analyses. They assign the same importance to the same sets of circumstances and cut reality into the same categories—once again the manifestation of Platonicity, the desire to cut reality into crisp shapes. What Robert Fisk calls “hotel journalism” further increased the mental contagion. While Lebanon in earlier journalism was part of the Levant, i.e., the eastern Mediterranean, it now suddenly became part of the Middle East, as if someone had managed to transport it closer to the sands of Saudi Arabia. The island of Cyprus, around sixty miles from my village in northern Lebanon, and with almost identical food, churches, and habits, suddenly became part of Europe (of course the natives on both sides became subsequently conditioned). While in the past a distinction had been drawn between Mediterranean and non-Mediterranean (i.e., between the olive oil and the butter), in the 1970s the distinction suddenly became that between Europe and non-Europe. Islam being the wedge between the two, one does not know where to place the indigenous Arabic-speaking Christians (or Jews) in that story. Categorizing is necessary for humans, but it becomes pathological when the category is seen as definitive, preventing people from considering the fuzziness of boundaries, let alone revising their categories. Contagion was the culprit. If you selected one hundred independent-minded journalists capable of seeing factors in isolation from one another, you would get one hundred different opinions. But the process of having these people report in lockstep caused the dimensionality of the opinion set to shrink considerably—they converged on opinions and used the same items as causes. For instance, to depart from Lebanon for a moment, all reporters now refer to the “roaring eighties,” assuming that there was something particularly distinct about that exact decade. And during the Internet bubble of the late 1990s, journalists agreed on
crazy indicators as explanatory of the quality of worthless companies that everyone wanted very badly.
*
If you want to see what I mean by the arbitrariness of categories, check the situation of polarized politics. The next time a Martian visits earth, try to explain to him why those who favor allowing the elimination of a fetus in the mother’s womb also oppose capital punishment. Or try to explain to him why those who accept abortion are supposed to be favorable to high taxation but against a strong military. Why do those who prefer sexual freedom need to be against individual economic liberty?
I noticed the absurdity of clustering when I was quite young. By some farcical turn of events, in that civil war of Lebanon, Christians became pro-free market and the capitalistic system—i.e., what a journalist would call “the Right”—and the Islamists became socialists, getting support from Communist regimes
(Pravda
, the organ of the Communist regime, called them “oppression fighters,” though subsequently when the Russians invaded Afghanistan, it was the Americans who sought association with bin Laden and his Moslem peers).
The best way to prove the arbitrary character of these categories, and the contagion effect they produce, is to remember how frequently these clusters reverse in history. Today’s alliance between Christian fundamentalists and the Israeli lobby would certainly seem puzzling to a nineteenth-century intellectual—Christians used to be anti-Semites and Moslems were the protectors of the Jews, whom they preferred to Christians. Libertarians used to be left-wing. What is interesting to me as a probabilist is that some random event makes one group that initially supports an issue ally itself with another group that supports another issue, thus causing the two items to fuse and unify … until the surprise of the separation.
Categorizing always produces reduction in true complexity. It is a manifestation of the Black Swan generator, that unshakable Platonicity that I defined in the Prologue. Any reduction of the world around us can have explosive consequences since it rules out some sources of uncertainty; it drives us to a misunderstanding of the fabric of the world. For instance, you may think that radical Islam (and its values) are your allies against the threat of Communism, and so you may help them develop, until they send two planes into downtown Manhattan.
It was a few years after the beginning of the Lebanese war, as I was attending the Wharton School, at the age of twenty-two, that I was hit with the idea of efficient markets—an idea that holds that there is no way to derive profits from traded securities since these instruments have automatically incorporated all the available information. Public information can therefore be useless, particularly to a businessman, since prices can already “include” all such information, and news shared with millions gives you no real advantage. Odds are that one or more of the hundreds of millions of other readers of such information will already have bought the security, thus pushing up the price. I then completely gave up reading newspapers and watching television, which freed up a considerable amount of time (say one hour or more a day, enough time to read more than a hundred additional books per year, which, after a couple of decades, starts mounting). But this argument was not quite the entire reason for my dictum in this book to avoid the newspapers, as we will see further benefits in avoiding the toxicity of information. It was initially a great excuse to avoid keeping up with the minutiae of business, a perfect alibi since I found nothing interesting about the details of the business world—inelegant, dull, pompous, greedy, unintellectual, selfish, and boring.
Where Is the Show?
Why someone with plans to become a “philosopher” or a “scientific philosopher of history” would wind up in business school, and the Wharton School no less, still escapes me. There I saw that it was not merely some inconsequential politician in a small and antique country (and his philosophical driver Mikhail) who did not know what was going on. After all, people in small countries are supposed to
not know
what is going on. What I saw was that in one of the most prestigious business schools in the world, in the most potent country in the history of the world, the executives of the most powerful corporations were coming to describe what they did for a living, and it was possible that they too did not know what was going on. As a matter of fact, in my mind it was far more than a possibility. I felt in my spine the weight of the epistemic arrogance of the human race.
*
I became obsessive. At the time, I started becoming conscious of my
subject—the
highly improbable consequential event
. And it was not only well-dressed, testosterone-charged corporate executives who were usually fooled by this concentrated luck, but persons of great learning. This awareness turned my Black Swan from a problem of lucky or unlucky people in business into a problem of knowledge and science. My idea is that not only are some scientific results useless in real life, because they underestimate the impact of the highly improbable (or lead us to ignore it), but that many of them may be actually creating Black Swans. These are not just taxonomic errors that can make you flunk a class in ornithology. I started to see the consequences of the idea.


================================================================================
CHAPTER/SECTION 181 (Item 186)
================================================================================

8¾
LBS LATER
Four and a half years after my graduation from Wharton (and 8¾ pounds heavier), on October 19, 1987, I walked home from the offices of the investment bank Credit Suisse First Boston in Midtown Manhattan to the Upper East Side. I walked slowly, as I was in a bewildered state.
That day saw a traumatic financial event: the largest market drop in (modern) history. It was all the more traumatic in that it took place at a time when we thought we had become sufficiently sophisticated with all these intelligent-talking Platonified economists (with their phony bell curve-based equations) to prevent, or at least forecast and control, big shocks. The drop was not even the response to any discernible news. The occurrence of the event lay outside anything one could have imagined on the previous day—had I pointed out its possibility, I would have been called a lunatic. It qualified as a Black Swan, but I did not know the expression then.
I ran into a colleague of mine, Demetrius, on Park Avenue, and, as I started talking to him, an anxiety-ridden woman, losing all inhibitions, jumped into the conversation: “Hey, do the two of you know what’s going on?” People on the sidewalk looked dazed. Earlier I had seen a few adults silently sobbing in the trading room of First Boston. I had spent the day at the epicenter of the events, with shell-shocked people running around like rabbits in front of headlights. When I got home, my cousin Alexis called to tell me that his neighbor committed suicide, jumping from his upper-floor apartment. It did not even feel eerie. It felt like Lebanon, with a twist: having seen both, I was struck that financial distress could be more demoralizing than war (just consider that financial problems and the accompanying
humiliations can lead to suicide, but war doesn’t appear to do so directly).
I feared a Pyrrhic victory: I had been vindicated intellectually, but I was afraid of being too right and seeing the system crumble under my feet. I did not really want to be
that
right. I will always remember the late Jimmy P. who, seeing his net worth in the process of melting down, kept half-jokingly begging the price on the screen to stop moving.
But I realized then and there that I did not give a hoot about the money. I experienced the strangest feeling I have ever had in my life, this deafening trumpet signaling to me that
I was right
, so loudly that it made my bones vibrate. I have never had it since and will never be able to explain it to those who have never experienced it. It was a physical sensation, perhaps a mixture of joy, pride, and terror.
And I felt vindicated? How?
During the one or two years after my arrival at Wharton, I had developed a precise but strange specialty: betting on rare and unexpected events, those that were on the
Platonic fold
, and considered “inconceivable” by the Platonic “experts.” Recall that the Platonic fold is where our representation of reality ceases to apply—but we do not know it.
For I was early to embrace, as a day job, the profession of “quantitative finance.” I became a “quant” and trader at the same time—a quant is a brand of industrial scientist who applies mathematical models of uncertainty to financial (or socioeconomic) data and complex financial instruments. Except that I was a quant exactly in reverse: I studied the flaws and the limits of these models, looking for the
Platonic fold
where they break down. Also I engaged in speculative trading, not “just tawk,” which was rare for quants since they were prevented from “taking risks,” their role being confined to analysis, not decision making. I was convinced that I was totally incompetent in predicting market prices—but that others were generally incompetent also but did not know it, or did not know that they were taking massive risks. Most traders were just “picking pennies in front of a streamroller,” exposing themselves to the high-impact rare event yet sleeping like babies, unaware of it. Mine was the only job you could do if you thought of yourself as risk-hating, risk-aware, and highly ignorant.
Also, the technical baggage that comes with being a quant (a mixture of applied mathematics, engineering, and statistics), in addition to the immersion in practice, turned out to be very useful for someone wanting to
be a philosopher.
*
First, when you spend a couple of decades doing mass-scale empirical work with data and taking risks based on such studies, you can easily spot elements in the texture of the world that the Platonified “thinker” is too brainwashed, or threatened, to see. Second, it allowed me to become formal and systematic in my thinking instead of wallowing in the anecdotal. Finally, both the philosophy of history and epistemology (the philosophy of knowledge) seemed inseparable from the empirical study of times series data, which is a succession of numbers in time, a sort of historical document containing numbers instead of words. And numbers are easy to process on computers. Studying historical data makes you conscious that history runs forward, not backward, and that it is messier than narrated accounts. Epistemology, the philosophy of history, and statistics aim at understanding truths, investigating the mechanisms that generate them, and separating regularity from the coincidental in historical matters. They all address the question of what one knows, except that they are all to be found in different buildings, so to speak.
The Four-Letter Word of Independence
That night, on October 19, 1987, I slept for twelve hours straight.
It was hard to tell my friends, all hurt in some manner by the crash, about this feeling of vindication. Bonuses at the time were a fraction of what they are today, but if my employer, First Boston, and the financial system survived until year-end, I would get the equivalent of a fellowship. This is sometimes called “f*** you money,” which, in spite of its coarseness, means that it allows you to act like a Victorian gentleman, free from slavery. It is a psychological buffer: the capital is not so large as to make you spoiled-rich, but large enough to give you the freedom to choose a
new occupation without excessive consideration of the financial rewards. It shields you from prostituting your mind and frees you from outside authority—any outside authority. (Independence is person-specific: I have always been taken aback at the high number of people in whom an astonishingly high income led to additional sycophancy as they became more dependent on their clients and employers and more addicted to making even more money.) While not substantial by some standards, it literally cured me of all financial ambition—it made me feel ashamed whenever I diverted time away from study for the pursuit of material wealth. Note that the designation
f*** you
corresponds to the exhilarating ability to pronounce that compact phrase
before
hanging up the phone.
These were the days when it was extremely common for traders to break phones when they lost money. Some resorted to destroying chairs, tables, or whatever would make noise. Once, in the Chicago pits, another trader tried to strangle me and it took four security guards to drag him away. He was irate because I was standing in what he deemed his “territory.” Who would want to leave such an environment? Compare it to lunches in a drab university cafeteria with gentle-mannered professors discussing the latest departmental intrigue. So I stayed in the quant and trading businesses (I’m still there), but organized myself to do minimal but intense (and entertaining) work, focus only on the most technical aspects, never attend business “meetings,” avoid the company of “achievers” and people in suits who don’t read books, and take a sabbatical year for every three on average to fill up gaps in my scientific and philosophical culture. To slowly distill my single idea, I wanted to become a flâneur, a professional meditator, sit in cafés, lounge, unglued to desks and organization structures, sleep as long as I needed, read voraciously, and not owe any explanation to anybody. I wanted to be left alone in order to build, small steps at a time, an entire system of thought based on my Black Swan idea.
Limousine Philosopher
The war in Lebanon and the crash of 1987 seemed identical phenomena. It became obvious to me that nearly everyone had a mental blindspot in acknowledging the role of such events: it was as if they were not able to see these mammoths, or that they rapidly forgot about them. The answer was looking straight at me: it was a psychological, perhaps even biological,
blindness;
the problem lay not in the nature of events, but in the way we perceived them.
I end this autobiographical prelude with the following story. I had no defined specialty (outside of my day job), and wanted none. When people at cocktail parties asked me what I did for a living, I was tempted to answer, “I am a
skeptical empiricist
and a flâneur-reader, someone committed to getting very deep into an idea,” but I made things simple by saying that I was a limousine driver.
Once, on a transatlantic flight, I found myself upgraded to first class next to an expensively dressed, high-powered lady dripping with gold and jewelry who continuously ate nuts (low-carb diet, perhaps), insisted on drinking only Evian, all the while reading the European edition of
The Wall Street Journal
. She kept trying to start a conversation in broken French, since she saw me reading a book (in French) by the sociologist-philosopher Pierre Bourdieu—which, ironically, dealt with the marks of social distinction. I informed her (in English) that I was a limousine driver, proudly insisting that I only drove “very upper-end” cars. An icy silence lasted the whole flight, and, although I could feel the tension, it allowed me to read in peace.
*
It is remarkable how fast and how effectively you can construct a nationality with a flag, a few speeches, and a national anthem; to this day I avoid the label “Lebanese,” preferring the less restrictive “Levantine” designation.
*
Benoît Mandelbrot, who had a similar experience at about the same age, though close to four decades earlier, remembers his own war episode as long stretches of painful boredom punctuated by brief moments of extreme fear.
*
The historian Niall Ferguson showed that, despite all the standard accounts of the buildup to the Great War, which describe “mounting tensions” and “escalating crises,” the conflict came as a surprise. Only retrospectively was it seen as unavoidable by backward-looking historians. Ferguson used a clever empirical argument to make his point: he looked at the prices of imperial bonds, which normally include investors’ anticipation of government’s financing needs and decline in expectation of conflicts since wars cause severe deficits. But bond prices did not reflect the anticipation of war. Note that this study illustrates, in addition, how working with prices can provide a good understanding of history.
*
We will see in
Chapter 10
some clever quantitative tests done to prove such herding; they show that, in many subject matters, the distance between opinions is remarkably narrower than the distance between the average of opinions and truth.
*
I then realized that the great strength of the free-market system is the fact that company executives don’t need to know what’s going on.
*
I specialized in complicated financial instruments called “derivatives,” those that required advanced mathematics—but for which the errors for using the wrong mathematics were the greatest. The subject was new and attractive enough for me to get a doctorate in it.
Note that I was not able to build a career just by betting on Black Swans—there were not enough tradable opportunities. I could, on the other hand, avoid being exposed to them by protecting my portfolio against large losses. So, in order to eliminate the dependence on randomness, I focused on technical inefficiencies between complicated instruments, and on exploiting these opportunities without exposure to the rare event, before they disappeared as my competitors became technologically advanced. Later on in my career I discovered the easier (and less randomness laden) business of protecting, insurance-style, large portfolios against the Black Swan.


================================================================================
CHAPTER/SECTION 182 (Item 187)
================================================================================

Chapter Two
YEVGENIA’S BLACK SWAN
Pink glasses and success—How Yevgenia stops marrying philosophers—I told you so
Five years ago, Yevgenia Nikolayevna Krasnova was an obscure and unpublished novelist, with an unusual background. She was a neuroscientist with an interest in philosophy (her first three husbands had been philosophers), and she got it into her stubborn Franco-Russian head to express her research and ideas in literary form. She dressed up her theories as stories, and mixed them with all manner of autobiographical commentary. She avoided the journalistic prevarications of contemporary narrative nonfiction (“On a clear April morning, John Smith left his house. …”). Foreign dialogue was always written in the original language, with translations appended like movie subtitles. She refused to dub into bad English conversations that took place in bad Italian.
*
No publisher would have given her the time of day, except that there was, at the time, some interest in those rare scientists who could manage to express themselves in semi-understandable sentences. A few publishers agreed to speak with her; they hoped that she would grow up and write a “popular science book on consciousness.” She received enough attention
to get the courtesy of rejection letters and occasional insulting comments instead of the far more insulting and demeaning silence.
Publishers were confused by her manuscript. She could not even answer their first question: “Is this fiction or nonfiction?” Nor could she respond to the “Who is this book written for?” on the publishers’ book proposal forms. She was told, “You need to understand who your audience is” and “amateurs write for themselves, professionals write for others.” She was also told to conform to a precise genre because “bookstores do not like to be confused and need to know where to place a book on the shelves.” One editor protectively added, “This, my dear friend, will only sell ten copies, including those bought by your ex-husbands and family members.”
She had attended a famous writing workshop five years earlier and came out nauseated. “Writing well” seemed to mean obeying arbitrary rules that had grown into gospel, with the confirmatory reinforcement of what we call “experience.” The writers she met were learning to retrofit what was deemed successful: they all tried to imitate stories that had appeared in past issues of
The New Yorker
—not realizing that most of what is new, by definition, cannot be modeled on past issues of
The New Yorker
. Even the idea of a “short story” was a me-too concept to Yevgenia. The workshop instructor, gentle but firm in his delivery, told her that her case was utterly hopeless.
Yegvenia ended up posting the entire manuscript of her main book,
A Story of Recursion
, on the Web. There it found a small audience, which included the shrewd owner of a small unknown publishing house, who wore pink-rimmed glasses and spoke primitive Russian (convinced that he was fluent). He offered to publish her, and agreed to her condition to keep her text completely unedited. He offered her a fraction of the standard royalty rate in return for her editorial stricture—he had so little to lose. She accepted since she had no choice.
It took five years for Yevgenia to graduate from the “egomaniac without anything to justify it, stubborn and difficult to deal with” category to “persevering, resolute, painstaking, and fiercely independent.” For her book slowly caught fire, becoming one of the great and strange successes in literary history, selling millions of copies and drawing so-called critical acclaim. The start-up house has since become a big corporation, with a (polite) receptionist to greet visitors as they enter the main office. Her book has been translated into forty languages (even French). You see her picture everywhere. She is said to be a pioneer of something called the
Consilient School. Publishers now have a theory that “truck drivers who read books do not read books written for truck drivers” and hold that “readers despise writers who pander to them.” A scientific paper, it is now understood, can hide trivialities or irrelevance with equations and jargon; consilient prose, by exposing an idea in raw form, allows it to be judged by the public.
Today, Yevgenia has stopped marrying philosophers (they argue too much), and she hides from the press. In classrooms, literary scholars discuss the many clues indicating the inevitability of the new style. The distinction between fiction and nonfiction is considered too archaic to withstand the challenges of modern society. It was so evident that we needed to remedy the fragmentation between art and science. After the fact, her talent was so obvious.
Many of the editors she later met blamed her for not coming to them, convinced that they would have immediately seen the merit in her work. In a few years, a literary scholar will write the essay “From Kundera to Krasnova,” showing how the seeds of her work can be found in Kundera—a precursor who mixed essay and metacommentary (Yevgenia never read Kundera, but did see the movie version of one of his books—there was no commentary in the movie). A prominent scholar will show how the influence of Gregory Bateson, who injected autobiographical scenes into his scholarly research papers, is visible on every page (Yevgenia has never heard of Bateson).
Yevgenia’s book is a Black Swan.
*
Her third husband was an Italian philosopher.


================================================================================
CHAPTER/SECTION 183 (Item 188)
================================================================================

Chapter Three
THE SPECULATOR AND THE PROSTITUTE
On the critical difference between speculators and prostitutes—Fairness, unfairness, and Black Swans—Theory of knowledge and professional incomes—How Extremistan is not the best place to visit, except, perhaps, if you are a winner
Yevgenia’s rise from the second basement to superstar is possible in only one environment, which I call Extremistan.
*
I will soon introduce the central distinction between the Black Swan–generating province of Extremistan and the tame, quiet, and uneventful province of Mediocristan.


================================================================================
CHAPTER/SECTION 184 (Item 189)
================================================================================

THE BEST (WORST) ADVICE
When I play back in my mind all the “advice” people have given me, I see that only a couple of ideas have stuck with me for life. The rest has been mere words, and I am glad that I did not heed most of it. Most consisted of recommendations such as “be measured and reasonable in your statements,” contradicting the Black Swan idea, since empirical reality is not “measured,” and its own version of “reasonableness” does not correspond
to the conventional middlebrow definition. To be genuinely empirical is to reflect reality as faithfully as possible; to be honorable implies not fearing the appearance and consequences of being outlandish. The next time someone pesters you with unneeded advice, gently remind him of the fate of the monk whom Ivan the Terrible put to death for delivering uninvited (and moralizing) advice. It works as a short-term cure.
The most important piece of advice was, in retrospect, bad, but it was also, paradoxically, the most consequential, as it pushed me deeper into the dynamics of the Black Swan. It came when I was twenty-two, one February afternoon, in the corridor of a building at 3400 Walnut Street in Philadelphia, where I lived. A second-year Wharton student told me to get a profession that is “scalable,” that is, one in which you are not paid by the hour and thus subject to the limitations of the amount of your labor. It was a very simple way to discriminate among professions and, from that, to generalize a separation between types of uncertainty—and it led me to the major philosophical problem, the problem of induction, which is the technical name for the Black Swan. It allowed me to turn the Black Swan from a logical impasse into an easy-to-implement solution, and, as we will see in the next chapters, to ground it in the texture of empirical reality.
How did career advice lead to such ideas about the nature of uncertainty? Some professions, such as dentists, consultants, or massage professionals, cannot be scaled: there is a cap on the number of patients or clients you can see in a given period of time. If you are a prostitute, you work by the hour and are (generally) paid by the hour. Furthermore, your presence is (I assume) necessary for the service you provide. If you open a fancy restaurant, you will at best steadily fill up the room (unless you franchise it). In these professions, no matter how highly paid, your income is subject to gravity. Your revenue depends on your continuous efforts more than on the quality of your decisions. Moreover, this kind of work is largely predictable: it will vary, but not to the point of making the income of a single day more significant than that of the rest of your life. In other words, it will not be Black Swan driven. Yevgenia Nikolayevna would not have been able to cross the chasm between underdog and supreme hero overnight had she been a tax accountant or a hernia specialist (but she would not have been an underdog either).
Other professions allow you to add zeroes to your output (and your income), if you do well, at little or no extra effort. Now being lazy, considering laziness as an asset, and eager to free up the maximum amount of
time in my day to meditate and read, I immediately (but mistakenly) drew a conclusion. I separated the “idea” person, who sells an intellectual product in the form of a transaction or a piece of work, from the “labor” person, who sells you his work.
If you are an idea person, you do not have to work hard, only think intensely. You do the same work whether you produce a hundred units or a thousand. In quant trading, the same amount of work is involved in buying a hundred shares as in buying a hundred thousand, or even a million. It is the same phone call, the same computation, the same legal document, the same expenditure of brain cells, the same effort in verifying that the transaction is right. Furthermore, you can work from your bathtub or from a bar in Rome. You can use leverage as a replacement for work! Well, okay, I was a little wrong about trading: one cannot work from a bathtub, but, when done right, the job allows considerable free time.
The same property applies to recording artists or movie actors: you let the sound engineers and projectionists do the work; there is no need to show up at every performance in order to perform. Similarly, a writer expends the same effort to attract one single reader as she would to capture several hundred million. J. K. Rowling, the author of the Harry Potter books, does not have to write each book again every time someone wants to read it. But this is not so for a baker: he needs to bake every single piece of bread in order to satisfy each additional customer.
So the distinction between writer and baker, speculator and doctor, fraudster and prostitute, is a helpful way to look at the world of activities. It separates those professions in which one can add zeroes of income with no greater labor from those in which one needs to add labor and time (both of which are in limited supply)—in other words, those subjected to gravity.


================================================================================
CHAPTER/SECTION 185 (Item 190)
================================================================================

BEWARE THE SCALABLE
But why was the advice from my fellow student bad?
If the advice was helpful, and it was, in creating a classification for ranking uncertainty and knowledge, it was a mistake as far as choices of profession went. It might have paid off for me, but only because I was lucky and happened to be “in the right place at the right time,” as the saying goes. If I myself had to give advice, I would recommend someone pick a profession that is
not
scalable! A scalable profession is good only if you are successful; they are more competitive, produce monstrous inequalities,
and are far more random, with huge disparities between efforts and rewards—a few can take a large share of the pie, leaving others out entirely at no fault of their own.
One category of profession is driven by the mediocre, the average, and the middle-of-the-road. In it, the mediocre is collectively consequential. The other has either giants or dwarves—more precisely, a very small number of giants and a huge number of dwarves.
Let us see what is behind the formation of unexpected giants—the Black Swan formation.
The Advent of Scalability
Consider the fate of Giaccomo, an opera singer at the end of the nineteenth century, before sound recording was invented. Say he performs in a small and remote town in central Italy. He is shielded from those big egos at La Scala in Milan and other major opera houses. He feels safe as his vocal cords will always be in demand somewhere in the district. There is no way for him to export his singing, and there is no way for the big guns to export theirs and threaten his local franchise. It is not yet possible for him to store his work, so his presence is needed at every performance, just as a barber is (still) needed today for every haircut. So the total pie is unevenly split, but only mildly so, much like your calorie consumption. It is cut in a few pieces and everyone has a share; the big guns have larger audiences and get more invitations than the small guy, but this is not too worrisome. Inequalities exist, but let us call them
mild
. There is no scalability yet, no way to double the largest in-person audience without having to sing twice.
Now consider the effect of the first music recording, an invention that introduced a great deal of injustice. Our ability to reproduce and repeat performances allows me to listen on my laptop to hours of background music of the pianist Vladimir Horowitz (now extremely dead) performing Rachmaninoff’s
Preludes
, instead of to the local Russian émigré musician (still living), who is now reduced to giving piano lessons to generally untalented children for close to minimum wage. Horowitz, though dead, is putting the poor man out of business. I would rather listen to Vladimir Horowitz or Arthur Rubinstein for $10.99 a CD than pay $9.99 for one by some unknown (but very talented) graduate of the Juilliard School or the Prague Conservatory. If you ask me why I select Horowitz, I will answer that it is because of the order, rhythm, or passion, when in fact there
are probably a legion of people I have never heard about, and will never hear about—those who did not make it to the stage, but who might play just as well.
Some people naïvely believe that the process of unfairness started with the gramophone, according to the logic that I just presented. I disagree. I am convinced that the process started much, much earlier, with our DNA, which stores information about our selves and allows us to repeat our performance without our being there by spreading our genes down the generations. Evolution is
scalable:
the DNA that wins (whether by luck or survival advantage) will reproduce itself, like a bestselling book or a successful record, and become pervasive. Other DNA will vanish. Just consider the difference between us humans (excluding financial economists and businessmen) and other living beings on our planet.
Furthermore, I believe that the big transition in social life came not with the gramophone, but when someone had the great but unjust idea to invent the alphabet, thus allowing us to store information and reproduce it. It accelerated further when another inventor had the even more dangerous and iniquitous notion of starting a printing press, thus promoting texts across boundaries and triggering what ultimately grew into a winner-take-all ecology. Now, what was so unjust about the spread of books? The alphabet allowed stories and ideas to be replicated with high fidelity and without limit, without any additional expenditure of energy on the author’s part for the subsequent performances. He didn’t even have to be alive for them—death is often a good career move for an author. This implies that those who, for some reason, start getting some attention can quickly reach more minds than others and displace the competitors from the bookshelves. In the days of bards and troubadours, everyone had an audience. A storyteller, like a baker or a coppersmith, had a market, and the assurance that none from far away could dislodge him from his territory. Today, a few take almost everything; the rest, next to nothing.
By the same mechanism, the advent of the cinema displaced neighborhood actors, putting the small guys out of business. But there is a difference. In pursuits that have a technical component, like being a pianist or a brain surgeon, talent is easy to ascertain, with subjective opinion playing a relatively small part. The inequity comes when someone perceived as being marginally better gets the whole pie.
In the arts—say the cinema—things are far more vicious. What we call “talent” generally comes from success, rather than its opposite. A great deal of empiricism has been done on the subject, most notably by Art De
Vany, an insightful and original thinker who singlemindedly studied wild uncertainty in the movies. He showed that, sadly, much of what we ascribe to skills is an after-the-fact attribution. The movie makes the actor, he claims—and a large dose of nonlinear luck makes the movie.
The success of movies depends severely on contagions. Such contagions do not just apply to the movies: they seem to affect a wide range of cultural products. It is hard for us to accept that people do not fall in love with works of art only for their own sake, but also in order to feel that they belong to a community. By imitating, we get closer to others—that is, other imitators. It fights solitude.
This discussion shows the difficulty in predicting outcomes in an environment of concentrated success. So for now let us note that the division between professions can be used to understand the division between types of random variables. Let us go further into the issue of knowledge, of inference about the unknown and the properties of the known.


================================================================================
CHAPTER/SECTION 186 (Item 191)
================================================================================

SCALABILITY AND GLOBALIZATION
Whenever you hear a snotty (and frustrated) European middlebrow presenting his stereotypes about Americans, he will often describe them as “uncultured,” “unintellectual,” and “poor in math” because, unlike his peers, Americans are not into equation drills and the constructions middlebrows call “high culture”—like knowledge of Goethe’s inspirational (and central) trip to Italy, or familiarity with the Delft school of painting. Yet the person making these statements is likely to be addicted to his iPod, wear blue jeans, and use Microsoft Word to jot down his “cultural” statements on his PC, with some Google searches here and there interrupting his composition. Well, it so happens that America is currently far, far more creative than these nations of museumgoers and equation solvers. It is also far more tolerant of bottom-up tinkering and undirected trial and error. And globalization has allowed the United States to specialize in the creative aspect of things, the production of concepts and ideas, that is, the scalable part of the products, and, increasingly, by exporting jobs, separate the less scalable components and assign them to those happy to be paid by the hour. There is more money in designing a shoe than in actually making it: Nike, Dell, and Boeing can get paid for just thinking, organizing, and leveraging their know-how and ideas while subcontracted factories in developing countries do the grunt work and engineers in cultured and mathematical states do the noncreative technical grind. The American
economy has leveraged itself heavily on the idea generation, which explains why losing manufacturing jobs can be coupled with a rising standard of living. Clearly the drawback of a world economy where the payoff goes to ideas is higher inequality among the idea generators together with a greater role for both opportunity and luck—but I will leave the socioeconomic discussion for Part Three and focus here on knowledge.


================================================================================
CHAPTER/SECTION 187 (Item 192)
================================================================================

TRAVELS INSIDE MEDIOCRISTAN
This scalable/nonscalable distinction allows us to make a clear-cut differentiation between two varieties of uncertainties, two types of randomness.
Let’s play the following thought experiment. Assume that you round up a thousand people randomly selected from the general population and have them stand next to one another in a stadium. You can even include Frenchmen (but please, not too many out of consideration for the others in the group), Mafia members, non-Mafia members, and vegetarians.
Imagine the heaviest person you can think of and add him to that sample. Assuming he weighs three times the average, between four hundred and five hundred pounds, he will rarely represent more than a very small fraction of the weight of the entire population (in this case, about a half of a percent).
You can get even more aggressive. If you picked the heaviest biologically possible human on the planet (who yet can still be called a human), he would not represent more than, say, 0.6 percent of the total, a very negligible increase. And if you had ten thousand persons, his contribution would be vanishingly small.
In the utopian province of Mediocristan, particular events don’t contribute much individually—only collectively. I can state the supreme law of Mediocristan as follows:
When your sample is large, no single instance will significantly change the aggregate or the total
. The largest observation will remain impressive, but eventually insignificant, to the sum.
I’ll borrow another example from my friend Bruce Goldberg: your caloric consumption. Look at how much you consume per year—if you are classified as human, close to eight hundred thousand calories. No single day, not even Thanksgiving at your great-aunt’s, will represent a large share of that. Even if you tried to kill yourself by eating, that day’s calories would not seriously affect your yearly consumption.
Now, if I told you that it is possible to run into someone who weighs
several thousand tons, or stands several hundred miles tall, you would be perfectly justified in having my frontal lobe examined, or in suggesting that I switch to science-fiction writing. But you cannot so easily rule out extreme variations with a different brand of quantities, to which we turn next.
The Strange Country of Extremistan
Consider by comparison the net worth of the thousand people you lined up in the stadium. Add to them the wealthiest person to be found on the planet—say, Bill Gates, the founder of Microsoft. Assume his net worth to be close to $80 billion—with the total capital of the others around a few million. How much of the total wealth would he represent? 99.9 percent? Indeed, all the others would represent no more than a rounding error for his net worth, the variation of his personal portfolio over the past second. For someone’s weight to represent such a share, he would need to weigh fifty million pounds!
Try it again with, say, book sales. Line up a thousand authors (or people begging to get published, but calling themselves authors instead of waiters), and check their book sales. Then add the living writer who (currently) has the most readers. J. K. Rowling, the author of the Harry Potter series, with several hundred million books sold, will dwarf the remaining thousand authors with, say, collectively, a few hundred thousand readers at most.
Try it also with academic citations (the mention of one academic by another academic in a formal publication), media references, income, company size, and so on. Let us call these
social
matters, as they are man-made, as opposed to physical ones, like the size of waistlines.
In Extremistan, inequalities are such that one single observation can disproportionately impact the aggregate, or the total
.
So while weight, height, and calorie consumption are from Mediocristan, wealth is not. Almost all social matters are from Extremistan. Another way to say it is that social quantities are informational, not physical: you cannot touch them. Money in a bank account is something important, but certainly
not physical
. As such it can take any value without necessitating the expenditure of energy. It is just a number!
Note that before the advent of modern technology, wars used to belong to Mediocristan. It is hard to kill many people if you need to slaughter
them one at the time. Today, with tools of mass destruction, all it takes is a button, a nutcase, or a small error to wipe out the planet.
Look at the implication for the Black Swan. Extremistan can produce Black Swans, and does, since a few occurrences have had huge influences on history. This is the main idea of this book.
Extremistan and Knowledge
While this distinction (between Mediocristan and Extremistan) has severe ramifications for both social fairness and the dynamics of events, let us see its application to knowledge, which is where most of its value lies. If a Martian came to earth and engaged in the business of measuring the heights of the denizens of this happy planet, he could safely stop at a hundred humans to get a good picture of the average height. If you live in Mediocristan, you can be comfortable with what you have measured—provided that you know for sure that it comes from Mediocristan. You can also be comfortable with
what you have learned
from the data. The epistemological consequence is that with Mediocristan-style randomness it is not
possible
*
to have a Black Swan surprise such that a single event can dominate a phenomenon.
Primo
, the first hundred days should reveal all you need to know about the data.
Secondo
, even if you do have a surprise, as we saw in the case of the heaviest human, it would not be consequential.
If you are dealing with quantities from Extremistan, you will have trouble figuring out the average from any sample since it can depend so much on one single observation. The idea is not more difficult than that. In Extremistan, one unit can easily affect the total in a disproportionate way. In this world, you should always be suspicious of the knowledge you derive from data. This is a very simple test of uncertainty that allows you to distinguish between the two kinds of randomness. Capish?
What you can know from data in Mediocristan augments very rapidly with the supply of information. But knowledge in Extremistan grows slowly and erratically with the addition of data, some of it extreme, possibly at an unknown rate.
Wild and Mild
If we follow my distinction of scalable versus nonscalable, we can see clear differences shaping up between Mediocristan and Extremistan. Here are a few examples.
Matters that seem to belong to Mediocristan
(subjected to what we call type 1 randomness): height, weight, calorie consumption, income for a baker, a small restaurant owner, a prostitute, or an orthodontist; gambling profits (in the very special case, assuming the person goes to a casino and maintains a constant betting size), car accidents, mortality rates, “IQ” (as measured).
Matters that seem to belong to Extremistan
(subjected to what we call type 2 randomness): wealth, income, book sales per author, book citations per author, name recognition as a “celebrity,” number of references on Google, populations of cities, uses of words in a vocabulary, numbers of speakers per language, damage caused by earthquakes, deaths in war, deaths from terrorist incidents, sizes of planets, sizes of companies, stock ownership, height between species (consider elephants and mice), financial markets (but your investment manager does not know it), commodity prices, inflation rates, economic data. The Extremistan list is much longer than the prior one.
The Tyranny of the Accident
Another way to rephrase the general distinction is as follows: Mediocristan is where we must endure the tyranny of the collective, the routine, the obvious, and the predicted; Extremistan is where we are subjected to the tyranny of the singular, the accidental, the unseen, and the unpredicted. As hard as you try, you will never lose a lot of weight in a single day; you need the collective effect of many days, weeks, even months. Likewise, if you work as a dentist, you will never get rich in a single day—but you can do very well over thirty years of motivated, diligent, disciplined, and regular attendance to teeth-drilling sessions. If you are subject to Extremistan-based speculation, however, you can gain or lose your fortune in a single minute.
Table 1
summarizes the differences between the two dynamics, to which I will refer in the rest of the book; confusing the left column with the right one can lead to dire (or extremely lucky) consequences.
TABLE 1
Mediocristan
Extremistan
Nonscalable
Scalable
Mild or type 1 randomness
Wild (even superwild) or type 2 randomness
The most typical member is mediocre
The most “typical” is either giant or dwarf, i.e., there is no typical member
Winners get a small segment of the total pie
Winner-take-almost-all effects
Example: audience of an opera singer before the gramophone
Today’s audience for an artist
More likely to be found in our ancestral environment
More likely to be found in our modern environment
Impervious to the Black Swan
Vulnerable to the Black Swan
Subject to gravity
There are no physical constraints on what a number can be
Corresponds (generally) to physical quantities, i.e., height
Corresponds to numbers, say, wealth
As close to utopian equality as reality can spontaneously deliver
Dominated by extreme winner-take-all inequality
Total is not determined by a single instance or observation
Total will be determined by a small number of extreme events
When you observe for a while you can get to know what’s going on
It takes a long time to know what’s going on
Tyranny of the collective
Tyranny of the accidental
Easy to predict from what you see and extend to what you do not see
Hard to predict from past information
History crawls
History makes jumps
Events are distributed
*
according to the “bell curve” (the GIF) or its variations
The distribution is either Mandelbrotian “gray” Swans (tractable scientifically) or totally intractable Black Swans
*
What I call “probability distribution” here is the model used to calculate the odds of different events, how they are distributed. When I say that an event is distributed according to the “bell curve,” I mean that the Gaussian bell curve (after C. F. Gauss; more on him later) can help provide probabilities of various occurrences.
This framework, showing that Extremistan is where most of the Black Swan action is, is only a rough approximation—please do not Platonify it; don’t simplify it beyond what’s necessary.
Extremistan does not always imply Black Swans. Some events can be rare and consequential, but somewhat predictable, particularly to those who are prepared for them and have the tools to understand them (instead of listening to statisticians, economists, and charlatans of the bell-curve variety). They are near–Black Swans. They are somewhat tractable scientifically—knowing about their incidence should lower your surprise; these events are rare but expected. I call this special case of “gray” swans Mandelbrotian randomness. This category encompasses the randomness that produces phenomena commonly known by terms such as
scalable, scale-invariant, power laws, Pareto-Zipf laws, Yule’s law, Paretian-stable processes, Levy-stable
, and
fractal laws
, and we will leave them aside for now since they will be covered in some depth in Part Three. They are scalable, according to the logic of this chapter, but you can know a little more about
how
they scale since they share much with the laws of nature.
You can still experience severe Black Swans in Mediocristan, though not easily. How? You may forget that something is random, think that it is deterministic, then have a surprise. Or you can tunnel and miss on a source of uncertainty, whether mild or wild, owing to lack of imagination—most Black Swans result from this “tunneling” disease, which I will discuss in
Chapter 9
.
*
This has been a “literary” overview of the central distinction of this book, offering a trick to distinguish between what can belong in Mediocristan and what belongs in Extremistan. I said that I will get into a more thorough examination in Part Three, so let us focus on epistemology for now and see how the distinction affects our knowledge.
*
To those readers who Googled Yevgenia Krasnova, I am sorry to say that she is (officially) a fictional character.
*
I emphasize
possible
because the chance of these occurrences is typically in the order of one in several trillion trillion, as close to impossible as it gets.
*
It is worth mentioning here that one of the mistakes people make in the interpretation of the Black Swan idea is that they believe that Black Swans are more frequent than in our imagination. Not quite the point. Black Swans are more consequential, not necessarily more frequent. There are actually fewer remote events, but they are more and more extreme in their impact, which confuses people, as they tend to write them off more easily.


================================================================================
CHAPTER/SECTION 188 (Item 193)
================================================================================

Chapter Four
ONE THOUSAND AND ONE DAYS, OR HOW NOT TO BE A SUCKER
Surprise, surprise—Sophisticated methods for learning from the future—Sextus was always ahead—The main idea is not to be a sucker—Let us move to Mediocristan, if we can find it
Which brings us to the Black Swan problem in its original form.
Imagine someone of authority and rank, operating in a place where rank matters—say, a government agency or a large corporation. He could be a verbose political commentator on Fox News stuck in front of you at the health club (impossible to avoid looking at the screen), the chairman of a company discussing the “bright future ahead,” a Platonic medical doctor who has categorically ruled out the utility of mother’s milk (because he did not see anything special in it), or a Harvard Business School professor who does not laugh at your jokes. He takes what he knows a little too seriously.
Say that a prankster surprises him one day by surreptitiously sliding a thin feather up his nose during a moment of relaxation. How would his dignified pompousness fare after the surprise? Contrast his authoritative demeanor with the shock of being hit by something totally unexpected that he does not understand. For a brief moment, before he regains his bearings, you will see disarray in his face.
I confess having developed an incorrigible taste for this kind of prank
during my first sleepaway summer camp. Introduced into the nostril of a sleeping camper, a feather would induce sudden panic. I spent part of my childhood practicing variations on the prank: in place of a thin feather you can roll the corner of a tissue to make it long and narrow. I got some practice on my younger brother. An equally effective prank would be to drop an ice cube down someone’s collar when he expects it least, say during an official dinner. I had to stop these pranks as I got deeper into adulthood, of course, but I am often involuntarily hit with such an image when bored out of my wits in meetings with serious-looking businesspersons (dark suits and standardized minds) theorizing, explaining things, or talking about random events with plenty of “because” in their conversation. I zoom in on one of them and imagine the ice cube sliding down his back—it would be less fashionable, though certainly more spectacular, if you put a living mouse there, particularly if the person is ticklish and is wearing a tie, which would block the rodent’s normal route of exit.
*
Pranks can be compassionate. I remember in my early trading days, at age twenty-five or so, when money was starting to become easy. I would take taxis, and if the driver spoke skeletal English and looked particularly depressed, I’d give him a $100 bill as a tip, just to give him a little jolt and get a kick out of his surprise. I’d watch him unfold the bill and look at it with some degree of consternation ($1 million certainly would have been better but it was not within my means). It was also a simple hedonic experiment: it felt elevating to make someone’s day with the trifle of $100. I eventually stopped; we all become stingy and calculating when our wealth grows and we start taking money seriously.
I don’t need much help from fate to get larger-scale entertainment: reality provides such forced revisions of beliefs at quite a high frequency. Many are quite spectacular. In fact, the entire knowledge-seeking enterprise is based on taking conventional wisdom and accepted scientific beliefs and shattering them into pieces with new counterintuitive evidence, whether at a micro scale (every scientific discovery is an attempt to produce a micro–Black Swan) or at a larger one (as with Poincaré’s and Einstein’s relativity). Scientists may be in the business of laughing at their predecessors, but owing to an array of human mental dispositions, few realize that someone will laugh at their beliefs in the (disappointingly near) future. In this case, my readers and I are laughing at the
present
state of social knowledge. These big guns do not see the inevitable overhaul of
their work coming, which means that you can usually count on them to be in for a surprise.


================================================================================
CHAPTER/SECTION 189 (Item 194)
================================================================================

HOW TO LEARN FROM THE TURKEY
The überphilosopher Bertrand Russell presents a particularly toxic variant of my surprise jolt in his illustration of what people in his line of business call the Problem of Induction or Problem of Inductive Knowledge (capitalized for its seriousness)—certainly the mother of all problems in life. How can we
logically
go from specific instances to reach general conclusions? How do we know what we know? How do we know that what we have observed from given objects and events suffices to enable us to figure out their other properties? There are traps built into any kind of knowledge gained from observation.
Consider a turkey that is fed every day. Every single feeding will firm up the bird’s belief that it is the general rule of life to be fed every day by friendly members of the human race “looking out for its best interests,” as a politician would say. On the afternoon of the Wednesday before Thanksgiving, something
unexpected
will happen to the turkey. It will incur a revision of belief.
*
The rest of this chapter will outline the Black Swan problem in its original form: How can we know the future, given knowledge of the past; or, more generally, how can we figure out properties of the (infinite) unknown based on the (finite) known? Think of the feeding again: What can a turkey learn about what is in store for it tomorrow from the events of yesterday? A lot, perhaps, but certainly a little less than it thinks, and it is just that “little less” that may make all the difference.
The turkey problem can be generalized to any situation where
the same hand that feeds you can be the one that wrings your neck
. Consider the case of the increasingly integrated German Jews in the 1930s—or my description in
Chapter 1
of how the population of Lebanon got lulled into a false sense of security by the appearance of mutual friendliness and tolerance.
Let us go one step further and consider induction’s most
worrisome
aspect: learning backward. Consider that the turkey’s experience may have, rather than no value, a
negative
value. It learned from observation, as we are all advised to do (hey, after all, this is what is believed to be the scientific method). Its confidence increased as the number of friendly feedings grew, and it felt increasingly safe even though the slaughter was more and more imminent. Consider that the feeling of safety reached its maximum when the risk was at the highest! But the problem is even more general than that; it strikes at the nature of empirical knowledge itself. Something has worked in the past, until—well, it unexpectedly no longer does, and what we have learned from the past turns out to be at best irrelevant or false, at worst viciously misleading.
FIGURE 1: ONE THOUSAND AND ONE DAYS OF HISTORY
A turkey before and after Thanksgiving. The history of a process over a thousand days tells you nothing about what is to happen next. This naïve projection of the future from the past can be applied to anything.
Figure 1
provides the prototypical case of the problem of induction as encountered in real life. You observe a hypothetical variable for one thousand days. It could be anything (with a few mild transformations): book sales, blood pressure, crimes, your personal income, a given stock, the interest on a loan, or Sunday attendance at a specific Greek Orthodox church. You subsequently derive
solely from past data
a few conclusions concerning the properties of the pattern with projections for the next thousand, even five thousand, days. On the one thousand and first day—boom! A big change takes place that is completely unprepared for by the past.
Consider the surprise of the Great War. After the Napoleonic conflicts, the world had experienced a period of peace that would lead any observer to believe in the disappearance of severely destructive conflicts. Yet, surprise!
It turned out to be the deadliest conflict, up until then, in the history of mankind.
Note that after the event you start predicting the possibility of other outliers happening locally, that is, in the process you were just surprised by,
but not elsewhere
. After the stock market crash of 1987 half of America’s traders braced for another one every October—not taking into account that there was no antecedent for the first one. We worry too late—ex post. Mistaking a naïve observation of the past as something definitive or representative of the future is the one and only cause of our inability to understand the Black Swan.
It would appear to a quoting dilettante—i.e., one of those writers and scholars who fill up their texts with phrases from some dead authority—that, as phrased by Hobbes, “from like antecedents flow like consequents.” Those who believe in the unconditional benefits of past experience should consider this pearl of wisdom allegedly voiced by a famous ship’s captain:
But in all my experience, I have never been in any accident… of any sort worth speaking about. I have seen but one vessel in distress in all my years at sea. I never saw a wreck and never have been wrecked nor was I ever in any predicament that threatened to end in disaster of any sort
.
E. J. Smith, 1907, Captain, RMS
Titanic
Captain Smith’s ship sank in 1912 in what became the most talked-about shipwreck in history.
*
Trained to Be Dull
Similarly, think of a bank chairman whose institution makes steady profits over a long time, only to lose everything in a single reversal of fortune. Traditionally, bankers of the lending variety have been pear-shaped, clean-shaven, and dress in possibly the most comforting and boring manner, in dark suits, white shirts, and red ties. Indeed, for their lending business, banks hire dull people and train them to be even more dull. But this is for show. If they look conservative, it is because their loans only go bust on rare, very rare, occasions. There is no way to gauge the effectiveness of their lending activity by observing it over a day, a week, a month, or … even a century! In the summer of 1982, large American banks lost close to all their past earnings (cumulatively), about everything they ever made in the history of American banking—everything. They had been lending to South and Central American countries that all defaulted at the same time—“an event of an exceptional nature.” So it took just one summer to figure out that this was a sucker’s business and that all their earnings came from a very risky game. All that while the bankers led everyone, especially themselves, into believing that they were “conservative.” They are not conservative; just phenomenally skilled at self-deception by burying the possibility of a large, devastating loss under the rug. In fact, the travesty repeated itself a decade later, with the “risk-conscious” large banks once again under financial strain, many of them near-bankrupt, after the real-estate collapse of the early 1990s in which the now defunct savings and loan industry required a taxpayer-funded bailout of more than half a trillion dollars. The Federal Reserve bank protected them at our expense: when “conservative” bankers make profits, they get the benefits; when they are hurt, we pay the costs.
After graduating from Wharton, I initially went to work for Bankers Trust (now defunct). There, the chairman’s office, rapidly forgetting about the story of 1982, broadcast the results of every quarter with an announcement explaining how smart, profitable, conservative (and good looking) they were. It was obvious that their profits were simply cash borrowed from destiny with some random payback time. I have no problem with risk taking, just please, please, do not call yourself conservative and act superior to other businesses who are not as vulnerable to Black Swans.
Another recent event is the almost-instant bankruptcy, in 1998, of a financial investment company (hedge fund) called Long-Term Capital Management
(LTCM), which used the methods and risk expertise of two “Nobel economists,” who were called “geniuses” but were in fact using phony, bell curve–style mathematics while managing to convince themselves that it was great science and thus turning the entire financial establishment into suckers. One of the largest trading losses ever in history took place in almost the blink of an eye, with no warning signal (more, much more on that in
Chapter 17
).
*
A Black Swan Is Relative to Knowledge
From the standpoint of the turkey, the nonfeeding of the one thousand and first day is a Black Swan. For the butcher, it is not, since its occurrence is not unexpected. So you can see here that the Black Swan is a sucker’s problem. In other words, it occurs relative to your expectation. You realize that you can eliminate a Black Swan by science (if you’re able), or by keeping an open mind. Of course, like the LTCM people, you can create Black Swans with science, by giving people confidence that the Black Swan cannot happen—this is when science turns normal citizens into suckers.
Note that these events do not have to be
instantaneous
surprises. Some of the historical fractures I mention in
Chapter 1
have lasted a few decades, like, say, the computer that brought consequential effects on society without its invasion of our lives being noticeable from day to day. Some Black Swans can come from the slow building up of incremental changes in the same direction, as with books that sell large amounts over years, never showing up on the bestseller lists, or from technologies that creep up on us slowly, but surely. Likewise, the growth of Nasdaq stocks in the late 1990s took a few years—but the growth would seem sharper if you were to plot it on a long historical line. Matters should be seen on some relative, not absolute, timescale: earthquakes last minutes, 9/11 lasted hours, but historical changes and technological implementations
are Black Swans that can take decades. In general, positive Black Swans take time to show their effect while negative ones happen very quickly—it is much easier and much faster to destroy than to build. (During the Lebanese war, my parents’ house in Amioun and my grandfather’s house in a nearby village were destroyed in just a few hours, dynamited by my grandfather’s enemies who controlled the area. It took seven thousand times longer—two years—to rebuild them. This asymmetry in timescales explains the difficulty in reversing time.)


================================================================================
CHAPTER/SECTION 190 (Item 195)
================================================================================

A BRIEF HISTORY OF THE BLACK SWAN PROBLEM
This turkey problem (a.k.a. the problem of induction) is a very old one, but for some reason it is likely to be called “Hume’s problem” by your local philosophy professor.
People imagine us skeptics and empiricists to be morose, paranoid, and tortured in our private lives, which may be the exact opposite of what history (and my private experience) reports. Like many of the skeptics I hang around with, Hume was jovial and a bon vivant, eager for literary fame, salon company, and pleasant conversation. His life was not devoid of anecdotes. He once fell into a swamp near the house he was building in Edinburgh. Owing to his reputation among the locals as an atheist, a woman refused to pull him out of it until he recited the Lord’s Prayer and the Belief, which, being practical-minded, he did. But not before he argued with her about whether Christians were obligated to help their enemies. Hume looked unprepossessing. “He exhibited that preoccupied stare of the thoughtful scholar that so commonly impresses the undiscerning as imbecile,” writes a biographer.
Strangely, Hume during his day was not mainly known for the works that generated his current reputation—he became rich and famous through writing a bestselling history of England. Ironically, when Hume was alive, his philosophical works, to which we now attach his fame, “fell deadborn off the presses,” while the works for which he was famous at the time are now harder to find. Hume wrote with such clarity that he puts to shame almost all current thinkers, and certainly the entire German graduate curriculum. Unlike Kant, Fichte, Schopenhauer, and Hegel, Hume is the kind of thinker who is
sometimes
read by the person mentioning his work.
I often hear “Hume’s problem” mentioned in connection with the problem of induction, but the problem is old, older than the interesting
Scotsman, perhaps as old as philosophy itself, maybe as old as olive-grove conversations. Let us go back into the past, as it was formulated with no less precision by the ancients.
Sextus the (Alas) Empirical
The violently antiacademic writer, and antidogma activist, Sextus Empiricus operated close to a millennium and a half before Hume, and formulated the turkey problem with great precision. We know very little about him; we do not know whether he was a philosopher or more of a copyist of philosophical texts by authors obscure to us today. We surmise that he lived in Alexandria in the second century of our era. He belonged to a school of medicine called “empirical,” since its practitioners doubted theories and causality and relied on past experience as guidance in their treatment, though not putting much trust in it. Furthermore, they did not trust that anatomy revealed function too obviously. The most famous proponent of the empirical school, Menodotus of Nicomedia, who merged empiricism and philosophical skepticism, was said to keep medicine an art, not a “science,” and insulate its practice from the problems of dogmatic science. The practice of medicine explains the addition of
empiricus
(“the empirical”) to Sextus’s name.
Sextus represented and jotted down the ideas of the school of the Pyrrhonian skeptics who were after some form of intellectual therapy resulting from the suspension of belief. Do you face the possibility of an adverse event? Don’t worry. Who knows, it may turn out to be good for you. Doubting the consequences of an outcome will allow you to remain imperturbable. The Pyrrhonian skeptics were docile citizens who followed customs and traditions whenever possible, but taught themselves to systematically doubt everything, and thus attain a level of serenity. But while conservative in their habits, they were rabid in their fight against dogma.
Among the surviving works of Sextus’s is a diatribe with the beautiful title
Adversos Mathematicos
, sometimes translated as
Against the Professors
. Much of it could have been written last Wednesday night!
Where Sextus is mostly interesting for my ideas is in his rare mixing of philosophy and decision making in his practice. He was a doer, hence classical scholars don’t say nice things about him. The methods of empirical medicine, relying on seemingly purposeless trial and error, will be central to my ideas on planning and prediction, on how to benefit from the Black Swan.
In 1998, when I went out on my own, I called my research laboratory and trading firm Empirica, not for the same antidogmatist reasons, but on account of the far more depressing reminder that it took at least another fourteen centuries after the works of the school of empirical medicine before medicine changed and finally became adogmatic, suspicious of theorizing, profoundly skeptical, and evidence-based! Lesson? That awareness of a problem does not mean much—particularly when you have special interests and self-serving institutions in play.
Algazel
The third major thinker who dealt with the problem was the eleventh-century Arabic-language skeptic Al-Ghazali, known in Latin as Algazel. His name for a class of dogmatic scholars was
ghabi
, literally “the imbeciles,” an Arabic form that is funnier than “moron” and more expressive than “obscurantist.” Algazel wrote his own
Against the Professors
, a diatribe called
Tahafut al falasifah
, which I translate as “The Incompetence of Philosophers.” It was directed at members of the school called
falasifah—
the Arabic intellectual establishment was the direct heir of the classical philosophy of the academy, and they managed to reconcile it with Islam through rational argument.
Algazel’s attack on “scientific” knowledge started a debate with Averroës, the medieval philosopher who ended up having the most profound influence of any medieval thinker (on Jews and Christians, though not on Moslems). The debate between Algazel and Averroës was finally, but sadly, won by both. In its aftermath, many Arab religious thinkers integrated and exaggerated Algazel’s skepticism of the scientific method, preferring to leave causal considerations to God (in fact it was a stretch of his idea). The West embraced Averroës’s rationalism, built upon Aristotle’s, which survived through Aquinas and the Jewish philosophers who called themselves Averroan for a long time. Many thinkers blame the Arabs’ later abandonment of scientific method on Algazel’s huge influence—though apparently this took place a few centuries later. He ended up fueling Sufi mysticism, in which the worshipper attempts to enter into communion with God, severing all connections with earthly matters. All of this came from the Black Swan problem.
The Skeptic, Friend of Religion
While the ancient skeptics advocated learned ignorance as the first step in honest inquiries toward truth, later medieval skeptics, both Moslems and Christians, used skepticism as a tool to avoid accepting what today we call science. Belief in the importance of the Black Swan problem, worries about induction, and skepticism can make some religious arguments more appealing, though in stripped-down, anticlerical, theistic form. This idea of relying on faith, not reason, was known as fideism. So there is a tradition of Black Swan skeptics who found solace in religion, best represented by Pierre Bayle, a French-speaking Protestant erudite, philosopher, and theologian, who, exiled in Holland, built an extensive philosophical architecture related to the Pyrrhonian skeptics. Bayle’s writings exerted some considerable influence on Hume, introducing him to ancient skepticism—to the point where Hume took ideas wholesale from Bayle. Bayle’s
Dictionnaire historique et critique
was the most read piece of scholarship of the eighteenth century, but like many of my French heroes (such as Frédéric Bastiat), Bayle does not seem to be part of the French curriculum and is nearly impossible to find in the original French language. Nor is the fourteenth-century Algazelist Nicolas of Autrecourt.
Indeed, it is not a well-known fact that the most complete exposition of the ideas of skepticism, until recently, remains the work of a powerful Catholic bishop who was an august member of the French Academy. Pierre-Daniel Huet wrote his
Philosophical Treatise on the Weaknesses of the Human Mind
in 1690, a remarkable book that tears through dogmas and questions human perception. Huet presents arguments against causality that are quite potent—he states, for instance, that any event can have an infinity of possible causes.
Both Huet and Bayle were erudites and spent their lives reading. Huet, who lived into his nineties, had a servant follow him with a book to read aloud to him during meals and breaks and thus avoid lost time. He was deemed the most read person in his day. Let me insist that erudition is important to me. It signals genuine intellectual curiosity. It accompanies an open mind and the desire to probe the ideas of others. Above all, an erudite can be dissatisfied with his own knowledge, and such dissatisfaction is a wonderful shield against Platonicity, the simplifications of the five-minute manager, or the philistinism of the overspecialized scholar. Indeed, scholarship without erudition can lead to disasters.
I Don’t Want to Be a Turkey
But promoting philosophical skepticism is not quite the mission of this book. If awareness of the Black Swan problem can lead us into withdrawal and extreme skepticism, I take here the exact opposite direction. I am interested in deeds and true empiricism. So, this book was not written by a Sufi mystic, or even by a skeptic in the ancient or medieval sense, or even (we will see) in a philosophical sense, but by a practitioner whose principal aim is to not be a sucker in things that matter, period.
Hume was radically skeptical in the philosophical cabinet, but abandoned such ideas when it came to daily life, since he could not handle them. I am doing here the exact opposite: I am skeptical in matters that have implications for daily life. In a way, all I care about is making a decision without being the turkey.
Many middlebrows have asked me over the past twenty years, “How do you, Taleb, cross the street given your extreme risk consciousness?” or have stated the more foolish “You are asking us to take
no
risks.” Of course I am not advocating total risk phobia (we will see that I favor an aggressive type of risk taking): all I will be showing you in this book is how to avoid crossing the street
blindfolded
.
They Want to Live in Mediocristan
I have just presented the Black Swan problem in its historical form: the central difficulty of generalizing from available information, or of learning from the past, the known, and the seen. I have also presented the list of those who, I believe, are the most relevant historical figures.
You can see that it is extremely convenient for us to assume that we live in Mediocristan. Why? Because it allows you to rule out these Black Swan surprises! The Black Swan problem either does not exist or is of small consequence if you live in Mediocristan!
Such an assumption magically drives away the problem of induction, which since Sextus Empiricus has been plaguing the history of thinking. The statistician can do away with epistemology.
Wishful thinking! We do not live in Mediocristan, so the Black Swan needs a different mentality. As we cannot push the problem under the rug, we will have to dig deeper into it. This is not a terminal difficulty—and we can even benefit from it.
•   •   •
Now, there are other themes arising from our blindness to the Black Swan:
We focus on preselected segments of the seen and generalize from it to the unseen: the error of confirmation.
We fool ourselves with stories that cater to our Platonic thirst for distinct patterns: the narrative fallacy.
We behave as if the Black Swan does not exist: human nature is not programmed for Black Swans.
What we see is not necessarily all that is there. History hides Black Swans from us and gives us a mistaken idea about the odds of these events: this is the distortion of silent evidence.
We “tunnel”: that is, we focus on a few well-defined sources of uncertainty, on too specific a list of Black Swans (at the expense of the others that do not easily come to mind).
I will discuss each of the points in the next five chapters. Then, in the conclusion of Part One, I will show how, in effect, they are the
same
topic.
*
I am safe since I never wear ties (except at funerals).
*
Since Russell’s original example used a chicken, this is the enhanced North American adaptation.
*
Statements like those of Captain Smith are so common that it is not even funny. In September 2006, a fund called Amaranth, ironically named after a flower that “never dies,” had to shut down after it lost close to $7 billion in a few days, the most impressive loss in trading history (another irony: I shared office space with the traders). A few days prior to the event, the company made a statement to the effect that investors should not worry because they had twelve risk managers—people who use models of the past to produce risk measures on the odds of such an event. Even if they had one hundred and twelve risk managers, there would be no meaningful difference; they still would have blown up. Clearly you cannot manufacture more information than the past can deliver; if you buy one hundred copies of
The New York Times
, I am not too certain that it would help you gain incremental knowledge of the future. We just don’t know how much information there is in the past.
*
The main tragedy of the high impact-low probability event comes from the mismatch between the time taken to compensate someone and the time one needs to be comfortable that he is not making a bet against the rare event. People have an incentive to bet against it, or to game the system since they can be paid a bonus reflecting their yearly performance when in fact all they are doing is producing illusory profits that they will lose back one day. Indeed, the tragedy of capitalism is that since the quality of the returns is not observable from past data, owners of companies, namely shareholders, can be taken for a ride by the managers who show returns and cosmetic profitability but in fact might be taking hidden risks.


================================================================================
CHAPTER/SECTION 191 (Item 196)
================================================================================

Chapter Five
CONFIRMATION SHMONFIRMATION!
I have so much evidence—Can Zoogles be (sometimes) Boogles?—Corroboration shmorroboration—Popper’s idea
As much as it is ingrained in our habits and conventional wisdom, confirmation can be a dangerous error.
Assume I told you that I had evidence that the football player O. J. Simpson (who was accused of killing his wife in the 1990s) was not a criminal. Look, the other day I had breakfast with him and
he didn’t kill anybody
. I am serious, I did not see him kill a single person. Wouldn’t that
confirm
his innocence? If I said such a thing you would certainly call a shrink, an ambulance, or perhaps even the police, since you might think that I spent too much time in trading rooms or in cafés thinking about this Black Swan topic, and that my logic may represent such an immediate danger to society that I myself need to be locked up immediately.
You would have the same reaction if I told you that I took a nap the other day on the railroad track in New Rochelle, New York, and was not killed. Hey, look at me, I am alive, I would say, and that is evidence that lying on train tracks is risk-free. Yet consider the following. Look again at
Figure 1
in
Chapter 4
; someone who observed the turkey’s first thousand days (but not the shock of the thousand and first) would tell you, and rightly so, that there is
no evidence
of the possibility of large events, i.e.,
Black Swans. You are likely to confuse that statement, however, particularly if you do not pay close attention, with the statement that there is
evidence of no possible
Black Swans. Even though it is in fact vast, the logical distance between the two assertions will seem very narrow in your mind, so that one can be easily substituted for the other. Ten days from now, if you manage to remember the first statement at all, you will be likely to retain the second, inaccurate version—that there is
proof of no Black Swans
. I call this confusion the round-trip fallacy, since these statements are not
interchangeable
.
Such confusion of the two statements partakes of a trivial, very trivial (but crucial), logical error—but we are not immune to trivial, logical errors, nor are professors and thinkers particularly immune to them (complicated equations do not tend to cohabit happily with clarity of mind). Unless we concentrate very hard, we are likely to unwittingly simplify the problem because our minds routinely do so without our knowing it.
It is worth a deeper examination here.
Many people confuse the statement “almost all terrorists are Moslems” with “almost all Moslems are terrorists.” Assume that the first statement is true, that 99 percent of terrorists are Moslems. This would mean that only about .001 percent of Moslems are terrorists, since there are more than one billion Moslems and only, say, ten thousand terrorists, one in a hundred thousand. So the logical mistake makes you (unconsciously) overestimate the odds of a randomly drawn individual Moslem person (between the age of, say, fifteen and fifty) being a terrorist by close to fifty thousand times!
The reader might see in this round-trip fallacy the unfairness of stereotypes—minorities in urban areas in the United States have suffered from the same confusion: even if most criminals come from their ethnic subgroup, most of their ethnic subgroup are not criminals, but they still suffer from discrimination by people who should know better.
“I never meant to say that the Conservatives are generally stupid. I meant to say that stupid people are generally Conservative,” John Stuart Mill once complained. This problem is chronic: if you tell people that the key to success is not always skills, they think that you are telling them that it is never skills, always luck.
Our inferential machinery, that which we use in daily life, is not made for a complicated environment in which a statement changes markedly when its wording is slightly modified. Consider that in a primitive environment there is no consequential difference between the statements
most
killers are wild animals
and
most wild animals are killers
. There is an error here, but it is almost inconsequential. Our statistical intuitions have not evolved for a habitat in which these subtleties can make a big difference.
Zoogles Are Not All Boogles
All zoogles are boogles. You saw a boogle. Is it a zoogle?
Not necessarily,
since not all boogles are zoogles;
adolescents who make a mistake in answering this kind of question on their SAT test might not make it to college. Yet another person can get very high scores on the SATs and still feel a chill of fear when someone from the wrong side of town steps into the elevator. This inability to automatically transfer knowledge and sophistication from one situation to another, or from theory to practice, is a quite disturbing attribute of human nature.
Let us call it the
domain specificity
of our reactions. By domain-specific I mean that our reactions, our mode of thinking, our intuitions, depend on the context in which the matter is presented, what evolutionary psychologists call the “domain” of the object or the event. The classroom is a domain; real life is another. We react to a piece of information not on its logical merit, but on the basis of which framework surrounds it, and how it registers with our social-emotional system. Logical problems approached one way in the classroom might be treated differently in daily life. Indeed they
are
treated differently in daily life.
Knowledge, even when it is exact, does not often lead to appropriate actions because we tend to forget what we know, or forget how to process it properly if we do not pay attention, even when we are experts. Statisticians, it has been shown, tend to leave their brains in the classroom and engage in the most trivial inferential errors once they are let out on the streets. In 1971, the psychologists Danny Kahneman and Amos Tversky plied professors of statistics with statistical questions not phrased as statistical questions. One was similar to the following (changing the example for clarity): Assume that you live in a town with two hospitals—one large, the other small. On a given day 60 percent of those born in one of the two hospitals are boys. Which hospital is it likely to be? Many statisticians made the equivalent of the mistake (during a casual conversation) of choosing the larger hospital, when in fact the very basis of statistics is that large samples are more stable and should fluctuate less from the long-term average—here, 50 percent for each of the sexes—than smaller samples.
These statisticians would have flunked their own exams. During my days as a quant I counted hundreds of such severe inferential mistakes made by statisticians who forgot that they were statisticians.
For another illustration of the way we can be ludicrously domain-specific in daily life, go to the luxury Reebok Sports Club in New York City, and look at the number of people who, after riding the escalator for a couple of floors, head directly to the StairMasters.
This domain specificity of our inferences and reactions works both ways: some problems we can understand in their applications but not in textbooks; others we are better at capturing in the textbook than in the practical application. People can manage to effortlessly solve a problem in a social situation but struggle when it is presented as an abstract logical problem. We tend to use different mental machinery—so-called modules—in different situations: our brain lacks a central all-purpose computer that starts with logical rules and applies them equally to all possible situations.
And as I’ve said, we can commit
a logical mistake in reality but not in the classroom
. This asymmetry is best visible in cancer detection. Take doctors examining a patient for signs of cancer; tests are typically done on patients who want to know if they are cured or if there is “recurrence.” (In fact, recurrence is a misnomer; it simply means that the treatment did not kill all the cancerous cells and that these undetected malignant cells have started to multiply out of control.) It is not feasible, in the present state of technology, to examine every single one of the patient’s cells to see if all of them are nonmalignant, so the doctor takes a sample by scanning the body with as much precision as possible. Then she makes an assumption about what she did not see. I was once taken aback when a doctor told me after a routine cancer checkup, “Stop worrying, we have evidence of cure.” “Why?” I asked. “There is evidence of
no
cancer” was the reply. “How do you know?” I asked. He replied, “The scan is negative.” Yet he went around calling himself doctor!
An acronym used in the medical literature is NED, which stands for No Evidence of Disease. There is no such thing as END, Evidence of No Disease. Yet my experience discussing this matter with plenty of doctors, even those who publish papers on their results, is that many slip into the round-trip fallacy during conversation.
Doctors in the midst of the scientific arrogance of the 1960s looked down at mothers’ milk as something primitive, as if it could be replicated by their laboratories—not realizing that mothers’ milk might include useful
components that could have eluded their scientific understanding—a simple confusion of
absence of evidence
of the benefits of mothers’ milk with
evidence of absence
of the benefits (another case of Platonicity as “it did not make sense” to breast-feed when we could simply use bottles). Many people paid the price for this naïve inference: those who were not breast-fed as infants turned out to be at an increased risk of a collection of health problems, including a higher likelihood of developing certain types of cancer—there had to be in mothers’ milk some necessary nutrients that still elude us. Furthermore, benefits to mothers who breast-feed were also neglected, such as a reduction in the risk of breast cancer.
Likewise with tonsils: the removal of tonsils may lead to a higher incidence of throat cancer, but for decades doctors never suspected that this “useless” tissue might actually have a use that escaped their detection. The same with the dietary fiber found in fruits and vegetables: doctors in the 1960s found it useless because they saw no immediate evidence of its necessity, and so they created a malnourished generation. Fiber, it turns out, acts to slow down the absorption of sugars in the blood and scrapes the intestinal tract of precancerous cells. Indeed medicine has caused plenty of damage throughout history, owing to this simple kind of inferential confusion.
I am not saying here that doctors should not have beliefs, only that some kinds of definitive, closed beliefs need to be avoided—this is what Menodotus and his school seemed to be advocating with their brand of skeptical-empirical medicine that avoided theorizing. Medicine has gotten better—but many kinds of knowledge have not.
Evidence
By a mental mechanism I call naïve empiricism, we have a natural tendency to look for instances that confirm our story and our vision of the world—these instances are always easy to find. Alas, with tools, and fools, anything can be easy to find. You take past instances that corroborate your theories and you treat them as
evidence
. For instance, a diplomat will show you his “accomplishments,” not what he failed to do. Mathematicians will try to convince you that their science is useful to society by pointing out instances where it proved helpful, not those where it was a waste of time, or, worse, those numerous mathematical applications that inflicted a severe cost on society owing to the highly unempirical nature of elegant mathematical theories.
Even in testing a hypothesis, we tend to look for instances where the hypothesis proved true. Of course we can easily find confirmation; all we have to do is look, or have a researcher do it for us. I can
find confirmation
for just about anything, the way a skilled London cabbie can find traffic to increase the fare, even on a holiday.
Some people go further and give me examples of events that we have been able to foresee with some success—indeed there are a few, like landing a man on the moon and the economic growth of the twenty-first century. One can find plenty of “counterevidence” to the points in this book, the best being that newspapers are excellent at predicting movie and theater schedules. Look, I predicted yesterday that the sun would rise today, and it did!


================================================================================
CHAPTER/SECTION 192 (Item 197)
================================================================================

NEGATIVE EMPIRICISM
The good news is that there is a way around this naïve empiricism. I am saying that a series of corroborative facts is not
necessarily
evidence. Seeing white swans does not confirm the nonexistence of black swans. There is an exception, however: I know what statement is wrong, but not necessarily what statement is correct. If I see a black swan I can certify that
all swans are not white!
If I see someone kill, then I can be practically certain that he is a criminal. If I don’t see him kill, I cannot be certain that he is innocent. The same applies to cancer detection: the finding of a single malignant tumor proves that you have cancer, but the absence of such a finding cannot allow you to say with certainty that you are cancer-free.
We can get closer to the truth by negative instances, not by verification! It is misleading to build a general rule from observed facts. Contrary to conventional wisdom, our body of knowledge does not increase from a series of confirmatory observations, like the turkey’s. But there are some things I can remain skeptical about, and others I can safely consider certain. This makes the consequences of observations one-sided. It is not much more difficult than that.
This asymmetry is immensely practical. It tells us that we do not have to be complete skeptics, just semiskeptics. The subtlety of real life over the books is that, in your decision making, you need be interested only in one side of the story: if you seek
certainty
about whether the patient has cancer, not
certainty
about whether he is healthy, then you might be satisfied with negative inference, since it will supply you the certainty you seek. So
we can learn a lot from data—but not as much as we expect. Sometimes a lot of data can be meaningless; at other times one single piece of information can be very meaningful. It is true that a thousand days cannot prove you right, but one day can prove you to be wrong.
The person who is credited with the promotion of this idea of one-sided semiskepticism is Sir Doktor Professor Karl Raimund Popper, who may be the only philosopher of science who is actually read and discussed by actors in the real world (though not as enthusiastically by professional philosophers). As I am writing these lines, a black-and-white picture of him is hanging on the wall of my study. It was a gift I got in Munich from the essayist Jochen Wegner, who, like me, considers Popper to be about all “we’ve got” among modern thinkers—well, almost. He writes to us, not to other philosophers. “We” are the empirical decision makers who hold that uncertainty is our discipline, and that understanding how to act under conditions of incomplete information is the highest and most urgent human pursuit.
Popper generated a large-scale theory around this asymmetry, based on a technique called “falsification” (to falsify is to prove wrong) meant to distinguish between science and nonscience, and people immediately started splitting hairs about its technicalities, even though it is not the most interesting, or the most original, of Popper’s ideas. This idea about the asymmetry of knowledge is so liked by practitioners, because it is obvious to them; it is the way they run their business. The philosopher
maudit
Charles Sanders Peirce, who, like an artist, got only posthumous respect, also came up with a version of this Black Swan solution when Popper was wearing diapers—some people even called it the Peirce-Popper approach. Popper’s far more powerful and original idea is the “open” society, one that relies on skepticism as a modus operandi, refusing and resisting definitive truths. He accused Plato of closing our minds, according to the arguments I described in the Prologue. But Popper’s biggest idea was his insight concerning the fundamental, severe, and incurable unpredictability of the world, and that I will leave for the chapter on prediction.
*
Of course, it is not so easy to “falsify,” i.e., to state that something is wrong with full certainty. Imperfections in your testing method may yield a mistaken “no.” The doctor discovering cancer cells might have faulty
equipment causing optical illusions; or he could be a bell-curve-using economist disguised as a doctor. An eyewitness to a crime might be drunk.
But it remains the case that you know what is wrong with a lot more confidence than you know what is right
. All pieces of information are not equal in importance.
Popper introduced the mechanism of conjectures and refutations, which works as follows: you formulate a (bold) conjecture and you start looking for the observation that would prove you wrong. This is the alternative to our search for confirmatory instances. If you think the task is easy, you will be disappointed—few humans have a natural ability to do this. I confess that I am not one of them; it does not come naturally to me.
*
Counting to Three
Cognitive scientists have studied our natural tendency to look only for corroboration; they call this vulnerability to the corroboration error the
confirmation bias
. There are some experiments showing that people focus only on the books read in Umberto Eco’s library. You can test a given rule either directly, by looking at instances where it works, or indirectly, by focusing on where it does not work. As we saw earlier, disconfirming instances are far more powerful in establishing truth. Yet we tend to not be aware of this property.
The first experiment I know of concerning this phenomenon was done by the psychologist P. C. Wason. He presented subjects with the three-number sequence 2, 4, 6, and asked them to try to guess the rule generating it. Their method of guessing was to produce other three-number sequences, to which the experimenter would respond “yes” or “no” depending on whether the new sequences were consistent with the rule. Once confident with their answers, the subjects would formulate the rule. (Note the similarity of this experiment to the discussion in
Chapter 1
of the way history presents itself to us: assuming history is generated according to some logic, we see only the events, never the rules, but need to guess how it works.) The correct rule was “numbers in ascending order,” nothing more. Very few subjects discovered it because in order to do so they had to offer a series in descending order (that the experimenter would say “no” to). Wason noticed that the subjects had a rule in mind, but gave
him examples aimed at confirming it instead of trying to supply series that were inconsistent with their hypothesis. Subjects tenaciously kept trying to confirm the rules that
they
had made up.
This experiment inspired a collection of similar tests, of which another example: Subjects were asked which questions to ask to find out whether a person was extroverted or not, purportedly for another type of experiment. It was established that subjects supplied mostly questions for which a “yes” answer would
support
the hypothesis.
But there are exceptions. Among them figure chess grand masters, who, it has been shown, actually do focus on where a speculative move might be weak; rookies, by comparison, look for confirmatory instances instead of falsifying ones. But don’t play chess to practice skepticism. Scientists believe that it is the search for their own weaknesses that makes them good chess players, not the practice of chess that turns them into skeptics. Similarly, the speculator George Soros, when making a financial bet, keeps looking for instances that would prove his initial theory wrong. This, perhaps, is true self-confidence: the ability to look at the world without the need to find signs that stroke one’s ego.
*
Sadly, the notion of corroboration is rooted in our intellectual habits and discourse. Consider this comment by the writer and critic John Updike: “When Julian Jaynes … speculates that until late in the second millennium
B.C
. men had no consciousness but were automatically obeying the voices of gods, we are astounded but compelled to follow this remarkable thesis through all the corroborative evidence.” Jaynes’s thesis may be right, but, Mr. Updike, the central problem of knowledge (and the point of this chapter) is that there is no such animal as
corroborative
evidence.
Saw Another Red Mini!
The following point further illustrates the absurdity of confirmation. If you believe that witnessing an additional white swan will bring confirmation that there are no black swans, then you should also accept the statement,
on purely logical grounds, that the sighting of a red Mini Cooper should confirm that there are
no black swans
.
Why? Just consider that the statement “all swans are white” is equivalent to “all nonwhite objects are not swans.” What confirms the latter statement should confirm the former. Therefore, a mind with a confirmation bent would infer that the sighting of a nonwhite object that is not a swan should bring such confirmation. This argument, known as Hempel’s raven paradox, was rediscovered by my friend the (thinking) mathematician Bruno Dupire during one of our intense meditating walks in London—one of those intense walk-discussions, intense to the point of our not noticing the rain. He pointed to a red Mini and shouted, “Look, Nassim, look! No Black Swan!”
Not Everything
We are not naïve enough to believe that someone will be immortal because we have never seen him die, or that someone is innocent of murder because we have never seen him kill. The problem of naïve generalization does not plague us everywhere. But such smart pockets of inductive skepticism tend to involve events that we have encountered in our natural environment, matters from which we have learned to avoid foolish generalization.
For instance, when children are presented with the picture of a single member of a group and are asked to guess the properties of other unseen members, they are capable of selecting
which
attributes to generalize. Show a child a photograph of someone overweight, tell her that he is a member of a tribe, and ask her to describe the rest of the population: she will (most likely) not jump to the conclusion that all the members of the tribe are weight-challenged. But she would respond differently to generalizations involving skin color. If you show her people of dark complexion and ask her to describe their co-tribesmen, she will assume that they too have dark skin.
So it seems that we are endowed with specific and elaborate inductive instincts showing us the way. Contrary to the opinion held by the great David Hume, and that of the British empiricist tradition, that
belief arises from custom
, as they assumed that we learn generalizations solely from experience and empirical observations, it was shown from studies of infant behavior that we come equipped with mental machinery that causes us to
selectively
generalize from experiences (i.e., to selectively acquire inductive learning in some domains but remain skeptical in others). By doing so, we are not learning from a mere thousand days, but benefiting, thanks to evolution, from the learning of our ancestors—which found its way into our biology.
Back to Mediocristan
And we may have learned things wrong from our ancestors. I speculate here that we probably inherited the instincts adequate for survival in the East African Great Lakes region where we presumably hail from, but these instincts are certainly not well adapted to the present, post-alphabet, intensely informational, and statistically complex environment.
Indeed our environment is a bit more complex than we (and our institutions) seem to realize. How? The modern world, being Extremistan, is dominated by rare—very rare—events. It can deliver a Black Swan after thousands and thousands of white ones, so we need to withhold judgment for longer than we are inclined to. As I said in
Chapter 3
, it is impossible—biologically impossible—to run into a human several hundred miles tall, so our intuitions rule these events out. But the sales of a book or the magnitude of social events do not follow such strictures. It takes a lot more than a thousand days to accept that a writer is ungifted, a market will not crash, a war will not happen, a project is hopeless, a country is “our ally,” a company will not go bust, a brokerage-house security analyst is not a charlatan, or a neighbor will not attack us. In the distant past, humans could make inferences far more accurately and quickly.
Furthermore, the sources of Black Swans today have multiplied beyond measurability.
*
In the primitive environment they were limited to newly encountered wild animals, new enemies, and abrupt weather changes. These events were repeatable enough for us to have built an innate fear of them. This instinct to make inferences rather quickly, and to “tunnel” (i.e., focus on a small number of sources of uncertainty, or causes of known Black Swans) remains rather ingrained in us. This instinct, in a word, is our predicament.
*
Neither Peirce nor Popper was the first to come up with this asymmetry. The philosopher Victor Brochard mentioned the importance of negative empiricism in 1878, as if it were a matter held by the empiricists to be the sound way to do business—ancients understood it implicitly. Out-of-print books deliver many surprises.
*
As I said in the Prologue, the likely not happening is also a Black Swan. So disconfirming the likely is equivalent to confirming the unlikely.
*
This confirmation problem pervades our modern life, since most conflicts have at their root the following mental bias: when Arabs and Israelis watch news reports they see different stories in the same succession of events. Likewise, Democrats and Republicans look at different parts of the same data and never converge to the same opinions. Once your mind is inhabited with a certain view of the world, you will tend to only consider instances proving you to be right. Paradoxically, the more information you have, the more justified you will feel in your views.
*
Clearly, weather-related and geodesic events (such as tornadoes and earthquakes) have not changed much over the past millennium, but what have changed are the socioeconomic consequences of such occurrences. Today, an earthquake or hurricane commands more and more severe economic consequences than it did in the past because of the interlocking relationships between economic entities and the intensification of the “network effects” that we will discuss in Part Three. Matters that used to have mild effects now command a high impact. Tokyo’s 1923 earthquake caused a drop of about a third in Japan’s GNP. Extrapolating from the tragedy of Kobe in 1994, we can easily infer that the consequences of another such earthquake in Tokyo would be far costlier than that of its predecessor.


================================================================================
CHAPTER/SECTION 193 (Item 198)
================================================================================

Chapter Six
THE NARRATIVE FALLACY
The cause of the because—How to split a brain—Effective methods of pointing at the ceiling—Dopamine will help you win—I will stop riding motorcycles (but not today)—Both empirical and psychologist? Since when?


================================================================================
CHAPTER/SECTION 194 (Item 199)
================================================================================

ON THE CAUSES OF MY REJECTION OF CAUSES
During the fall of 2004, I attended a conference on aesthetics and science in Rome, perhaps the best possible location for such a meeting since aesthetics permeates everything there, down to one’s personal behavior and tone of voice. At lunch, a prominent professor from a university in southern Italy greeted me with extreme enthusiasm. I had listened earlier that morning to his impassioned presentation; he was so charismatic, so convinced, and so convincing that, although I could not understand much of what he said, I found myself fully agreeing with everything. I could only make out a sentence here and there, since my knowledge of Italian worked better in cocktail parties than in intellectual and scholarly venues. At some point during his speech, he turned all red with anger—thus convincing me (and the audience) that he was definitely right.
He assailed me during lunch to congratulate me for showing the effects of those causal links that are more prevalent in the human mind than in reality. The conversation got so animated that we stood together near the
buffet table, blocking the other delegates from getting close to the food. He was speaking accented French (with his hands), I was answering in primitive Italian (with my hands), and we were so vivacious that the other guests were afraid to interrupt a conversation of such importance and animation. He was emphatic about my previous book on randomness, a sort of angry trader’s reaction against blindness to luck in life and in the markets, which had been published there under the musical title
Giocati dal caso
. I had been lucky to have a translator who knew almost more about the topic than I did, and the book found a small following among Italian intellectuals. “I am a huge fan of your ideas, but I feel slighted. These are truly mine too, and you wrote the book that I (almost) planned to write,” he said. “You are a lucky man; you presented in such a comprehensive way the effect of chance on society and the overestimation of cause and effect. You show how stupid we are to systematically try to
explain
skills.”
He stopped, then added, in a calmer tone: “But,
mon cher ami
, let me tell you
quelque chose
[uttered very slowly, with his thumb hitting his index and middle fingers]: had you grown up in a Protestant society where people are told that efforts are linked to rewards and individual responsibility is emphasized, you would never have seen the world in such a manner. You were able to see luck and separate cause and effect
because
of your Eastern Orthodox Mediterranean heritage.” He was using the French
à cause
. And he was so convincing that, for a minute, I agreed with his interpretation.
We like stories, we like to summarize, and we like to simplify, i.e., to reduce the dimension of matters. The first of the problems of human nature that we examine in this section, the one just illustrated above, is what I call the
narrative fallacy
. (It is actually a fraud, but, to be more polite, I will call it a fallacy.) The fallacy is associated with our vulnerability to overinterpretation and our predilection for compact stories over raw truths. It severely distorts our mental representation of the world; it is particularly acute when it comes to the rare event.
Notice how my thoughtful Italian fellow traveler shared my militancy against overinterpretation and against the overestimation of cause, yet was unable to see me and my work without a reason, a cause, tagged to both, as anything other than part of a story. He had to
invent
a cause. Furthermore, he was not aware of his having fallen into the causation trap, nor was I immediately aware of it myself.
The narrative fallacy addresses our limited ability to look at sequences
of facts without weaving an explanation into them, or, equivalently, forcing a logical link, an
arrow of relationship
, upon them. Explanations bind facts together. They make them all the more easily remembered; they help them
make more sense
. Where this propensity can go wrong is when it increases our
impression
of understanding.
This chapter will cover, just like the preceding one, a single problem, but seemingly in different disciplines. The problem of narrativity, although extensively studied in one of its versions by psychologists, is not so “psychological”: something about the way disciplines are designed masks the point that it is more generally a problem of
information
. While narrativity comes from an ingrained biological need to reduce dimensionality, robots would be prone to the same process of reduction. Information
wants
to be reduced.
To help the reader locate himself: in studying the problem of induction in the previous chapter, we examined what could be inferred about the unseen, what lies
outside
our information set. Here, we look at the seen, what lies
within
the information set, and we examine the distortions in the act of processing it. There is plenty to say on this topic, but the angle I take concerns narrativity’s simplification of the world around us and its effects on our perception of the Black Swan and wild uncertainty.


================================================================================
CHAPTER/SECTION 195 (Item 200)
================================================================================

SPLITTING BRAINS
Ferreting out antilogics is an exhilarating activity. For a few months, you experience the titillating sensation that you’ve just entered a new world. After that, the novelty fades, and your thinking returns to business as usual. The world is dull again until you find another subject to be excited about (or manage to put another hotshot in a state of total rage).
For me, one such antilogic came with the discovery—thanks to the literature on cognition—that, counter to what everyone believes,
not theorizing
is an act—that theorizing can correspond to the absence of willed activity, the “default” option. It takes considerable effort to see facts (and remember them) while withholding judgment and resisting explanations. And this theorizing disease is rarely under our control: it is largely anatomical, part of our biology, so fighting it requires fighting one’s own self. So the ancient skeptics’ precepts to withhold judgment go against our nature. Talk is cheap, a problem with advice-giving philosophy we will see in
Chapter 13
.
Try to be a true skeptic with respect to your interpretations and you will be worn out in no time. You will also be humiliated for resisting to theorize. (There are tricks to achieving true skepticism; but you have to go through the back door rather than engage in a frontal attack on yourself.) Even from an anatomical perspective, it is impossible for our brain to see anything in raw form without some interpretation. We may not even always be conscious of it.
Post hoc rationalization
. In an experiment, psychologists asked women to select from among twelve pairs of nylon stockings the ones they preferred. The researchers then asked the women their reasons for their choices. Texture, “feel,” and color featured among the selected reasons. All the pairs of stockings were, in fact, identical. The women supplied backfit,
post hoc
explanations. Does this suggest that we are better at explaining than at understanding? Let us see.
A series of famous experiments on split-brain patients gives us convincing physical—that is, biological—evidence of the automatic aspect of the act of interpretation. There appears to be a sense-making organ in us—though it may not be easy to zoom in on it with any precision. Let us see how it is detected.
Split-brain patients have no connection between the left and the right sides of their brains, which prevents information from being shared between the two cerebral hemispheres. These patients are jewels, rare and invaluable for researchers. You literally have two different persons, and you can communicate with each one of them separately; the differences between the two individuals give you some indication about the specialization of each of the hemispheres. This splitting is usually the result of surgery to remedy more serious conditions like severe epilepsy; no, scientists in Western countries (and most Eastern ones) are no longer allowed to cut human brains in half, even if it is for the pursuit of knowledge and wisdom.
Now, say that you induced such a person to perform an act—raise his finger, laugh, or grab a shovel—in order to ascertain how he ascribes a reason to his act (when in fact you know that there is no reason for it other than your inducing it). If you ask the right hemisphere, here isolated from the left side, to perform the action, then ask the other hemisphere for an explanation, the patient will invariably offer some interpretation: “I was pointing at the ceiling in order to …,” “I saw something interesting on the wall,” or, if you ask this author, I will offer my usual “because I am originally from the Greek Orthodox village of Amioun, northern Lebanon,” et cetera.
Now, if you do the opposite, namely instruct the isolated left hemisphere of a right-handed person to perform an act and ask the right hemisphere for the reasons, you will be plainly told, “I don’t know.” Note that the left hemisphere is where language and deduction generally reside. I warn the reader hungry for “science” against attempts to build a neural map: all I’m trying to show is the biological basis of this tendency toward causality, not its precise location. There are reasons for us to be suspicious of these “right brain/left brain” distinctions and subsequent pop-science generalizations about personality. Indeed, the idea that the left brain controls language may not be so accurate: the left brain seems more precisely to be where pattern interpretation resides, and it may control language only insofar as language has a pattern-interpretation attribute. Another difference between the hemispheres is that the right brain deals with novelty. It tends to see the gestalt (the general, or the forest), in a parallel mode, while the left brain is concerned with the trees, in a serial mode.
To see an illustration of our biological dependence on a story, consider the following experiment. First, read this:
A BIRD IN THE
THE HAND IS WORTH
TWO IN THE BUSH
Do you see anything unusual? Try again.
*
The Sydney-based brain scientist Alan Snyder (who has a Philadelphia accent) made the following discovery. If you inhibit the left hemisphere of a right-handed person (more technically, by directing low-frequency magnetic pulses into the left frontotemporal lobes), you lower his rate of error in reading the above caption. Our propensity to impose meaning and concepts blocks our awareness of the details making up the concept. However, if you zap people’s left hemispheres, they become more realistic—they can draw better and with more verisimilitude. Their minds become better at seeing the objects themselves, cleared of theories, narratives, and prejudice.
Why is it hard to avoid interpretation? It is key that, as we saw with the vignette of the Italian scholar, brain functions often operate outside our awareness. You interpret pretty much as you perform other activities deemed automatic and outside your control, like breathing.
What makes nontheorizing
cost
you so much more energy than theorizing? First, there is the impenetrability of the activity. I said that much of it takes place outside of our awareness: if you don’t know that you are making the inference, how can you stop yourself unless you stay in a continuous state of alert? And if you need to be continuously on the watch, doesn’t that cause fatigue? Try it for an afternoon and see.
A Little More Dopamine
In addition to the story of the left-brain interpreter, we have more physiological evidence of our ingrained pattern seeking, thanks to our growing knowledge of the role of neurotransmitters, the chemicals that are assumed to transport signals between different parts of the brain. It appears that pattern perception increases along with the concentration in the brain of the chemical dopamine. Dopamine also regulates moods and supplies an internal reward system in the brain (not surprisingly, it is found in slightly higher concentrations in the left side of the brains of right-handed persons than on the right side). A higher concentration of dopamine appears to lower skepticism and result in greater vulnerability to pattern detection; an injection of L-dopa, a substance used to treat patients with Parkinson’s disease, seems to increase such activity and lowers one’s suspension of belief. The person becomes vulnerable to all manner of fads, such as astrology, superstitions, economics, and tarot-card reading.
Actually, as I am writing this, there is news of a pending lawsuit by a patient going after his doctor for more than $200,000—an amount he allegedly lost while gambling. The patient claims that the treatment of his Parkinson’s disease caused him to go on wild betting sprees in casinos. It turns out that one of the side effects of L-dopa is that a small but significant minority of patients become compulsive gamblers. Since such gambling is associated with their seeing what they believe to be clear patterns in random numbers, this illustrates the
relation between knowledge and randomness
. It also shows that some aspects of what we call “knowledge” (and what I call narrative) are an ailment.
Once again, I warn the reader that I am not focusing on dopamine as the
reason
for our overinterpreting; rather, my point is that there is a physical and neural correlate to such operation and that our minds are largely victims of our physical embodiment. Our minds are like inmates, captive to our biology, unless we manage a cunning escape. It is the lack of our control of such inferences that I am stressing. Tomorrow, someone may
discover another chemical or organic basis for our perception of patterns, or counter what I said about the left-brain interpreter by showing the role of a more complex structure; but it would not negate the idea that perception of causation has a biological foundation.
Andrey Nikolayevich’s Rule
There is another, even deeper reason for our inclination to narrate, and it is not psychological. It has to do with the effect of order on information storage and retrieval in any system, and it’s worth explaining here because of what I consider the central problems of probability and information theory.
The first problem is that information is
costly to obtain
.
The second problem is that information is also
costly to store
—like real estate in New York. The more orderly, less random, patterned, and
narratized
a series of words or symbols, the easier it is to store that series in one’s mind or jot it down in a book so your grandchildren can read it someday.
Finally, information is costly to manipulate and retrieve.
With so many brain cells—one hundred billion (and counting)—the attic is quite large, so the difficulties probably do not arise from storage-capacity limitations, but may be just indexing problems. Your conscious, or working, memory, the one you are using to read these lines and make sense of their meaning, is considerably smaller than the attic. Consider that your working memory has difficulty holding a mere phone number longer than seven digits. Change metaphors slightly and imagine that your consciousness is a desk in the Library of Congress: no matter how many books the library holds, and makes available for retrieval, the size of your desk sets some processing limitations. Compression is vital to the performance of conscious work.
Consider a collection of words glued together to constitute a 500-page book. If the words are purely random, picked up from the dictionary in a totally unpredictable way, you will not be able to summarize, transfer, or reduce the dimensions of that book without losing something significant from it. You need 100,000 words to carry the exact message of a random 100,000 words with you on your next trip to Siberia. Now consider the opposite: a book filled with the repetition of the following sentence: “The chairman of
[insert here your company name]
is a lucky fellow who happened to be in the right place at the right time and claims credit for the
company’s success, without making a single allowance for luck,” running ten times per page for 500 pages. The entire book can be accurately compressed, as I have just done, into 34 words (out of 100,000); you could reproduce it with total fidelity out of such a kernel. By finding the pattern, the logic of the series, you no longer need to memorize it all. You just store the pattern. And, as we can see here, a pattern is obviously more compact than raw information. You looked into the book and found a
rule
. It is along these lines that the great probabilist Andrey Nikolayevich Kolmogorov defined the degree of randomness; it is called “Kolmogorov complexity.”
We, members of the human variety of primates, have a hunger for rules because we need to reduce the dimension of matters so they can get into our heads. Or, rather, sadly, so we can
squeeze
them into our heads. The more random information is, the greater the dimensionality, and thus the more difficult to summarize. The more you summarize, the more order you put in, the less randomness. Hence
the same condition that makes us simplify pushes us to think that the world is less random than it actually is
.
And the Black Swan is what we leave out of simplification.
Both the artistic and scientific enterprises are the product of our need to reduce dimensions and inflict some order on things. Think of the world around you, laden with trillions of details. Try to describe it and you will find yourself tempted to weave a thread into what you are saying. A novel, a story, a myth, or a tale, all have the same function: they spare us from the complexity of the world and shield us from its randomness. Myths impart order to the disorder of human perception and the perceived “chaos of human experience.”
*
Indeed, many severe psychological disorders accompany the feeling of loss of control of—being able to “make sense” of—one’s environment.
Platonicity affects us here once again. The very same desire for order, interestingly, applies to scientific pursuits—it is just that, unlike art, the (stated) purpose of science is to get to the truth, not to give you a feeling of organization or make you feel better. We tend to use knowledge as therapy.
A Better Way to Die
To view the potency of narrative, consider the following statement: “The king died and the queen died.” Compare it to “The king died, and then the queen died of grief.” This exercise, presented by the novelist E. M. Forster, shows the distinction between mere succession of information and a plot. But notice the hitch here: although we added information to the second statement, we effectively reduced the dimension of the total. The second sentence is, in a way, much lighter to carry and easier to remember; we now have one single piece of information in place of two. As we can remember it with less effort, we can also sell it to others, that is, market it better as a packaged idea. This, in a nutshell, is the definition and function of a
narrative
.
To see how the narrative can lead to a mistake in the assessment of the odds, do the following experiment. Give someone a well-written detective story—say, an Agatha Christie novel with a handful of characters who can all be plausibly deemed guilty. Now question your subject about the probabilities of each character’s being the murderer. Unless she writes down the percentages to keep an exact tally of them, they should add up to well over 100 percent (even well over 200 percent for a good novel). The better the detective writer, the higher that number.


================================================================================
CHAPTER/SECTION 196 (Item 201)
================================================================================

REMEMBRANCE OF THINGS NOT QUITE PAST
Our tendency to perceive—to impose
—narrativity
and
causality
are symptoms of the same disease—dimension reduction. Moreover, like causality, narrativity has a chronological dimension and leads to the perception of the flow of time. Causality makes time flow in a single direction, and so does narrativity.
But memory and the arrow of time can get mixed up. Narrativity can viciously affect the remembrance of past events as follows: we will tend to more easily remember those facts from our past that fit a narrative, while we tend to neglect others that do not
appear
to play a causal role in that narrative. Consider that we recall events in our memory all the while knowing the answer of what happened subsequently. It is literally impossible to ignore posterior information when solving a problem. This simple inability to remember not the true sequence of events but a reconstructed one will make history appear in hindsight to be far more explainable than it actually was—or is.
Conventional wisdom holds that memory is like a serial recording device like a computer diskette. In reality, memory is dynamic—not static—like a paper on which new texts (or new versions of the same text) will be continuously recorded, thanks to the power of posterior information. (In a remarkable insight, the nineteenth-century Parisian poet Charles Baudelaire compared our memory to a palimpsest, a type of parchment on which old texts can be erased and new ones written over them.) Memory is more of a self-serving dynamic revision machine: you remember the last time you remembered the event and, without realizing it,
change the story at every subsequent remembrance
.
So we pull memories along causative lines, revising them involuntarily and unconsciously. We continuously renarrate past events in the light of what appears to make what we think of as logical sense after these events occur.
By a process called reverberation, a memory corresponds to the strengthening of connections from an increase of brain activity in a given sector of the brain—the more activity, the stronger the memory. While we believe that the memory is fixed, constant, and connected, all this is very far from truth. What makes sense according to information obtained subsequently will be remembered more vividly. We invent some of our memories—a sore point in courts of law since it has been shown that plenty of people have invented child-abuse stories by dint of listening to theories.
The Madman’s Narrative
We have far too many possible ways to interpret past events for our own good.
Consider the behavior of paranoid people. I have had the privilege to work with colleagues who have hidden paranoid disorders that come to the surface on occasion. When the person is highly intelligent, he can astonish you with the most far-fetched, yet completely plausible interpretations of the most innocuous remark. If I say to them, “I am afraid that …,” in reference to an undesirable state of the world, they may interpret it literally, that I am experiencing actual fright, and it triggers an episode of fear on the part of the paranoid person. Someone hit with such a disorder can muster the most insignificant of details and construct an elaborate and coherent theory of why there is a conspiracy against him. And if you gather, say, ten paranoid people, all in the same state of
episodic delusion, the ten of them will provide ten distinct, yet coherent, interpretations of events.
When I was about seven, my schoolteacher showed us a painting of an assembly of impecunious Frenchmen in the Middle Ages at a banquet held by one of their benefactors, some benevolent king, as I recall. They were holding the soup bowls to their lips. The schoolteacher asked me why they had their noses in the bowls and I answered, “Because they were not taught manners.” She replied, “Wrong. The reason is that they are hungry.” I felt stupid at not having thought of this, but I could not understand what made one explanation more likely than the other, or why we weren’t both wrong (there was no, or little, silverware at the time, which seems the most likely explanation).
Beyond our perceptional distortions, there is a problem with logic itself. How can someone have no clue yet be able to hold a set of perfectly sound and coherent viewpoints that match the observations and abide by every single possible rule of logic? Consider that two people can hold incompatible beliefs based on the exact same data. Does this mean that there are possible families of explanations and that each of these can be equally perfect and sound? Certainly not. One may have a million ways to explain things, but the true explanation is unique, whether or not it is within our reach.
In a famous argument, the logician W. V. Quine showed that there exist families of logically consistent interpretations and theories that can match a given series of facts. Such insight should warn us that mere absence of nonsense may not be sufficient to make something true.
Quine’s problem is related to his finding difficulty in translating statements between languages, simply because one could interpret any sentence in an infinity of ways. (Note here that someone splitting hairs could find a self-canceling aspect to Quine’s own writing. I wonder how he expects us to understand this very point in a noninfinity of ways).
This does not mean that we cannot talk about causes; there are ways to escape the narrative fallacy. How? By making conjectures and running experiments, or as we will see in Part Two (alas), by making testable predictions.
*
The psychology experiments I am discussing here do so: they select a population and run a test. The results should hold in Tennessee, in China, even in France.
Narrative and Therapy
If narrativity causes us to see past events as more predictable, more expected, and less random than they actually were, then we should be able to make it work for us as therapy against some of the stings of randomness.
Say some unpleasant event, such as a car accident for which you feel indirectly responsible, leaves you with a bad lingering aftertaste. You are tortured by the thought that you caused injuries to your passengers; you are continuously aware that you could have avoided the accident. Your mind keeps playing alternative scenarios branching out of a main tree: if you did not wake up three minutes later than usual, you would have avoided the car accident. It was not your intension to injure your passengers, yet your mind is inhabited with remorse and guilt. People in professions with high randomness (such as in the markets) can suffer more than their share of the toxic effect of look-back stings: I should have sold my portfolio at the top; I could have bought that stock years ago for pennies and I would now be driving a pink convertible; et cetera. If you are a professional, you can feel that you “made a mistake,” or, worse, that “mistakes were made,” when you failed to do the equivalent of buying the winning lottery ticket for your investors, and feel the need to apologize for your “reckless” investment strategy (that is, what seems reckless in retrospect).
How can you get rid of such a persistent throb? Don’t try to willingly avoid thinking about it: this will almost surely backfire. A more appropriate solution is to make the event appear more unavoidable. Hey, it was bound to take place and it seems futile to agonize over it. How can you do so? Well,
with a narrative
. Patients who spend fifteen minutes every day writing an account of their daily troubles feel indeed better about what has befallen them. You feel less guilty for not having avoided certain events; you feel less responsible for it. Things appear as if they were bound to happen.
If you work in a randomness-laden profession, as we see, you are likely to suffer burnout effects from that constant second-guessing of your past actions in terms of what played out subsequently. Keeping a diary is the least you can do in these circumstances.


================================================================================
CHAPTER/SECTION 197 (Item 202)
================================================================================

TO BE WRONG WITH INFINITE PRECISION
We harbor a crippling dislike for the abstract.
One day in December 2003, when Saddam Hussein was captured, Bloomberg News flashed the following headline at 13:01:
U.S. TREASURIES RISE; HUSSEIN CAPTURE MAY NOT CURB TERRORISM
.
Whenever there is a market move, the news media feel obligated to give the “reason.” Half an hour later, they had to issue a new headline. As these U.S. Treasury bonds fell in price (they fluctuate all day long, so there was nothing special about that), Bloomberg News had a new reason for the fall: Saddam’s capture (the same Saddam). At 13:31 they issued the next bulletin:
U.S. TREASURIES FALL; HUSSEIN CAPTURE BOOSTS ALLURE OF RISKY ASSETS
.
So it was the same capture (the cause) explaining one event and its exact opposite. Clearly, this can’t be; these two facts cannot be linked.
Do media journalists repair to the nurse’s office every morning to get their daily dopamine injection so that they can narrate better? (Note the irony that the word
dope
, used to designate the illegal drugs athletes take to improve performance, has the same root as
dopamine.)
It happens all the time: a cause is proposed to make you swallow the news and make matters more concrete. After a candidate’s defeat in an election, you will be supplied with the “cause” of the voters’ disgruntlement. Any conceivable cause can do. The media, however, go to great lengths to make the process “thorough” with their armies of fact-checkers. It is as if they wanted to be wrong with infinite precision (instead of accepting being approximately right, like a fable writer).
Note that in the absence of any other information about a person you encounter, you tend to fall back on her nationality and background as a salient attribute (as the Italian scholar did with me). How do I know that this attribution to the background is bogus? I did my own empirical test by checking how many traders with my background who experienced the same war became skeptical empiricists, and found none out of twenty-six. This nationality business helps you make a great story and satisfies your hunger for ascription of causes. It seems to be the dump site where all explanations go until one can ferret out a more obvious one (such as, say, some evolutionary argument that “makes sense”). Indeed, people tend to fool themselves with their self-narrative of “national identity,” which, in a breakthrough paper in
Science
by sixty-five authors, was shown to be a total fiction. (“National traits” might be great for movies, they might
help a lot with war, but they are Platonic notions that carry no empirical validity—yet, for example, both the English and the non-English erroneously believe in an English “national temperament.”) Empirically, sex, social class, and profession seem to be better predictors of someone’s behavior than nationality (a male from Sweden resembles a male from Togo more than a female from Sweden; a philosopher from Peru resembles a philosopher from Scotland more than a janitor from Peru; and so on).
The problem of overcausation does not lie with the journalist, but with the public. Nobody would pay one dollar to buy a series of abstract statistics reminiscent of a boring college lecture. We want to be told stories, and there is nothing wrong with that—except that we should check more thoroughly whether the story provides consequential distortions of reality. Could it be that fiction reveals truth while nonfiction is a harbor for the liar? Could it be that fables and stories are closer to the truth than is the thoroughly fact-checked ABC News? Just consider that the newspapers try to get impeccable facts, but weave them into a narrative in such a way as to convey the impression of causality (and knowledge). There are fact-checkers, not intellect-checkers. Alas.
But there is no reason to single out journalists. Academics in narrative disciplines do the same thing, but dress it up in a formal language—we will catch up to them in
Chapter 10
, on prediction.
Besides narrative and causality, journalists and public intellectuals of the sound-bite variety do not make the world simpler. Instead, they almost invariably make it look far more complicated than it is. The next time you are asked to discuss world events, plead ignorance, and give the arguments I offered in this chapter casting doubt on the visibility of the immediate cause. You will be told that “you overanalyze,” or that “you are too complicated.” All you will be saying is that you don’t know!
Dispassionate Science
Now, if you think that science is an abstract subject free of sensationalism and distortions, I have some sobering news. Empirical researchers have found evidence that scientists too are vulnerable to narratives, emphasizing titles and “sexy” attention-grabbing punch lines over more substantive matters. They too are human and get their attention from sensational matters. The way to remedy this is through meta-analyses of scientific studies, in which an überresearcher peruses the entire literature, which includes the less-advertised articles, and produces a synthesis.


================================================================================
CHAPTER/SECTION 198 (Item 203)
================================================================================

THE SENSATIONAL AND THE BLACK SWAN
Let us see how narrativity affects our understanding of the Black Swan. Narrative, as well as its associated mechanism of salience of the sensational fact, can mess up our projection of the odds. Take the following experiment conducted by Kahneman and Tversky, the pair introduced in the previous chapter: the subjects were forecasting professionals who were asked to imagine the following scenarios and estimate their odds.
A massive flood somewhere in America in which more than a thousand people die.
An earthquake in California
, causing massive flooding, in which more than a thousand people die.
Respondents estimated the first event to be
less
likely than the second. An earthquake in California, however, is a readily imaginable
cause
, which greatly increases the mental availability—hence the assessed probability—of the flood scenario.
Likewise, if I asked you how many cases of lung cancer are likely to take place in the country, you would supply some number, say half a million. Now, if instead I asked you many cases of lung cancer are likely to take place
because
of smoking, odds are that you would give me a much higher number (I would guess more than twice as high). Adding the
because
makes these matters far more plausible, and far more
likely
. Cancer from smoking seems more likely than cancer without a cause attached to it—an unspecified cause means no cause at all.
I return to the example of E. M. Forster’s plot from earlier in this chapter, but seen from the standpoint of probability. Which of these two statements seems more likely?
Joey seemed happily married. He killed his wife
.
Joey seemed happily married. He killed his wife to get her inheritance
.
Clearly the second statement seems more likely at first blush, which is a pure mistake of logic, since the first, being broader, can accommodate more causes, such as he killed his wife because he went mad, because she cheated with both the postman and the ski instructor, because he entered a state of delusion and mistook her for a financial forecaster.
All this can lead to pathologies in our decision making. How?
Just imagine that, as shown by Paul Slovic and his collaborators, people
are more likely to pay for terrorism insurance than for plain insurance (which covers, among other things, terrorism).
The Black Swans we imagine, discuss, and worry about do not resemble those likely to be Black Swans. We worry about the wrong “improbable” events, as we will see next.
Black Swan Blindness
The first question about the paradox of the perception of Black Swans is as follows: How is it that
some
Black Swans are overblown in our minds when the topic of this book is that we mainly neglect Black Swans?
The answer is that there are two varieties of rare events: a) the
narrated
Black Swans, those that are present in the current discourse and that you are likely to hear about on television, and b) those nobody talks about, since they escape models—those that you would feel ashamed discussing in public because they do not seem plausible. I can safely say that it is entirely compatible with human nature that the incidences of Black Swans would be overestimated in the first case, but severely underestimated in the second one.
Indeed, lottery buyers overestimate their chances of winning because they visualize such a potent payoff—in fact, they are so blind to the odds that they treat odds of one in a thousand and one in a million almost in the same way.
Much of the empirical research agrees with this pattern of overestimation and underestimation of Black Swans. Kahneman and Tversky initially showed that people overreact to low-probability outcomes
when you discuss the event with them
, when you make them aware of it. If you ask someone, “What is the probability of death from a plane crash?” for instance, they will raise it. However, Slovic and his colleagues found, in insurance patterns, neglect of these highly improbable events in people’s insurance purchases. They call it the “preference for insuring against probable small losses”—at the expense of the less probable but larger impact ones.
Finally, after years of searching for empirical tests of our scorn of the abstract, I found researchers in Israel that ran the experiments I had been waiting for. Greg Barron and Ido Erev provide experimental evidence that agents underweigh small probabilities when they engage in sequential experiments in which
they derive the probabilities themselves
, when they are
not supplied with the odds. If you draw from an urn with a very small number of red balls and a high number of black ones, and if you do not have a clue about the relative proportions, you are likely to underestimate the number of red balls. It is only when you are supplied with their frequency—say, by telling you that 3 percent of the balls are red—that you overestimate it in your betting decision.
I’ve spent a lot of time wondering how we can be so myopic and shorttermist yet survive in an environment that is not entirely from Mediocristan. One day, looking at the gray beard that makes me look ten years older than I am and thinking about the pleasure I derive from exhibiting it, I realized the following. Respect for elders in many societies might be a kind of compensation for our short-term memory. The word
senate
comes from
senatus
, “aged” in Latin;
sheikh
in Arabic means both a member of the ruling elite and “elder.” Elders are repositories of complicated inductive learning that includes information about rare events. Elders can scare us with stories—which is why we become overexcited when we think of a
specific
Black Swan. I was excited to find out that this also holds true in the animal kingdom: a paper in
Science
showed that elephant matriarchs play the role of superadvisers on rare events.
We learn from repetition—at the expense of events that have not happened before. Events that are nonrepeatable are ignored before their occurrence, and overestimated after (for a while). After a Black Swan, such as September 11, 2001, people expect it to recur when in fact the odds of that happening have arguably been lowered. We like to think about
specific
and known Black Swans when in fact the very nature of randomness lies in its abstraction. As I said in the Prologue, it is the wrong definition of a god.
The economist Hyman Minsky sees the cycles of risk taking in the economy as following a pattern: stability and absence of crises encourage risk taking, complacency, and lowered awareness of the possibility of problems. Then a crisis occurs, resulting in people being shell-shocked and scared of investing their resources. Strangely, both Minsky and his school, dubbed Post-Keynesian, and his opponents, the libertarian “Austrian” economists, have the same analysis, except that the first group recommends governmental intervention to smooth out the cycle, while the second believes that civil servants should not be trusted to deal with such matters. While both schools of thought seem to fight each other, they both emphasize fundamental uncertainty and stand outside the mainstream economic departments (though they have large followings among businessmen
and nonacademics). No doubt this emphasis on fundamental uncertainty bothers the Platonifiers.
All the tests of probability I discussed in this section are important; they show how we are fooled by the rarity of Black Swans but not by the role they play in the aggregate, their
impact
. In a preliminary study, the psychologist Dan Goldstein and I subjected students at the London Business School to examples from two domains, Mediocristan and Extremistan. We selected height, weight, and Internet hits per website. The subjects were good at guessing the role of rare events in Mediocristan-style environments. But their intuitions failed when it came to variables outside Mediocristan, showing that we are effectively not skilled at intuitively gauging the impact of the improbable, such as the contribution of a blockbuster to total book sales. In one experiment they underestimated by thirty-three times the
effect
of a rare event.
Next, let us see how this lack of understanding of abstract matters affects us.
The Pull of the Sensational
Indeed, abstract statistical information does not sway us as much as the anecdote—no matter how sophisticated the person. I will give a few instances.
The Italian Toddler
. In the late 1970s, a toddler fell into a well in Italy. The rescue team could not pull him out of the hole and the child stayed at the bottom of the well, helplessly crying. Understandably, the whole of Italy was concerned with his fate; the entire country hung on the frequent news updates. The child’s cries produced acute pains of guilt in the powerless rescuers and reporters. His picture was prominently displayed on magazines and newspapers, and you could hardly walk in the center of Milan without being reminded of his plight.
Meanwhile, the civil war was raging in Lebanon, with an occasional hiatus in the conflict. While in the midst of their mess, the Lebanese were also absorbed in the fate of that child. The
Italian
child. Five miles away, people were dying from the war, citizens were threatened with car bombs, but the fate of the Italian child ranked high among the interests of the population in the Christian quarter of Beirut. “Look how cute that poor thing is,” I was told. And the entire town expressed relief upon his eventual rescue.
As Stalin, who knew something about the business of mortality, supposedly said, “One death is a tragedy; a million is a statistic.” Statistics stay silent in us.
Terrorism kills, but the biggest killer remains the environment, responsible for close to 13 million deaths annually. But terrorism causes outrage, which makes us overestimate the likelihood of a potential terrorist attack—and react more violently to one when it happens. We feel the sting of man-made damage far more than that caused by nature.
Central Park
. You are on a plane on your way to spend a long (bibulous) weekend in New York City. You are sitting next to an insurance salesman who, being a salesman, cannot stop talking. For him,
not talking
is the effortful activity. He tells you that his cousin (with whom he will celebrate the holidays) worked in a law office with someone whose brother-in-law’s business partner’s twin brother was mugged and killed in Central Park. Indeed, Central Park in glorious New York City. That was in 1989, if he remembers it well (the year is now 2007). The poor victim was only thirty-eight and had a wife and three children, one of whom had a birth defect and needed special care at Cornell Medical Center. Three children, one of whom needed special care, lost their father because of his foolish visit to Central Park.
Well, you are likely to avoid Central Park during your stay. You know you can get crime statistics from the Web or from any brochure, rather than anecdotal information from a verbally incontinent salesman. But you can’t help it. For a while, the name Central Park will conjure up the image of that that poor, undeserving man lying on the polluted grass. It will take a lot of statistical information to override your hesitation.
Motorcycle Riding
. Likewise, the death of a relative in a motorcycle accident is far more likely to influence your attitude toward motorcycles than volumes of statistical analyses. You can effortlessly look up accident statistics on the Web, but they do not easily come to mind. Note that I ride my red Vespa around town, since no one in my immediate environment has recently suffered an accident—although I am aware of this problem in logic, I am incapable of acting on it.
Now, I do not disagree with those recommending the use of a narrative to get attention. Indeed, our consciousness may be linked to our ability to concoct some form of story about ourselves. It is just that narrative can be lethal when used in the wrong places.


================================================================================
CHAPTER/SECTION 199 (Item 204)
================================================================================

THE SHORTCUTS
Next I will go beyond narrative to discuss the more general attributes of thinking and reasoning behind our crippling shallowness. These defects in reasoning have been cataloged and investigated by a powerful research tradition represented by a school called the Society of Judgment and Decision Making (the only academic and professional society of which I am a member, and proudly so; its gatherings are the only ones where I do not have tension in my shoulders or anger fits). It is associated with the school of research started by Daniel Kahneman, Amos Tversky, and their friends, such as Robyn Dawes and Paul Slovic. It is mostly composed of empirical psychologists and cognitive scientists whose methodology hews strictly to running very precise, controlled experiments (physics-style) on humans and making catalogs of how people react, with minimal theorizing. They look for regularities. Note that empirical psychologists use the bell curve to gauge errors in their testing methods, but as we will see more technically in
Chapter 15
, this is one of the rare adequate applications of the bell curve in social science, owing to the nature of the experiments. We have seen such types of experiments earlier in this chapter with the flood in California, and with the identification of the confirmation bias in
Chapter 5
. These researchers have mapped our activities into (roughly) a dual mode of thinking, which they separate as “System 1” and “System 2,” or the
experiential
and the
cogitative
. The distinction is straightforward.
System 1
, the experiential one, is effortless, automatic, fast, opaque (we do not know that we are using it), parallel-processed, and can lend itself to errors. It is what we call “intuition,” and performs these quick acts of prowess that became popular under the name
blink
, after the title of Malcolm Gladwell’s bestselling book. System 1 is highly emotional, precisely because it is quick. It produces shortcuts, called “heuristics,” that allow us to function rapidly and effectively. Dan Goldstein calls these heuristics “fast and frugal.” Others prefer to call them “quick and dirty.” Now, these shortcuts are certainly virtuous, since they are rapid, but, at times, they can lead us into some severe mistakes. This main idea generated an entire school of research called the
heuristics and biases
approach (heuristics corresponds to the study of shortcuts, biases stand for mistakes).
System 2
, the cogitative one, is what we normally call
thinking
. It is what you use in a classroom, as it is effortful (even for Frenchmen), reasoned,
slow, logical, serial, progressive, and self-aware (you can follow the steps in your reasoning). It makes fewer mistakes than the experiential system, and, since you know how you derived your result, you can retrace your steps and correct them in an adaptive manner.
Most of our mistakes in reasoning come from using System 1 when we are in fact thinking that we are using System 2. How? Since we react without thinking and introspection, the main property of System 1 is our lack of awareness of using it!
Recall the round-trip error, our tendency to confuse “no evidence of Black Swans” with “evidence of no Black Swans;” it shows System 1 at work. You have to make an effort (System 2) to override your first reaction. Clearly Mother Nature makes you use the fast System 1 to get out of trouble, so that you do not sit down and cogitate whether there is truly a tiger attacking you or if it is an optical illusion. You run immediately, before you become “conscious” of the presence of the tiger.
Emotions are assumed to be the weapon System 1 uses to direct us and force us to act quickly. It mediates risk avoidance far more effectively than our cognitive system. Indeed, neurobiologists who have studied the emotional system show how it often reacts to the presence of danger long before we are consciously aware of it—we experience fear and start reacting a few milliseconds before we realize that we are facing a snake.
Much of the trouble with human nature resides in our inability to use much of System 2, or to use it in a prolonged way without having to take a long beach vacation. In addition, we often just forget to use it.
Beware the Brain
Note that neurobiologists make, roughly, a similar distinction to that between System 1 and System 2, except that they operate along anatomical lines. Their distinction differentiates between parts of the brain, the
cortical
part, which we are supposed to use for thinking, and which distinguishes us from other animals, and the fast-reacting
limbic
brain, which is the center of emotions, and which we share with other mammals.
As a skeptical empiricist, I do not want to be the turkey, so I do not want to focus solely on specific organs in the brain, since we do not observe brain functions very well. Some people try to identify what are called the neural correlates of, say, decision making, or more aggressively the neural “substrates” of, say, memory. The brain might be more complicated machinery than we think; its anatomy has fooled us repeatedly in
the past. We can, however, assess regularities by running precise and thorough experiments on how people react under certain conditions, and keep a tally of what we see.
For an example that justifies skepticism about unconditional reliance on neurobiology, and vindicates the ideas of the empirical school of medicine to which Sextus belonged, let’s consider the intelligence of birds. I kept reading in various texts that the cortex is where animals do their “thinking,” and that the creatures with the largest cortex have the highest intelligence—we humans have the largest cortex, followed by bank executives, dolphins, and our cousins the apes. Well, it turns out that some birds, such as parrots, have a high level of intelligence, equivalent to that of dolphins, but that the intelligence of birds correlates with the size of another part of the brain, called the hyperstriatum. So neurobiology with its attribute of “hard science” can sometimes (though not always) fool you into a Platonified, reductive statement. I am amazed that the “empirics,” skeptical about links between anatomy and function, had such insight—no wonder their school played a very small part in intellectual history. As a skeptical empiricist I prefer the experiments of empirical psychology to the theories-based MRI scans of neurobiologists, even if the former appear less “scientific” to the public.
How to Avert the Narrative Fallacy
I’ll conclude by saying that our misunderstanding of the Black Swan can be largely attributed to our using System 1, i.e., narratives, and the sensational—as well as the emotional—which imposes on us a wrong map of the likelihood of events. On a day-to-day basis, we are not introspective enough to realize that we understand what is going on a little less than warranted from a dispassionate observation of our experiences. We also tend to forget about the notion of Black Swans immediately after one occurs—since they are too abstract for us—focusing, rather, on the precise and vivid events that easily come to our minds. We do worry about Black Swans, just the wrong ones.
Let me bring Mediocristan into this. In Mediocristan, narratives seem to work—the past is likely to yield to our inquisition. But not in Extremistan, where you do not have repetition, and where you need to remain suspicious of the sneaky past and avoid the easy and obvious narrative.
Given that I have lived largely deprived of information, I’ve often felt that I inhabit a different planet than my peers, which can sometimes be extremely
painful. It’s like they have a virus controlling their brains that prevents them from seeing things going forward—the Black Swan around the corner.
The way to avoid the ills of the narrative fallacy is to favor experimentation over storytelling, experience over history, and clinical knowledge over theories. Certainly the newspaper cannot perform an experiment, but it can choose one report over another—there is plenty of empirical research to present and interpret from—as I am doing in this book. Being empirical does not mean running a laboratory in one’s basement: it is just a mind-set that favors a certain class of knowledge over others. I do not forbid myself from using the word
cause
, but the causes I discuss are either bold speculations (presented as such) or the result of experiments, not stories.
Another approach is to predict and keep a tally of the predictions.
Finally, there may be a way to use a narrative—but for a good purpose. Only a diamond can cut a diamond; we can use our ability to convince with a story that conveys the right message—what storytellers seem to do.
So far we have discussed two internal mechanisms behind our blindness to Black Swans, the confirmation bias and the narrative fallacy. The next chapters will look into an external mechanism: a defect in the way we receive and interpret recorded events, and a defect in the way we act on them.
*
The word
the
is written twice.
*
The Parisian novelist Georges Perec tried to break away from narrative and attempted to write a book as large as the world. He had to settle for an exhaustive account of what happened on the Place Saint-Sulpice between October 18 and October 20, 1974. Even so, his account was not so exhaustive, and he ended up with a narrative.
*
Such tests avoid both the narrative fallacy and much of the confirmation bias, since testers are obliged to take into account the failures as well as the successes of their experiments.


================================================================================
CHAPTER/SECTION 200 (Item 205)
================================================================================

Chapter Seven
LIVING IN THE ANTECHAMBER OF HOPE
How to avoid watercoolers—Select your brother-in-law—Yevgenia’s favorite book—What deserts can and cannot deliver—On the avoidance of hope—
El desierto de los tártaros—
The virtues of slow motion
Assume that, like Yevgenia, your activities depend on a Black Swan surprise—i.e., you are a reverse turkey. Intellectual, scientific, and artistic activities belong to the province of Extremistan, where there is a severe concentration of success, with a very small number of winners claiming a large share of the pot. This seems to apply to all professional activities I find nondull and “interesting” (I am still looking for a single counterexample, a nondull activity that belongs to Mediocristan).
Acknowledging the role of this concentration of success, and acting accordingly, causes us to be punished twice: we live in a society where the reward mechanism is based on the illusion of the regular; our hormonal reward system also needs tangible and steady results. It too thinks that the world is steady and well behaved—it falls for the confirmation error. The world has changed too fast for our genetic makeup. We are alienated from our environment.


================================================================================
CHAPTER/SECTION 201 (Item 206)
================================================================================

PEER CRUELTY
Every morning you leave your cramped apartment in Manhattan’s East Village to go to your laboratory at the Rockefeller University in the East Sixties. You return in the late evening, and people in your social network ask you if you had a good day, just to be polite. At the laboratory, people are more tactful. Of course you did not have a good day; you found nothing. You are not a watch repairman. Your
finding nothing
is very valuable, since it is part of the process of discovery—hey, you know where
not
to look. Other researchers, knowing your results, would avoid trying your special experiment, provided a journal is thoughtful enough to consider your “found nothing” as information and publish it.
Meanwhile your brother-in-law is a salesman for a Wall Street firm, and keeps getting large commissions—large and steady commissions. “He is doing very well,” you hear, particularly from your father-in-law, with a small pensive nanosecond of silence after the utterance—which makes you realize that he just made a comparison. It was involuntary, but he made one.
Holidays can be terrible. You run into your brother-in-law at family reunions and, invariably, detect unmistakable signs of frustration on the part of your wife, who, briefly, fears that she married a loser, before remembering the logic of your profession. But she has to fight her first impulse. Her sister will not stop talking about their renovations, their new wallpaper. Your wife will be a little more silent than usual on the drive home. This sulking will be made slightly worse because the car you are driving is rented, since you cannot afford to garage a car in Manhattan. What should you do? Move to Australia and thereby make family reunions less frequent, or switch brothers-in-laws by marrying someone with a less “successful” brother?
Or should you dress like a hippie and become defiant? That may work for an artist, but not so easily for a scientist or a businessman. You are trapped.
You work on a project that does not deliver immediate or steady results; all the while, people around you work on projects that do. You are in trouble. Such is the lot of scientists, artists, and researchers lost in society rather than living in an insulated community or an artist colony.
Positive lumpy outcomes, for which we either collect big or get nothing, prevail in numerous occupations, those invested with a sense of mission,
such as doggedly pursuing (in a smelly laboratory) the elusive cure for cancer, writing a book that will change the way people view the world (while living hand to mouth), making music, or painting miniature icons on subway trains and considering it a higher form of art despite the diatribes of the antiquated “scholar” Harold Bloom.
If you are a researcher, you will have to publish inconsequential articles in “prestigious” publications so that others say hello to you once in a while when you run into them at conferences.
If you run a public corporation, things were great for you before you had shareholders, when you and your partners were the sole owners, along with savvy venture capitalists who understood uneven results and the lumpy nature of economic life. But now you have a slow-thinking thirty-year-old security analyst at a downtown Manhattan firm who “judges” your results and reads too much into them. He likes routine rewards, and the last thing you can deliver are routine rewards.
Many people labor in life under the impression that they are doing something right, yet they may not show solid results for a long time. They need a capacity for continuously adjourned gratification to survive a steady diet of peer cruelty without becoming demoralized. They look like idiots to their cousins, they look like idiots to their peers, they need courage to continue. No confirmation comes to them, no validation, no fawning students, no Nobel, no Shnobel. “How was your year?” brings them a small but containable spasm of pain deep inside, since almost all of their years will seem wasted to someone looking at their life from the outside. Then bang, the lumpy event comes that brings the grand vindication. Or it may never come.
Believe me, it is tough to deal with the social consequences of the appearance of continuous failure. We are social animals; hell is other people.
Where the Relevant Is the Sensational
Our intuitions are not cut out for nonlinearities. Consider our life in a primitive environment where process and result are closely connected. You are thirsty; drinking brings you adequate satisfaction. Or even in a not-so-primitive environment, when you engage in building, say, a bridge or a stone house, more work will lead to more apparent results, so your mood is propped up by visible continuous feedback.
In a primitive environment, the relevant
is
the sensational. This applies to our knowledge. When we try to collect information about the world
around us, we tend to be guided by our biology, and our attention flows effortlessly toward the sensational—not the relevant so much as the sensational. Somehow the guidance system has gone wrong in the process of our coevolution with our habitat—it was transplanted into a world in which the relevant is often boring, nonsensational.
Furthermore, we think that if, say, two variables are causally linked, then a steady input in one variable should
always
yield a result in the other one. Our emotional apparatus is designed for linear causality. For instance, if you study every day, you expect to learn something in proportion to your studies. If you feel that you are not going anywhere, your emotions will cause you to become demoralized. But modern reality rarely gives us the privilege of a satisfying, linear, positive progression: you may think about a problem for a year and learn nothing; then, unless you are disheartened by the emptiness of the results and give up, something will come to you in a flash.
Researchers spent some time dealing with this notion of gratification; neurology has been enlightening us about the tension between the notions of immediate rewards and delayed ones. Would you like a massage today, or two next week? Well, the news is that the logical part of our mind, that “higher” one, which distinguishes us from animals, can override our animal instinct, which asks for immediate rewards. So we are a little better than animals, after all—but perhaps not by much. And not all of the time.
Nonlinearities
The situation can get a little more tragic—the world is more nonlinear than we think, and than scientists would like to think.
With linearities, relationships between variables are clear, crisp, and constant, therefore Platonically easy to grasp in a single sentence, such as “A 10 percent increase in money in the bank corresponds to a 10 percent increase in interest income and a 5 percent increase in obsequiousness on the part of the personal banker.” If you have more money in the bank, you get more interest. Nonlinear relationships can vary; perhaps the best way to describe them is to say that they cannot be expressed verbally in a way that does justice to them. Take the relationship between pleasure and drinking water. If you are in a state of painful thirst, then a bottle of water increases your well-being significantly. More water means more pleasure. But what if I gave you a cistern of water? Clearly your well-being becomes
rapidly insensitive to further quantities. As a matter of fact, if I gave you the choice between a bottle or a cistern you would prefer the bottle—so your enjoyment
declines
with additional quantities.
These nonlinear relationships are ubiquitous in life. Linear relationships are truly the exception; we only focus on them in classrooms and textbooks because they are easier to understand. Yesterday afternoon I tried to take a fresh look around me to catalog what I could see during my day that was linear. I could not find anything, no more than someone hunting for squares or triangles could find them in the rain forest—or, as we will see in Part Three, any more than someone looking for bell-shape randomness finding it in socioeconomic phenomena.
You play tennis every day with no improvement, then suddenly you start beating the pro.
Your child does not seem to have a learning impediment, but he does not seem to want to speak. The schoolmaster pressures you to start considering “other options,” namely therapy. You argue with her to no avail (she is supposed to be the “expert”). Then, suddenly, the child starts composing elaborate sentences, perhaps a bit too elaborate for his age group. I will repeat that linear progression, a Platonic idea, is not the norm.
Process over Results
We favor the sensational and the extremely visible. This affects the way we judge heroes. There is little room in our consciousness for heroes who do not deliver visible results—or those heroes who focus on process rather than results.
However, those who claim that they value process over result are not telling the whole truth, assuming of course that they are members of the human species. We often hear the semi-lie that writers do not write for glory, that artists create for the sake of art, because the activity is “its own reward.” True, these activities can generate a steady flow of autosatisfaction. But this does not mean that artists do not crave some form of attention, or that they would not be better off if they got some publicity; it does not mean that writers do not wake up early Saturday morning to check if
The New York Times Book Review
has featured their work, even if it is a very long shot, or that they do not keep checking their mailbox for that long-awaited reply from
The New Yorker
. Even a philosopher the caliber of Hume spent a few weeks sick in bed after the trashing of his masterpiece
(what later became known as his version of the Black Swan problem) by some dim-thinking reviewer—whom he knew to be wrong and to have missed his whole point.
Where it gets painful is when you see one of your peers, whom you despise, heading to Stockholm for his Nobel reception.
Most people engaged in the pursuits that I call “concentrated” spend most of their time waiting for the big day that (usually) never comes.
True, this takes your mind away from the pettiness of life—the cappuccino that is too warm or too cold, the waiter too slow or too intrusive, the food too spicy or not enough, the overpriced hotel room that does not quite resemble the advertised picture—all these considerations disappear because you have your mind on much bigger and better things. But this does not mean that the person insulated from materialistic pursuits becomes impervious to other pains, those issuing from disrespect. Often these Black Swan hunters feel shame, or are made to feel shame, at not contributing. “You betrayed those who had high hopes for you,” they are told, increasing their feeling of guilt. The problem of lumpy payoffs is not so much in the lack of income they entail, but the pecking order, the loss of dignity, the subtle humiliations near the watercooler.
It is my great hope someday to see science and decision makers rediscover what the ancients have always known, namely that our highest currency is respect.
Even economically, the individual Black Swan hunters are not the ones who make the bucks. The researcher Thomas Astebro has shown that returns on independent inventions (you take the cemetery into account) are far lower than those on venture capital. Some blindness to the odds or an obsession with their own positive Black Swan is necessary for entrepreneurs to function. The venture capitalist is the one who gets the shekels. The economist William Baumol calls this “a touch of madness.” This may indeed apply to all concentrated businesses: when you look at the empirical record, you not only see that venture capitalists do better than entrepreneurs, but publishers do better than writers, dealers do better than artists, and science does better than scientists (about 50 percent of scientific and scholarly papers, costing months, sometimes years, of effort, are never truly read). The person involved in such gambles is paid in a currency other than material success: hope.
Human Nature, Happiness, and Lumpy Rewards
Let me distill the main idea behind what researchers call hedonic happiness.
Making $1 million in one year, but nothing in the preceding nine, does not bring the same pleasure as having the total evenly distributed over the same period, that is, $100,000 every year for ten years in a row. The same applies to the inverse order—making a bundle the first year, then nothing for the remaining period. Somehow, your pleasure system will be saturated rather quickly, and it will not carry forward the hedonic balance like a sum on a tax return. As a matter of fact, your happiness depends far more on the number of instances of positive feelings, what psychologists call “positive affect,” than on their intensity when they hit. In other words, good news is good news first;
how
good matters rather little. So to have a pleasant life you should spread these small “affects” across time as evenly as possible. Plenty of mildly good news is preferable to one single lump of great news.
Sadly, it may be even worse for you to make $10 million, then lose back nine, than to making nothing at all! True, you may end up with a million (as compared to nothing), but it may be better had you got zilch. (This assumes, of course, that you care about financial rewards.)
So from a narrowly defined accounting point of view, which I may call here “hedonic calculus,” it does not pay to shoot for one large win. Mother Nature destined us to derive enjoyment from a steady flow of pleasant small, but frequent, rewards. As I said, the rewards do not have to be large, just frequent—a little bit here, a little bit there. Consider that our major satisfaction for thousands of years came in the form of food and water (and something else more private), and that while we need these steadily, we quickly reach saturation.
The problem, of course, is that we do not live in an environment where results are delivered in a steady manner—Black Swans dominate much of human history. It is unfortunate that the right strategy for our current environment may not offer
internal
rewards and positive feedback.
The same property in reverse applies to our unhappiness. It is better to lump all your pain into a brief period rather than have it spread out over a longer one.
But some people find it possible to transcend the asymmetry of pains and joys, escape the hedonic deficit, set themselves outside that game—and live with hope. There is some good news, as we see next.
The Antechamber of Hope
For Yevgenia Krasnova, a person could love one book, at most a few—beyond this was a form of promiscuity. Those who talk about books as commodities are inauthentic, just as those who collect acquaintances can be superficial in their friendships. A novel you like resembles a friend. You read it and reread it, getting to know it better. Like a friend, you accept it the way it is; you do not judge it. Montaigne was asked “why” he and the writer Etienne de la Boétie were friends—the kind of question people ask you at a cocktail party as if you knew the answer, or as if there were an answer to know. It was typical of Montaigne to reply, “Parce que c’était lui, parce que c’était moi” (because it was him and because it was me). Likewise, Yevgenia claims that she likes that
one
book “because it is it and because I am me.” Yevgenia once even walked out on a schoolteacher because he analyzed that book and thus violated her rule. One does not sit idle listening as people wax analytical about your friends. A very stubborn schoolchild she was.
This book she has as a friend is
Il deserto dei tartari
, by Dino Buzzati, a novel that was well known in Italy and France during her childhood, but that, strangely, nobody she knows in America had heard of. Its English title is mistranslated as
The Tartar Steppe
instead of
The Desert of the Tartars
.
Yevgenia encountered
Il deserto
when she was thirteen, in her parents’ weekend country house in a small village two hundred kilometers outside Paris, where their Russian and French books multiplied without the constraints of the overfed Parisian apartment. She was so bored in the country that she could not even read. Then, one afternoon, she opened the book and was sucked into it.
Inebriated by Hope
Giovanni Drogo is a man of promise. He has just graduated from the military academy with the rank of junior officer, and active life is just starting. But things do not turn out as planned: his initial four-year assignment is a remote outpost, the Bastiani fortress, protecting the nation from the Tartars likely to invade from the border desert—not too desirable a position. The fortress is located a few days by horseback from the town; there is nothing but bareness around it—none of the social buzz that a man of his age could look forward to. Drogo thinks that his assignment in the
outpost is temporary, a way for him to pay his dues before more appealing positions present themselves. Later, back in town, in his impeccably ironed uniform and with his athletic figure, few ladies will be able to resist him.
What is Drogo to do in this hole? He discovers a loophole, a way to be transferred after only four months. He decides to use the loophole.
At the very last minute, however, Drogo takes a glance at the desert from the window of the medical office and decides to extend his stay. Something in the walls of the fort and the silent landscape ensnares him. The appeal of the fort and waiting for the attackers, the big battle with the ferocious Tartars, gradually become his only reason to exist. The entire atmosphere of the fort is one of anticipation. The other men spend their time looking at the horizon and awaiting the big event of the enemy attack. They are so focused that, on rare occasions, they can detect the most insignificant stray animal that appears at the edge of the desert and mistake it for an enemy attack.
Sure enough, Drogo spends the rest of his life extending his stay, delaying the beginning of his life in the city—thirty-five years of pure hope, spent in the grip of the idea that one day, from the remote hills that no human has ever crossed, the attackers will eventually emerge and help him rise to the occasion.
At the end of the novel we see Drogo dying in a roadside inn as the event for which he has waited all his life takes place. He has missed it.
The Sweet Trap of Anticipation
Yevgenia read
Il deserto
numerous times; she even learned Italian (and perhaps married an Italian) so she could read it in the original. Yet she never had the heart to reread the painful ending.
I presented the Black Swan as the outlier, the important event that is not expected to happen. But consider the opposite: the unexpected event that
you very badly want to happen
. Drogo is obsessed and blinded by the possibility of an unlikely event; that rare occurrence is his raison d’être. At thirteen, when she encountered the book, little did Yevgenia know that she would spend an entire life playing Giovanni Drogo in the antechamber of hope, waiting for the big event, sacrificing for it, and refusing intermediate steps, the consolation prizes.
She did not mind the sweet trap of anticipation: to her it was a life worth living; it was worth living in the cathartic simplicity of a single purpose.
Indeed, “be careful what you wish for”: she may have been happier before the Black Swan of her success than after.
One of the attributes of a Black Swan is an asymmetry in consequences—either positive or negative. For Drogo the consequences were thirty-five years spent waiting in the antechamber of hope for just a few randomly distributed hours of glory—which he ended up missing.
When You Need the Bastiani Fortress
Note that there was no brother-in-law around in Drogo’s social network. He was lucky to have companions in his mission. He was a member of a community at the gate of the desert intently looking together at the horizon. Drogo had the advantage of an association with peers and the avoidance of social contact with others outside the community. We are local animals, interested in our immediate neighborhood—even if people far away consider us total idiots. Those homo sapiens are abstract and remote and we do not care about them because we do not run into them in elevators or make eye contact with them. Our shallowness can sometimes work for us.
It may be a banality that we need others for many things, but we need them far more than we realize, particularly for dignity and respect. Indeed, we have very few historical records of people who have achieved anything extraordinary without such peer validation—but we have the freedom to choose our peers. If we look at the history of ideas, we see schools of thought occasionally forming, producing unusual work unpopular outside the school. You hear about the Stoics, the Academic Skeptics, the Cynics, the Pyrrhonian Skeptics, the Essenes, the Surrealists, the Dadaists, the anarchists, the hippies, the fundamentalists. A school allows someone with unusual ideas with the remote possibility of a payoff to find company and create a microcosm insulated from others. The members of the group can be ostracized together—which is better than being ostracized alone.
If you engage in a Black Swan–dependent activity, it is better to be part of a group.


================================================================================
CHAPTER/SECTION 202 (Item 207)
================================================================================

EL DESIERTO DE LOS TÁRTAROS
Yevgenia met Nero Tulip in the lobby of the Hotel Danieli in Venice. He was a trader who lived between London and New York. At the time,
traders from London went to Venice on Friday noon during the low season, just to talk to other traders (from London).
As Yevgenia and Nero stood engaged in an effortless conversation, she noticed that her husband was looking uncomfortably at them from the bar where he sat, trying to stay focused on the pontifications of one of his childhood friends. Yevgenia realized that she was going to see a bit more of Nero.
They met again in New York, first in a clandestine way. Her husband, being a philosophy professor, had too much time on his hands, so he started paying close attention to her schedule and became clingy. The clingier he got, the more stifled Yevgenia felt, which made him even clingier. She dumped him, called her lawyer who was by then expecting to hear from her, and saw more of Nero openly.
Nero had a stiff gait since he was recovering from a helicopter crash—he gets a little too arrogant after episodes of success and starts taking uncalculated physical risks, though he remains financially hyperconservative, even paranoid. He had spent months immobile in a London hospital, hardly able to read or write, trying to resist having to watch television, teasing the nurses, and waiting for his bones to heal. He can draw the ceiling with its fourteen cracks from memory, as well as the shabby white building across the street with its sixty-three windowpanes, all in need of professional cleaning.
Nero claimed that he was comfortable in Italian when he drank, so Yevgenia gave him a copy of
Il deserto
. Nero did not read novels—“Novels are fun to write, not read,” he claimed. So he left the book by his bedside for a while.
Nero and Yevgenia were, in a sense, like night and day. Yevgenia went to bed at dawn, working on her manuscripts at night. Nero rose at dawn, like most traders, even on weekends. He then worked for an hour on his opus,
Treatise on Probability
, and never touched it again after that. He had been writing it for a decade and felt rushed to finish it only when his life was threatened. Yevgenia smoked; Nero was mindful of his health, spending at least an hour a day at the gym or in the pool. Yevgenia hung around intellectuals and bohemians; Nero often felt comfortable with street-smart traders and businessmen who had never been to college and spoke with cripplingly severe Brooklyn accents. Yevgenia never understood how a classicist and a polyglot like Nero could socialize with people like that. What was worse, she had this French Fifth Republic overt disdain
for money, unless disguised by an intellectual or cultural façade, and she could hardly bear these Brooklyn fellows with thick hairy fingers and gigantic bank accounts. Nero’s post-Brooklyn friends, in turn, found her snotty. (One of the effects of prosperity has been a steady migration of streetwise people from Brooklyn to Staten Island and New Jersey.)
Nero was also elitist, unbearably so, but in a different way. He separated those who could
connect the dots
, Brooklyn-born or not, from those who could not, regardless of their levels of sophistication and learning.
A few months later, after he was done with Yevgenia (with inordinate relief) he opened
Il deserto
and was sucked into it. Yevgenia had the prescience that, like her, Nero would identify with Giovanni Drogo, the main character of
Il deserto
. He did.
Nero, in turn, bought cases of the English (bad) translation of the book and handed copies to anyone who said a polite hello to him, including his New York doorman who could hardly speak English, let alone read it. Nero was so enthusiastic while explaining the story that the doorman got interested and Nero had to order the Spanish translation for him,
El desierto de los tártaros
.
Bleed or Blowup
Let us separate the world into two categories. Some people are like the turkey, exposed to a major blowup without being aware of it, while others play reverse turkey, prepared for big events that might surprise others. In some strategies and life situations, you gamble dollars to win a succession of pennies while appearing to be winning all the time. In others, you risk a succession of pennies to win dollars. In other words, you bet either that the Black Swan will happen or that it will never happen, two strategies that require completely different mind-sets.
We have seen that we (humans) have a marked preference for making a little bit of income at a time. Recall from
Chapter 4
that in the summer of 1982, large American banks lost close to everything they had ever earned, and more.
So some matters that belong to Extremistan are extremely dangerous but do not appear to be so beforehand, since they hide and delay their risks—so suckers think they are “safe.” It is indeed a property of Extremistan to look less risky, in the short run, than it really is.
Nero called the businesses exposed to such blowups dubious businesses, particularly since he distrusted whatever method was being used to
compute the odds of a blowup. Recall from
Chapter 4
that the accounting period upon which companies’ performances are evaluated is too short to reveal whether or not they are doing a great job. And, owing to the shallowness of our intuitions, we formulate our risk assessments too quickly.
I will rapidly present Nero’s idea. His premise was the following trivial point: some business bets in which one wins big but infrequently, yet loses small but frequently, are worth making if others are suckers for them and
if you have the personal and intellectual stamina
. But you need such stamina. You also need to deal with people in your entourage heaping all manner of insult on you, much of it blatant. People often accept that a financial strategy with a small chance of success is not necessarily a bad one as long as the success is large enough to justify it. For a spate of psychological reasons, however, people have difficulty carrying out such a strategy, simply because it requires a combination of belief, a capacity for delayed gratification, and the willingness to be spat upon by clients without blinking. And those who lose money for any reason start looking like guilty dogs, eliciting more scorn on the part of their entourage.
Against that background of potential blowup disguised as skills, Nero engaged in a strategy that he called “bleed.” You lose steadily, daily, for a long time, except when some event takes place for which you get paid disproportionately well. No single event can make you blow up, on the other hand—some changes in the world can produce extraordinarily large profits that pay back such bleed for years, sometimes decades, sometimes even centuries.
Of all the people he knew, Nero was the least genetically designed for such a strategy. His brain disagreed so heavily with his body that he found himself in a state of continuous warfare. It was his body that was his problem, which accumulated physical fatigue from the neurobiological effect of exposure to the small continuous losses, Chinese-water-torture-style, throughout the day. Nero discovered that the losses went to his emotional brain, bypassing his higher cortical structures and slowly affecting his hippocampus and weakening his memory. The hippocampus is the structure where memory is supposedly controlled. It is the most plastic part of the brain; it is also the part that is assumed to absorb all the damage from repeated insults like the chronic stress we experience daily from small doses of negative feelings—as opposed to the invigorating “good stress” of the tiger popping up occasionally in your living room. You can rationalize all you want; the hippocampus takes the insult of chronic stress seriously, incurring irreversible atrophy. Contrary to popular belief, these small, seemingly
harmless stressors do not strengthen you; they can amputate part of your self.
It was the exposure to a high level of information that poisoned Nero’s life. He could sustain the pain if he saw only weekly performance numbers, instead of updates every minute. He did better emotionally with his own portfolio than with those of clients, since he was not obligated to monitor it continuously.
If his neurobiological system was a victim of the confirmation bias, reacting to the short term and the visible, he could trick his brain to escape its vicious effect by focusing only on the longer haul. He refused to look at any printout of his track record that was shorter than ten years. Nero came of age, intellectually speaking, with the stock market crash of 1987, in which he derived monstrous returns on what small equity he controlled. This episode would forever make his track record valuable, taken as a whole. In close to twenty years of trading, Nero had only four good years. For him, one was more than enough. All he needed was one good year per century.
Investors were no problem for him—they needed his trading as insurance and paid him well. He just had to exhibit a mild degree of contempt toward those he wanted to shed, which did not take much effort on his part. This effort was not contrived: Nero did not think much of them and let his body language express it freely, all the while maintaining an unfashionably high level of courtesy. He made sure, after a long string of losses, that they did not think he was apologetic—indeed, paradoxically, they became more supportive that way. Humans will believe anything you say provided you do not exhibit the smallest shadow of diffidence; like animals, they can detect the smallest crack in your confidence before you express it. The trick is to be as smooth as possible in personal manners. It is much easier to signal self-confidence if you are exceedingly polite and friendly; you can control people without having to offend their sensitivity. The problem with business people, Nero realized, is that if you act like a loser they will treat you as a loser—you set the yardstick yourself. There is no absolute measure of good or bad. It is not what you are telling people, it is how you are saying it.
But you need to remain understated and maintain an Olympian calm in front of others.
When he worked as a trader for an investment bank, Nero had to face the typical employee-evaluation form. The form was supposed to keep track of “performance,” supposedly as a check against employees slacking
off. Nero found the evaluation absurd because it did not so much judge the quality of a trader’s performance as encourage him to game the system by working for short-term profits at the expense of possible blowups—like banks that give foolish loans that have a small probability of blowing up, because the loan officer is shooting for his next quarterly evaluation. So one day early in his career, Nero sat down and listened very calmly to the evaluation of his “supervisor.” When Nero was handed the evaluation form he tore it into small pieces in front of him. He did this very slowly, accentuating the contrast between the nature of the act and the tranquillity with which he tore the paper. The boss watched him blank with fear, eyes popping out of his head. Nero focused on his undramatic, slow-motion act, elated by both the feeling of standing up for his beliefs and the aesthetics of its execution. The combination of elegance and dignity was exhilarating. He knew that he would either be fired or left alone. He was left alone.


================================================================================
CHAPTER/SECTION 203 (Item 208)
================================================================================

Chapter Eight
GIACOMO CASANOVA’S UNFAILING LUCK: THE PROBLEM OF SILENT EVIDENCE
The Diagoras problem—How Black Swans make their way out of history books—Methods to help you avoid drowning—The drowned do not usually vote—We should all be stockbrokers—Do silent witnesses count?—Casanova’s étoile—New York is “so invincible”
Another fallacy in the way we understand events is that of silent evidence. History hides both Black Swans and its Black Swan–generating ability from us.


================================================================================
CHAPTER/SECTION 204 (Item 209)
================================================================================

THE STORY OF THE DROWNED WORSHIPPERS
More than two thousand years ago, the Roman orator, belletrist, thinker, Stoic, manipulator-politician, and (usually) virtuous gentleman, Marcus Tullius Cicero, presented the following story. One Diagoras, a nonbeliever in the gods, was shown painted tablets bearing the portraits of some worshippers who prayed, then survived a subsequent shipwreck. The implication was that praying protects you from drowning. Diagoras asked, “Where were the pictures of those who prayed, then drowned?”
The drowned worshippers, being dead, would have a lot of trouble advertising their experiences from the bottom of the sea. This can fool the casual observer into believing in miracles.
We call this the problem of silent evidence. The idea is simple, yet potent and universal. While most thinkers try to put to shame those who came
before
them, Cicero puts to shame almost all empirical thinkers who came
after
him, until very recently.
Later on, both my hero of heroes, the essayist Michel de Montaigne and the empirical Francis Bacon, mentioned the point in their works, applying it to the formation of false beliefs. “And such is the way of all superstition, whether in astrology, dreams, omens, divine judgments, or the like,” wrote Bacon in his
Novum Organum
. The problem, of course, is that unless they are drilled into us systematically, or integrated into our way of thinking, these great observations are rapidly forgotten.
Silent evidence pervades everything connected to the notion of
history
. By history, I don’t just mean those learned-but-dull books in the history section (with Renaissance paintings on their cover to attract buyers). History, I will repeat, is
any succession of events
seen with the effect of
posteriority
.
This bias extends to the ascription of factors in the success of ideas and religions, to the illusion of skill in many professions, to success in artistic occupations, to the nature versus nurture debate, to mistakes in using evidence in the court of law, to illusions about the “logic” of history—and of course, most severely, in our perception of the nature of extreme events.
You are in a classroom listening to someone self-important, dignified, and ponderous (but dull), wearing a tweed jacket (white shirt, polka-dot tie), pontificating for two hours on the theories of history. You are too paralyzed by boredom to understand what on earth he is talking about, but you hear the names of big guns: Hegel, Fichte, Marx, Proudhon, Plato, Herodotus, Ibn Khaldoun, Toynbee, Spengler, Michelet, Carr, Bloch, Fukuyama, Schmukuyama, Trukuyama. He seems deep and knowledgeable, making sure that no attention lapse will make you forget that his approach is “post-Marxist,” “postdialectical,” or post-something, whatever that means. Then you realize that a large part of what he is saying reposes on a simple optical illusion! But this will not make a difference: he is so invested in it that if you questioned his method he would react by throwing even more names at you.
It is so easy to avoid looking at the cemetery while concocting historical theories. But this is not just a problem with history. It is a problem with the way we construct samples and gather evidence
in every domain
. We shall call this distortion a bias, i.e., the difference between what you see
and what is there. By
bias
I mean a systematic error consistently showing a more positive, or negative, effect from the phenomenon, like a scale that unfailingly shows you a few pounds heavier or lighter than your true weight, or a video camera that adds a few sizes to your waistline. This bias has been rediscovered here and there throughout the past century across disciplines, often to be rapidly forgotten (like Cicero’s insight). As drowned worshippers do not write histories of their experiences (it is better to be alive for that), so it is with the losers in history, whether people or ideas. Remarkably, historians and other scholars in the humanities who need to understand silent evidence the most do not seem to have a name for it (and I looked hard). As for journalists, fuhgedaboudit! They are industrial producers of the distortion.
The term
bias
also indicates the condition’s potentially quantifiable nature: you may be able to calculate the distortion, and to correct for it by taking into account both the dead and the living, instead of only the living.
Silent evidence is what events use to conceal their own randomness, particularly the Black Swan type of randomness.
Sir Francis Bacon is an interesting and endearing fellow in many respects.
He harbored a deep-seated, skeptical, nonacademic, antidogmatic, and obsessively empirical nature, which, to someone skeptical, nonacademic, antidogmatic, and obsessively empirical, like this author, is a quality almost impossible to find in the thinking business. (Anyone can be skeptical; any scientist can be overly empirical—it is the rigor coming from the combination of skepticism and empiricism that’s hard to come by.) The problem is that his empiricism wanted us to confirm, not disconfirm; thus he introduced the problem of confirmation, that beastly corroboration that generates the Black Swan.


================================================================================
CHAPTER/SECTION 205 (Item 210)
================================================================================

THE CEMETERY OF LETTERS
The Phoenicians, we are often reminded, produced no literature, although they allegedly invented the alphabet. Commentators discuss their philistinism from the basis of this absence of a written legacy, asserting that by race or culture, they were more interested in commerce than in the arts. Accordingly, the Phoenician invention of the alphabet served the lower purpose of commercial record keeping rather than the more noble purpose
of literary production. (I remember finding on the shelves of a country house I once rented a mildewed history book by Will and Ariel Durant describing the Phoenicians as the “merchant race.” I was tempted to throw it in the fireplace.) Well, it now seems that the Phoenicians wrote quite a bit, but using a perishable brand of papyrus that did not stand the biodegradative assaults of time. Manuscripts had a high rate of extinction before copyists and authors switched to parchment in the second or third century. Those not copied during that period simply disappeared.
The neglect of silent evidence is endemic to the way we study comparative talent, particularly in activities that are plagued with winner-take-all attributes. We may enjoy what we see, but there is no point reading too much into success stories because we do not see the full picture.
Recall the
winner-take-all
effect from
Chapter 3
: notice the large number of people who call themselves writers but are (only “temporarily”) operating the shiny cappuccino machines at Starbucks. The inequity in this field is larger than, say, medicine, since we rarely see medical doctors serving hamburgers. I can thus infer that I can largely gauge the performance of the latter profession’s entire population from what sample is visible to me. Likewise with plumbers, taxi drivers, prostitutes, and those in professions devoid of superstar effects. Let us go beyond the discussion on Extremistan and Mediocristan in
Chapter 3
. The consequence of the superstar dynamic is that what we call “literary heritage” or “literary treasures” is a minute proportion of what has been produced cumulatively. This is the first point. How it invalidates the identification of talent can be derived immediately from it: say you attribute the success of the nineteenth-century novelist Honoré de Balzac to his superior “realism,” “insights,” “sensitivity,” “treatment of characters,” “ability to keep the reader riveted,” and so on. These may be deemed “superior” qualities that lead to superior performance
if, and only if
, those who lack what we call talent also lack these qualities. But what if there are dozens of comparable literary masterpieces that happened to perish? And, following my logic, if there are indeed many perished manuscripts with similar attributes, then, I regret to say, your idol Balzac was just the beneficiary of disproportionate luck compared to his peers. Furthermore, you may be committing an injustice to others by favoring him.
My point, I will repeat, is not that Balzac is untalented, but that he is less
uniquely
talented than we think. Just consider the thousands of writers now completely vanished from consciousness: their record does not
enter into analyses. We do not see the tons of rejected manuscripts because these writers have never been published.
The New Yorker
alone rejects close to a hundred manuscripts a day, so imagine the number of geniuses that we will never hear about. In a country like France, where more people write books while, sadly, fewer people read them, respectable literary publishers accept one in ten thousand manuscripts they receive from firsttime authors. Consider the number of actors who have never passed an audition but would have done very well had they had that lucky break in life.
The next time you visit a Frenchman of comfortable means, you will likely spot the stern books from the collection
Bibliothèque de la Pléiade
, which their owner will never, almost never, read, mostly on account of their uncomfortable size and weight. Membership in the
Pléiade
means membership in the literary canon. The tomes are expensive; they have the distinctive smell of ultrathin India paper, compressing the equivalent of fifteen hundred pages into the size of a drugstore paperback. They are supposed to help you maximize the number of masterpieces per Parisian square foot. The publisher Gallimard has been extremely selective in electing writers into the
Pléiade
collection–only a few authors, such as the aesthete and adventurer André Malraux, have made it in while still alive. Dickens, Dostoyevsky, Hugo, and Stendhal are in, along with Mallarmé, Sartre, Camus, and … Balzac. Yet if you follow Balzac’s own ideas, which I will examine next, you would accept that there is no ultimate justification for such an official corpus.
Balzac outlined the entire business of silent evidence in his novel
Lost Illusions
. Lucien de Rubempré (alias of Lucien Chardon), the penurious provincial genius, “goes up” to Paris to start a literary career. We are told that he is talented—actually
he
is told that he is talented by the semiaristocratic set in Angoulême. But it is difficult to figure out whether this is due to his good looks or to the literary quality of his works—or even whether literary quality is visible, or, as Balzac seems to wonder, if it has much to do with anything. Success is presented cynically, as the product of wile and promotion or the lucky surge of interest for reasons completely external to the works themselves. Lucien discovers the existence of the immense cemetery inhabited by what Balzac calls “nightingales.”
Lucien was told that this designation “nightingale” was given by bookstores to those works residing on the shelves in the solitary depths of their shops.
Balzac presents to us the sorry state of contemporary literature when Lucien’s manuscript is rejected by a publisher who has never read it; later on, when Lucien’s reputation has developed, the very same manuscript is accepted by another publisher who did not read it either! The work itself was a secondary consideration.
In another example of silent evidence, the book’s characters keep bemoaning that things are no longer as they were
before
, implying that literary fairness prevailed in more ancient times—as if there was no cemetery before. They fail to take into account the nightingales among the ancients’ work! Notice that close to two centuries ago people had an idealized opinion of their own past, just as we have an idealized opinion of today’s past.
I mentioned earlier that to understand successes and analyze what
caused
them, we need to study the traits present in failures. It is to a more general version of this point that I turn next.
How to Become a Millionaire in Ten Steps
Numerous studies of millionaires aimed at figuring out the skills required for hotshotness follow the following methodology. They take a population of hotshots, those with big titles and big jobs, and study their attributes. They look at what those big guns have in common: courage, risk taking, optimism, and so on, and infer that these traits, most notably risk taking, help you to become successful. You would also probably get the same impression if you read CEOs’ ghostwritten autobiographies or attended their presentations to fawning MBA students.
Now take a look at the cemetery. It is quite difficult to do so because people who fail do not seem to write memoirs, and, if they did, those business publishers I know would not even consider giving them the courtesy of a returned phone call (as to returned e-mail, fuhgedit). Readers would not pay $26.95 for a story of failure, even if you convinced them that it had more useful tricks than a story of success.
*
The entire notion of biography is grounded in the arbitrary ascription of a causal relation between specified traits and subsequent events. Now consider the cemetery. The graveyard of failed persons will be full of people who shared the following traits: courage, risk taking, optimism, et cetera. Just like the population of millionaires. There may be some differences in skills, but what truly separates the two is for the most part a single factor: luck. Plain luck.
You do not need a lot of empiricism to figure this out: a simple thought experiment suffices. The fund-management industry claims that some people are extremely skilled, since year after year they have outperformed the market. They will identify these “geniuses” and convince you of their abilities. My approach has been to manufacture cohorts of purely random investors and, by simple computer simulation, show how it would be impossible to not have these geniuses produced
just by luck
. Every year you fire the losers, leaving only the winners, and thus end up with long-term steady winners. Since you do not observe the cemetery of failed investors, you will think that it is a good business, and that some operators are considerably better than others. Of course an explanation will be readily provided for the success of the lucky survivors: “He eats tofu,” “She works late; just the other day I called her office at eight P.M. …” Or of course, “She is naturally lazy. People with that type of laziness can see things clearly.” By the mechanism of retrospective determinism we will find the “cause”—actually, we need to see the cause. I call these simulations of hypothetical cohorts, often done by computer, an engine of computational epistemology. Your thought experiments can be run on a computer. You just simulate an alternative world, plain random, and verify that it looks similar to the one in which we live. Not getting lucky billionaires in these experiments would be the exception.
*
Recall the distinction between Mediocristan and Extremistan in
Chapter 3
. I said that taking a “scalable” profession is not a good idea, simply because there are far too few winners in these professions. Well, these professions produce a large cemetery: the pool of starving actors is larger than the one of starving accountants, even if you assume that, on average, they earn the same income.


================================================================================
CHAPTER/SECTION 206 (Item 211)
================================================================================

A HEALTH CLUB FOR RATS
The second, and more vicious, variety of the problem of silent evidence is as follows. When I was in my early twenties and still read the newspaper, and thought that steadily reading the newspapers was something useful to me, I came across an article discussing the mounting threat of the Russian Mafia in the United States and its displacement of the traditional Louie and Tony in some neighborhoods of Brooklyn. The article explained their toughness and brutality as a result of their being hardened by their Gulag experiences. The Gulag was a network of labor camps in Siberia where criminals and dissidents were routinely deported. Sending people to Siberia was one of the purification methods initially used by the czarist regimes and later continued and perfected by the Soviets. Many deportees did not survive these labor camps.
Hardened by the Gulag?
The sentence jumped out at me as both profoundly flawed (and a reasonable inference). It took me a while to figure out the nonsense in it since it was protected by cosmetic wrapping; the following thought experiment will give the intuition. Assume that you’re able to find a large, assorted population of rats: fat, thin, sickly, strong, well-proportioned, et cetera. (You can easily get them from the kitchens of fancy New York restaurants.) With these thousands of rats, you build a heterogeneous cohort, one that is well representative of the general New York rat population. You bring them to my laboratory on East Fifty-ninth Street in New York City and we put the entire collection in a large vat. We subject the rats to increasingly higher levels of radiation (since this is supposed to be a thought experiment, I am told that there is no cruelty in the process). At every level of radiation, those that are naturally stronger (and this is the key) will survive; the dead will drop out of your sample. We will progressively have a stronger and stronger collection of rats. Note the following central fact: every single rat, including the strong ones, will be
weaker
after the radiation than before.
An observer endowed with analytical abilities, who probably got excellent grades in college, would be led to believe that treatment in my laboratory is an excellent health-club replacement, and one that could be generalized to all mammals (think of the potential commercial success). His logic would run as follows: Hey, these rats are stronger than the rest of the rat population. What do they seem to have in common? They all came from that Black Swan guy Taleb’s workshop. Not many people will have the temptation to go look at the dead rats.
Next we pull the following trick on
The New York Times:
we let these surviving rats loose in New York City and inform the chief rodent correspondent of the newsworthy disruption in the pecking order in the New York rat population. He will write a lengthy (and analytical) article on the social dynamics of New York rats that includes the following passage: “Those rats are now bullies in the rat population. They literally run the show.
Strengthened
by their experience in the laboratory of the reclusive (but friendly) statistician/philosopher/trader Dr. Taleb, they …”
Vicious Bias
There is a vicious attribute to the bias: it can hide best when its impact is largest. Owing to the invisibility of the dead rats, the more lethal the risks, the less visible they will be, since the severely victimized are likely to be eliminated from the evidence. The more injurious the treatment, the larger the difference between the surviving rats and the rest, and the more fooled you will be about the
strengthening
effect. One of the two following ingredients is necessary for this difference between the true effect (weakening) and the observed one (strengthening): a) a degree of inequality in strength, or diversity, in the base cohort, or b) unevenness, or diversity, somewhere in the treatment. Diversity here has to do with the degree of uncertainty inherent in the process.
More Hidden Applications
We can keep going with this argument; it has such universality that once we get the bug it is hard to look at reality with the same eyes again. Clearly it robs our observations of their realistic power. I will enumerate a few more cases to illustrate the weaknesses of our inferential machinery.
The stability of species
. Take the number of species that we now consider extinct. For a long time scientists took the number of such species as that implied from an analysis of the extant fossils. But this number ignores the silent cemetery of species that came and left without leaving traces in the form of fossils; the fossils that we have managed to find correspond to a smaller proportion of all species that came and disappeared. This implies that our biodiversity was far greater than it seemed at first examination. A more worrisome consequence is that the rate of extinction of species may be far greater than we think—close to 99.5 percent of species that transited through earth are now extinct, a number that scientists have kept raising
through time. Life is a great deal more fragile than we have allowed for. But this does not mean we (humans) should feel guilty for extinctions around us; nor does it mean that we should act to stop them—species were coming and going before we started messing up the environment. There is no need to feel moral responsibility for every endangered species.
Does crime pay?
Newspapers report on the criminals who get caught. There is no section in
The New York Times
recording the stories of those who committed crimes but have not been caught. So it is with cases of tax evasion, government bribes, prostitution rings, poisoning of wealthy spouses (with substances that do not have a name and cannot be detected), and drug trafficking.
In addition, our representation of the standard criminal might be based on the properties of those less intelligent ones who were caught.
Once we seep ourselves into the notion of silent evidence, so many things around us that were previously hidden start manifesting themselves. Having spent a couple of decades in this mind-set, I am convinced (but cannot prove) that training and education can help us avoid its pitfalls.
The Evolution of the Swimmer’s Body
What do the popular expressions “a swimmer’s body” and “beginner’s luck” have in common? What do they seem to share with the concept of history?
There is a belief among gamblers that beginners are almost always lucky. “It gets worse later, but gamblers are always lucky when they start out,” you hear. This statement is actually empirically true: researchers confirm that gamblers have lucky beginnings (the same applies to stock market speculators). Does this mean that each one of us should become a gambler for a while, take advantage of lady luck’s friendliness to beginners, then stop?
The answer is no. The same optical illusion prevails: those who start gambling will be either lucky or unlucky (given that the casino has the advantage, a slightly greater number will be unlucky). The lucky ones, with the feeling of having been selected by destiny, will continue gambling; the others, discouraged, will stop and will not show up in the sample. They will probably take up, depending on their temperaments, bird-watching, Scrabble, piracy, or other pastimes. Those who continue gambling will remember having been lucky as beginners. The dropouts, by definition, will
no longer be part of the surviving gamblers’ community. This explains beginner’s luck.
There is an analogy with what is called in common parlance a “swimmer’s body,” which led to a mistake I shamefully made a few years ago (in spite of my specialty in this bias, I did not notice that I was being fooled). When asking around about the comparative physical elegance of athletes, I was often told that runners looked anorexic, cyclists bottom-heavy, and weight lifters insecure and a little primitive. I inferred that I should spend some time inhaling chlorine in the New York University pool to get those “elongated muscles.” Now suspend the causality. Assume that a person’s genetic variance allows for a certain type of body shape. Those born with a natural tendency to develop a swimmer’s body become better swimmers. These are the ones you see in your sample splashing up and down at the pools. But they would have looked pretty much the same if they lifted weights. It is a fact that a given muscle grows almost the same way whether you take steroids or climb walls at the local gym.


================================================================================
CHAPTER/SECTION 207 (Item 212)
================================================================================

WHAT YOU SEE AND WHAT YOU DON’T SEE
Katrina, the devastating hurricane that hit New Orleans in 2005, got plenty of politicizing politicians on television. These legislators, moved by the images of devastation and the pictures of angry victims made homeless, made promises of “rebuilding.” It was so noble on their part to do something humanitarian, to rise above our abject selfishness.
Did they promise to do so with their own money? No. It was with public money. Consider that such funds will be taken away from somewhere else, as in the saying “You take from Peter to give to Paul.” That
somewhere else
will be less mediatized. It may be privately funded cancer research, or the next efforts to curb diabetes. Few seem to pay attention to the victims of cancer lying lonely in a state of untelevised depression. Not only do these cancer patients not vote (they will be dead by the next ballot), but they do not manifest themselves to our emotional system. More of them die every day than were killed by Hurricane Katrina; they are the ones who need us the most—not just our financial help, but our attention and kindness. And they may be the ones from whom the money will be taken—indirectly, perhaps even directly. Money (public or private) taken away from research might be responsible for killing them—in a crime that may remain silent.
A ramification of the idea concerns our decision making under a cloud
of possibilities. We see the obvious and visible consequences, not the invisible and less obvious ones. Yet those unseen consequences can be—nay, generally are—more meaningful.
Frédéric Bastiat was a nineteenth-century humanist of a strange variety, one of those rare independent thinkers—independent to the point of being unknown in his own country, France, since his ideas ran counter to French political orthodoxy (he joins another of my favorite thinkers, Pierre Bayle, in being unknown at home and in his own language). But he has a large number of followers in America.
In his essay “What We See and What We Don’t See,” Bastiat offered the following idea: we can see what governments do, and therefore sing their praises—but we do not see the alternative. But there is an alternative; it is less obvious and remains unseen.
Recall the confirmation fallacy: governments are great at telling you what they did, but not what they did not do. In fact, they engage in what could be labeled as phony “philanthropy,” the activity of helping people in a visible and sensational way without taking into account the unseen cemetery of invisible consequences. Bastiat inspired libertarians by attacking the usual arguments that showed the benefits of governments. But his ideas can be generalized to apply to both the Right and the Left.
Bastiat goes a bit deeper. If both the positive and the negative consequences of an action fell on its author, our learning would be fast. But often an action’s positive consequences benefit only its author, since they are visible, while the negative consequences, being invisible, apply to others, with a net cost to society. Consider job-protection measures: you notice those whose jobs are made safe and ascribe social benefits to such protections. You do not notice the effect on those who cannot find a job as a result, since the measure will reduce job openings. In some cases, as with the cancer patients who may be punished by Katrina, the positive consequences of an action will immediately benefit the politicians and phony humanitarians, while the negative ones take a long time to appear—they may never become noticeable. One can even blame the press for directing charitable contributions toward those who may need them the least.
Let us apply this reasoning to September 11, 2001. Around twenty-five hundred people were directly killed by bin Laden’s group in the Twin Towers of the World Trade Center. Their families benefited from the support of all manner of agencies and charities, as they should. But, according to researchers, during the remaining three months of the year, close to
one thousand people died as silent victims of the terrorists. How? Those who were afraid of flying and switched to driving ran an increased risk of death. There was evidence of an increase of casualties on the road during that period; the road is considerably more lethal than the skies. These families got no support—they did not even know that their loved ones were also the victims of bin Laden.
In addition to Bastiat, I have a weakness for Ralph Nader (the activist and consumer advocate, certainly not the politician and political thinker). He may be the American citizen who saved the highest number of lives by exposing the safety record of car companies. But, in his political campaign a few years ago, even he forgot to trumpet the tens of thousands of lives saved by his seat belt laws. It is much easier to sell “Look what I did for you” than “Look what I avoided for you.”
Recall from the Prologue the story of the hypothetical legislator whose actions might have avoided the attack of September 11. How many such people are walking the street without the upright gait of the phony hero?
Have the guts to consider the silent consequences when standing in front of the next snake-oil humanitarian.
Doctors
Our neglect of silent evidence kills people daily. Assume that a drug saves many people from a potentially dangerous ailment, but runs the risk of killing a few, with a net benefit to society. Would a doctor prescribe it? He has no incentive to do so. The lawyers of the person hurt by the side effects will go after the doctor like attack dogs, while the lives saved by the drug might not be accounted for anywhere.
A life saved is a statistic; a person hurt is an anecdote. Statistics are invisible; anecdotes are salient. Likewise, the risk of a Black Swan is invisible.
*
Giacomo Casanova, a.k.a. Jacques, Chevalier de Seingalt. Some readers might be surprised that the legendary seducer did not look quite like James Bond.


================================================================================
CHAPTER/SECTION 208 (Item 213)
================================================================================

THE TEFLON-STYLE PROTECTION OF GIACOMO CASANOVA
This brings us to gravest of all manifestations of silent evidence, the illusion of stability. The bias lowers our perception of the risks we incurred in the past, particularly for those of us who were lucky to have survived them. Your life came under a serious threat but, having survived it, you retrospectively underestimate how risky the situation actually was.
The adventurer Giacomo Casanova, later self-styled Jacques, Chevalier de Seingalt, the wannabe intellectual and legendary seducer of women, seems to have had a Teflon-style trait that would cause envy on the part of the most resilient of Mafia dons: misfortune did not stick to him. Casanova, while known for his seductions, viewed himself as some sort of a scholar. He aimed at literary fame with his twelve-volume
History of My Life
, written in bad (charmingly bad) French. In addition to the extremely useful lessons on how to become a seducer, the
History
provides an engrossing account of a succession of reversals of fortune. Casanova felt that every time he got into difficulties, his lucky star, his
étoile
, would pull him out of trouble. After things got bad for him, they somehow recovered by some invisible hand, and he was led to believe that it was his intrinsic
property to recover from hardships by running every time into a new opportunity. He would somehow meet someone in extremis who offered him a financial transaction, a new patron that he had not betrayed in the past, or someone generous enough and with a weak enough memory to forget past betrayals. Could Casanova have been selected by destiny to bounce back from all hardships?
Not necessarily. Consider the following: of all the colorful adventurers who have lived on our planet, many were occasionally crushed, and a few did bounce back repeatedly. It is those who survive who will tend to believe that they are indestructible; they will have a long and interesting enough experience to write books about it. Until, of course …
Actually, adventurers who feel singled out by destiny abound, simply because there are plenty of adventurers, and we do not hear the stories of those down on their luck. As I started writing this chapter, I recalled a conversation with a woman about her flamboyant fiancé, the son of a civil servant, who managed through a few financial transactions to catapult himself into the life of a character in a novel, with handmade shoes, Cuban cigars, collectible cars, and so on. The French have a word for this,
flambeur
, which means a mixture of extravagant bon vivant, wild speculator, and risk taker, all the while bearing considerable personal charm; a word that does not seem to be available in Anglo-Saxon cultures. The fiancé was spending his money very quickly, and as we were having the conversation about his fate (she was going to marry him, after all), she explained to me that he was undergoing slightly difficult times, but that there was no need to worry since he always came back with a vengeance. That was a few years ago. Out of curiosity, I have just tracked him down (trying to do so tactfully): he has not recovered (yet) from his latest blow of fortune. He also dropped out of the scene and is no longer to be found among other
flambeurs
.
How does this relate to the dynamics of history? Consider what is generally called the resilience of New York City. For seemingly transcendental reasons, every time it gets close to the brink of disaster, the city manages to pull back and recover. Some people truly believe that this is an internal property of New York City. The following quote is from a
New York Times
article:
Which is why New York still needs Samuel M. E. An economist who turns 77 today, Mr. E. studied New York City through half a century
of booms and busts. … “We have a record of going through tough times and coming back stronger than ever,” he said.
Now run the idea in reverse: think of cities as little Giacomo Casanovas, or as rats in my laboratory. As we put the thousands of rats through a very dangerous process, let’s put a collection of cities in a simulator of history: Rome, Athens, Carthage, Byzantium, Tyre, Catal Hyuk (located in modern-day Turkey, it is one of the first known human settlements), Jericho, Peoria, and, of course, New York City. Some cities will survive the harsh conditions of the simulator. As to others, we know that history might not be too kind. I am sure that Carthage, Tyre, and Jericho had their local, no less eloquent, Samuel M. E., saying, “Our enemies have tried to destroy us many times; but we always came back more resilient than before. We are now invincible.”
This bias causes the survivor to be an unqualified witness of the process. Unsettling? The fact that you survived is a condition that may weaken your interpretation of the properties of the survival, including the shallow notion of “cause.”
You can do a lot with the above statement. Replace the retired economist Samuel E. with a CEO discussing his corporation’s ability to recover from past problems. How about the touted “resilience of the financial system”? How about a general who has had a good run?
The reader can now see why I use Casanova’s unfailing luck as a generalized framework for the analysis of history, all histories. I generate artificial histories featuring, say, millions of Giacomo Casanovas, and observe the difference between the attributes of the successful Casanovas (because you generate them, you know their exact properties) and those an observer of the result would obtain. From that perspective, it is not a good idea to be a Casanova.
“I Am a Risk Taker”
Consider the restaurant business in a competitive place like New York City. One has indeed to be foolish to open one, owing to the enormous risks involved and the harrying quantity of work to get anywhere in the business, not counting the finicky fashion-minded clients. The cemetery of failed restaurants is very silent: walk around Midtown Manhattan and you will see these warm patron-filled restaurants with limos waiting outside
for the diners to come out with their second, trophy, spouses. The owner is overworked but happy to have all these important people patronize his eatery. Does this mean that it makes sense to open a restaurant in such a competitive neighborhood? Certainly not, yet people do it out of the foolish risk-taking trait that pushes us to jump into such adventures blinded by the outcome.
Clearly there is an element of the surviving Casanovas in us, that of the risk-taking genes, which encourages us to take blind risks, unaware of the variability in the possible outcomes. We inherited the taste for uncalculated risk taking. Should we encourage such behavior?
In fact, economic growth comes from such risk taking. But some fool might argue the following: if someone followed reasoning such as mine, we would not have had the spectacular growth we experienced in the past. This is exactly like someone playing Russian roulette and finding it a good idea because he survived and pocketed the money.
We are often told that we humans have an optimistic bent, and that
it is supposed to be good for us
. This argument appears to justify general risk taking as a positive enterprise, and one that is glorified in the common culture. Hey, look, our ancestors took the challenges—while you, NNT, are encouraging us to do nothing (I am not).
We have enough evidence to confirm that, indeed, we humans are an extremely lucky species, and that we got the genes of the risk takers. The foolish risk takers, that is. In fact, the Casanovas who survived.
Once again, I am not dismissing the idea of risk taking, having been involved in it myself. I am only critical of the encouragement of
uninformed
risk taking. The überpsychologist Danny Kahneman has given us evidence that we generally take risks not out of bravado but out of ignorance and blindness to probability! The next few chapters will show in more depth how we tend to dismiss outliers and adverse outcomes when projecting the future. But I insist on the following:
that we got here by accident does not mean that we should continue to take the same risks
. We are mature enough a race to realize this point, enjoy our blessings, and try to preserve, by becoming more conservative, what we got by luck. We have been playing Russian roulette; now let’s stop and get a real job.
I have two further points to make on this subject. First, justification of overoptimism on grounds that “it brought us here” arises from a far more serious mistake about human nature: the belief that we are built to understand nature and our own nature and that our decisions are, and have
been, the result of our own choices. I beg to disagree. So many instincts drive us.
Second, a little more worrisome than the first point: evolutionary fitness is something that is continuously touted and aggrandized by the crowd who takes it as gospel. The more unfamiliar someone is with the wild Black Swan–generating randomness, the more he or she believes in the optimal working of evolution. Silent evidence is not present in their theories. Evolution is a series of flukes, some good, many bad. You only see the good. But, in the short term, it is not obvious which traits are really good for you, particularly if you are in the Black Swan–generating environment of Extremistan. This is like looking at rich gamblers coming out of the casino and claiming that a taste for gambling is good for the species because gambling makes you rich! Risk taking made many species head for extinction!
This idea that we are here, that this is the best of all possible worlds, and
that evolution did a great job
seems rather bogus in the light of the silent-evidence effect. The fools, the Casanovas, and the blind risk takers are often the ones who win in the short term. Worse, in a Black Swan environment, where one single but rare event can come shake up a species after a very long run of “fitness,” the foolish risk takers can also win in the long term! I will revisit this idea in Part Three, where I show how Extremistan worsens the silent-evidence effect.
But there is another manifestation that merits a mention.


================================================================================
CHAPTER/SECTION 209 (Item 214)
================================================================================

I AM A BLACK SWAN: THE ANTHROPIC BIAS
I want to stay closer to earth and avoid bringing higher-up metaphysical or cosmological arguments into this discussion—there are so many significant dangers to worry about down here on planet earth and it would be a good idea to postpone the metaphysical philosophizing for later. But it would be useful to take a peek (not more) at what is called the anthropic cosmological argument, as it points out the gravity of our misunderstanding of historical stability.
A recent wave of philosophers and physicists (and people combining the two categories) has been examining
the self-sampling assumption
, which is a generalization of the principle of the Casanova bias to our own existence.
Consider our own fates. Some people reason that the odds of any of us being in existence are so low that our being here cannot be attributed to
an accident of fate. Think of the odds of the parameters being exactly where they need to be to induce our existence (any deviation from the optimal calibration would have made our world explode, collapse, or simply not come into existence). It is often said that the world seems to have been built to the specifications that would make our existence possible. According to such an argument, it could not come from luck.
However,
our presence in the sample
completely vitiates the computation of the odds. Again, the story of Casanova can make the point quite simple—much simpler than in its usual formulation. Think again of all the possible worlds as little Casanovas following their own fates. The one who is still kicking (by accident) will feel that, given that he cannot be so lucky, there had to be some transcendental force guiding him and supervising his destiny: “Hey, otherwise the odds would be too low to get here just by luck.” For someone who observes
all
adventurers, the odds of finding a Casanova are not low at all: there are so many adventurers, and someone is bound to win the lottery ticket.
The problem here with the universe and the human race is that
we are the surviving Casanovas
. When you start with many adventurous Casanovas, there is bound to be a survivor, and guess what: if you are here talking about it, you are likely to be that particular one (notice the “condition”: you survived to talk about it). So we can no longer naïvely compute odds without considering that the condition that we are in existence imposes restrictions on the process that led us here.
Assume that history delivers either “bleak” (i.e., unfavorable) or “rosy” (i.e., favorable) scenarios. The bleak scenarios lead to extinction. Clearly, if I am now writing these lines, it is certainly because history delivered a “rosy” scenario, one that allowed me to be here, a historical route in which my forebears avoided massacre by the many invaders who roamed the Levant. Add to that beneficial scenarios free of meteorite collisions, nuclear war, and other large-scale terminal epidemics. But I do not have to look at humanity as a whole. Whenever I probe into my own biography I am alarmed at how tenuous my life has been so far. Once when I returned to Lebanon during the war, at the age of eighteen, I felt episodes of extraordinary fatigue and cold chills in spite of the summer heat. It was typhoid fever. Had it not been for the discovery of antibiotics, only a few decades earlier, I would not be here today. I was also later “cured” of another severe disease that would have left me for dead, thanks to a treatment that depends on another recent medical technology. As a human
being alive here in the age of the Internet, capable of writing and reaching an audience, I have also benefited from society’s luck and the remarkable absence of recent large-scale war. In addition, I am the result of the rise of the human race, itself an accidental event.
My being here is a consequential low-probability occurrence, and I tend to forget it.
Let us return to the touted recipes for becoming a millionaire in ten steps. A successful person will try to convince you that his achievements could not possibly be accidental, just as a gambler who wins at roulette seven times in a row will explain to you that the odds against such a streak are one in several million, so you either have to believe some transcendental intervention is in play or accept his skills and insight in picking the winning numbers. But if you take into account the quantity of gamblers out there, and the number of gambling sessions (several million episodes in total), then it becomes obvious that such strokes of luck are bound to happen. And if you are talking about them, they have happened to you.
The
reference point argument
is as follows: do not compute odds from the vantage point of the winning gambler (or the lucky Casanova, or the endlessly bouncing back New York City, or the invincible Carthage), but from all those who started in the cohort. Consider once again the example of the gambler. If you look at the population of beginning gamblers taken as a whole, you can be close to certain that one of them (but you do not know in advance which one) will show stellar results just by luck. So, from the
reference point
of the beginning cohort, this is not a big deal. But from the reference point of the winner (and, who does not, and this is key, take the losers into account), a long string of wins will appear to be too extraordinary an occurrence to be explained by luck. Note that a “history” is just a series of numbers through time. The numbers can represent degrees of wealth, fitness, weight, anything.
The Cosmetic Because
This in itself greatly weakens the notion of “because” that is often propounded by scientists, and almost always misused by historians. We have to accept the fuzziness of the familiar “because” no matter how queasy it makes us feel (and it does makes us queasy to remove the analgesic illusion of causality). I repeat that we are explanation-seeking animals who tend to think that everything has an identifiable cause and grab the most apparent
one as
the
explanation. Yet there may not be a visible
because;
to the contrary, frequently there is nothing, not even a spectrum of possible explanations. But silent evidence masks this fact. Whenever our survival is in play, the very notion of
because
is severely weakened. The condition of survival drowns all possible explanations. The Aristotelian “because” is not there to account for a solid link between two items, but rather, as we saw in
Chapter 6
, to cater to our hidden weakness for imparting explanations.
Apply this reasoning to the following question: Why didn’t the bubonic plague kill more people? People will supply quantities of cosmetic explanations involving theories about the intensity of the plague and “scientific models” of epidemics. Now, try the weakened causality argument that I have just emphasized in this chapter: had the bubonic plague killed more people, the observers (us) would not be here to observe. So it may not necessarily be the property of diseases to spare us humans. Whenever your survival is in play, don’t immediately look for causes and effects. The main identifiable reason for our survival of such diseases might simply be inaccessible to us: we are here since, Casanova-style, the “rosy” scenario played out, and if it seems too hard to understand it is because we are too brainwashed by notions of causality and we think that it is smarter to say
because
than to accept randomness.
My biggest problem with the educational system lies precisely in that it forces students to squeeze explanations out of subject matters and
shames
them for withholding judgment, for uttering the “I don’t know.” Why did the Cold War end? Why did the Persians lose the battle of Salamis? Why did Hannibal get his behind kicked? Why did Casanova bounce back from hardship? In each of these examples, we are taking a condition, survival, and looking for the explanations, instead of flipping the argument on its head and stating that
conditional on such survival
, one cannot read
that
much into the process, and should learn instead to invoke some measure of randomness (randomness, in practice, is what we don’t know; to invoke randomness is to plead ignorance). It is not just your college professor who gives you bad habits. I showed in
Chapter 6
how newspapers need to stuff their texts with causal links to make you enjoy the narratives. But have the integrity to deliver your “because” very sparingly; try to limit it to situations where the “because” is derived from experiments, not backward-looking history.
Note here that I am not saying causes do not exist; do not use this argument to avoid trying to learn from history. All I am saying is that it is
not so simple;
be suspicious of the “because” and handle it with care—particularly in situations where you suspect silent evidence.
We have seen several varieties of the silent evidence that cause deformations in our perception of empirical reality, making it appear more explainable (and more stable) than it actually is. In addition to the confirmation error and the narrative fallacy, the manifestations of silent evidence further distort the role and importance of Black Swans. In fact, they cause a gross overestimation at times (say, with literary success), and underestimation at others (the stability of history; the stability of our human species).
I said earlier that our perceptual system may not react to what does not lie in front of our eyes, or what does not arouse our emotional attention. We are made to be superficial, to heed what we see and not heed what does not vividly come to mind. We wage a double war against silent evidence. The unconscious part of our inferential mechanism (and there is one) will ignore the cemetery, even if we are intellectually aware of the need to take it into account. Out of sight, out of mind: we harbor a natural, even physical, scorn of the abstract.
This will be further illustrated in the next chapter.
*
The best noncharlatanic finance book I know is called
What I Learned Losing a Million Dollars
, by D. Paul and B. Moynihan. The authors had to self-publish the book.
*
Doctors are rightfully and vigorously skeptical of anecdotal results, and require that studies of drug efficacy probe into the cemetery of silent evidence. However, the same doctors fall for the bias elsewhere! Where? In their personal lives, or in their investment activities. At the cost of being repetitive, I have to once again state my amazement at the aspect of human nature that allows us to mix the most rigorous skepticism and the most acute gullibility.
*
Silent evidence can actually bias matters to look less stable and riskier than they actually are. Take cancer. We are in the habit of counting survival rates from diagnosed cancer cases—which should overestimate the danger from cancer. Many people develop cancer that remains undiagnosed, and go on to live a long and comfortable life, then die of something else, either because their cancer was not lethal or because it went into spontaneous remission. Not counting these cases biases the risks upward.


================================================================================
CHAPTER/SECTION 210 (Item 215)
================================================================================

Chapter Nine
THE LUDIC FALLACY, OR THE UNCERTAINTY OF THE NERD
Lunch at Lake Como (west)—The military as philosophers—Plato’s randomness


================================================================================
CHAPTER/SECTION 211 (Item 216)
================================================================================

FAT TONY
“Fat Tony” is one of Nero’s friends who irritates Yevgenia Krasnova beyond measure. We should perhaps more thoughtfully style him “Horizontally-challenged Tony,” since he is not as objectively overweight as his nickname indicates; it is just that his body shape makes whatever he wears seem ill-fitted. He wears only tailored suits, many of them cut for him in Rome, but they look as if he bought them from a Web catalog. He has thick hands, hairy fingers, wears a gold wrist chain, and reeks of licorice candies that he devours in industrial quantities as a substitute for an old smoking habit. He doesn’t usually mind people calling him Fat Tony, but he much prefers to be called just Tony. Nero calls him, more politely, “Brooklyn Tony,” because of his accent and his Brooklyn way of thinking, though Tony is one of the prosperous Brooklyn people who moved to New Jersey twenty years ago.
Tony is a successful nonnerd with a happy disposition. He leads a gregarious existence. His sole visible problem seems to be his weight and the corresponding nagging by his family, remote cousins, and friends, who
keep warning him about that premature heart attack. Nothing seems to work; Tony often goes to a fat farm in Arizona to
not
eat, lose a few pounds, then gain almost all of them back in his first-class seat on the flight back. It is remarkable how his self-control and personal discipline, otherwise admirable, fail to apply to his waistline.
He started as a clerk in the back office of a New York bank in the early 1980s, in the letter-of-credit department. He pushed papers and did some grunt work. Later he grew into giving small business loans and figured out the game of how you can get financing from the monster banks, how their bureaucracies operate, and what they like to see on paper. All the while an employee, he started acquiring property in bankruptcy proceedings, buying it from financial institutions. His big insight is that bank employees who sell you a house that’s not theirs just don’t care as much as the owners; Tony knew very rapidly how to talk to them and maneuver. Later, he also learned to buy and sell gas stations with money borrowed from small neighborhood bankers.
Tony has this remarkable habit of trying to make a buck effortlessly, just for entertainment, without straining, without office work, without meeting, just by melding his deals into his private life. Tony’s motto is “Finding who the sucker is.” Obviously, they are often the banks: “The clerks don’t care about nothing.” Finding these suckers is second nature to him. If you took walks around the block with Tony you would feel considerably more informed about the texture of the world just “tawking” to him.
Tony is remarkably gifted at getting unlisted phone numbers, first-class seats on airlines for no additional money, or your car in a garage that is officially full, either through connections or his forceful charm.
Non-Brooklyn John
I found the perfect non-Brooklyn in someone I will call Dr. John. He is a former engineer currently working as an actuary for an insurance company. He is thin, wiry, and wears glasses and a dark suit. He lives in New Jersey not far from Fat Tony but certainly they rarely run into each other. Tony never takes the train, and, actually, never commutes (he drives a Cadillac, and sometimes his wife’s Italian convertible, and jokes that he is more visible than the rest of the car). Dr. John is a master of the schedule; he is as predictable as a clock. He quietly and efficiently reads the newspaper on the train to Manhattan, then neatly folds it for the lunchtime continuation.
While Tony makes restaurant owners rich (they beam when they see him coming and exchange noisy hugs with him), John meticulously packs his sandwich every morning, fruit salad in a plastic container. As for his clothing, he also wears a suit that looks like it came from a Web catalog, except that it is quite likely that it actually did.
Dr. John is a painstaking, reasoned, and gentle fellow. He takes his work seriously, so seriously that, unlike Tony, you can see a line in the sand between his working time and his leisure activities. He has a PhD in electrical engineering from the University of Texas at Austin. Since he knows both computers and statistics, he was hired by an insurance company to do computer simulations; he enjoys the business. Much of what he does consists of running computer programs for “risk management.”
I know that it is rare for Fat Tony and Dr. John to breathe the same air, let alone find themselves at the same bar, so consider this a pure thought exercise. I will ask each of them a question and compare their answers.
NNT (that is, me): Assume that a coin is fair, i.e., has an equal probability of coming up heads or tails when flipped. I flip it ninety-nine times and get heads each time. What are the odds of my getting tails on my next throw?
Dr. John: Trivial question. One half, of course, since you are assuming 50 percent odds for each and independence between draws.
NNT: What do you say, Tony?
Fat Tony: I’d say no more than 1 percent, of course.
NNT: Why so? I gave you the initial assumption of a fair coin, meaning that it was 50 percent either way.
Fat Tony: You are either full of crap or a pure sucker to buy that “50 pehcent” business. The coin gotta be loaded. It can’t be a fair game. (Translation: It is far more likely that your assumptions about the fairness are wrong than the coin delivering ninety-nine heads in ninety-nine throws.)
NNT: But Dr. John said 50 percent.
Fat Tony (whispering in my ear): I know these guys with the nerd examples from the bank days. They think way too slow. And they are too commoditized. You can take them for a ride.
Now, of the two of them, which would you favor for the position of mayor of New York City (or Ulan Bator, Mongolia)? Dr. John thinks entirely within the box, the box that was given to him; Fat Tony, almost entirely outside the box.
To set the terminology straight, what I call “a nerd” here doesn’t have to look sloppy, unaesthetic, and sallow, and wear glasses and a portable computer on his belt as if it were an ostensible weapon. A nerd is simply someone who thinks exceedingly inside the box.
Have you ever wondered why so many of these straight-A students end up going nowhere in life while someone who lagged behind is now getting the shekels, buying the diamonds, and getting his phone calls returned? Or even getting the Nobel Prize in a real discipline (say, medicine)? Some of this may have something to do with luck in outcomes, but there is this sterile and obscurantist quality that is often associated with classroom knowledge that may get in the way of understanding what’s going on in real life. In an IQ test, as well as in any academic setting (including sports), Dr. John would vastly outperform Fat Tony. But Fat Tony would outperform Dr. John in any other possible ecological, real-life situation. In fact, Tony, in spite of his lack of culture, has an enormous curiosity about the texture of reality, and his own erudition—to me, he is more scientific in the literal, though not in the social, sense than Dr. John.
We will get deep, very deep, into the difference between the answers of Fat Tony and Dr. John; this is probably the most vexing problem I know about the connections between two varieties of knowledge, what we dub Platonic and a-Platonic. Simply, people like Dr. John can cause Black Swans outside Mediocristan—their minds are closed. While the problem is very general, one of its nastiest illusions is what I call the ludic fallacy—the attributes of the uncertainty we face in real life have little connection to the sterilized ones we encounter in exams and games.
So I close Part One with the following story.


================================================================================
CHAPTER/SECTION 212 (Item 217)
================================================================================

LUNCH AT LAKE COMO
One spring day a few years ago, I was surprised to receive an invitation from a think tank sponsored by the United States Defense Department to a brainstorming session on risk that was to take place in Las Vegas the following fall. The person who invited me announced on the phone, “We’ll have lunch on a terrace overlooking Lake Como,” which put me in a state of severe distress. Las Vegas (along with its sibling the emirate of Dubai) is perhaps one place I’d never wish to visit before I die. Lunch at “fake Como” would be torture. But I’m glad I went.
The think tank had gathered a nonpolitical collection of people they called doers and scholars (and practitioners like me who do not accept the
distinction) involved in uncertainty in a variety of disciplines. And they symbolically picked a major casino as a venue.
The symposium was a closed-doors, synod-style assembly of people who would never have mixed otherwise. My first surprise was to discover that the military people there thought, behaved, and acted like philosophers—far more so than the philosophers we will see splitting hairs in their weekly colloquium in Part Three. They thought out of the box, like traders, except much better and without fear of introspection. An assistant secretary of defense was among us, but had I not known his profession I would have thought he was a practitioner of skeptical empiricism. Even an engineering investigator who had examined the cause of a space shuttle explosion was thoughtful and open-minded. I came out of the meeting realizing that only military people deal with randomness with genuine, introspective intellectual honesty—unlike academics and corporate executives using other people’s money. This does not show in war movies, where they are usually portrayed as war-hungry autocrats. The people in front of me were not the people who initiate wars. Indeed, for many, the successful defense policy is the one that manages to eliminate potential dangers without war, such as the strategy of bankrupting the Russians through the escalation in defense spending. When I expressed my amazement to Laurence, another finance person who was sitting next to me, he told me that the military collected more genuine intellects and risk thinkers than most if not all other professions. Defense people wanted to understand the epistemology of risk.
In the group was a gentleman who ran a group of professional gamblers and who was banned from most casinos. He had come to share his wisdom with us. He sat not far from a stuffy professor of political science, dry like a bone and, as is characteristic of “big names,” careful about his reputation, who said nothing out of the box, and who did not smile once. During the sessions, I tried to imagine the hotshot with a rat dropped down his back, putting him in a state of wriggling panic. He was perhaps good at writing Platonic models of something called game theory, but when Laurence and I went after him on his improper use of financial metaphors, he lost all his arrogance.
Now, when you think of the major risks casinos face, gambling situations come to mind. In a casino, one would think, the risks include lucky gamblers blowing up the house with a series of large wins and cheaters taking away money through devious methods. It is not just the general public that would believe so, but the casino management as well. Consequently,
the casino had a high-tech surveillance system tracking cheaters, card counters, and other people who try to derive an advantage over them.
Each of the participants gave his presentation and listened to those of the others. I came to discuss Black Swans, and I intended to tell them that the only thing I know is that we know precious little about them, but that it was their property to sneak up on us, and that attempts at Platonifying them led to additional misunderstandings. Military people can understand such things, and the idea became recently prevalent in military circles with the expression
unknown unknown
(as opposed to the
known unknown)
. But I had prepared my talk (on five restaurant napkins, some stained) and was ready to discuss a new phrase I coined for the occasion: the
ludic fallacy
. I intended to tell them that I should not be speaking at a casino because it had nothing to do with uncertainty.
The Uncertainty of the Nerd
What is the
ludic
fallacy?
Ludic
comes from
ludus
, Latin for games.
I was hoping that the representatives of the casino would speak before me so I could start harassing them by showing (politely) that a casino was precisely the venue
not
to pick for such a discussion, since the class of risks casinos encounter are very insignificant
outside
of the building, and their study not readily transferable. My idea is that gambling was
sterilized
and domesticated uncertainty. In the casino you know the rules, you can calculate the odds, and the type of uncertainty we encounter there, we will see later, is
mild
, belonging to Mediocristan. My prepared statement was this: “The casino is the only human venture I know where the probabilities are known, Gaussian (i.e., bell-curve), and almost computable.” You cannot expect the casino to pay out a million times your bet, or to change the rules abruptly on you during the game—there are never days in which “36 black” is designed to pop up 95 percent of the time.
*
In real life you do not know the odds; you need to discover them, and the sources of uncertainty are not defined. Economists, who do not consider
what was discovered by noneconomists worthwhile, draw an artificial distinction between Knightian risks (which you can compute) and Knightian uncertainty (which you cannot compute), after one Frank Knight, who rediscovered the notion of unknown uncertainty and did a lot of thinking but perhaps never took risks, or perhaps lived in the vicinity of a casino. Had he taken economic or financial risks he would have realized that these “computable” risks are largely absent from real life! They are laboratory contraptions!
Yet we automatically, spontaneously associate chance with these Platonified games. I find it infuriating to listen to people who, upon being informed that I specialize in problems of chance, immediately shower me with references to dice. Two illustrators for a paperback edition of one of my books spontaneously and independently added a die to the cover and below every chapter, throwing me into a state of rage. The editor, familiar with my thinking, warned them to “avoid the ludic fallacy,” as if it were a well-known intellectual violation. Amusingly, they both reacted with an “Ah, sorry, we didn’t know.”
Those who spend too much time with their noses glued to maps will tend to mistake the map for the territory. Go buy a recent history of probability and probabilistic thinking; you will be showered with names of alleged “probability thinkers” who all base their ideas on these sterilized constructs. I recently looked at what college students are taught under the subject of chance and came out horrified; they were brainwashed with this ludic fallacy and the outlandish bell curve. The same is true of people doing PhD’s in the field of probability theory. I’m reminded of a recent book by a thoughtful mathematician, Amir Aczel, called
Chance
. Excellent book perhaps, but like all other modern books it is grounded in the ludic fallacy. Furthermore, assuming chance has anything to do with mathematics, what little mathematization we can do in the real world does not assume the mild randomness represented by the bell curve, but rather scalable wild randomness. What can be mathematized is usually not Gaussian, but Mandelbrotian.
Now, go read any of the classical thinkers who had something practical to say about the subject of chance, such as Cicero, and you find something different: a notion of probability that remains fuzzy throughout, as it needs to be, since such fuzziness is the very nature of uncertainty. Probability is a liberal art; it is a child of skepticism, not a tool for people with calculators on their belts to satisfy their desire to produce fancy calculations and certainties. Before Western thinking drowned in its “scientific”
mentality, what is arrogantly called the Enlightenment, people prompted their brain to think—not compute. In a beautiful treatise now vanished from our consciousness,
Dissertation on the Search for Truth
, published in 1673, the polemist Simon Foucher exposed our psychological predilection for certainties. He teaches us the art of doubting, how to position ourselves between doubting and believing. He writes: “One needs to exit doubt in order to produce science—but few people heed the importance of not exiting from it prematurely. … It is a fact that one usually exits doubt without realizing it.” He warns us further: “We are dogma-prone from our mother’s wombs.”
By the confirmation error discussed in
Chapter 5
, we use the example of games, which probability theory was successful at tracking, and claim that this is a general case. Furthermore, just as we tend to underestimate the role of luck in life in general, we tend to
overestimate
it in games of chance.
“This building is inside the Platonic fold; life stands outside of it,” I wanted to shout.
Gambling with the Wrong Dice
I was in for quite a surprise when I learned that the building too was outside the Platonic fold.
The casino’s risk management, aside from setting its gambling policies, was geared toward reducing the losses resulting from cheaters. One does not need heavy training in probability theory to understand that the casino was sufficiently diversified across the different tables to not have to worry about taking a hit from an extremely lucky gambler (the diversification argument that leads to the bell curve, as we will see in
Chapter 15
). All they had to do was control the “whales,” the high rollers flown in at the casino’s expense from Manila or Hong Kong; whales can swing several million dollars in a gambling bout. Absent cheating, the performance of most individual gamblers would be the equivalent of a drop in the bucket, making the aggregate very stable.
I promised not to discuss any of the details of the casino’s sophisticated surveillance system; all I am allowed to say is that I felt transported into a James Bond movie—I wondered if the casino was an imitation of the movies or if it was the other way around. Yet, in spite of such sophistication, their risks had nothing to do with what can be anticipated knowing that the business is a casino. For it turned out that the four largest losses
incurred or narrowly avoided by the casino fell completely outside their sophisticated models.
First, they lost around $100 million when an irreplaceable performer in their main show was maimed by a tiger (the show,
Siegfried and Roy
, had been a major Las Vegas attraction). The tiger had been reared by the performer and even slept in his bedroom; until then, nobody suspected that the powerful animal would turn against its master. In scenario analyses, the casino had even conceived of the animal jumping into the crowd, but nobody came near to the idea of insuring against what happened.
Second, a disgruntled contractor was hurt during the construction of a hotel annex. He was so offended by the settlement offered him that he made an attempt to dynamite the casino. His plan was to put explosives around the pillars in the basement. The attempt was, of course, thwarted (otherwise, to use the arguments in
Chapter 8
, we would not have been there), but I shivered at the thought of possibly sitting above a pile of dynamite.
Third, casinos must file a special form with the Internal Revenue Service documenting a gambler’s profit if it exceeds a given amount. The employee who was supposed to mail the forms hid them, instead, for completely unexplainable reasons, in boxes under his desk. This went on for years without anyone noticing that something was wrong. The employee’s refraining from sending the documents was truly impossible to predict. Tax violations (and negligence) being serious offences, the casino faced the near loss of a gambling license or the onerous financial costs of a suspension. Clearly they ended up paying a monstrous fine (an undisclosed amount), which was the luckiest way out of the problem.
Fourth, there was a spate of other dangerous scenes, such as the kidnapping of the casino owner’s daughter, which caused him, in order to secure cash for the ransom, to violate gambling laws by dipping into the casino coffers.
Conclusion:
A back-of-the-envelope calculation shows that the dollar value of these Black Swans, the off-model hits and potential hits I’ve just outlined, swamp the on-model risks by a factor of close to 1,000 to 1. The casino spent hundreds of millions of dollars on gambling theory and high-tech surveillance while the bulk of their risks came from outside their models.
All this, and yet the rest of the world still learns about uncertainty and probability from gambling examples.


================================================================================
CHAPTER/SECTION 213 (Item 218)
================================================================================

WRAPPING UP PART ONE
The Cosmetic Rises to the Surface
All of the topics in Part One are actually only one. You can think about a subject for a long time, to the point of being possessed by it. Somehow you have a lot of ideas, but they do not seem explicitly connected; the logic linking them remains concealed from you. Yet you know deep down that all these are
the same
idea. Meanwhile, what Nietzsche calls
bildungsphilisters
,
*
or learned philistines, blue collars of the thinking business, tell you that you are spread out between fields; you reply that these disciplines are artificial and arbitrary, to no avail. Then you tell them that you are a limousine driver, and they leave you alone—you feel better because you do not identify with them, and thus you no longer need to be amputated to fit into the Procrustean bed of the disciplines. Finally, a little push and you see that it was all one single problem.
One evening I found myself at a cocktail party in Munich at the apartment of a former art historian who had more art books in its library than I thought existed. I stood drinking excellent Riesling in the spontaneously formed English-speaking corner of the apartment, in the hope of getting to a state where I would be able to start speaking my brand of fake German. One of the most insightful thinkers I know, the computer entrepreneur Yossi Vardi, prompted me to summarize “my idea” while standing on one leg. It was not too convenient to stand on one leg after a few glasses of perfumed Riesling, so I failed in my improvisation. The next day I experienced staircase wit. I jumped out of bed with the following idea:
the cosmetic and the Platonic rise naturally to the surface
. This is a simple extension of the problem of knowledge. It is simply that one side of Eco’s library, the one we never see, has the property of being ignored. This is also the problem of silent evidence. It is why we do not see Black Swans: we worry about those that happened, not those that may happen but did not. It is why we Platonify, liking known schemas and well-organized knowledge—to the point of blindness to reality. It is why we fall for the problem of induction, why we
confirm
. It is why those who “study” and fare well in school have a tendency to be suckers for the ludic fallacy.
And it is why we have Black Swans and never learn from their occurrence, because the ones that did not happen were too abstract. Thanks to Vardi, I now belonged to the club of single-idea people.
We love the tangible, the confirmation, the palpable, the real, the visible, the concrete, the known, the seen, the vivid, the visual, the social, the embedded, the emotionally laden, the salient, the stereotypical, the moving, the theatrical, the romanced, the cosmetic, the official, the scholarly-sounding verbiage (b******t), the pompous Gaussian economist, the mathematicized crap, the pomp, the Académie Française, Harvard Business School, the Nobel Prize, dark business suits with white shirts and Ferragamo ties, the moving discourse, and the lurid. Most of all we favor
the narrated
.
Alas, we are not manufactured, in our current edition of the human race, to understand abstract matters—we need context. Randomness and uncertainty are abstractions. We respect what has happened, ignoring what
could have
happened. In other words, we are naturally shallow and superficial—and we do not know it. This is not a psychological problem; it comes from the main property of information. The dark side of the moon is harder to see; beaming light on it costs energy. In the same way, beaming light on the unseen is costly in both computational and mental effort.
Distance from Primates
There have been in history many distinctions between higher and lower forms of humans. For the Greeks, there were the Greeks and the barbarians, those people of the north who uttered amorphous sentences similar, to the Attic ear, to an animal’s shrieks. For the English, a higher form of life was the gentleman’s—contrary to today’s definition, a gentleman’s life was practiced through idleness and a code of behavior that included, along with a set of manners, the avoidance of work beyond the necessities of comfortable subsistence. For New Yorkers, there are those with a Manhattan zip code and those with such a thing as a Brooklyn or, worse, Queens address. For the earlier Nietzsche, there was the Apollonian compared to the Dionysian; for the better-known Nietzsche, there was the Übermensch, something his readers interpret however it suits them. For a modern stoic, a higher individual subscribes to a dignified system of virtue that determines elegance in one’s behavior and the ability to separate results from efforts. All of these distinctions aim at lengthening the distance
between us and our relatives among other primates. (I keep insisting that, when it comes to decision making, the distance between us and these hairy cousins is far shorter than we think.)
I propose that if you want a simple step to a higher form of life, as distant from the animal as you can get, then you may have to denarrate, that is, shut down the television set, minimize time spent reading newspapers, ignore the blogs. Train your reasoning abilities to control your decisions; nudge System 1 (the heuristic or experiential system) out of the important ones. Train yourself to spot
the difference between the sensational and the empirical
. This insulation from the toxicity of the world will have an additional benefit: it will improve your well-being. Also, bear in mind how shallow we are with probability, the mother of all abstract notions. You do not have to do much more in order to gain a deeper understanding of things around you. Above all, learn to avoid “tunneling.”
A bridge here to what is to come. The Platonic blindness I illustrated with the casino story has another manifestation: focusing. To be able to focus is a great virtue if you are a watch repairman, a brain surgeon, or a chess player. But the last thing you need to do when you deal with uncertainty is to “focus” (you should tell uncertainty to focus, not us). This “focus” makes you a sucker; it translates into prediction problems, as we will see in the next section. Prediction, not narration, is the real test of our understanding of the world.
*
My colleague Mark Spitznagel found a martial version of the ludic fallacy: organized competitive fighting trains the athlete to focus on the game and, in order not to dissipate his concentration, to ignore the possibility of what is not specifically allowed by the rules, such as kicks to the groin, a surprise knife, et cetera. So those who win the gold medal might be precisely those who will be most vulnerable in real life. Likewise, you see people with huge muscles (in black T-shirts) who can impress you in the artificial environment of the gym but are unable to lift a stone.
*
What Nietzsche means by this term are the dogma-prone newspaper readers and opera lovers who have cosmetic exposure to culture and shallow depth. I extend the term here to the philistine hiding in academia who lacks in erudition out of lack of curiosity and is closely centered on his ideas.


================================================================================
CHAPTER/SECTION 214 (Item 219)
================================================================================

W
hen I ask people to name three recently implemented technologies that most impact our world today, they usually propose the computer, the Internet, and the laser. All three were unplanned, unpredicted, and unappreciated upon their discovery, and remained unappreciated well after their initial use. They were consequential. They were Black Swans. Of course, we have this retrospective illusion of their partaking in some master plan. You can create your own lists with similar results, whether you use political events, wars, or intellectual epidemics.
You would expect our record of prediction to be horrible: the world is far, far more complicated than we think, which is not a problem, except when most of us don’t know it. We tend to “tunnel” while looking into the future, making it business as usual, Black Swan–free, when in fact there is nothing usual about the future. It is not a Platonic category!
We have seen how good we are at narrating backward, at inventing stories that convince us that we understand the past. For many people, knowledge has the remarkable power of producing confidence instead of measurable aptitude. Another problem: the focus on the (inconsequential) regular, the Platonification that makes the forecasting “inside the box.”
I find it scandalous that in spite of the empirical record we continue to project into the future as if we were good at it, using tools and methods that exclude rare events. Prediction is firmly institutionalized in our world. We are suckers for those who help us navigate uncertainty, whether the
fortune-teller or the “well-published” (dull) academics or civil servants using phony mathematics.
From Yogi Berra to Henri Poincaré
The great baseball coach Yogi Berra has a saying, “It is tough to make predictions, especially about the future.” While he did not produce the writings that would allow him to be considered a philosopher, in spite of his wisdom and intellectual abilities, Berra can claim to know something about randomness. He was a practitioner of uncertainty, and, as a baseball player and coach, regularly faced random outcomes, and had to face their results deep into his bones.
In fact, Yogi Berra is not the only thinker who thought about how much of the future lies beyond our abilities. Many less popular, less pithy, but not less competent thinkers than he have examined our inherent limitations in this regard, from the philosophers Jacques Hadamard and Henri Poincaré (commonly described as mathematicians), to the philosopher Friedrich von Hayek (commonly described, alas, as an economist), to the philosopher Karl Popper (commonly known as a philosopher). We can safely call this the Berra-Hadamard-Poincaré-Hayek-Popper conjecture, which puts structural, built-in limits to the enterprise of predicting.
“The future ain’t what it used to be,” Berra later said.
*
He seems to have been right: the gains in our ability to model (and predict) the world may be dwarfed by the increases in its complexity—implying a greater and greater role for the unpredicted. The larger the role of the Black Swan, the harder it will be for us to predict. Sorry.
Before going into the limits of prediction, we will discuss our track record in forecasting and the relation between gains in knowledge and the offsetting gains in confidence.
*
Note that these sayings attributed to Yogi Berra might be apocryphal—it was the physicist Niels Bohr who came up with the first one, and plenty of others came up with the second. These sayings remain, however, quintessential Berraisms.


================================================================================
CHAPTER/SECTION 215 (Item 220)
================================================================================

Chapter Ten
THE SCANDAL OF PREDICTION
Welcome to Sydney—How many lovers did she have?—How to be an economist, wear a nice suit, and make friends—Not right, just “almost” right—Shallow rivers can have deep spots
One March evening, a few men and women were standing on the esplanade overlooking the bay outside the Sydney Opera House. It was close to the end of the summer in Sydney, but the men were wearing jackets despite the warm weather. The women were more thermally comfortable than the men, but they had to suffer the impaired mobility of high heels.
They all had come to pay the price of sophistication. Soon they would listen for several hours to a collection of oversize men and women singing endlessly in Russian. Many of the opera-bound people looked like they worked for the local office of J. P. Morgan, or some other financial institution where employees experience differential wealth from the rest of the local population, with concomitant pressures on them to live by a sophisticated script (wine and opera). But I was not there to take a peek at the neosophisticates. I had come to look at the Sydney Opera House, a building that adorns every Australian tourist brochure. Indeed, it is striking, though it looks like the sort of building architects create in order to impress other architects.
That evening walk in the very pleasant part of Sydney called the Rocks
was a pilgrimage. While Australians were under the illusion that they had built a monument to distinguish their skyline, what they had really done was to construct a monument to our failure to predict, to plan, and to come to grips with our
unknowledge
of the future—our systematic underestimation of what the future has in store.
The Australians had actually built a symbol of the epistemic arrogance of the human race. The story is as follows. The Sydney Opera House was supposed to open in early 1963 at a cost of AU$ 7 million. It finally opened its doors more than ten years later, and, although it was a less ambitious version than initially envisioned, it ended up costing around AU$ 104 million. While there are far worse cases of planning failures (namely the Soviet Union), or failures to forecast (all important historical events), the Sydney Opera House provides an aesthetic (at least in principle) illustration of the difficulties. This opera-house story is the mildest of all the distortions we will discuss in this section (it was only money, and it did not cause the spilling of innocent blood). But it is nevertheless emblematic.
This chapter has two topics. First, we are demonstrably arrogant about what we think we know. We certainly know a lot, but we have a built-in tendency to think that we know a little bit more than we actually do, enough of
that little bit
to occasionally get into serious trouble. We shall see how you can verify, even measure, such arrogance in your own living room.
Second, we will look at the implications of this arrogance for all the activities involving prediction.
Why on earth do we predict so much? Worse, even, and more interesting: Why don’t we talk about our record in predicting? Why don’t we see how we (almost) always miss the big events? I call this the scandal of prediction.


================================================================================
CHAPTER/SECTION 216 (Item 221)
================================================================================

ON THE VAGUENESS OF CATHERINE’S LOVER COUNT
Let us examine what I call
epistemic arrogance
, literally, our hubris concerning the limits of our knowledge.
Epistēmē
is a Greek word that refers to knowledge; giving a Greek name to an abstract concept makes it sound important. True, our knowledge does grow, but it is threatened by greater increases in confidence, which make our increase in knowledge at the same time an increase in confusion, ignorance, and conceit.
Take a room full of people. Randomly pick a number. The number could correspond to anything: the proportion of psychopathic stockbrokers
in western Ukraine, the sales of this book during the months with
r
in them, the average IQ of business-book editors (or business writers), the number of lovers of Catherine II of Russia, et cetera. Ask each person in the room to independently estimate a range of possible values for that number set in such a way that they believe that they have a 98 percent chance of being right, and less than 2 percent chance of being wrong. In other words, whatever they are guessing has about a 2 percent chance to fall outside their range. For example:
“I am 98 percent confident that the population of Rajastan is between 15 and 23 million.”
“I am 98 percent confident that Catherine II of Russia had between 34 and 63 lovers.”
You can make inferences about human nature by counting how many people in your sample guessed wrong; it is not expected to be too much higher than two out of a hundred participants. Note that the subjects (your victims) are free to set their range as wide as they want: you are not trying to gauge their knowledge but rather
their evaluation of their own knowledge
.
Now, the results. Like many things in life, the discovery was unplanned, serendipitous, surprising, and took a while to digest. Legend has it that Albert and Raiffa, the researchers who noticed it, were actually looking for something quite different, and more boring: how humans figure out probabilities in their decision making when uncertainty is involved (what the learned call
calibrating)
. The researchers came out befuddled. The 2 percent error rate turned out to be close to 45 percent in the population being tested! It is quite telling that the first sample consisted of Harvard Business School students, a breed not particularly renowned for their humility or introspective orientation. MBAs are particularly nasty in this regard, which might explain their business success. Later studies document more humility, or rather a smaller degree of arrogance, in other populations. Janitors and cabdrivers are rather humble. Politicians and corporate executives, alas … I’ll leave them for later.
Are we twenty-two times too comfortable with what we know? It seems so.
This experiment has been replicated dozens of times, across populations, professions, and cultures, and just about every empirical psychologist and decision theorist has tried it on his class to show his students the big problem of humankind: we are simply not wise enough to be trusted with knowledge. The intended 2 percent error rate usually turns out to be
between 15 percent and 30 percent, depending on the population and the subject matter.
I have tested myself and, sure enough, failed, even while consciously trying to be humble by carefully setting a wide range—and yet such underestimation happens to be, as we will see, the core of my professional activities. This bias seems present in all cultures, even those that favor humility—there may be no consequential difference between downtown Kuala Lumpur and the ancient settlement of Amioun, (currently) Lebanon. Yesterday afternoon, I gave a workshop in London, and had been mentally writing on my way to the venue because the cabdriver had an above-average ability to “find traffic.” I decided to make a quick experiment during my talk.
I asked the participants to take a stab at a range for the number of books in Umberto Eco’s library, which, as we know from the introduction to Part One, contains 30,000 volumes. Of the sixty attendees, not a single one made the range wide enough to include the actual number (the 2 percent error rate became 100 percent). This case may be an aberration, but the distortion is exacerbated with quantities that are out of the ordinary. Interestingly, the crowd erred on the very high and the very low sides: some set their ranges at 2,000 to 4,000; others at 300,000 to 600,000.
True, someone warned about the nature of the test can play it safe and set the range between zero and infinity; but this would no longer be “calibrating”—that person would not be conveying any information, and could not produce an informed decision in such a manner. In this case it is more honorable to just say, “I don’t want to play the game; I have no clue.”
It is not uncommon to find counterexamples, people who overshoot in the opposite direction and actually overestimate their error rate: you may have a cousin particularly careful in what he says, or you may remember that college biology professor who exhibited pathological humility; the tendency that I am discussing here applies to the average of the population, not to every single individual. There are sufficient variations around the average to warrant occasional counterexamples. Such people are in the minority—and, sadly, since they do not easily achieve prominence, they do not seem to play too influential a role in society.
Epistemic arrogance bears a double effect: we overestimate what we know, and underestimate uncertainty, by compressing the range of possible uncertain states (i.e., by reducing the space of the unknown).
The applications of this distortion extend beyond the mere pursuit of
knowledge: just look into the lives of the people around you. Literally any decision pertaining to the future is likely to be infected by it. Our human race is affected by a chronic underestimation of the possibility of the future straying from the course initially envisioned (in addition to other biases that sometimes exert a compounding effect). To take an obvious example, think about how many people divorce. Almost all of them are acquainted with the statistic that between one-third and one-half of all marriages fail, something the parties involved did not forecast while tying the knot. Of course, “not us,” because “we get along so well” (as if others tying the knot got along poorly).
I remind the reader that I am not testing how much people know, but assessing
the difference between what people actually know and how much they think they know
. I am reminded of a measure my mother concocted, as a joke, when I decided to become a businessman. Being ironic about my (perceived) confidence, though not necessarily unconvinced of my abilities, she found a way for me to make a killing. How? Someone who could figure out how to buy me at the price I am truly worth and sell me at what I think I am worth would be able to pocket a huge difference. Though I keep trying to convince her of my internal humility and insecurity concealed under a confident exterior; though I keep telling her that I am an introspector—she remains skeptical. Introspector shmintrospector, she still jokes at the time of this writing that I am a little ahead of myself.


================================================================================
CHAPTER/SECTION 217 (Item 222)
================================================================================

BLACK SWAN BLINDNESS REDUX
The simple test above suggests the presence of an ingrained tendency in humans to underestimate outliers—or Black Swans. Left to our own devices, we tend to think that what happens every decade in fact only happens once every century, and, furthermore, that we know what’s going on.
This miscalculation problem is a little more subtle. In truth, outliers are not as sensitive to underestimation since they are fragile to estimation errors, which can go in both directions. As we saw in
Chapter 6
, there are conditions under which people overestimate the unusual or some specific unusual event (say when sensational images come to their minds)—which, we have seen, is how insurance companies thrive. So my general point is that these events are very fragile to
miscalculation
, with a general severe underestimation mixed with an occasional severe overestimation.
The errors get worse with the degree of remoteness to the event. So far, we have only considered a 2 percent error rate in the game we saw earlier,
but if you look at, say, situations where the odds are one in a hundred, one in a thousand, or one in a million, then the errors become monstrous. The longer the odds, the larger the epistemic arrogance.
Note here one particularity of our intuitive judgment: even if we lived in Mediocristan, in which large events are rare (and, mostly, inconsequential), we would still underestimate extremes—we would think that they are even rarer. We underestimate our error rate even with Gaussian variables. Our intuitions are sub-Mediocristani. But we do not live in Mediocristan. The numbers we are likely to estimate on a daily basis belong largely in Extremistan, i.e., they are run by concentration and subjected to Black Swans.
Guessing and Predicting
There is no effective difference between my guessing a variable that is not random, but for which my information is partial or deficient, such as the number of lovers who transited through the bed of Catherine II of Russia, and predicting a random one, like tomorrow’s unemployment rate or next year’s stock market. In this sense, guessing (what I don’t know, but what someone else may know) and predicting (what has not taken place yet) are the same thing.
To further appreciate the connection between guessing and predicting, assume that instead of trying to gauge the number of lovers of Catherine of Russia, you are estimating the less interesting but, for some, more important question of the population growth for the next century, the stockmarket returns, the social-security deficit, the price of oil, the results of your great-uncle’s estate sale, or the environmental conditions of Brazil two decades from now. Or, if you are the publisher of Yevgenia Krasnova’s book, you may need to produce an estimate of the possible future sales. We are now getting into dangerous waters: just consider that most professionals who make forecasts are also afflicted with the mental impediment discussed above. Furthermore, people who make forecasts professionally are often
more
affected by such impediments than those who don’t.


================================================================================
CHAPTER/SECTION 218 (Item 223)
================================================================================

INFORMATION IS BAD FOR KNOWLEDGE
You may wonder how learning, education, and experience affect epistemic arrogance—how educated people might score on the above test, as compared with the rest of the population (using Mikhail the cabdriver as a benchmark). You will be surprised by the answer: it depends on the profession.
I will first look at the advantages of the “informed” over the rest of us in the humbling business of prediction.
I recall visiting a friend at a New York investment bank and seeing a frenetic hotshot “master of the universe” type walking around with a set of wireless headphones wrapped around his ears and a microphone jutting out of the right side that prevented me from focusing on his lips during my twenty-second conversation with him. I asked my friend the purpose of that contraption. “He likes to keep in touch with London,” I was told. When you are employed, hence dependent on other people’s judgment, looking busy can help you claim responsibility for the results in a random environment. The appearance of busyness reinforces the perception of causality, of the link between results and one’s role in them. This of course applies even more to the CEOs of large companies who need to trumpet a link between their “presence” and “leadership” and the results of the company. I am not aware of any studies that probe the usefulness of their time being invested in conversations and the absorption of small-time information—nor have too many writers had the guts to question how large the CEO’s role is in a corporation’s success.
Let us discuss one main effect of information: impediment to knowledge.
Aristotle Onassis, perhaps the first mediatized tycoon, was principally famous for being rich—and for exhibiting it. An ethnic Greek refugee from southern Turkey, he went to Argentina, made a lump of cash by importing Turkish tobacco, then became a shipping magnate. He was reviled when he married Jacqueline Kennedy, the widow of the American president John F. Kennedy, which drove the heartbroken opera singer Maria Callas to immure herself in a Paris apartment to await death.
If you study Onassis’s life, which I spent part of my early adulthood doing, you would notice an interesting regularity: “work,” in the conventional sense, was not his thing. He did not even bother to have a desk, let alone an office. He was not just a dealmaker, which does not necessitate having an office, but he also ran a shipping empire, which requires day-to-day monitoring. Yet his main tool was a notebook, which contained all the information he needed. Onassis spent his life trying to socialize with the rich and famous, and to pursue (and collect) women. He generally woke up at noon. If he needed legal advice, he would summon his lawyers to some nightclub in Paris at two
A.M
. He was said to have an irresistible charm, which helped him take advantage of people.
Let us go beyond the anecdote. There may be a “fooled by randomness”
effect here, of making a causal link between Onassis’s success and his modus operandi. I may never know if Onassis was skilled or lucky, though I am convinced that his charm opened doors for him, but I can subject his modus to a rigorous examination by looking at empirical research on the link between information and understanding. So this statement,
additional knowledge of the minutiae of daily business can be useless, even actually toxic
, is indirectly but quite effectively testable.
Show two groups of people a blurry image of a fire hydrant, blurry enough for them not to recognize what it is. For one group, increase the resolution slowly, in ten steps. For the second, do it faster, in five steps. Stop at a point where both groups have been presented an identical image and ask each of them to identify what they see. The members of the group that saw fewer intermediate steps are likely to recognize the hydrant much faster. Moral? The more information you give someone, the more hypotheses they will formulate along the way, and the worse off they will be. They see more random noise and mistake it for information.
The problem is that our ideas are sticky: once we produce a theory, we are not likely to change our minds—so those who delay developing their theories are better off. When you develop your opinions on the basis of weak evidence, you will have difficulty interpreting subsequent information that contradicts these opinions, even if this new information is obviously more accurate. Two mechanisms are at play here: the confirmation bias that we saw in
Chapter 5
, and belief perseverance, the tendency not to reverse opinions you already have. Remember that we treat ideas like possessions, and it will be hard for us to part with them.
The fire hydrant experiment was first done in the sixties, and replicated several times since. I have also studied this effect using the mathematics of information: the more detailed knowledge one gets of empirical reality, the more one will see the noise (i.e., the anecdote) and mistake it for actual information. Remember that we are swayed by the sensational. Listening to the news on the radio every hour is far worse for you than reading a weekly magazine, because the longer interval allows information to be filtered a bit.
In 1965, Stuart Oskamp supplied clinical psychologists with successive files, each containing an increasing amount of information about patients; the psychologists’ diagnostic abilities did not grow with the additional supply of information. They just got more confident in their original diagnosis. Granted, one may not expect too much of psychologists of the 1965 variety, but these findings seem to hold across disciplines.
Finally, in another telling experiment, the psychologist Paul Slovic asked bookmakers to select from eighty-eight variables in past horse races those that they found useful in computing the odds. These variables included all manner of statistical information about past performances. The bookmakers were given the ten most useful variables, then asked to predict the outcome of races. Then they were given ten more and asked to predict again. The increase in the information set did not lead to an increase in their accuracy; their confidence in their choices, on the other hand, went up markedly. Information proved to be toxic. I’ve struggled much of my life with the common middlebrow belief that “more is better”—more is sometimes, but not always, better. This toxicity of knowledge will show in our investigation of the so-called expert.


================================================================================
CHAPTER/SECTION 219 (Item 224)
================================================================================

THE EXPERT PROBLEM, OR THE TRAGEDY OF THE EMPTY SUIT
So far we have not questioned the authority of the professionals involved but rather their ability to gauge the boundaries of their own knowledge. Epistemic arrogance does not preclude skills. A plumber will almost always know more about plumbing than a stubborn essayist and mathematical trader. A hernia surgeon will rarely know less about hernias than a belly dancer. But their probabilities, on the other hand, will be off—and, this is the disturbing point, you may know much more on that score than the expert. No matter what anyone tells you, it is a good idea to question
the error rate
of an expert’s procedure. Do not question his procedure, only his confidence. (As someone who was burned by the medical establishment, I learned to be cautious, and I urge everyone to be: if you walk into a doctor’s office with a symptom, do not listen to his odds of its
not
being cancer.)
I will separate the two cases as follows. The mild case:
arrogance in the presence of (some) competence
, and the severe case:
arrogance mixed with incompetence (the empty suit)
. There are some professions in which you know more than the experts, who are, alas, people for whose opinions you are paying—instead of them paying you to listen to them. Which ones?
What Moves and What Does Not Move
There is a very rich literature on the so-called expert problem, running empirical testing on experts to verify their record. But it seems to be confusing
at first. On one hand, we are shown by a class of expert-busting researchers such as Paul Meehl and Robyn Dawes that the “expert” is the closest thing to a fraud, performing no better than a computer using a single metric, their intuition getting in the way and blinding them. (As an example of a computer using a single metric, the ratio of liquid assets to debt fares better than the majority of credit analysts.) On the other hand, there is abundant literature showing that many people can beat computers thanks to their intuition. Which one is correct?
There must be some disciplines with true experts. Let us ask the following questions: Would you rather have your upcoming brain surgery performed by a newspaper’s science reporter or by a certified brain surgeon? On the other hand, would you prefer to listen to an economic forecast by someone with a PhD in finance from some “prominent” institution such as the Wharton School, or by a newspaper’s business writer? While the answer to the first question is empirically obvious, the answer to the second one isn’t at all. We can already see the difference between “know-how” and “know-what.” The Greeks made a distinction between
technē
and
epistēmē
. The empirical school of medicine of Menodotus of Nicomedia and Heraclites of Tarentum wanted its practitioners to stay closest to
technē
(i.e., “craft”), and away from
epistēmē
(i.e., “knowledge,” “science”).
The psychologist James Shanteau undertook the task of finding out which disciplines have experts and which have none. Note the confirmation problem here: if you want to prove that there are no experts, then you will be able to find
a
profession in which experts are useless. And you can prove the opposite just as well. But there is a regularity: there are professions where experts play a role, and others where there is no evidence of skills. Which are which?
Experts who tend to be experts:
livestock judges, astronomers, test pilots, soil judges, chess masters, physicists, mathematicians (when they deal with mathematical problems, not empirical ones), accountants, grain inspectors, photo interpreters, insurance analysts (dealing with bell curve–style statistics).
Experts who tend to be … not experts:
stockbrokers, clinical psychologists, psychiatrists, college admissions officers, court judges, councilors, personnel selectors, intelligence analysts (the CIA’s record, in spite of its costs, is pitiful), unless one takes into account some great dose of invisible prevention. I would add these results from my own examination of the literature: economists, financial forecasters, finance professors, political scientists,
“risk experts,” Bank for International Settlements staff, august members of the International Association of Financial Engineers, and personal financial advisers.
Simply,
things that move
, and therefore require knowledge, do not usually have experts, while things that don’t move seem to have some experts. In other words, professions that deal with the future and base their studies on the nonrepeatable past have an expert problem (with the exception of the weather and businesses involving short-term physical processes, not socioeconomic ones). I am not saying that no one who deals with the future provides any valuable information (as I pointed out earlier, newspapers can predict theater opening hours rather well), but rather that those who provide no tangible added value are generally dealing with the future.
Another way to see it is that things that move are often Black Swan–prone. Experts are narrowly focused persons who need to “tunnel.” In situations where tunneling is safe, because Black Swans are not consequential, the expert will do well.
Robert Trivers, an evolutionary psychologist and a man of supernormal insights, has another answer (he became one of the most influential evolutionary thinkers since Darwin with ideas he developed while trying to go to law school). He links it to self-deception. In fields where we have ancestral traditions, such as pillaging, we are very good at predicting outcomes by gauging the balance of power. Humans and chimps can immediately sense which side has the upper hand, and make a cost-benefit analysis about whether to attack and take the goods and the mates. Once you start raiding, you put yourself into a delusional mind-set that makes you ignore additional information—it is best to avoid wavering during battle. On the other hand, unlike raids, large-scale wars are not something present in human heritage—we are new to them—so we tend to misestimate their duration and overestimate our relative power. Recall the underestimation of the duration of the Lebanese war. Those who fought in the Great War thought it would be a mere cakewalk. So it was with the Vietnam conflict, so it is with the Iraq war, and just about every modern conflict.
You cannot ignore self-delusion. The problem with experts is that they do not know what they do not know. Lack of knowledge and delusion about the quality of your knowledge come together—the same process that makes you know less also makes you satisfied with your knowledge.
Next, instead of the range of forecasts, we will concern ourselves with the accuracy of forecasts, i.e., the ability to predict the number itself.
How to Have the Last Laugh
We can also learn about prediction errors from trading activities. We quants have ample data about economic and financial forecasts—from general data about large economic variables to the forecasts and market calls of the television “experts” or “authorities.” The abundance of such data and the ability to process it on a computer make the subject invaluable for an empiricist. If I had been a journalist, or, God forbid, a historian, I would have had a far more difficult time testing the predictive effectiveness of these verbal discussions. You cannot process verbal commentaries with a computer—at least not so easily. Furthermore, many economists naïvely make the mistake of producing a lot of forecasts concerning many variables, giving us a database of economists and variables, which enables us to see whether some economists are better than others (there is no consequential difference) or if there are certain variables for which they are more competent (alas, none that are meaningful).
I was in a seat to observe from very close our ability to predict. In my full-time trader days, a couple of times a week, at 8:30
A.M.
, my screen would flash some economic number released by the Department of Commerce, or Treasury, or Trade, or some such honorable institution. I never had a clue about what these numbers meant and never saw any need to invest energy in finding out. So I would not have cared the least about them except that people got all excited and talked quite a bit about what these figures were going to mean, pouring verbal sauce around the forecasts. Among such numbers you have the Consumer Price Index (CPI), Nonfarm Payrolls (changes in the number of employed individuals), the Index of Leading Economic Indicators, Sales of Durable Goods (dubbed “doable girls” by traders), the Gross Domestic Product (the most important one), and many more that generate different levels of excitement depending on their presence in the discourse.
The data vendors allow you to take a peek at forecasts by “leading economists,” people (in suits) who work for the venerable institutions, such as J. P. Morgan Chase or Morgan Stanley. You can watch these economists talk, theorizing eloquently and convincingly. Most of them earn seven figures and they rank as stars, with teams of researchers crunching numbers and projections. But the stars are foolish enough to publish their projected numbers, right there, for posterity to observe and assess their degree of competence.
Worse yet, many financial institutions produce booklets every year-end
called “Outlook for 200X,” reading into the following year. Of course they do not check how their previous forecasts fared
after
they were formulated. The public might have been even more foolish in buying the arguments without requiring the following simple tests—easy though they are, very few of them have been done. One elementary empirical test is to compare these star economists to a hypothetical cabdriver (the equivalent of Mikhail from
Chapter 1
): you create a synthetic agent, someone who takes the most recent number as the best predictor of the next, while assuming that he does not know anything. Then all you have to do is compare the error rates of the hotshot economists and your synthetic agent. The problem is that when you are swayed by stories you forget about the necessity of such testing.
Events Are Outlandish
The problem with prediction is a little more subtle. It comes mainly from the fact that we are living in Extremistan, not Mediocristan. Our predictors may be good at predicting the ordinary, but not the irregular, and this is where they ultimately fail. All you need to do is miss one interest-rates move, from 6 percent to 1 percent in a longer-term projection (what happened between 2000 and 2001) to have all your subsequent forecasts rendered completely ineffectual in correcting your cumulative track record. What matters is not how often you are right, but how large your cumulative errors are.
And these cumulative errors depend largely on the big surprises, the big opportunities. Not only do economic, financial, and political predictors miss them, but they are quite ashamed to say anything outlandish to their clients—and yet
events, it turns out, are almost always outlandish
. Furthermore, as we will see in the next section, economic forecasters tend to fall closer to one another than to the resulting outcome. Nobody wants to be off the wall.
Since my testing has been informal, for commercial and entertainment purposes, for my own consumption and not formatted for publishing, I will use the more formal results of other researchers who did the dog work of dealing with the tedium of the publishing process. I am surprised that so little introspection has been done to check on the usefulness of these professions. There are a few—but not many—formal tests in three domains: security analysis, political science, and economics. We will no doubt have more in a few years. Or perhaps not—the authors of such papers
might become stigmatized by his colleagues. Out of close to a million papers published in politics, finance, and economics, there have been only a small number of checks on the predictive quality of such knowledge.
Herding Like Cattle
A few researchers have examined the work and attitude of security analysts, with amazing results, particularly when one considers the epistemic arrogance of these operators. In a study comparing them with weather forecasters, Tadeusz Tyszka and Piotr Zielonka document that the analysts are worse at predicting, while having a greater faith in their own skills. Somehow, the analysts’ self-evaluation did not decrease their error margin after their failures to forecast.
Last June I bemoaned the dearth of such published studies to Jean-Philippe Bouchaud, whom I was visiting in Paris. He is a boyish man who looks half my age though he is only slightly younger than I, a matter that I half jokingly attribute to the beauty of physics. Actually he is not exactly a physicist but one of those quantitative scientists who apply methods of statistical physics to economic variables, a field that was started by Benoît Mandelbrot in the late 1950s. This community does not use Mediocristan mathematics, so they seem to care about the truth. They are completely outside the economics and business-school finance establishment, and survive in physics and mathematics departments or, very often, in trading houses (traders rarely hire economists for their own consumption, but rather to provide stories for their less sophisticated clients). Some of them also operate in sociology with the same hostility on the part of the “natives.” Unlike economists who wear suits and spin theories, they use empirical methods to observe the data and do not use the bell curve.
He surprised me with a research paper that a summer intern had just finished under his supervision and that had just been accepted for publication; it scrutinized two thousand predictions by security analysts. What it showed was that these brokerage-house analysts predicted
nothing
—a naïve forecast made by someone who takes the figures from one period as predictors of the next would not do markedly worse. Yet analysts are informed about companies’ orders, forthcoming contracts, and planned expenditures, so this advanced knowledge
should
help them do considerably better than a naïve forecaster looking at the past data without further information. Worse yet, the forecasters’ errors were significantly larger than the average difference between individual forecasts, which indicates herding.
Normally, forecasts should be as far from one another as they are from the predicted number. But to understand how they manage to stay in business, and why they don’t develop severe nervous breakdowns (with weight loss, erratic behavior, or acute alcoholism), we must look at the work of the psychologist Philip Tetlock.
I Was “Almost” Right
Tetlock studied the business of political and economic “experts.” He asked various specialists to judge the likelihood of a number of political, economic, and military events occurring within a specified time frame (about five years ahead). The outcomes represented a total number of around twenty-seven thousand predictions, involving close to three hundred specialists. Economists represented about a quarter of his sample. The study revealed that experts’ error rates were clearly many times what they had estimated. His study exposed an expert problem: there was no difference in results whether one had a PhD or an undergraduate degree. Well-published professors had no advantage over journalists. The only regularity Tetlock found was the negative effect of reputation on prediction: those who had a big reputation were worse predictors than those who had none.
But Tetlock’s focus was not so much to show the real competence of experts (although the study was quite convincing with respect to that) as to investigate why the experts did not realize that they were not so good at their own business, in other words, how they spun their stories. There seemed to be a logic to such incompetence, mostly in the form of belief defense, or the protection of self-esteem. He therefore dug further into the mechanisms by which his subjects generated ex post explanations.
I will leave aside how one’s ideological commitments influence one’s perception and address the more general aspects of this blind spot toward one’s own predictions.
You tell yourself that you were playing a different game
. Let’s say you failed to predict the weakening and precipitous fall of the Soviet Union (which no social scientist saw coming). It is easy to claim that you were excellent at understanding the political workings of the Soviet Union, but that these Russians, being exceedingly Russian, were skilled at hiding from you crucial economic elements. Had you been in possession of such economic intelligence, you would certainly have been able to predict the demise of the Soviet regime. It is not your skills that are to blame. The
same might apply to you if you had forecast the landslide victory for Al Gore over George W. Bush. You were not aware that the economy was in such dire straits; indeed, this fact seemed to be concealed from everyone. Hey, you are not an economist, and the game turned out to be about economics.
You invoke the outlier
. Something happened that was outside the system, outside the scope of your science. Given that it was not predictable, you are not to blame. It was a Black Swan and you are not supposed to predict Black Swans. Black Swans, NNT tells us, are fundamentally unpredictable (but then I think that NNT would ask you, Why rely on predictions?). Such events are “exogenous,” coming from outside your science. Or maybe it was an event of very, very low probability, a thousand-year flood, and we were unlucky to be exposed to it. But next time, it will not happen. This focus on the narrow game and linking one’s performance to a given script is how the nerds explain the failures of mathematical methods in society. The model was right, it worked well, but the game turned out to be a different one than anticipated.
The “almost right” defense
. Retrospectively, with the benefit of a revision of values and an informational framework, it is easy to feel that it was a close call. Tetlock writes, “Observers of the former Soviet Union who, in 1988, thought the Communist Party could not be driven from power by 1993 or 1998 were especially likely to believe that Kremlin hardliners almost overthrew Gorbachev in the 1991 coup attempt, and they would have if the conspirators had been more resolute and less inebriated, or if key military officers had obeyed orders to kill civilians challenging martial law or if Yeltsin had not acted so bravely.”
I will go now into more general defects uncovered by this example. These “experts” were lopsided: on the occasions when they were right, they attributed it to their own depth of understanding and expertise; when wrong, it was either the situation that was to blame, since it was unusual, or, worse, they did not recognize that they were wrong and spun stories around it. They found it difficult to accept that their grasp was a little short. But this attribute is universal to all our activities: there is something in us designed to protect our self-esteem.
We humans are the victims of an asymmetry in the perception of random events. We attribute our successes to our skills, and our failures to external events outside our control, namely to randomness. We feel responsible for the good stuff, but not for the bad. This causes us to think that we are better than others at whatever we do for a living. Ninety-four
percent of Swedes believe that their driving skills put them in the top 50 percent of Swedish drivers; 84 percent of Frenchmen feel that their lovemaking abilities put them in the top half of French lovers.
The other effect of this asymmetry is that we feel a little unique, unlike others, for whom we do not perceive such an asymmetry. I have mentioned the unrealistic expectations about the future on the part of people in the process of tying the knot. Also consider the number of families who tunnel on their future, locking themselves into hard-to-flip real estate thinking they are going to live there permanently, not realizing that the general track record for sedentary living is dire. Don’t they see those well-dressed real-estate agents driving around in fancy two-door German cars? We are very nomadic, far more than we plan to be, and forcibly so. Consider how many people who have abruptly lost their job deemed it likely to occur, even a few days before. Or consider how many drug addicts entered the game willing to stay in it so long.
There is another lesson from Tetlock’s experiment. He found what I mentioned earlier, that many university stars, or “contributors to top journals,” are no better than the average
New York Times
reader or journalist in detecting changes in the world around them. These sometimes overspecialized experts failed tests in their own specialties.
The hedgehog and the fox
. Tetlock distinguishes between two types of predictors, the hedgehog and the fox, according to a distinction promoted by the essayist Isaiah Berlin. As in Aesop’s fable, the hedgehog knows one thing, the fox knows many things—these are the adaptable types you need in daily life. Many of the prediction failures come from hedgehogs who are mentally married to a single big Black Swan event, a big bet that is not likely to play out. The hedgehog is someone focusing on a single, improbable, and consequential event, falling for the narrative fallacy that makes us so blinded by one single outcome that we cannot imagine others.
Hedgehogs, because of the narrative fallacy, are easier for us to understand—their ideas work in sound bites. Their category is overrepresented among famous people; ergo famous people are on average worse at forecasting than the rest of the predictors.
I have avoided the press for a long time because whenever journalists hear my Black Swan story, they ask me to give them a list of future impacting events. They want me to be
predictive
of these Black Swans. Strangely, my book
Fooled by Randomness
, published a week before September 11, 2001, had a discussion of the possibility of a plane crashing into my office building. So I was naturally asked to show “how I predicted the event.” I
didn’t predict it—it was a chance occurrence. I am not playing oracle! I even recently got an e-mail asking me to list the next ten Black Swans. Most fail to get my point about the error of specificity, the narrative fallacy, and the idea of prediction. Contrary to what people might expect, I am not recommending that anyone become a hedgehog—rather, be a fox with an open mind. I know that history is going to be dominated by an improbable event, I just don’t know what that event will be.
Reality? What For?
I found no formal, Tetlock-like comprehensive study in economics journals. But, suspiciously, I found no paper trumpeting economists’ ability to produce reliable projections. So I reviewed what articles and working papers in economics I could find. They collectively show no convincing evidence that economists as a community have an ability to predict, and, if they have some ability, their predictions are at best just
slightly
better than random ones—not good enough to help with serious decisions.
The most interesting test of how academic methods fare in the real world was run by Spyros Makridakis, who spent part of his career managing competitions between forecasters who practice a “scientific method” called econometrics—an approach that combines economic theory with statistical measurements. Simply put, he made people forecast
in real life
and then he judged their accuracy. This led to the series of “M-Competitions” he ran, with assistance from Michele Hibon, of which M3 was the third and most recent one, completed in 1999. Makridakis and Hibon reached the sad conclusion that “statistically sophisticated or complex methods do not necessarily provide more accurate forecasts than simpler ones.”
I had an identical experience in my quant days—the foreign scientist with the throaty accent spending his nights on a computer doing complicated mathematics rarely fares better than a cabdriver using the simplest methods within his reach. The problem is that we focus on the rare occasion when these methods work and almost never on their far more numerous failures. I kept begging anyone who would listen to me: “Hey, I am an uncomplicated, no-nonsense fellow from Amioun, Lebanon, and have trouble understanding why something is considered valuable if it requires running computers overnight but does not enable me to predict better than any other guy from Amioun.” The only reactions I got from these
colleagues were related to the geography and history of Amioun rather than a no-nonsense explanation of their business. Here again, you see the narrative fallacy at work, except that in place of journalistic stories you have the more dire situation of the “scientists” with a Russian accent looking in the rearview mirror, narrating with equations, and refusing to look ahead because he may get too dizzy. The econometrician Robert Engel, an otherwise charming gentleman, invented a very complicated statistical method called GARCH and got a Nobel for it. No one tested it to see if it has any validity in real life. Simpler, less sexy methods fare exceedingly better, but they do not take you to Stockholm. You have an expert problem in Stockholm, and I will discuss it in
Chapter 17
.
This unfitness of complicated methods seems to apply to all methods. Another study effectively tested practitioners of something called game theory, in which the most notorious player is John Nash, the schizophrenic mathematician made famous by the film
A Beautiful Mind
. Sadly, for all the intellectual appeal of these methods and all the media attention, its practitioners are no better at predicting than university students.
There is another problem, and it is a little more worrisome. Makridakis and Hibon were to find out that the strong empirical evidence of their studies has been ignored by theoretical statisticians. Furthermore, they encountered shocking hostility toward their empirical verifications. “Instead [statisticians] have concentrated their efforts in building more sophisticated models without regard to the ability of such models to more accurately predict real-life data,” Makridakis and Hibon write.
Someone may counter with the following argument: Perhaps economists’ forecasts create feedback that cancels their effect (this is called the Lucas critique, after the economist Robert Lucas). Let’s say economists predict inflation; in response to these expectations the Federal Reserve acts and lowers inflation. So you cannot judge the forecast accuracy in economics as you would with other events. I agree with this point, but I do not believe that it is the cause of the economists’ failure to predict. The world is far too complicated for their discipline.
When an economist fails to predict outliers he often invokes the issue of earthquakes or revolutions, claiming that he is not into geodesics, atmospheric sciences, or political science, instead of incorporating these fields into his studies and accepting that his field does not exist in isolation. Economics is the most insular of fields; it is the one that quotes least from outside itself! Economics is perhaps the subject that currently has the
highest number of philistine scholars—scholarship without erudition and natural curiosity can close your mind and lead to the fragmentation of disciplines.


================================================================================
CHAPTER/SECTION 220 (Item 225)
================================================================================

“OTHER THAN THAT,” IT WAS OKAY
We have used the story of the Sydney Opera House as a springboard for our discussion of prediction. We will now address another constant in human nature: a systematic error made by project planners, coming from a mixture of human nature, the complexity of the world, or the structure of organizations. In order to survive, institutions may need to give themselves and others the appearance of having a “vision.”
Plans fail because of what we have called tunneling, the neglect of sources of uncertainty outside the plan itself.
The typical scenario is as follows. Joe, a nonfiction writer, gets a book contract with a set final date for delivery two years from now. The topic is relatively easy: the authorized biography of the writer Salman Rushdie, for which Joe has compiled ample data. He has even tracked down Rushdie’s former girlfriends and is thrilled at the prospect of pleasant interviews. Two years later, minus, say, three months, he calls to explain to the publisher that he will be
a little
delayed. The publisher has seen this coming; he is used to authors being late. The publishing house now has cold feet because the subject has
unexpectedly
faded from public attention—the firm projected that interest in Rushdie would remain high, but attention has faded, seemingly because the Iranians, for some reason, lost interest in killing him.
Let’s look at the source of the biographer’s underestimation of the time for completion. He projected his own schedule, but he tunneled, as he did not forecast that some “external” events would emerge to slow him down. Among these external events were the disasters on September 11, 2001, which set him back several months; trips to Minnesota to assist his ailing mother (who eventually recovered); and many more, like a broken engagement (though not with Rushdie’s ex-girlfriend). “Other than that,” it was all within his plan; his own work did not stray the least from schedule. He does not feel responsible for his failure.
*
The unexpected has a one-sided effect with projects
. Consider the
track records of builders, paper writers, and contractors. The unexpected almost always pushes in a single direction: higher costs and a longer time to completion. On very rare occasions, as with the Empire State Building, you get the opposite: shorter completion and lower costs—these occasions are becoming truly exceptional nowadays.
We can run experiments and test for repeatability to verify if such errors in projection are part of human nature. Researchers have tested how students estimate the time needed to complete their projects. In one representative test, they broke a group into two varieties, optimistic and pessimistic. Optimistic students promised twenty-six days; the pessimistic ones forty-seven days. The average actual time to completion turned out to be fifty-six days.
The example of Joe the writer is not acute. I selected it because it concerns a repeatable, routine task—for such tasks our planning errors are milder. With projects of great novelty, such as a military invasion, an all-out war, or something entirely new, errors explode upward. In fact, the more routine the task, the better you learn to forecast. But there is always something nonroutine in our modern environment.
There may be incentives for people to promise shorter completion dates—in order to win the book contract or in order for the builder to get your down payment and use it for his upcoming trip to Antigua. But the planning problem exists even where there is no incentive to underestimate the duration (or the costs) of the task. As I said earlier, we are too narrow-minded a species to consider the possibility of events straying from our mental projections, but furthermore, we are too focused on matters internal to the project to take into account external uncertainty, the “unknown unknown,” so to speak, the contents of the unread books.
There is also the nerd effect, which stems from the mental elimination of off-model risks, or
focusing
on what you know. You view the world from
within
a model. Consider that most delays and cost overruns arise from unexpected elements that did not enter into the plan—that is, they lay outside the model at hand—such as strikes, electricity shortages, accidents, bad weather, or rumors of Martian invasions. These small Black Swans that threaten to hamper our projects do not seem to be taken into account. They are too abstract—we don’t know how they look and cannot talk about them intelligently.
We cannot truly plan, because we do not understand the future—but this is not necessarily bad news. We could plan
while bearing in mind such limitations
. It just takes guts.
The Beauty of Technology: Excel Spreadsheets
In the not too distant past, say the precomputer days, projections remained vague and qualitative, one had to make a mental effort to keep track of them, and it was a strain to push scenarios into the future. It took pencils, erasers, reams of paper, and huge wastebaskets to engage in the activity. Add to that an accountant’s love for tedious, slow work. The activity of projecting, in short, was effortful, undesirable, and marred with self-doubt.
But things changed with the intrusion of the spreadsheet. When you put an Excel spreadsheet into computer-literate hands you get a “sales projection” effortlessly extending ad infinitum! Once on a page or on a computer screen, or, worse, in a PowerPoint presentation, the projection takes on a life of its own, losing its vagueness and abstraction and becoming what philosophers call reified, invested with concreteness; it takes on a new life as a tangible object.
My friend Brian Hinchcliffe suggested the following idea when we were both sweating at the local gym. Perhaps the ease with which one can project into the future by dragging cells in these spreadsheet programs is responsible for the armies of forecasters confidently producing longer-term forecasts (all the while tunneling on their assumptions). We have become worse planners than the Soviet Russians thanks to these potent computer programs given to those who are incapable of handling their knowledge. Like most commodity traders, Brian is a man of incisive and sometimes brutally painful realism.
A classical mental mechanism, called anchoring, seems to be at work here. You lower your anxiety about uncertainty by producing a number, then you “anchor” on it, like an object to hold on to in the middle of a vacuum. This anchoring mechanism was discovered by the fathers of the psychology of uncertainty, Danny Kahneman and Amos Tversky, early in their heuristics and biases project. It operates as follows. Kahneman and Tversky had their subjects spin a wheel of fortune. The subjects first looked at the number on the wheel,
which they knew was random
, then they were asked to estimate the number of African countries in the United Nations. Those who had a low number on the wheel estimated a low number of African nations; those with a high number produced a higher estimate.
Similarly, ask someone to provide you with the last four digits of his social security number. Then ask him to estimate the number of dentists in
Manhattan. You will find that by making him aware of the four-digit number, you elicit an estimate that is correlated with it.
We use reference points in our heads, say sales projections, and start building beliefs around them because less mental effort is needed to compare an idea to a reference point than to evaluate it in the absolute
(System 1
at work!). We cannot work without a point of reference.
So the introduction of a reference point in the forecaster’s mind will work wonders. This is no different from a starting point in a bargaining episode: you open with high number (“I want a million for this house”); the bidder will answer “only eight-fifty”—the discussion will be determined by that initial level.
The Character of Prediction Errors
Like many biological variables, life expectancy is from Mediocristan, that is, it is subjected to mild randomness. It is not scalable, since the older we get, the less likely we are to live. In a developed country a newborn female is expected to die at around 79, according to insurance tables. When she reaches her 79th birthday, her life expectancy, assuming that she is in typical health, is another 10 years. At the age of 90, she should have another 4.7 years to go. At the age of 100, 2.5 years. At the age of 119, if she miraculously lives that long, she should have about nine months left. As she lives beyond the expected date of death, the number of additional years to go decreases. This illustrates the major property of random variables related to the bell curve. The conditional expectation of additional life drops as a person gets older.
With human projects and ventures we have another story. These are often scalable, as I said in
Chapter 3
. With scalable variables, the ones from Extremistan, you will witness the exact opposite effect. Let’s say a project is expected to terminate in 79 days, the same expectation in days as the newborn female has in years. On the 79th day, if the project is not finished, it will be expected to take another 25 days to complete. But on the 90th day, if the project is still not completed, it should have about 58 days to go. On the 100th, it should have 89 days to go. On the 119th, it should have an extra 149 days. On day 600, if the project is not done, you will be expected to need an extra 1,590 days. As you see,
the longer you wait, the longer you will be expected to wait
.
Let’s say you are a refugee waiting for the return to your homeland. Each day that passes you are getting farther from, not closer to, the day of
triumphal return. The same applies to the completion date of your next opera house. If it was expected to take two years, and three years later you are asking questions, do not expect the project to be completed any time soon. If wars last on average six months, and your conflict has been going on for two years, expect another few years of problems. The Arab-Israeli conflict is sixty years old, and counting—yet it was considered “a simple problem” sixty years ago. (Always remember that, in a modern environment, wars last longer and kill more people than is typically planned.) Another example: Say that you send your favorite author a letter, knowing that he is busy and has a two-week turnaround. If three weeks later your mailbox is still empty, do not expect the letter to come tomorrow—it will take on average another three weeks. If three months later you still have nothing, you will have to expect to wait another year. Each day will bring you closer to your death but further from the receipt of the letter.
This subtle but extremely consequential property of scalable randomness is unusually counterintuitive. We misunderstand the logic of large deviations from the norm.
I will get deeper into these properties of scalable randomness in Part Three. But let us say for now that they are central to our misunderstanding of the business of prediction.


================================================================================
CHAPTER/SECTION 221 (Item 226)
================================================================================

DON’T CROSS A RIVER IF IT IS (ON AVERAGE) FOUR FEET DEEP
Corporate and government projections have an additional easy-to-spot flaw: they do not attach a
possible error rate
to their scenarios. Even in the absence of Black Swans this omission would be a mistake.
I once gave a talk to policy wonks at the Woodrow Wilson Center in Washington, D.C., challenging them to be aware of our weaknesses in seeing ahead.
The attendees were tame and silent. What I was telling them was against everything they believed and stood for; I had gotten carried away with my aggressive message, but they looked thoughtful, compared to the testosterone-charged characters one encounters in business. I felt guilty for my aggressive stance. Few asked questions. The person who organized the talk and invited me must have been pulling a joke on his colleagues. I was like an aggressive atheist making his case in front of a synod of cardinals, while dispensing with the usual formulaic euphemisms.
Yet some members of the audience were sympathetic to the message. One anonymous person (he is employed by a governmental agency) explained
to me privately after the talk that in January 2004 his department was forecasting the price of oil for twenty-five years later at $27 a barrel, slightly higher than what it was at the time. Six months later, around June 2004, after oil doubled in price, they had to revise their estimate to $54 (the price of oil is currently, as I am writing these lines, close to $79 a barrel). It did not dawn on them that it was ludicrous to forecast a second time given that their forecast was off so early and so markedly, that this business of forecasting had to be somehow questioned. And they were looking
twenty-five years
ahead! Nor did it hit them that there was something called an error rate to take into account.
*
Forecasting without incorporating an error rate uncovers three fallacies, all arising from the same misconception about the nature of uncertainty.
The first fallacy:
variability matters
. The first error lies in taking a projection too seriously, without heeding its accuracy. Yet, for planning purposes, the accuracy in your forecast matters far more than the forecast itself. I will explain it as follows.
Don’t cross a river if it is four feet deep on average
. You would take a different set of clothes on your trip to some remote destination if I told you that the temperature was expected to be seventy degrees Fahrenheit, with an expected error rate of forty degrees than if I told you that my margin of error was only five degrees. The policies we need to make decisions on should depend far more on the range of possible outcomes than on the expected final number. I have seen, while working for a bank, how people project cash flows for companies without wrapping them in the thinnest layer of uncertainty. Go to the stockbroker and check on what method they use to forecast sales ten years ahead to “calibrate” their valuation models. Go find out how analysts forecast government deficits. Go to a bank or security-analysis training program and see how they teach
trainees to make assumptions; they do not teach you to build an error rate around those assumptions—but their error rate is so large that it is far more significant than the projection itself!
The second fallacy lies in failing to take into account forecast degradation as the projected period lengthens. We do not realize the full extent of the difference between near and far futures. Yet the degradation in such forecasting through time becomes evident through simple introspective examination—without even recourse to scientific papers, which on this topic are suspiciously rare. Consider forecasts, whether economic or technological, made in 1905 for the following quarter of a century. How close to the projections did 1925 turn out to be? For a convincing experience, go read George Orwell’s
1984
. Or look at more recent forecasts made in 1975 about the prospects for the new millennium. Many events have taken place and new technologies have appeared that lay outside the forecasters’ imaginations; many more that were expected to take place or appear did not do so. Our forecast errors have traditionally been enormous, and there may be no reasons for us to believe that we are suddenly in a more privileged position to see into the future compared to our blind predecessors. Forecasting by bureaucrats tends to be used for anxiety relief rather than for adequate policy making.
The third fallacy, and perhaps the gravest, concerns a misunderstanding of the random character of the variables being forecast. Owing to the Black Swan, these variables can accommodate far more optimistic—or far more pessimistic—scenarios than are currently expected. Recall from my experiment with Dan Goldstein testing the domain-specificity of our intuitions, how we tend to make no mistakes in Mediocristan, but make large ones in Extremistan as we do not realize the consequences of the rare event.
What is the implication here? Even if you agree with a given forecast, you have to worry about the real possibility of significant divergence from it. These divergences may be welcomed by a speculator who does not depend on steady income; a retiree, however, with set risk attributes cannot afford such gyrations. I would go even further and, using the argument about the depth of the river, state that it is the lower bound of estimates (i.e., the worst case) that matters when engaging in a policy—the worst case is far more consequential than the forecast itself. This is particularly true if the bad scenario is not acceptable. Yet the current phraseology makes no allowance for that. None.
It is often said that “is wise he who can see things coming.” Perhaps the wise one is the one who knows that he cannot see things far away.
Get Another Job
The two typical replies I face when I question forecasters’ business are: “What should he do? Do you have a better way for us to predict?” and “If you’re so smart, show me your own prediction.” In fact, the latter question, usually boastfully presented, aims to show the superiority of the practitioner and “doer” over the philosopher, and mostly comes from people who do not know that I was a trader. If there is one advantage of having been in the daily practice of uncertainty, it is that one does not have to take any crap from bureaucrats.
One of my clients asked for my predictions. When I told him I had none, he was offended and decided to dispense with my services. There is in fact a routine, unintrospective habit of making businesses answer questionnaires and fill out paragraphs showing their “outlooks.” I have never had an outlook and have never made professional predictions—but at least
I know that I cannot forecast
and a small number of people (those I care about) take that as an asset.
There are those people who produce forecasts uncritically. When asked why they forecast, they answer, “Well, that’s what we’re paid to do here.”
My suggestion: get another job.
This suggestion is not too demanding: unless you are a slave, I assume you have some amount of control over your job selection. Otherwise this becomes a problem of ethics, and a grave one at that. People who are trapped in their jobs who forecast simply because “that’s my job,” knowing pretty well that their forecast is ineffectual, are not what I would call ethical. What they do is no different from repeating lies simply because “it’s my job.”
Anyone who causes harm by forecasting should be treated as either a fool or a liar. Some forecasters cause more damage to society than criminals. Please, don’t drive a school bus blindfolded.
At JFK
At New York’s JFK airport you can find gigantic newsstands with walls full of magazines. They are usually manned by a very polite family from the Indian subcontinent (just the parents; the children are in medical school). These walls present you with the entire corpus of what an “informed” person needs in order “to know what’s going on.” I wonder how long it would take to read every single one of these magazines, excluding the fishing and motorcycle periodicals (but including the gossip magazines—you might as well have some fun). Half a lifetime? An entire lifetime?
Caravaggio’s
The Fortune-Teller
. We have always been suckers for those who tell us about the future. In this picture the fortune-teller is stealing the victim’s ring.
Sadly, all this knowledge would not help the reader to forecast what is to happen tomorrow. Actually, it might decrease his ability to forecast.
There is another aspect to the problem of prediction: its inherent limitations, those that have little to do with human nature, but instead arise from the very nature of information itself. I have said that the Black Swan has three attributes: unpredictability, consequences, and retrospective explainability. Let us examine this unpredictability business.
*
*
The book you have in your hands is approximately and “unexpectedly” fifteen months late.
*
While forecast errors have always been entertaining, commodity prices have been a great trap for suckers. Consider this 1970 forecast by U.S. officials (signed by the U.S. Secretaries of the Treasury, State, Interior, and Defense): “the standard price of foreign crude oil by 1980 may well decline and will in any event not experience a substantial increase.” Oil prices went up tenfold by 1980. I just wonder if current forecasters lack in intellectual curiosity or if they are intentionally ignoring forecast errors.
Also note this additional aberration: since high oil prices are marking up their inventories, oil companies are making record bucks and oil executives are getting huge bonuses because “they did a good job”—as if they brought profits by
causing
the rise of oil prices.
*
I owe the reader an answer concerning Catherine’s lover count. She had only twelve.


================================================================================
CHAPTER/SECTION 222 (Item 227)
================================================================================

Chapter Eleven
HOW TO LOOK FOR BIRD POOP
Popper’s prediction about the predictors—Poincaré plays with billiard balls—Von Hayek is allowed to be irreverent—Anticipation machines—Paul Samuelson wants you to be rational—Beware the philosopher—Demand some certainties
.
We’ve seen that a) we tend to both tunnel and think “narrowly” (epistemic arrogance), and b) our prediction record is highly overestimated—many people who think they can predict actually can’t.
We will now go deeper into the unadvertised structural limitations on our ability to predict. These limitations may arise not from us but from the nature of the activity itself—too complicated, not just for us, but for any tools we have or can conceivably obtain. Some Black Swans will remain elusive, enough to kill our forecasts.


================================================================================
CHAPTER/SECTION 223 (Item 228)
================================================================================

HOW TO LOOK FOR BIRD POOP
In the summer of 1998 I worked at a European-owned financial institution. It wanted to distinguish itself by being rigorous and farsighted. The unit involved in trading had five managers, all serious-looking (always in dark blue suits, even on dress-down Fridays), who had to meet throughout the summer in order “to formulate the five-year plan.” This was supposed
to be a meaty document, a sort of user’s manual for the firm. A five-year plan? To a fellow deeply skeptical of the central planner, the notion was ludicrous; growth within the firm had been organic and unpredictable, bottom-up not top-down. It was well known that the firm’s most lucrative department was the product of a chance call from a customer asking for a specific but strange financial transaction. The firm accidentally realized that they could build a unit just to handle these transactions, since they were profitable, and it rapidly grew to dominate their activities.
The managers flew across the world in order to meet: Barcelona, Hong Kong, et cetera. A lot of miles for a lot of verbiage. Needless to say they were usually sleep-deprived. Being an executive does not require very developed frontal lobes, but rather a combination of charisma, a capacity to sustain boredom, and the ability to shallowly perform on harrying schedules. Add to these tasks the “duty” of attending opera performances.
The managers sat down to brainstorm during these meetings, about, of course, the medium-term future—they wanted to have “vision.” But then an event occurred that was not in the previous five-year plan: the Black Swan of the Russian financial default of 1998 and the accompanying meltdown of the values of Latin American debt markets. It had such an effect on the firm that, although the institution had a sticky employment policy of retaining managers, none of the five was still employed there a month after the sketch of the 1998 five-year plan.
Yet I am confident that today their replacements are still meeting to work on the next “five-year plan.” We never learn.
Inadvertent Discoveries
The discovery of human epistemic arrogance, as we saw in the previous chapter, was allegedly inadvertent. But so were many other discoveries as well. Many more than we think.
The classical model of discovery is as follows: you search for what you know (say, a new way to reach India) and find something you didn’t know was there (America).
If you think that the inventions we see around us came from someone sitting in a cubicle and concocting them according to a timetable, think again: almost everything of the moment is the product of serendipity. The term
serendipity
was coined in a letter by the writer Hugh Walpole, who derived it from a fairy tale, “The Three Princes of Serendip.” These
princes “were always making discoveries by accident or sagacity, of things which they were not in quest of.”
In other words, you find something you are not looking for and it changes the world, while wondering after its discovery why it “took so long” to arrive at something so obvious. No journalist was present when the wheel was invented, but I am ready to bet that people did not just embark on the project of inventing the wheel (that main engine of growth) and then complete it according to a timetable. Likewise with most inventions.
Sir Francis Bacon commented that the most important advances are the least predictable ones, those “lying out of the path of the imagination.” Bacon was not the last intellectual to point this out. The idea keeps popping up, yet then rapidly dying out. Almost half a century ago, the bestselling novelist Arthur Koestler wrote an entire book about it, aptly called
The Sleepwalkers
. It describes discoverers as sleepwalkers stumbling upon results and not realizing what they have in their hands. We think that the import of Copernicus’s discoveries concerning planetary motions was obvious to him and to others in his day; he had been dead seventy-five years before the authorities started getting offended. Likewise we think that Galileo was a victim in the name of science; in fact, the church didn’t take him too seriously. It seems, rather, that Galileo caused the uproar himself by ruffling a few feathers. At the end of the year in which Darwin and Wallace presented their papers on evolution by natural selection that changed the way we view the world, the president of the Linnean society, where the papers were presented, announced that the society saw “no striking discovery,” nothing in particular that could revolutionize science.
We forget about unpredictability when it is our turn to predict. This is why people can read this chapter and similar accounts, agree entirely with them, yet fail to heed their arguments when thinking about the future.
Take this dramatic example of a serendipitous discovery. Alexander Fleming was cleaning up his laboratory when he found that penicillium mold had contaminated one of his old experiments. He thus happened upon the antibacterial properties of penicillin, the reason many of us are alive today (including, as I said in
Chapter 8
, myself, for typhoid fever is often fatal when untreated). True, Fleming was looking for “something,” but the actual discovery was simply serendipitous. Furthermore, while in hindsight the discovery appears momentous, it took a very long time for
health officials to realize the importance of what they had on their hands. Even Fleming lost faith in the idea before it was subsequently revived.
In 1965 two radio astronomists at Bell Labs in New Jersey who were mounting a large antenna were bothered by a background noise, a hiss, like the static that you hear when you have bad reception. The noise could not be eradicated—even after they cleaned the bird excrement out of the dish, since they were convinced that bird poop was behind the noise. It took a while for them to figure out that what they were hearing was the trace of the birth of the universe, the cosmic background microwave radiation. This discovery revived the big bang theory, a languishing idea that was posited by earlier researchers. I found the following comments on Bell Labs’ website commenting on how this “discovery” was one of the century’s greatest advances:
Dan Stanzione, then Bell Labs president and Lucent’s chief operating officer when Penzias [one of the radio astronomers involved in the discovery] retired, said Penzias “embodies the creativity and technical excellence that are the hallmarks of Bell Labs.” He called him a Renaissance figure who “extended our fragile understanding of creation, and advanced the frontiers of science in many important areas.”
Renaissance shmenaissance. The two fellows were looking for bird poop! Not only were they not looking for anything remotely like the evidence of the big bang but, as usual in these cases, they did not immediately see the importance of their find. Sadly, the physicist Ralph Alpher, the person who initially conceived of the idea, in a paper coauthored with heavyweights George Gamow and Hans Bethe, was surprised to read about the discovery in
The New York Times
. In fact, in the languishing papers positing the birth of the universe, scientists were doubtful whether such radiation could ever be measured. As happens so often in discovery, those looking for evidence did not find it; those not looking for it found it and were hailed as discoverers.
We have a paradox. Not only have forecasters generally failed dismally to foresee the drastic changes brought about by unpredictable discoveries, but incremental change has turned out to be generally slower than forecasters expected. When a new technology emerges, we either grossly underestimate or severely overestimate its importance. Thomas Watson, the founder of IBM, once predicted that there would be no need for more than just a handful of computers.
That the reader of this book is probably reading these lines not on a screen but in the pages of that anachronistic device, the book, would seem quite an aberration to certain pundits of the “digital revolution.” That you are reading them in archaic, messy, and inconsistent English, French, or Swahili, instead of in Esperanto, defies the predictions of half a century ago that the world would soon be communicating in a logical, unambiguous, and Platonically designed lingua franca. Likewise, we are not spending long weekends in space stations as was universally predicted three decades ago. In an example of corporate arrogance, after the first moon landing the now-defunct airline Pan Am took advance bookings for round-trips between earth and the moon. Nice prediction, except that the company failed to foresee that it would be out of business not long after.
A Solution Waiting for a Problem
Engineers tend to develop tools for the pleasure of developing tools, not to induce nature to yield its secrets. It so happens that
some
of these tools bring us more knowledge; because of the silent evidence effect, we forget to consider tools that accomplished nothing but keeping engineers off the streets. Tools lead to unexpected discoveries, which themselves lead to other unexpected discoveries. But rarely do our tools seem to work as intended; it is only the engineer’s gusto and love for the building of toys and machines that contribute to the augmentation of our knowledge. Knowledge does not progress from tools designed to verify or help theories, but rather the opposite. The computer was not built to allow us to develop new, visual, geometric mathematics, but for some other purpose. It happened to allow us to discover mathematical objects that few cared to look for. Nor was the computer invented to let you chat with your friends in Siberia, but it has caused some long-distance relationships to bloom. As an essayist, I can attest that the Internet has helped me to spread my ideas by bypassing journalists. But this was not the stated purpose of its military designer.
The laser is a prime illustration of a tool made for a given purpose (actually no real purpose) that then found applications that were not even dreamed of at the time. It was a typical “solution looking for a problem.” Among the early applications was the surgical stitching of detached retinas. Half a century later,
The Economist
asked Charles Townes, the alleged inventor of the laser, if he had had retinas on his mind. He had not. He was satisfying his desire to split light beams, and that was that. In fact,
Townes’s colleagues teased him quite a bit about the irrelevance of his discovery. Yet just consider the effects of the laser in the world around you: compact disks, eyesight corrections, microsurgery, data storage and retrieval—all unforeseen applications of the technology.
*
We build toys. Some of those toys change the world.
Keep Searching
In the summer of 2005 I was the guest of a biotech company in California that had found inordinate success. I was greeted with T-shirts and pins showing a bell-curve buster and the announcement of the formation of the Fat Tails Club (“fat tails” is a technical term for Black Swans). This was my first encounter with a firm that lived off Black Swans of the positive kind. I was told that a scientist managed the company and that he had the instinct, as a scientist, to just let scientists look wherever their instinct took them. Commercialization came later. My hosts, scientists at heart, understood that research involves a large element of serendipity, which can pay off big as long as one knows how serendipitous the business can be and structures it around that fact. Viagra, which changed the mental outlook and social mores of retired men, was meant to be a hypertension drug. Another hypertension drug led to a hair-growth medication. My friend Bruce Goldberg, who understands randomness, calls these unintended side applications “corners.” While many worry about unintended consequences, technology adventurers thrive on them.
The biotech company seemed to follow implicitly, though not explicitly, Louis Pasteur’s adage about creating luck by sheer exposure. “Luck favors the prepared,” Pasteur said, and, like all great discoverers, he knew something about accidental discoveries. The best way to get maximal exposure is to keep researching. Collect opportunities—on that, later.
To predict the spread of a technology implies predicting a large element of fads and social contagion
, which lie outside the objective utility of the technology itself (assuming there is such an animal as objective utility). How many wonderfully useful ideas have ended up in the cemetery, such as the Segway, an electric scooter that, it was prophesized, would change
the morphology of cities, and many others. As I was mentally writing these lines I saw a
Time
magazine cover at an airport stand announcing the “meaningful inventions” of the year. These inventions seemed to be meaningful as of the issue date, or perhaps for a couple of weeks after. Journalists can teach us how to
not
learn.


================================================================================
CHAPTER/SECTION 224 (Item 229)
================================================================================

HOW TO PREDICT YOUR PREDICTIONS!
This brings us to Sir Doktor Professor Karl Raimund Popper’s attack on historicism. As I said in
Chapter 5
, this was his most significant insight, but it remains his least known. People who do not really know his work tend to focus on Popperian falsification, which addresses the verification or nonverification of claims. This focus obscures his central idea: he made skepticism a
method
, he made of a skeptic someone constructive.
Just as Karl Marx wrote, in great irritation, a diatribe called
The Misery of Philosophy
in response to Proudhon’s
The Philosophy of Misery
, Popper, irritated by some of the philosophers of his time who believed in the scientific understanding of history, wrote, as a pun,
The Misery of Historicism
(which has been translated as
The Poverty of Historicism
).
*
Popper’s insight concerns the limitations in forecasting historical events and the need to downgrade “soft” areas such as history and social science to a level slightly above aesthetics and entertainment, like butterfly or coin collecting. (Popper, having received a classical Viennese education, didn’t go quite that far; I do. I am from Amioun.) What we call here soft historical sciences are narrative dependent studies.
Popper’s central argument is that in order to predict historical events you need to predict technological innovation, itself fundamentally unpredictable.
“Fundamentally” unpredictable? I will explain what he means using a modern framework. Consider the following property of knowledge: If you expect that you will know
tomorrow
with certainty that your boyfriend has been cheating on you all this time, then you know
today
with certainty that your boyfriend is cheating on you and will take action
today
, say, by grabbing a pair of scissors and angrily cutting all his Ferragamo ties in half. You won’t tell yourself, This is what I will figure out tomorrow, but
today is different so I will ignore the information and have a pleasant dinner. This point can be generalized to all forms of knowledge. There is actually a law in statistics called the
law of iterated expectations
, which I outline here in its strong form: if I expect to expect something at some date in the future, then I already expect that something at present.
Consider the wheel again. If you are a Stone Age historical thinker called on to predict the future in a comprehensive report for your chief tribal planner, you must project the invention of the wheel or you will miss pretty much all of the action. Now, if you can prophesy the invention of the wheel, you already know what a wheel looks like, and thus you already
know how
to build a wheel, so you are already on your way. The Black Swan needs to be predicted!
But there is a weaker form of this law of iterated knowledge. It can be phrased as follows:
to understand the future to the point of being able to predict it, you need to incorporate elements from this future itself
. If you know about the discovery you are about to make in the future, then you have almost made it. Assume that you are a special scholar in Medieval University’s Forecasting Department specializing in the projection of future history (for our purposes, the remote twentieth century). You would need to hit upon the inventions of the steam machine, electricity, the atomic bomb, and the Internet, as well as the institution of the airplane onboard massage and that strange activity called the business meeting, in which well-fed, but sedentary, men voluntarily restrict their blood circulation with an expensive device called a necktie.
This incapacity is not trivial. The mere knowledge that something has been invented often leads to a series of inventions of a similar nature, even though not a single detail of this invention has been disseminated—there is no need to find the spies and hang them publicly. In mathematics, once a proof of an arcane theorem has been announced, we frequently witness the proliferation of similar proofs coming out of nowhere, with occasional accusations of leakage and plagiarism. There may be no plagiarism: the information that the solution exists is itself a big piece of the solution.
By the same logic, we are not easily able to conceive of future inventions (if we were, they would have already been invented). On the day when we are able to foresee inventions we will be living in a state where everything conceivable has been invented. Our own condition brings to mind the apocryphal story from 1899 when the head of the U.S. patent office
resigned because he deemed that there was nothing left to discover—except that on that day the resignation would be justified.
*
Popper was not the first to go after the limits to our knowledge. In Germany, in the late nineteenth century, Emil du Bois-Reymond claimed that
ignoramus et ignorabimus
—we are ignorant and will remain so. Somehow his ideas went into oblivion. But not before causing a reaction: the mathematician David Hilbert set to defy him by drawing a list of problems that mathematicians would need to solve over the next century.
Even du Bois-Reymond was wrong. We are not even good at understanding the unknowable. Consider the statements we make about things that we will never come to know—we confidently underestimate what knowledge we may acquire in the future. Auguste Comte, the founder of the school of positivism, which is (unfairly) accused of aiming at the scientization of everything in sight, declared that mankind would forever remain ignorant of the chemical composition of the fixed stars. But, as Charles Sanders Peirce reported, “The ink was scarcely dry upon the printed page before the spectroscope was discovered and that which he had deemed absolutely unknowable was well on the way of getting ascertained.” Ironically, Comte’s other projections, concerning what we would come to learn about the workings of society, were grossly—and dangerously—overstated. He assumed that society was like a clock that would yield its secrets to us.
I’ll summarize my argument here: Prediction requires knowing about technologies that will be discovered in the future. But that very knowledge would almost automatically allow us to start developing those technologies right away. Ergo, we do not know what we will know.
Some might say that the argument, as phrased, seems obvious, that we always think that we have reached definitive knowledge but don’t notice that those past societies we laugh at also thought the same way. My argument is trivial, so why don’t we take it into account? The answer lies in a pathology of human nature. Remember the psychological discussions on asymmetries in the perception of skills in the previous chapter? We see flaws in others and not in ourselves. Once again we seem to be wonderful at self-deceit machines.
Monsieur le professeur Henri Poincaré. Somehow they stopped making this kind of thinker.
Courtesy of Université Nancy-2
.


================================================================================
CHAPTER/SECTION 225 (Item 230)
================================================================================

THE NTH BILLIARD BALL
Henri Poincaré, in spite of his fame, is regularly considered to be an undervalued scientific thinker, given that it took close to a century for some of his ideas to be appreciated. He was perhaps the last great thinking mathematician (or possibly the reverse, a mathematical thinker). Every time I see a T-shirt bearing the picture of the modern icon Albert Einstein, I cannot help thinking of Poincaré—Einstein is worthy of our reverence, but he has displaced many others. There is so little room in our consciousness; it is winner-take-all up there.
Third Republic–Style Decorum
Again, Poincaré is in a class by himself. I recall my father recommending Poincaré’s essays, not just for their scientific content, but for the quality of his French prose. The grand master wrote these wonders as serialized articles and composed them like extemporaneous speeches. As in every masterpiece, you see a mixture of repetitions, digressions, everything a “me too” editor with a prepackaged mind would condemn—but these make his text even more readable owing to an iron consistency of thought.
Poincaré became a prolific essayist in his thirties. He seemed in a hurry and died prematurely, at fifty-eight; he was in such a rush that he did not bother correcting typos and grammatical errors in his text, even after spotting them, since he found doing so a gross misuse of his time. They no
longer make geniuses like that—or they no longer let them write in their own way.
Poincaré’s reputation as a thinker waned rapidly after his death. His idea that concerns us took almost a century to resurface, but in another form. It was indeed a great mistake that I did not carefully read his essays as a child, for in his magisterial
La science et l’hypothèse
, I discovered later, he angrily disparages the use of the bell curve.
I will repeat that Poincaré was the true kind of philosopher of science: his philosophizing came from his witnessing the limits of the subject itself, which is what true philosophy is all about. I love to tick off French literary intellectuals by naming Poincaré as my favorite French philosopher.
“Him a philosophe? What do you mean, monsieur?”
It is always frustrating to explain to people that the thinkers they put on the pedestals, such as Henri Bergson or Jean-Paul Sartre, are largely the result of fashion production and can’t come close to Poincaré in terms of sheer influence that will continue for centuries to come. In fact, there is a scandal of prediction going on here, since it is the French Ministry of National Education that decides who is a philosopher and which philosophers need to be studied.
I am looking at Poincaré’s picture. He was a bearded, portly and imposing, well-educated patrician gentleman of the French Third Republic, a man who lived and breathed general science, looked deep into his subject, and had an astonishing breadth of knowledge. He was part of the class of mandarins that gained respectability in the late nineteenth century: upper middle class, powerful, but not exceedingly rich. His father was a doctor and professor of medicine, his uncle was a prominent scientist and administrator, and his cousin Raymond became a president of the republic of France. These were the days when the grandchildren of businessmen and wealthy landowners headed for the intellectual professions.
However, I can hardly imagine him on a T-shirt, or sticking out his tongue like in that famous picture of Einstein. There is something non-playful about him, a Third Republic style of dignity.
In his day, Poincaré was thought to be the king of mathematics and science, except of course by a few narrow-minded mathematicians like Charles Hermite who considered him too intuitive, too intellectual, or too “hand-waving.” When mathematicians say “hand-waving,” disparagingly, about someone’s work, it means that the person has: a) insight, b) realism, c) something to say, and it means that d) he is right because that’s what critics say when they can’t find anything more negative. A nod from Poincaré made or broke a career. Many claim that Poincaré figured
out relativity before Einstein—and that Einstein got the idea from him—but that he did not make a big deal out of it. These claims are naturally made by the French, but there seems to be some validation from Einstein’s friend and biographer Abraham Pais. Poincaré was too aristocratic in both background and demeanor to complain about the ownership of a result.
Poincaré is central to this chapter because he lived in an age when we had made extremely rapid intellectual progress in the fields of prediction—think of celestial mechanics. The scientific revolution made us feel that we were in possession of tools that would allow us to grasp the future. Uncertainty was gone. The universe was like a clock and, by studying the movements of the pieces, we could project into the future. It was only a matter of writing down the right models and having the engineers do the calculations. The future was a mere extension of our technological certainties.
The Three Body Problem
Poincaré was the first known big-gun mathematician to understand and explain that there are fundamental limits to our equations. He introduced nonlinearities, small effects that can lead to severe consequences, an idea that later became popular, perhaps a bit too popular, as chaos theory. What’s so poisonous about this popularity? Because Poincaré’s entire point is about the limits that nonlinearities put on forecasting; they are not an invitation to use mathematical techniques to make extended forecasts. Mathematics can show us its own limits rather clearly.
There is (as usual) an element of the unexpected in this story. Poincaré initially responded to a competition organized by the mathematician Gösta Mittag-Leffer to celebrate the sixtieth birthday of King Oscar of Sweden. Poincaré’s memoir, which was about the stability of the solar system, won the prize that was then the highest scientific honor (as these were the happy days before the Nobel Prize). A problem arose, however, when a mathematical editor checking the memoir before publication realized that there was a calculation error, and that, after consideration, it led to the opposite conclusion—unpredictability, or, more technically, nonintegrability. The memoir was discreetly pulled and reissued about a year later.
Poincaré’s reasoning was simple: as you project into the future you may need an increasing amount of precision about the dynamics of the process that you are modeling, since your error rate grows very rapidly. The problem is that near precision is not possible since the degradation of your forecast compounds abruptly—you would eventually need to figure out the past with infinite precision. Poincaré showed this in a very simple case, famously known as the “three body problem.” If you have only two planets in a solar-style system, with nothing else affecting their course, then you may be able to indefinitely predict the behavior of these planets, no sweat. But add a third body, say a comet, ever so small, between the planets. Initially the third body will cause no drift, no impact; later, with time, its effects on the two other bodies may become explosive. Small differences in where this tiny body is located will eventually dictate the future of the behemoth planets.
FIGURE 2: PRECISION AND FORECASTING
One of the readers of a draft of this book, David Cowan, gracefully drew this picture of scattering, which shows how, at the second bounce, variations in the initial conditions can lead to extremely divergent results. As the initial imprecision in the angle is multiplied, every additional bounce will be further magnified. This causes a severe multiplicative effect where the error grows out disproportionately.
Explosive forecasting difficulty comes from complicating the mechanics, ever so slightly. Our world, unfortunately, is far more complicated than the three body problem; it contains far more than three objects. We are dealing with what is now called a dynamical system—and the world, we will see, is a little too much of a dynamical system.
Think of the difficulty in forecasting in terms of branches growing out of a tree; at every fork we have a multiplication of new branches. To see how our intuitions about these nonlinear multiplicative effects are rather weak, consider this story about the chessboard. The inventor of the chessboard requested the following compensation: one grain of rice for the first
square, two for the second, four for the third, eight, then sixteen, and so on, doubling every time, sixty-four times. The king granted this request, thinking that the inventor was asking for a pittance—but he soon realized that he was outsmarted. The amount of rice exceeded all possible grain reserves!
This multiplicative difficulty leading to the need for greater and greater precision in assumptions can be illustrated with the following simple exercise concerning the prediction of the movements of billiard balls on a table. I use the example as computed by the mathematician Michael Berry. If you know a set of basic parameters concerning the ball at rest, can compute the resistance of the table (quite elementary), and can gauge the strength of the impact, then it is rather easy to predict what would happen at the first hit. The second impact becomes more complicated, but possible; you need to be more careful about your knowledge of the initial states, and more precision is called for. The problem is that to correctly compute the ninth impact, you need to take into account the gravitational pull of someone standing next to the table (modestly, Berry’s computations use a weight of less than 150 pounds). And to compute the fifty-sixth impact, every single elementary particle of the universe needs to be present in your assumptions! An electron at the edge of the universe, separated from us by 10 billion light-years, must figure in the calculations, since it exerts a meaningful effect on the outcome. Now, consider the additional burden of having to incorporate predictions about
where these variables will be in the future
. Forecasting the motion of a billiard ball on a pool table requires knowledge of the dynamics of the entire universe, down to every single atom! We can easily predict the movements of large objects like planets (though not too far into the future), but the smaller entities can be difficult to figure out—and there are so many more of them.
Note that this billiard-ball story assumes a plain and simple world; it does not even take into account these crazy social matters possibly endowed with free will. Billiard balls do not have a mind of their own. Nor does our example take into account relativity and quantum effects. Nor did we use the notion (often invoked by phonies) called the “uncertainty principle.” We are not concerned with the limitations of the precision in measurements done at the subatomic level. We are just dealing with billiard balls!
In a dynamical system, where you are considering more than a ball on its own, where trajectories in a way depend on one another, the ability to project into the future is not just reduced, but is subjected to a fundamental limitation. Poincaré proposed that we can only work with qualitative
matters—some property of systems can be
discussed
, but not computed. You can think rigorously, but you cannot use numbers. Poincaré even invented a field for this, analysis in situ, now part of topology. Prediction and forecasting are a more complicated business than is commonly accepted, but it takes someone who knows mathematics to understand that. To accept it takes both understanding and courage.
In the 1960s the MIT meteorologist Edward Lorenz rediscovered Poincaré’s results on his own—once again, by accident. He was producing a computer model of weather dynamics, and he ran a simulation that projected a weather system a few days ahead. Later he tried to repeat the same simulation with the exact same model and what he thought were the same input parameters, but he got wildly different results. He initially attributed these differences to a computer bug or a calculation error. Computers then were heavier and slower machines that bore no resemblance to what we have today, so users were severely constrained by time. Lorenz subsequently realized that the consequential divergence in his results arose not from error, but from a small rounding in the input parameters. This became known as the butterfly effect, since a butterfly moving its wings in India could cause a hurricane in New York, two years later. Lorenz’s findings generated interest in the field of chaos theory.
Naturally researchers found predecessors to Lorenz’s discovery, not only in the work of Poincaré, but also in that of the insightful and intuitive Jacques Hadamard, who thought of the same point around 1898, and then went on to live for almost seven more decades—he died at the age of ninety-eight.
*
They Still Ignore Hayek
Popper and Poincaré’s findings limit our ability to see into the future, making it a very complicated reflection of the past—if it is a reflection of the past at all. A potent application in the social world comes from a friend of Sir Karl, the intuitive economist Friedrich Hayek. Hayek is one of the rare celebrated members of his “profession” (along with J. M. Keynes and G.L.S. Shackle) to focus on true uncertainty, on the limitations of knowledge, on the unread books in Eco’s library.
In 1974 he received the Bank of Sweden Prize in Economic Sciences in
Memory of Alfred Nobel, but if you read his acceptance speech you will be in for a bit of a surprise. It was eloquently called “The Pretense of Knowledge,” and he mostly railed about other economists and about the idea of the planner. He argued against the use of the tools of hard science in the social ones, and depressingly, right before the big boom for these methods in economics. Subsequently, the prevalent use of complicated equations made the environment for true empirical thinkers worse than it was before Hayek wrote his speech. Every year a paper or a book appears, bemoaning the fate of economics and complaining about its attempts to ape physics. The latest I’ve seen is about how economists should shoot for the role of lowly philosophers rather than that of high priests. Yet, in one ear and out the other.
For Hayek, a true forecast is done organically by a system, not by fiat. One single institution, say, the central planner, cannot
aggregate
knowledge; many important pieces of information will be missing. But society as a whole will be able to integrate into its functioning these multiple pieces of information. Society as a whole thinks outside the box. Hayek attacked socialism and managed economies as a product of what I have called
nerd knowledge, or Platonicity
—owing to the growth of scientific knowledge, we overestimate our ability to understand the subtle changes that constitute the world, and what weight needs to be imparted to each such change. He aptly called this “scientism.”
This disease is severely ingrained in our institutions. It is why I fear governments and large corporations—it is hard to distinguish between them. Governments make forecasts; companies produce projections; every year various forecasters project the level of mortgage rates and the stock market at the end of the following year. Corporations survive not because they have made good forecasts, but because, like the CEOs visiting Wharton I mentioned earlier, they may have been the lucky ones. And, like a restaurant owner, they may be hurting themselves, not us—perhaps helping us and subsidizing our consumption by giving us goods in the process, like cheap telephone calls to the rest of the world funded by the overinvestment during the dotcom era. We consumers can let them forecast all they want if that’s what is necessary for them to get into business. Let them go hang themselves if they wish.
As a matter of fact, as I mentioned in
Chapter 8
, we New Yorkers are all benefiting from the quixotic overconfidence of corporations and restaurant entrepreneurs. This is the benefit of capitalism that people discuss the least.
But corporations can go bust as often as they like, thus subsidizing us consumers by transferring their wealth into our pockets—the more bankruptcies, the better it is for us—unless they are “too big to fail” and require subsidies, which is an argument in favor of letting companies go bust early. Government is a more serious business and we need to make sure we do not pay the price for its folly. As individuals we should love free markets because operators in them can be as incompetent as they wish.
The only criticism one might have of Hayek is that he makes a hard and qualitative distinction between social sciences and physics. He shows that the methods of physics do not translate to its social science siblings, and he blames the engineering-oriented mentality for this. But he was writing at a time when physics, the queen of science, seemed to zoom in our world. It turns out that even the natural sciences are far more complicated than that. He was right about the social sciences, he is certainly right in trusting hard scientists more than social theorizers, but what he said about the weaknesses of social knowledge applies to all knowledge. All knowledge.
Why? Because of the confirmation problem, one can argue that we know very little about our natural world; we advertise the read books and forget about the unread ones. Physics has been successful, but it is a narrow field of hard science in which we have been successful, and people tend to generalize that success to all science. It would be preferable if we were better at understanding cancer or the (highly nonlinear) weather than the origin of the universe.
How Not to Be a Nerd
Let us dig deeper into the problem of knowledge and continue the comparison of Fat Tony and Dr. John in
Chapter 9
. Do nerds tunnel, meaning, do they focus on crisp categories and miss sources of uncertainty? Remember from the Prologue my presentation of Platonification as a top-down focus on a world composed of these crisp categories.
*
Think of a bookworm picking up a new language. He will learn, say, Serbo-Croatian or !Kung by reading a grammar book cover to cover, and memorizing the rules. He will have the impression that some higher grammatical authority set the linguistic regulations so that nonlearned ordinary
people could subsequently speak the language. In reality, languages grow organically; grammar is something people without anything more exciting to do in their lives codify into a book. While the scholastic-minded will memorize declensions, the a-Platonic nonnerd will acquire, say, Serbo-Croatian by picking up potential girlfriends in bars on the outskirts of Sarajevo, or talking to cabdrivers, then fitting (if needed) grammatical rules to the knowledge he already possesses.
Consider again the central planner. As with language, there is no grammatical authority codifying social and economic events; but try to convince a bureaucrat or social scientist that the world might not want to follow his “scientific” equations. In fact, thinkers of the Austrian school, to which Hayek belonged, used the designations
tacit
or
implicit
precisely for that part of knowledge that cannot be written down, but that we should avoid repressing. They made the distinction we saw earlier between “know-how” and “know-what”—the latter being more elusive and more prone to nerdification.
To clarify, Platonic is top-down, formulaic, closed-minded, self-serving, and commoditized; a-Platonic is bottom-up, open-minded, skeptical, and empirical.
The reason for my singling out the great Plato becomes apparent with the following example of the master’s thinking: Plato believed that we should use both hands with equal dexterity. It would not “make sense” otherwise. He considered favoring one limb over the other a deformation caused by the “folly of mothers and nurses.” Asymmetry bothered him, and he projected his ideas of elegance onto reality. We had to wait until Louis Pasteur to figure out that chemical molecules were either left- or right-handed and that this mattered considerably.
One can find similar ideas among several disconnected branches of thinking. The earliest were (as usual) the empirics, whose bottom-up, theory-free, “evidence-based” medical approach was mostly associated with Philnus of Cos, Serapion of Alexandria, and Glaucias of Tarentum, later made skeptical by Menodotus of Nicomedia, and currently well-known by its vocal practitioner, our friend the great skeptical philosopher Sextus Empiricus. Sextus who, we saw earlier, was perhaps the first to discuss the Black Swan. The empirics practiced the “medical art” without relying on reasoning; they wanted to benefit from chance observations by making guesses, and experimented and tinkered until they found something that worked. They did minimal theorizing.
Their methods are being revived today as evidence-based medicine,
after two millennia of persuasion. Consider that before we knew of bacteria, and their role in diseases, doctors rejected the practice of hand washing because it
made no sense
to them, despite the evidence of a meaningful decrease in hospital deaths. Ignaz Semmelweis, the mid-nineteenth-century doctor who promoted the idea of hand washing, wasn’t vindicated until decades after his death. Similarly it may not “make sense” that acupuncture works, but if pushing a needle in someone’s toe systematically produces relief from pain (in properly conducted empirical tests), then it could be that there are functions too complicated for us to understand, so let’s go with it for now while keeping our minds open.
Academic Libertarianism
To borrow from Warren Buffett, don’t ask the barber if you need a haircut—and don’t ask an academic if what he does is relevant. So I’ll end this discussion of Hayek’s libertarianism with the following observation. As I’ve said, the problem with organized knowledge is that there is an occasional divergence of interests between academic guilds and knowledge itself. So I cannot for the life of me understand why today’s libertarians do not go after tenured faculty (except perhaps because many libertarians are academics). We saw that companies can go bust, while governments remain. But while governments remain, civil servants can be demoted and congressmen and senators can be eventually voted out of office. In academia a tenured faculty is permanent—the business of knowledge has permanent “owners.” Simply, the charlatan is more the product of control than the result of freedom and lack of structure.
Prediction and Free Will
If you know all possible conditions of a physical system you can, in theory (though not, as we saw, in practice), project its behavior into the future. But this only concerns inanimate objects. We hit a stumbling block when social matters are involved. It is another matter to project a future when humans are involved,
if you consider them living beings and endowed with free will
.
If I can predict all of your actions, under given circumstances, then you may not be as free as you think you are. You are an automaton responding to environmental stimuli. You are a slave of destiny. And the illusion of free will could be reduced to an equation that describes the result of interactions among molecules. It would be like studying the mechanics of a
clock: a genius with extensive knowledge of the initial conditions and the causal chains would be able to extend his knowledge to the future of
your
actions. Wouldn’t that be stifling?
However, if you believe in free will you can’t truly believe in social science and economic projection. You cannot predict how people will act. Except, of course, if there is a trick, and that trick is the cord on which neoclassical economics is suspended. You simply assume that individuals will be
rational
in the future and thus act predictably. There is a strong link between rationality, predictability, and mathematical tractability. A rational individual will perform a
unique
set of actions in specified circumstances. There is one and only one answer to the question of how “rational” people satisfying their best interests would act. Rational actors must be coherent: they cannot prefer apples to oranges, oranges to pears, then pears to apples. If they did, then it would be difficult to generalize their behavior. It would also be difficult to project their behavior in time.
In orthodox economics, rationality became a straitjacket. Platonified economists ignored the fact that people might prefer to do something other than maximize their economic interests. This led to mathematical techniques such as “maximization,” or “optimization,” on which Paul Samuelson built much of his work. Optimization consists in finding the mathematically optimal policy that an economic agent could pursue. For instance, what is the “optimal” quantity you should allocate to stocks? It involves complicated mathematics and thus raises a barrier to entry by non-mathematically trained scholars. I would not be the first to say that this optimization set back social science by reducing it from the intellectual and reflective discipline that it was becoming to an attempt at an “exact science.” By “exact science,” I mean a second-rate engineering problem for those who want to pretend that they are in the physics department—so-called physics envy. In other words, an intellectual fraud.
Optimization is a case of sterile modeling that we will discuss further in
Chapter 17
. It had no practical (or even theoretical) use, and so it became principally a competition for academic positions, a way to make people compete with mathematical muscle. It kept Platonified economists out of the bars, solving equations at night. The tragedy is that Paul Samuelson, a quick mind, is said to be one of the most intelligent scholars of his generation. This was clearly a case of very badly invested intelligence. Characteristically, Samuelson intimidated those who questioned his techniques with the statement “Those who can, do science, others do methodology.” If you knew math, you could “do science.” This is reminiscent
of psychoanalysts who silence their critics by accusing them of having trouble with their fathers. Alas, it turns out that it was Samuelson and most of his followers who did not
know
much math, or did not know how to use what math they knew, how to apply it to reality. They only knew enough math to be blinded by it.
Tragically, before the proliferation of empirically blind idiot savants, interesting work had been begun by true thinkers, the likes of J. M. Keynes, Friedrich Hayek, and the great Benoît Mandelbrot, all of whom were displaced because they moved economics away from the precision of second-rate physics. Very sad. One great underestimated thinker is G.L.S. Shackle, now almost completely obscure, who introduced the notion of “unknowledge,” that is, the unread books in Umberto Eco’s library. It is unusual to see Shackle’s work mentioned at all, and I had to buy his books from secondhand dealers in London.
Legions of empirical psychologists of the heuristics and biases school have shown that the model of rational behavior under uncertainty is not just grossly inaccurate but plain wrong as a description of reality. Their results also bother Platonified economists because they reveal that there are several ways to be irrational. Tolstoy said that happy families were all alike, while each unhappy one is unhappy in its own way. People have been shown to make errors equivalent to preferring apples to oranges, oranges to pears, and
pears to apples
, depending on how the relevant questions are presented to them. The sequence matters! Also, as we have seen with the anchoring example, subjects’ estimates of the number of dentists in Manhattan are influenced by which random number they have just been presented with—the
anchor
. Given the randomness of the anchor, we will have randomness in the estimates. So if people make inconsistent choices and decisions, the central core of economic optimization fails. You can no longer produce a “general theory,” and without one you cannot predict.
You have to learn to live without a general theory, for Pluto’s sake!


================================================================================
CHAPTER/SECTION 226 (Item 231)
================================================================================

THE GRUENESS OF EMERALD
Recall the turkey problem. You look at the past and derive some rule about the future. Well, the problems in projecting from the past can be even worse than what we have already learned, because the same past data can confirm a theory and also its exact opposite! If you survive until tomorrow, it could mean that either a) you are more likely to be immortal or b) that you are closer to death. Both conclusions rely on the exact same data. If you are a turkey being fed for a long period of time, you can either naïvely assume that feeding
confirms your safety
or be shrewd and consider that it
confirms the danger
of being turned into supper. An acquaintance’s unctuous past behavior may indicate his genuine affection for me and his concern for my welfare; it may also confirm his mercenary and calculating desire to get my business one day.
FIGURE 3
A series of a seemingly growing bacterial population (or of sales records, or of any variable observed through time—such as the total feeding of the turkey in
Chapter 4
).
FIGURE 4
Easy to fit the trend—there is one and only one linear model that fits the data. You can project a continuation into the future.
FIGURE 5
We look at a broader scale. Hey, other models also fit it rather well.
FIGURE 6
And the real “generating process” is extremely simple but it had nothing to do with a linear model! Some parts of it appear to be linear and we are fooled by extrapolating in a direct line.
*
So not only can the past be misleading, but there are also many degrees of freedom in our interpretation of past events.
For the technical version of this idea, consider a series of dots on a page representing a number through time—the graph would resemble
Figure 1
showing the first thousand days in
Chapter 4
. Let’s say your high school teacher asks you to extend the series of dots. With a linear model, that is, using a ruler, you can run only a straight line, a
single
straight line from the past to the future. The linear model is unique. There is one and only one straight line that can project from a series of points. But it can get trickier. If you do not limit yourself to a straight line, you find that there is a huge family of curves that can do the job of connecting the dots. If you project from the past in a linear way, you continue a trend. But possible future deviations from the course of the past are infinite.
This is what the philosopher Nelson Goodman called the riddle of induction: We project a straight line only because we have a linear model in our head—the fact that a number has risen for 1,000 days straight should make you more confident that it will rise in the future. But if you have a nonlinear model in your head, it might confirm that the number should decline on day 1,001.
Let’s say that you observe an emerald. It was green yesterday and the day before yesterday. It is green again today. Normally this would confirm the “green” property: we can assume that the emerald will be green tomorrow. But to Goodman, the emerald’s color history could equally confirm the “grue” property. What is this grue property? The emerald’s grue property is to be green until some specified date, say, December 31, 2006, and then blue thereafter.
The riddle of induction is another version of the narrative fallacy—you face an infinity of “stories” that explain what you have seen. The severity of Goodman’s riddle of induction is as follows: if there is no longer even a single unique way to “generalize” from what you see, to make an inference about the unknown, then how should you operate? The answer, clearly, will be that you should employ “common sense,” but your common sense may not be so well developed with respect to some Extremistan variables.


================================================================================
CHAPTER/SECTION 227 (Item 232)
================================================================================

THAT GREAT ANTICIPATION MACHINE
The reader is entitled to wonder, So, NNT, why on earth do we plan? Some people do it for monetary gain, others because it’s “their job.” But we also do it without such intentions—spontaneously.
Why? The answer has to do with human nature. Planning may come with the package of what makes us human, namely, our consciousness.
There is supposed to be an evolutionary dimension to our need to project matters into the future, which I will rapidly summarize here, since it can be an excellent candidate explanation, an excellent conjecture, though, since it is linked to evolution, I would be cautious.
The idea, as promoted by the philosopher Daniel Dennett, is as follows: What is the most potent use of our brain? It is precisely the ability to project conjectures into the future and play the counterfactual game—“If I punch him in the nose, then he will punch me back right away, or, worse, call his lawyer in New York.” One of the advantages of doing so is that we can let our conjectures die in our stead. Used correctly and in place of more visceral reactions, the ability to project effectively frees us from immediate, first-order natural selection—as opposed to more primitive organisms that were vulnerable to death and only grew by the improvement in the gene pool through the selection of the best. In a way, projecting allows us to cheat evolution: it now takes place in our head, as a series of projections and counterfactual scenarios.
This ability to mentally play with conjectures, even if it frees us from the laws of evolution, is itself supposed to be the product of evolution—it is as if evolution has put us on a long leash whereas other animals live on the very short leash of immediate dependence on their environment. For Dennett, our brains are “anticipation machines;” for him the human mind and consciousness are emerging properties, those properties necessary for our accelerated development.
Why do we listen to experts and their forecasts? A candidate explanation is that society reposes on specialization, effectively the division of knowledge. You do not go to medical school the minute you encounter a big health problem; it is less taxing (and certainly safer) for you to consult someone who has already done so. Doctors listen to car mechanics (not for health matters, just when it comes to problems with their cars); car mechanics listen to doctors. We have a natural tendency to listen to the expert, even in fields where there may be no experts.
*
Most of the debate between creationists and evolutionary theorists (of which I do not partake) lies in the following: creationists believe that the world comes from some form of design while evolutionary theorists see the world as a result of random changes by an aimless process. But it is hard to look at a computer or a car and consider them the result of aimless process. Yet they are.
*
Recall from
Chapter 4
how Algazel and Averroës traded insults through book titles. Perhaps one day I will be lucky enough to read an attack on this book in a diatribe called
The White Swan
.
*
Such claims are not uncommon. For instance the physicist Albert Michelson imagined, toward the end of the nineteenth century, that what was left for us to discover in the sciences of nature was no more than fine-tuning our precisions by a few decimal places.
*
There are more limits I haven’t even attempted to discuss here. I am not even bringing up the class of incomputability people call NP completeness.
*
This idea pops up here and there in history, under different names. Alfred North Whitehead called it the “fallacy of misplaced concreteness,” e.g., the mistake of confusing a model with the physical entity that it means to describe.
*
These graphs also illustrate a statistical version of the narrative fallacy—you find a model that fits the past. “Linear regression” or “R-square” can ultimately fool you beyond measure, to the point where it is no longer funny. You can fit the linear part of the curve and claim a high R-square, meaning that your model fits the data very well and has high predictive powers. All that off hot air: you only fit the linear segment of the series. Always remember that “R-square” is unfit for Extremistan; it is only good for academic promotion.


================================================================================
CHAPTER/SECTION 228 (Item 233)
================================================================================

Chapter Twelve
EPISTEMOCRACY, A DREAM
This is only an essay—Children and philosophers vs. adults and nonphilosophers—Science as an autistic enterprise—The past too has a past—Mispredict and live a long, happy life (if you survive)
Someone with a low degree of epistemic arrogance is not too visible, like a shy person at a cocktail party. We are not predisposed to respect humble people, those who try to suspend judgment. Now contemplate
epistemic humility
. Think of someone heavily introspective, tortured by the awareness of his own ignorance. He lacks the courage of the idiot, yet has the rare guts to say “I don’t know.” He does not mind looking like a fool or, worse, an ignoramus. He hesitates, he will not commit, and he agonizes over the consequences of being wrong. He introspects, introspects, and introspects until he reaches physical and nervous exhaustion.
This does not necessarily mean that he lacks confidence, only that he holds his own knowledge to be suspect. I will call such a person an
epistemocrat;
the province where the laws are structured with this kind of human fallibility in mind I will call an
epistemocracy
.
The major modern epistemocrat is Montaigne.
Monsieur de Montaigne, Epistemocrat
At the age of thirty-eight, Michel Eyquem de Montaigne retired to his estate, in the countryside of southwestern France. Montaigne, which means mountain in Old French, was the name of the estate. The area is known today for the Bordeaux wines, but in Montaigne’s time not many people invested their mental energy and sophistication in wine. Montaigne had stoic tendencies and would not have been strongly drawn to such pursuits anyway. His idea was to write a modest collection of “attempts,” that is, essays. The very word
essay
conveys the tentative, the speculative, and the nondefinitive. Montaigne was well grounded in the classics and wanted to meditate on life, death, education, knowledge, and some not uninteresting biological aspects of human nature (he wondered, for example, whether cripples had more vigorous libidos owing to the richer circulation of blood in their sexual organs).
The tower that became his study was inscribed with Greek and Latin sayings, almost all referring to the vulnerability of human knowledge. Its windows offered a wide vista of the surrounding hills.
Montaigne’s subject, officially, was himself, but this was mostly as a means to facilitate the discussion; he was not like those corporate executives who write biographies to make a boastful display of their honors and accomplishments. He was mainly interested in
discovering
things about himself, making us discover things about himself, and presenting matters that could be generalized—generalized to the entire human race. Among the inscriptions in his study was a remark by the Latin poet Terence:
Homo sum, humani a me nil alienum puto
—I am a man, and nothing human is foreign to me.
Montaigne is quite refreshing to read after the strains of a modern education since he fully accepted human weaknesses and understood that no philosophy could be effective unless it took into account our deeply ingrained imperfections, the limitations of our rationality, the flaws that make us human. It is not that he was ahead of his time; it would be better said that later scholars (advocating rationality) were backward.
He was a thinking, ruminating fellow, and his ideas did not spring up in his tranquil study, but while on horseback. He went on long rides and came back with ideas. Montaigne was neither one of the academics of the Sorbonne nor a professional man of letters, and he was
not
these things on two planes. First, he was a
doer;
he had been a magistrate, a businessman,
and the mayor of Bordeaux before he retired to mull over his life and, mostly, his own knowledge. Second, he was an antidogmatist: he was a skeptic with charm, a fallible, noncommittal, personal, introspective writer, and, primarily, someone who, in the great classical tradition, wanted to be a man. Had he been in a different period, he would have been an empirical skeptic—he had skeptical tendencies of the Pyrrhonian variety, the antidogmatic kind like Sextus Empiricus, particularly in his awareness of the need to suspend judgment.
Epistemocracy
Everyone has an idea of utopia. For many it means equality, universal justice, freedom from oppression, freedom from work (for some it may be the more modest, though no more attainable, society with commuter trains free of lawyers on cell phones). To me utopia is an epistemocracy, a society in which anyone of rank is an epistemocrat, and where epistemocrats manage to be elected. It would be a society governed from the basis of the awareness of ignorance, not knowledge.
Alas, one cannot assert authority by accepting one’s own fallibility. Simply, people need to be blinded by knowledge—we are made to follow leaders who can gather people together because the advantages of being in groups trump the disadvantages of being alone. It has been more profitable for us to bind together in the wrong direction than to be alone in the right one. Those who have followed the assertive idiot rather than the introspective wise person have passed us some of their genes. This is apparent from a social pathology: psychopaths rally followers.
Once in a while you encounter members of the human species with so much intellectual superiority that they can change their minds effortlessly.
Note here the following Black Swan asymmetry. I believe that you can be dead certain about
some
things, and ought to be so. You can be more confident about disconfirmation than confirmation. Karl Popper was accused of promoting self-doubt while writing in an aggressive and confident tone (an accusation that is occasionally addressed to this author by people who don’t follow my logic of skeptical empiricism). Fortunately, we have learned a lot since Montaigne about how to carry on the skeptical-empirical enterprise. The Black Swan asymmetry allows you to be confident
about what is wrong
, not about what you believe is right. Karl Popper was once asked whether one “could falsify falsification” (in other words, if one could be skeptical about skepticism). His answer was
that he threw students out of his lectures for asking far more intelligent questions than that one. Quite tough, Sir Karl was.


================================================================================
CHAPTER/SECTION 229 (Item 234)
================================================================================

THE PAST’S PAST, AND THE PAST’S FUTURE
Some truths only hit children—adults and nonphilosophers get sucked into the minutiae of practical life and need to worry about “serious matters,” so they abandon these insights for seemingly more relevant questions. One of these truths concerns the larger difference in texture and quality between the past and the future. Thanks to my studying this distinction all my life, I understand it better than I did during my childhood, but I no longer envision it as vividly.
The only way you can imagine a future “similar” to the past is by assuming that it will be an
exact
projection of it, hence predictable. Just as you know with some precision when you were born, you would then know with equal precision when you will die. The notion of future mixed with
chance
, not a deterministic extension of your perception of the past, is a mental operation that our mind cannot perform. Chance is too fuzzy for us to be a category by itself. There is an asymmetry between past and future, and it is too subtle for us to understand naturally.
The first consequence of this asymmetry is that, in people’s minds, the relationship between the past and the future does not learn from the relationship between the past and the past previous to it. There is a blind spot: when we think of tomorrow we do not frame it in terms of what we thought about yesterday on the day before yesterday. Because of this introspective defect we fail to learn about the difference between our past predictions and the subsequent outcomes. When we think of tomorrow, we just project it as another yesterday.
This small blind spot has other manifestations. Go to the primate section of the Bronx Zoo where you can see our close relatives in the happy primate family leading their own busy social lives. You can also see masses of tourists laughing at the caricature of humans that the lower primates represent. Now imagine being a member of a higher-level species (say a “real” philosopher, a truly wise person), far more sophisticated than the human primates. You would certainly laugh at the people laughing at the nonhuman primates. Clearly, to those people amused by the apes, the idea of a being who would look down on them the way they look down on the apes cannot immediately come to their minds—if it did, it would elicit self-pity. They would stop laughing.
Accordingly, an element in the mechanics of how the human mind learns from the past makes us believe in definitive solutions—yet not consider that those who preceded us thought that they too had definitive solutions. We laugh at others and we don’t realize that someone will be just as justified in laughing at us on some not too remote day. Such a realization would entail the recursive, or second-order, thinking that I mentioned in the Prologue; we are not good at it.
This mental block about the future has not yet been investigated and labeled by psychologists, but it appears to resemble autism. Some autistic subjects can possess high levels of mathematical or technical intelligence. Their social skills are defective, but that is not the root of their problem. Autistic people cannot put themselves in the shoes of others, cannot view the world from their standpoint. They see others as inanimate objects, like machines, moved by explicit rules. They cannot perform such simple mental operations as “he knows that I don’t know that I know,” and it is this inability that impedes their social skills. (Interestingly, autistic subjects, regardless of their “intelligence,” also exhibit an inability to comprehend uncertainty.)
Just as autism is called “mind blindness,” this inability to think dynamically, to position oneself with respect to a future observer, we should call “future blindness.”
Prediction, Misprediction, and Happiness
I searched the literature of cognitive science for any research on “future blindness” and found nothing. But in the literature on happiness I did find an examination of our chronic errors in prediction that will make us happy.
This prediction error works as follows. You are about to buy a new car. It is going to change your life, elevate your status, and make your commute a vacation. It is so quiet that you can hardly tell if the engine is on, so you can listen to Rachmaninoff’s nocturnes on the highway. This new car will bring you to a permanently elevated plateau of contentment. People will think, Hey, he has a great car, every time they see you. Yet you forget that the last time you bought a car, you also had the same expectations. You do not anticipate that the effect of the new car will eventually wane and that you will revert to the initial condition, as you did last time. A few weeks after you drive your new car out of the showroom, it will
become dull. If you had expected this, you probably would not have bought it.
You are about to commit a prediction error that you have already made. Yet it would cost so little to introspect!
Psychologists have studied this kind of misprediction with respect to both pleasant and unpleasant events. We overestimate the effects of both kinds of future events on our lives. We seem to be in a psychological predicament that makes us do so. This predicament is called “anticipated utility” by Danny Kahneman and “affective forecasting” by Dan Gilbert. The point is not so much that we tend to mispredict our future happiness, but rather that we do not learn recursively from past experiences. We have evidence of a mental block and distortions in the way we fail to learn from our past errors in projecting the future of our affective states.
We grossly overestimate the length of the effect of misfortune on our lives. You think that the loss of your fortune or current position will be devastating, but you are probably wrong. More likely, you will adapt to anything, as you probably did after past misfortunes. You may feel a sting, but it will not be as bad as you expect. This kind of misprediction may have a purpose: to motivate us to perform
important
acts (like buying new cars or getting rich) and to prevent us from taking certain unnecessary risks. And it is part of a more general problem: we humans are supposed to fool ourselves a little bit here and there. According to Trivers’s theory of self-deception, this is supposed to orient us favorably toward the future. But self-deception is not a desirable feature outside of its natural domain. It prevents us from taking some unnecessary risks—but we saw in
Chapter 6
how it does not as readily cover a spate of modern risks that we do not fear because they are not vivid, such as investment risks, environmental dangers, or long-term security.
Helenus and the Reverse Prophecies
If you are in the business of being a seer, describing the future to other less-privileged mortals, you are judged on the merits of your predictions.
Helenus, in
The Iliad
, was a different kind of seer. The son of Priam and Hecuba, he was the cleverest man in the Trojan army. It was he who, under torture, told the Achaeans how they would capture Troy (apparently he didn’t predict that he himself would be captured). But this is not what distinguished him. Helenus, unlike other seers, was able to predict
the past
with great precision—without having been given any details of it. He predicted backward.
Our problem is not just that we do not know the future, we do not know much of the past either. We badly need someone like Helenus if we are to know history. Let us see how.
The Melting Ice Cube
Consider the following thought experiment borrowed from my friends Aaron Brown and Paul Wilmott:
Operation 1 (the melting ice cube):
Imagine an ice cube and consider how it may melt over the next two hours while you play a few rounds of poker with your friends. Try to envision the shape of the resulting puddle.
Operation 2 (where did the water come from?):
Consider a puddle of water on the floor. Now try to reconstruct in your mind’s eye the shape of the ice cube it may once have been. Note that the puddle may not have necessarily originated from an ice cube.
The second operation is harder. Helenus indeed had to have skills.
The difference between these two processes resides in the following. If you have the right models (and some time on your hands, and nothing better to do) you can predict with great precision how the ice cube will melt—this is a specific engineering problem devoid of complexity, easier than the one involving billiard balls. However, from the pool of water you can build infinite possible ice cubes, if there was in fact an ice cube there at all. The first direction, from the ice cube to the puddle, is called the
forward process
. The second direction, the
backward process
, is much, much more complicated. The forward process is generally used in physics and engineering; the backward process in nonrepeatable, nonexperimental historical approaches.
In a way, the limitations that prevent us from unfrying an egg also prevent us from reverse engineering history.
Now, let me increase the complexity of the forward-backward problem just a bit by assuming nonlinearity. Take what is generally called the “butterfly in India” paradigm from the discussion of Lorenz’s discovery in the previous chapter. As we have seen, a small input in a complex system can lead to nonrandom large results, depending on very special conditions. A single butterfly flapping its wings in New Delhi may be the certain
cause
of a hurricane in North Carolina, though the hurricane may take
place a couple of years later. However,
given the observation of a hurricane in North Carolina
, it is dubious that you could figure out the causes with any precision: there are billions of billions of such small things as wing-flapping butterflies in Timbuktu or sneezing wild dogs in Australia that could have caused it. The process from the butterfly to the hurricane is greatly simpler than the reverse process
from
the hurricane
to
the potential butterfly.
Confusion between the two is disastrously widespread in common culture. This “butterfly in India” metaphor has fooled at least one filmmaker. For instance,
Happenstance
(a.k.a.
The Beating of a Butterfly’s Wings)
, a French-language film by one Laurent Firode, meant to encourage people to focus on small things that can change the course of their lives. Hey, since a small event (a petal falling on the ground and getting your attention) can lead to your choosing one person over another as a mate for life, you should focus on these very small details. Neither the filmmaker nor the critics realized that they were dealing with the backward process; there are trillions of such small things in the course of a simple day, and examining all of them lies outside of our reach.
Once Again, Incomplete Information
Take a personal computer. You can use a spreadsheet program to generate a random sequence, a succession of points we can call a history. How? The computer program responds to a very complicated equation of a nonlinear nature that produces numbers that seem random. The equation is very simple: if you know it, you can predict the sequence. It is almost impossible, however, for a human being to reverse engineer the equation and predict further sequences. I am talking about a simple one-line computer program (called the “tent map”) generating a handful of data points, not about the billions of simultaneous events that constitute the real history of the world. In other words, even if history were a nonrandom series generated by some “equation of the world,” as long as reverse engineering such an equation does not seem within human possibility, it should be deemed random and not bear the name “deterministic chaos.” Historians should stay away from chaos theory and the difficulties of reverse engineering except to discuss general properties of the world and learn the limits of what they can’t know.
This brings me to a greater problem with the historian’s craft. I will
state the fundamental problem of practice as follows: while in theory randomness is an intrinsic property, in practice, randomness is
incomplete information
, what I called
opacity
in
Chapter 1
.
Nonpractitioners of randomness do not understand the subtlety. Often, in conferences when they hear me talk about uncertainty and randomness, philosophers, and sometimes mathematicians, bug me about the least relevant point, namely whether the randomness I address is “true randomness” or “deterministic chaos” that masquerades as randomness. A true random system is in fact random and does not have predictable properties. A chaotic system has entirely predictable properties, but they are hard to know. So my answer to them is dual.
a) There is no functional difference in practice between the two since we will never get to make the distinction—the difference is mathematical, not practical. If I see a pregnant woman, the sex of her child is a purely random matter to me (a 50 percent chance for either sex)—but not to her doctor, who might have done an ultrasound. In practice, randomness is fundamentally incomplete information.
b) The mere fact that a person is talking about the difference implies that he has never made a meaningful decision under uncertainty—which is why he does not realize that they are indistinguishable in practice.
Randomness, in the end, is just unknowledge. The world is opaque and appearances fool us.
What They Call Knowledge
One final word on history.
History is like a museum where one can go to see the repository of the past, and taste the charm of olden days. It is a wonderful mirror in which we can see our own narratives. You can even track the past using DNA analyses. I am fond of literary history. Ancient history satisfies my desire to build my own self-narrative, my identity, to connect with my (complicated) Eastern Mediterranean roots. I even prefer the accounts of older, patently less accurate books to modern ones. Among the authors I’ve reread (the ultimate test of whether you like an author is if you’ve reread him) the following come to mind: Plutarch, Livy, Suetonius, Diodorus Siculus, Gibbon, Carlyle, Renan, and Michelet. These accounts are patently substandard, compared to today’s works; they are largely anecdotal, and full of myths. But I know this.
History is useful for the thrill of knowing the past, and for the narrative
(indeed), provided it remains a harmless narrative. One should learn under severe caution. History is certainly not a place to theorize or derive general knowledge, nor is it meant to help in the future, without some caution. We can get negative confirmation from history, which is invaluable, but we get plenty of illusions of knowledge along with it.
This brings me back once again to Menodotus and the treatment of the turkey problem and how to not be a sucker for the past. The empirical doctor’s approach to the problem of induction was to
know
history without theorizing from it. Learn to read history, get all the knowledge you can, do not frown on the anecdote, but do not draw any causal links, do not try to reverse engineer too much—but if you do, do not make big scientific claims. Remember that the empirical skeptics had respect for custom: they used it as a default, a basis for action, but not for more than that. This clean approach to the past they called
epilogism
.
*
But most historians have another opinion. Consider the representative introspection
What Is History?
by Edward Hallett Carr. You will catch him explicitly pursuing causation as a central aspect of his job. You can even go higher up: Herodotus, deemed to be the father of the subject, defined his purpose in the opening of his work:
To preserve a memory of the deeds of the Greeks and barbarians, “and in particular, beyond everything else, to give a
cause
[emphasis mine] to their fighting one another.”
You see the same with all theoreticians of history, whether Ibn Khaldoun, Marx, or Hegel. The more we try to turn history into anything other than an enumeration of accounts to be enjoyed with minimal theorizing, the more we get into trouble. Are we so plagued with the narrative fallacy?
†
We may have to wait for a generation of skeptical-empiricist historians capable of understanding the difference between a forward process and a reverse one.
Just as Popper attacked the historicists in their making claims about the future, I have just presented the weakness of the historical approach in knowing the
past
itself.
After this discussion about future (and past) blindness, let us see what to do about it. Remarkably, there are extremely practical measures we can take. We will explore this next.
*
Yogi Berra might have a theory of epilogism with his saying, “You can observe a lot by just watching.”
†
While looking at the past it would be a good idea to resist naïve analogies. Many people have compared the United States today to Ancient Rome, both from a military standpoint (the destruction of Carthage was often invoked as an incentive for the destruction of enemy regimes) and from a social one (the endless platitudinous warnings of the upcoming decline and fall). Alas, we need to be extremely careful in transposing knowledge from a simple environment that is closer to type 1, like the one we had in antiquity, to today’s type 2, complex system, with its intricate webs of casual links. Another error is to draw casual conclusions from the absence of nuclear war, since, invoking the Casanova argument of
Chapter 8
, I would repeat that we would not be here had a nuclear war taken place, and it is not a good idea for us to derive a “cause” when our survival is conditioned on that cause.


================================================================================
CHAPTER/SECTION 230 (Item 235)
================================================================================

Chapter Thirteen
APPELLES THE PAINTER, OR WHAT DO YOU DO IF YOU CANNOT PREDICT?
*
You should charge people for advice—My two cents here—Nobody knows anything, but, at least, he knows it—Go to parties


================================================================================
CHAPTER/SECTION 231 (Item 236)
================================================================================

ADVICE IS CHEAP, VERY CHEAP
It is not a good habit to stuff one’s text with quotations from prominent thinkers, except to make fun of them or provide a historical reference. They “make sense,” but well-sounding maxims force themselves on our gullibility and do not always stand up to empirical tests. So I chose the following statement by the überphilosopher Bertrand Russell precisely because I disagree with it.
The demand for certainty is one which is natural to man, but is nevertheless an intellectual vice. If you take your children for a picnic on a doubtful day, they will demand a dogmatic answer as to whether it will be fine or wet, and be disappointed in you when you cannot be sure. …
But so long as men are not
trained
[emphasis mine] to withhold judgment in the absence of evidence, they will be led astray by cocksure prophets … For the learning of every virtue there is an appropriate discipline, and for the learning of suspended judgment the best discipline is philosophy.
The reader may be surprised that I disagree. It is hard to disagree that the demand for certainty is an intellectual vice. It is hard to disagree that we can be led astray by some cocksure prophet. Where I beg to differ with the great man is that I do not believe in the track record of advice-giving “philosophy” in helping us deal with the problem; nor do I believe that virtues can be
easily
taught; nor do I urge people to strain in order to avoid making a judgment. Why? Because we have to deal with humans as humans. We cannot
teach
people to withhold judgment; judgments are embedded in the way we view objects. I do not see a “tree;” I see a pleasant or an ugly tree. It is not possible without great, paralyzing effort to strip these small values we attach to matters. Likewise, it is not possible to hold a situation in one’s head without some element of bias. Something in our dear human nature makes us want to believe; so what?
Philosophers since Aristotle have taught us that we are deep-thinking animals, and that we can learn by reasoning. It took a while to discover that we do effectively think, but that we more readily narrate backward in order to give ourselves the illusion of understanding, and give a cover to our past actions. The minute we forgot about this point, the “Enlightenment” came to drill it into our heads for a second time.
I’d rather degrade us humans to a level certainly above other known animals but not quite on a par with the ideal Olympian man who can absorb philosophical statements and act accordingly. Indeed, if philosophy were
that
effective, the self-help section of the local bookstore would be of some use in consoling souls experiencing pain—but it isn’t. We forget to philosophize when under strain.
I’ll end this section on prediction with the following two lessons, one very brief (for the small matters), one rather lengthy (for the large, important decisions).
Being a Fool in the Right Places
The lesson for the small is:
be human!
Accept that being human involves some amount of epistemic arrogance in running your affairs. Do not be ashamed of that. Do not try to always withhold judgment—opinions are the stuff of life. Do not try to avoid predicting—yes, after this diatribe about prediction I am
not
urging you to stop being a fool. Just be a fool in the right places.
*
What you should avoid is unnecessary dependence on large-scale harmful predictions—those and only those. Avoid the big subjects that may hurt your future: be fooled in small matters, not in the large. Do not listen to economic forecasters or to predictors in social science (they are mere entertainers), but do make your own forecast for the picnic. By all means, demand certainty for the next picnic; but avoid government social-security forecasts for the year 2040.
Know how to rank beliefs not according to their plausibility but by the harm they may cause.
Be Prepared
The reader might feel queasy reading about these general failures to see the future and wonder what to do. But if you shed the idea of full predictability, there are plenty of things to do provided you remain conscious of their limits. Knowing that you cannot predict does not mean that you cannot benefit from unpredictability.
The bottom line: be prepared! Narrow-minded prediction has an analgesic or therapeutic effect. Be aware of the numbing effect of magic numbers. Be prepared for all relevant eventualities.


================================================================================
CHAPTER/SECTION 232 (Item 237)
================================================================================

THE IDEA OF POSITIVE ACCIDENT
Recall the empirics, those members of the Greek school of empirical medicine. They considered that you should be open-minded in your medical diagnoses to let luck play a role. By luck, a patient might be cured, say, by
eating some food that accidentally turns out to be the cure for his disease, so that the treatment can then be used on subsequent patients. The
positive
accident (like hypertension medicine producing side benefits that led to Viagra) was the empirics’ central method of medical discovery.
This same point can be generalized to life: maximize the serendipity around you.
Sextus Empiricus retold the story of Apelles the Painter, who, while doing a portrait of a horse, was attempting to depict the foam from the horse’s mouth. After trying very hard and making a mess, he gave up and, in irritation, took the sponge he used for cleaning his brush and threw it at the picture. Where the sponge hit, it left a perfect representation of the foam.
Trial and error means trying a lot. In
The Blind Watchmaker
, Richard Dawkins brilliantly illustrates this notion of the world without grand design, moving by small incremental random changes. Note a slight disagreement on my part that does not change the story by much: the world, rather, moves by
large
incremental random changes.
Indeed, we have psychological and intellectual difficulties with trial and error, and with accepting that series of small failures are necessary in life. My colleague Mark Spitznagel understood that we humans have a mental hang-up about failures: “You need to love to lose” was his motto. In fact, the reason I felt immediately at home in America is precisely because American culture encourages the process of failure, unlike the cultures of Europe and Asia where failure is met with stigma and embarrassment. America’s specialty is to take these small risks for the rest of the world, which explains this country’s disproportionate share in innovations. Once established, an idea or a product is later “perfected” over there.
Volatility and Risk of Black Swan
People are often ashamed of losses, so they engage in strategies that produce very little volatility but contain the risk of a large loss—like collecting nickels in front of steamrollers. In Japanese culture, which is ill-adapted to randomness and badly equipped to understand that bad performance can come from bad luck, losses can severely tarnish someone’s reputation. People hate volatility, thus engage in strategies exposed to blowups, leading to occasional suicides after a big loss.
Furthermore, this trade-off between volatility and risk can show up in
careers that give the appearance of being stable, like jobs at IBM until the 1990s. When laid off, the employee faces a total void: he is no longer fit for anything else. The same holds for those in protected industries. On the other hand, consultants can have volatile earnings as their clients’ earnings go up and down, but face a lower risk of starvation, since their skills match demand—
fluctuat nec mergitur
(fluctuates but doesn’t sink). Likewise, dictatorships that do not appear volatile, like, say, Syria or Saudi Arabia, face a larger risk of chaos than, say, Italy, as the latter has been in a state of continual political turmoil since the second war. I learned about this problem from the finance industry, in which we see “conservative” bankers sitting on a pile of dynamite but fooling themselves because their operations seem dull and lacking in volatility.
Barbell Strategy
I am trying here to generalize to real life the notion of the “barbell” strategy I used as a trader, which is as follows. If you know that you are vulnerable to prediction errors, and if you accept that most “risk measures” are flawed, because of the Black Swan, then your strategy is to be as hyperconservative and hyperaggressive as you can be instead of being mildly aggressive or conservative. Instead of putting your money in “medium risk” investments (how do you know it is medium risk? by listening to tenure-seeking “experts”?), you need to put a portion, say 85 to 90 percent, in extremely safe instruments, like Treasury bills—as safe a class of instruments as you can manage to find on this planet. The remaining 10 to 15 percent you put in extremely speculative bets, as leveraged as possible (like options), preferably venture capital–style portfolios.
*
That way you do not depend on errors of risk management; no Black Swan can hurt you at all, beyond your “floor,” the nest egg that you have in maximally safe investments. Or, equivalently, you can have a speculative portfolio and insure it (if possible) against losses of more than, say, 15 percent. You are “clipping” your incomputable risk, the one that is harmful to you. Instead of having medium risk, you have high risk on one side and no risk on the other. The average will be medium risk but constitutes a positive exposure to the Black Swan. More technically, this can be called a “convex” combination. Let us see how this can be implemented in all aspects of life.
“Nobody Knows Anything”
The legendary screenwriter William Goldman was said to have shouted “Nobody knows anything!” in relation to the prediction of movie sales. Now, the reader may wonder how someone as successful as Goldman can figure out what to do without making predictions. The answer stands perceived business logic on its head. He knew that he could not predict individual events, but he was well aware that the unpredictable, namely a movie turning into a blockbuster, would benefit him immensely.
So the second lesson is more aggressive: you can actually take advantage of the problem of prediction and epistemic arrogance! As a matter of fact, I suspect that the most successful businesses are precisely those that know how to work around inherent unpredictability and even exploit it.
Recall my discussion of the biotech company whose managers understood that the essence of research is in the unknown unknowns. Also, notice how they seized on the “corners,” those free lottery tickets in the world.
Here are the (modest) tricks. But note that the more modest they are, the more effective they will be.
First, make a distinction between
positive contingencies
and
negative ones. Learn to distinguish between those human undertakings in which the lack of predictability can be (or has been) extremely beneficial and those where the failure to understand the future caused harm. There are both positive and negative Black Swans. William Goldman was involved in the movies, a positive–Black Swan business. Uncertainty did occasionally pay off there.
A negative–Black Swan business is one where the unexpected can hit hard and hurt severely. If you are in the military, in catastrophe insurance, or in homeland security, you face only downside. Likewise, as we saw in
Chapter 7
, if you are in banking and lending, surprise outcomes are likely to be negative for you. You lend,
and in the best of circumstances you get your loan back—but you may lose all of your money if the borrower defaults. In the event that the borrower enjoys great financial success, he is not likely to offer you an additional dividend.
Aside from the movies, examples of positive–Black Swan businesses are: some segments of publishing, scientific research, and venture capital. In these businesses, you lose small to make big. You have little to lose per book and, for completely unexpected reasons, any given book might take off. The downside is small and easily controlled. The problem with publishers, of course, is that they regularly pay up for books, thus making their upside rather limited and their downside monstrous. (If you pay $10 million for a book, your Black Swan is it not being a bestseller.) Likewise, while technology can carry a great payoff, paying for the hyped-up story, as people did with the dot-com bubble, can make any upside limited and any downside huge. It is the venture capitalist who invested in a speculative company and sold his stake to unimaginative investors who is the beneficiary of the Black Swan, not the “me, too” investors.
In these businesses you are lucky if you don’t know anything—particularly if others don’t know anything either, but aren’t aware of it. And you fare best if you know where your ignorance lies, if you are the only one looking at the unread books, so to speak. This dovetails into the “barbell” strategy of taking maximum exposure to the positive Black Swans while remaining paranoid about the negative ones. For your exposure to the positive Black Swan, you do not need to have any precise understanding of the structure of uncertainty. I find it hard to explain that when you have a very limited loss you need to get as aggressive, as speculative, and sometimes as “unreasonable” as you can be.
Middlebrow thinkers sometimes make the analogy of such strategy with that of collecting “lottery tickets.” It is plain wrong. First, lottery tickets do not have a scalable payoff; there is a known upper limit to what they can deliver. The ludic fallacy applies here—the scalability of real-life payoffs compared to lottery ones makes the payoff unlimited or of unknown limit. Secondly, the lottery tickets have known rules and laboratory-style well-presented possibilities; here we do not know the rules and can benefit from
this additional uncertainty, since it cannot hurt you and can only benefit you.
*
Don’t look for the
precise
and the
local. Simply, do not be narrow-minded. The great discoverer Pasteur, who came up with the notion that chance favors the prepared, understood that you do not look for something particular every morning but work hard to let contingency enter your working life. As Yogi Berra, another great thinker, said, “You got to be very careful if you don’t know where you’re going, because you might not get there.”
Likewise, do not try to predict precise Black Swans—it tends to make you more vulnerable to the ones you did not predict. My friends Andy Marshall and Andrew Mays at the Department of Defense face the same problem. The impulse on the part of the military is to devote resources to predicting the next problems. These thinkers advocate the opposite: invest in preparedness, not in prediction.
Remember that infinite vigilance is just not possible.
Seize any opportunity, or anything that looks like opportunity
. They are rare, much rarer than you think. Remember that positive Black Swans have a necessary first step: you need to be exposed to them. Many people do not realize that they are getting a lucky break in life when they get it. If a big publisher (or a big art dealer or a movie executive or a hotshot banker or a big thinker) suggests
an appointment, cancel anything you have planned: you may never see such a window open up again. I am sometimes shocked at how little people realize that these opportunities do not grow on trees. Collect as many free nonlottery tickets (those with open-ended payoffs) as you can, and, once they start paying off, do not discard them. Work hard, not in grunt work, but in chasing such opportunities and maximizing exposure to them. This makes living in big cities invaluable because you increase the odds of serendipitous encounters—you gain exposure to the envelope of serendipity. The idea of settling in a rural area on grounds that one has good communications “in the age of the Internet” tunnels out of such sources of positive uncertainty. Diplomats understand that very well: casual chance discussions at cocktail parties usually lead to big breakthroughs—not dry correspondence or telephone conversations. Go to parties! If you’re a scientist, you will chance upon a remark that might spark new research. And if you are autistic, send your associates to these events.
Beware of precise plans by governments
. As discussed in
Chapter 10
, let governments predict (it makes officials feel better about themselves and justifies their existence) but do not set much store by what they say. Remember that the interest of these civil servants is to survive and self-perpetuate—not to get to the truth. It does not mean that governments are useless, only that you need to keep a vigilant eye on their side effects. For instance, regulators in the banking business are prone to a severe expert problem and they tend to condone reckless but (hidden) risk taking. Andy Marshall and Andy Mays asked me if the private sector could do better in predicting. Alas, no. Once again, recall the story of banks hiding explosive risks in their portfolios. It is not a good idea to trust corporations with matters such as rare events because the performance of these executives is not observable on a short-term basis, and they will game the system by showing good performance so they can get their yearly bonus. The Achilles’ heel of capitalism is that if you make corporations compete, it is sometimes the one that is most exposed to the negative Black Swan that will appear to be the most fit for survival. Also recall from the footnote on Ferguson’s discovery in
Chapter 1
that markets are not good predictors of wars. No one in particular is a good predictor of anything. Sorry.
“There are some people who, if they don’t already know, you can’t tell ’em,” as the great philosopher of uncertainty Yogi Berra once said.
Do not waste your time trying to fight forecasters, stock analysts, economists, and social scientists, except to play pranks on them
. They are considerably easy to make fun of, and many get angry quite readily. It is ineffective to moan about unpredictability: people will continue to predict foolishly, especially if they are paid for it, and you cannot put an end to institutionalized frauds. If you ever do have to heed a forecast, keep in mind that its accuracy degrades rapidly as you extend it through time.
If you hear a “prominent” economist using the word
equilibrium
, or
normal distribution
, do not argue with him; just ignore him, or try to put a rat down his shirt.
The Great Asymmetry
All these recommendations have one point in common: asymmetry. Put yourself in situations where favorable consequences are much larger than unfavorable ones.
Indeed, the notion of
asymmetric outcomes
is the central idea of this book: I will never get to know the unknown since, by definition, it is unknown. However, I can always guess how it might affect me, and I should base my decisions around that.
This idea is often erroneously called Pascal’s wager, after the philosopher and (thinking) mathematician Blaise Pascal. He presented it something like this: I do not know whether God exists, but I know that I have nothing to gain from being an atheist if he does not exist, whereas I have plenty to lose if he does. Hence, this justifies my belief in God.
Pascal’s argument is severely flawed theologically: one has to be naïve enough to believe that God would not penalize us for false belief. Unless, of course, one is taking the quite restrictive view of a naïve God. (Bertrand Russell was reported to have claimed that God would need to have created fools for Pascal’s argument to work.)
But the idea behind Pascal’s wager has fundamental applications outside of theology. It stands the entire notion of knowledge on its head. It eliminates the need for us to understand the probabilities of a rare event (there are fundamental limits to our knowledge of these); rather, we can focus on the payoff and benefits of an event if it takes place. The probabilities of very rare events are not computable; the effect of an event on us is
considerably easier to ascertain (the rarer the event, the fuzzier the odds). We can have a clear idea of the consequences of an event, even if we do not know how likely it is to occur. I don’t know the odds of an earthquake, but I can imagine how San Francisco might be affected by one. This idea that in order to make a decision you need to focus on the consequences (which you can know) rather than the probability (which you can’t know) is the
central idea of uncertainty
. Much of my life is based on it.
You can build an overall theory of decision making on this idea. All you have to do is mitigate the consequences. As I said, if my portfolio is exposed to a market crash, the odds of which I can’t compute, all I have to do is buy insurance, or get out and invest the amounts I am not willing to ever lose in less risky securities.
Effectively, if free markets have been successful, it is precisely because they allow the trial-and-error process I call “stochastic tinkering” on the part of competing individual operators who fall for the narrative fallacy—but are effectively collectively partaking of a grand project. We are increasingly learning to practice stochastic tinkering without knowing it—thanks to overconfident entrepreneurs, naïve investors, greedy investment bankers, and aggressive venture capitalists brought together by the free-market system. The next chapter shows why I am optimistic that the academy is losing its power and ability to put knowledge in straitjackets and that more out-of-the-box knowledge will be generated Wiki-style.
In the end we are being driven by history, all the while thinking that we are doing the driving.
I’ll sum up this long section on prediction by stating that we can easily narrow down the reasons we can’t figure out what’s going on. There are: a) epistemic arrogance and our corresponding future blindness; b) the Platonic notion of categories, or how people are fooled by reductions, particularly if they have an academic degree in an expert-free discipline; and, finally c) flawed tools of inference, particularly the Black Swan–free tools from Mediocristan.
In the next section we will go deeper, much deeper, into these tools from Mediocristan, into the “plumbing,” so to speak. Some readers may see it as an appendix; others may consider it the heart of the book.
*
This chapter provides a general conclusion for those who by now say, “Taleb, I get the point, but what should I do?” My answer is that if you got the point, you are pretty much there. But here is a nudge.
*
Dan Gilbert showed in a famous paper, “How Mental Systems Believe,” that we are not natural skeptics and that not believing required an expenditure of mental effort.
*
Make sure that you have plenty of these small bets; avoid being blinded by the vividness of one single Black Swan. Have as many of these small bets as you can conceivably have. Even venture capital firms fall for the narrative fallacy with a few stories that “make sense” to them; they do not have as many bets as they should. If venture capital firms are profitable, it is not because of the stories they have in their heads, but because they are exposed to unplanned rare events.
*
There is a finer epistemological point. Remember that in a virtuous Black Swan business, what the past did not reveal is almost certainly going to be good for you. When you look at past biotech revenues, you do not see the superblockbuster in them, and owing to the potential for a cure for cancer (or headaches, or baldness, or bad sense of humor, etc.), there is a small probability that the sales in that industry may turn out to be monstrous, far larger than might be expected. On the other hand, consider negative Black Swan businesses. The track record you see is likely to overestimate the properties. Recall the 1982 blowup of banks: they appeared to the naïve observer to be more profitable than they seemed. Insurance companies are of two kinds: the regular diversifiable kind that belongs to Mediocristan (say, life insurance) and the more critical and explosive Black Swan–prone risks that are usually sold to reinsurers. According to the data, reinsurers have lost money on underwriting over the past couple of decades, but, unlike bankers, they are introspective enough to know that it actually could have been far worse, because the past twenty years did not have a big catastrophe, and all you need is one of those per century to kiss the business good-bye. Many finance academics doing “valuation” on insurance seem to have missed the point.


================================================================================
CHAPTER/SECTION 233 (Item 238)
================================================================================

I
t’s time to deal in some depth with four final items that bear on our Black Swan.
Primo
, I have said earlier that the world is moving deeper into Extremistan, that it is less and less governed by Mediocristan—in fact, this idea is more subtle than that. I will show how and present the various ideas we have about the formation of inequality.
Secondo
, I have been describing the Gaussian bell curve as a contagious and severe delusion, and it is time to get into that point in some depth.
Terso
, I will present what I call Mandelbrotian, or fractal, randomness. Remember that for an event to be a Black Swan, it does not just have to be rare, or just wild; it has to be unexpected, has to lie outside our tunnel of possibilities. You must be a sucker for it. As it happens, many rare events can yield their structure to us: it is not easy to compute their probability, but it is easy to get a
general
idea about the possibility of their occurrence. We can turn these Black Swans into Gray Swans, so to speak, reducing their surprise effect. A person aware of the possibility of such events can come to belong to the non-sucker variety.
Finally, I will present the ideas of those philosophers who focus on phony uncertainty. I organized this book in such a way that the more technical (though nonessential) sections are here; these can be skipped without any loss to the thoughtful reader, particularly
Chapters 15
,
17
, and the second half of
Chapter 16
. I will alert the reader with footnotes. The reader less interested in the mechanics of deviations can then directly proceed to
Part 4
.


================================================================================
CHAPTER/SECTION 234 (Item 239)
================================================================================

Chapter Fourteen
FROM MEDIOCRISTAN TO EXTREMISTAN, AND BACK
I prefer Horowitz—How to fall from favor—The long tail—Get ready for some surprises—It’s not just money
Let us see how an increasingly man-made planet can evolve away from mild into wild randomness. First, I describe how we get to Extremistan. Then, I will take a look at its evolution.
The World Is Unfair
Is the world that unfair? I have spent my entire life studying randomness, practicing randomness, hating randomness. The more that time passes, the worse things seem to me, the more scared I get, the more disgusted I am with Mother Nature. The more I think about my subject, the more I see evidence that the world we have in our minds is different from the one playing outside. Every morning the world appears to me more random than it did the day before, and humans seem to be even more fooled by it than they were the previous day. It is becoming unbearable. I find writing these lines painful; I find the world revolting.
Two “soft” scientists propose intuitive models for the development of this inequity: one is a mainstream economist, the other a sociologist. Both simplify a little too much. I will present their ideas because they are easy
to understand, not because of the scientific quality of their insights or any consequences in their discoveries; then I will show the story as seen from the vantage point of the natural scientists.
Let me start with the economist Sherwin Rosen. In the early eighties, he wrote papers about “the economics of superstars.” In one of the papers he conveyed his sense of outrage that a basketball player could earn $1.2 million a year, or a television celebrity could make $2 million. To get an idea of how this concentration is increasing—i.e., of how we are moving away from Mediocristan—consider that television celebrities and sports stars (even in Europe) get contracts today, only two decades later, worth in the hundreds of millions of dollars! The extreme is about (so far) twenty times higher than it was two decades ago!
According to Rosen, this inequality comes from a tournament effect: someone who is marginally “better” can easily win the entire pot, leaving the others with nothing. Using an argument from
Chapter 3
, people prefer to pay $10.99 for a recording featuring Horowitz to $9.99 for a struggling pianist. Would you rather read Kundera for $13.99 or some unknown author for $1? So it looks like a tournament, where the winner grabs the whole thing—and he does not have to win by much.
But the role of luck is missing in Rosen’s beautiful argument. The problem here is the notion of “better,” this focus on skills as leading to success. Random outcomes, or an arbitrary situation, can also explain success, and provide the initial push that leads to a winner-take-all result. A person can get slightly ahead for entirely random reasons; because we like to imitate one another, we will flock to him. The world of contagion is so underestimated!
As I am writing these lines I am using a Macintosh, by Apple, after years of using Microsoft-based products. The Apple technology is vastly better, yet the inferior software won the day. How? Luck.
The Matthew Effect
More than a decade before Rosen, the sociologist of science Robert K. Merton presented his idea of the Matthew effect, by which people take from the poor to give to the rich.
*
He looked at the performance of scientists and showed how an initial advantage follows someone through life. Consider the following process.
Let’s say someone writes an academic paper quoting fifty people who have worked on the subject and provided background materials for his study; assume, for the sake of simplicity, that all fifty are of equal merit. Another researcher working on the exact same subject will randomly cite three of those fifty in his bibliography. Merton showed that many academics cite references without having read the original work; rather, they’ll read a paper and draw their own citations from among its sources. So a third researcher reading the second article selects three of the previously referenced authors for
his
citations. These three authors will receive cumulatively more and more attention as their names become associated more tightly with the subject at hand. The difference between the winning three and the other members of the original cohort is mostly luck: they were initially chosen not for their greater skill, but simply for the way their names appeared in the prior bibliography. Thanks to their reputations, these successful academics will go on writing papers and their work will be easily accepted for publication. Academic success is partly (but significantly) a lottery.
*
It is easy to test the effect of reputation. One way would be to find papers that were written by famous scientists, had their authors’ identities changed by mistake, and got rejected. You could verify how many of these rejections were subsequently overturned after the true identities of the authors were established. Note that scholars are judged mostly on how many times their work is referenced in other people’s work, and thus cliques of people who quote one another are formed (it’s an “I quote you, you quote me” type of business).
Eventually, authors who are not often cited will drop out of the game by, say, going to work for the government (if they are of a gentle nature), or for the Mafia, or for a Wall Street firm (if they have a high level of hormones). Those who got a good push in the beginning of their scholarly careers will keep getting persistent cumulative advantages throughout life. It is easier for the rich to get richer, for the famous to become more famous.
In sociology, Matthew effects bear the less literary name “cumulative
advantage.” This theory can easily apply to companies, businessmen, actors, writers, and anyone else who benefits from past success. If you get published in
The New Yorker
because the color of your letterhead attracted the attention of the editor, who was daydreaming of daisies, the resultant reward can follow you for life. More significantly, it will follow
others
for life. Failure is also cumulative; losers are likely to also lose in the future, even if we don’t take into account the mechanism of demoralization that might exacerbate it and cause additional failure.
Note that art, because of its dependence on word of mouth, is extremely prone to these cumulative-advantage effects. I mentioned clustering in
Chapter 1
, and how journalism helps perpetuate these clusters. Our opinions about artistic merit are the result of arbitrary contagion even more than our political ideas are. One person writes a book review; another person reads it and writes a commentary that uses the same arguments. Soon you have several hundred reviews that actually sum up in their contents to no more than two or three because there is so much overlap. For an anecdotal example read
Fire the Bastards!
, whose author, Jack Green, goes systematically through the reviews of William Gaddis’s novel
The Recognitions
. Green shows clearly how book reviewers anchor on other reviews and reveals powerful mutual influence, even in their wording. This phenomenon is reminiscent of the herding of financial analysts I discussed in
Chapter 10
.
The advent of the modern media has accelerated these cumulative advantages. The sociologist Pierre Bourdieu noted a link between the increased concentration of success and the globalization of culture and economic life. But I am not trying to play sociologist here, only show that unpredictable elements can play a role in social outcomes.
Merton’s cumulative-advantage idea has a more general precursor, “preferential attachment,” which, reversing the chronology (though not the logic), I will present next. Merton was interested in the social aspect of knowledge, not in the dynamics of social randomness, so his studies were derived separately from research on the dynamics of randomness in more mathematical sciences.
Lingua Franca
The theory of preferential attachment is ubiquitous in its applications: it can explain why city size is from Extremistan, why vocabulary is concentrated
among a small number of words, or why bacteria populations can vary hugely in size.
The scientists J. C. Willis and G. U. Yule published a landmark paper in
Nature
in 1922 called “Some Statistics of Evolution and Geographical Distribution in Plants and Animals, and Their Significance.” Willis and Yule noted the presence in biology of the so-called power laws, tractable versions of the scalable randomness that I discussed in
Chapter 3
. These power laws (on which more technical information in the following chapters) had been noticed earlier by Vilfredo Pareto, who found that they applied to the distribution of income. Later, Yule presented a simple model showing how power laws can be generated. His point was as follows: Let’s say species split in two at some constant rate, so that new species arise. The richer in species a genus is, the richer it will tend to get, with the same logic as the Matthew effect. Note the following caveat: in Yule’s model the species never die out.
During the 1940s, a Harvard linguist, George Zipf, examined the properties of language and came up with an empirical regularity now known as Zipf’s law, which, of course, is not a law (and if it were, it would not be Zipf’s). It is just another way to think about the process of inequality. The mechanisms he described were as follows: the more you use a word, the less effortful you will find it to use that word again, so you borrow words from your private dictionary in proportion to their past use. This explains why out of the sixty thousand main words in English, only a few hundred constitute the bulk of what is used in writings, and even fewer appear regularly in conversation. Likewise, the more people aggregate in a particular city, the more likely a stranger will be to pick that city as his destination. The big get bigger and the small stay small, or get relatively smaller.
A great illustration of preferential attachment can be seen in the mushrooming use of English as a lingua franca—though not for its intrinsic qualities, but because people need to use one single language, or stick to one as much as possible, when they are having a conversation. So whatever language appears to have the upper hand will suddenly draw people in droves; its usage will spread like an epidemic, and other languages will be rapidly dislodged. I am often amazed to listen to conversations between people from two neighboring countries, say, between a Turk and an Iranian, or a Lebanese and a Cypriot, communicating in bad English, moving their hands for emphasis, searching for these words that come out of their
throats at the cost of great physical effort. Even members of the Swiss Army use English (not French) as a lingua franca (it would be fun to listen). Consider that a very small minority of Americans of northern European descent is from England; traditionally the preponderant ethnic groups are of German, Irish, Dutch, French, and other northern European extraction. Yet because all these groups now use English as their main tongue, they have to study the roots of their adoptive tongue and develop a cultural association with parts of a particular wet island, along with its history, its traditions, and its customs!
Ideas and Contagions
The same model can be used for the contagions and concentration of ideas. But there are some restrictions on the nature of epidemics I must discuss here. Ideas do not spread without some form of structure. Recall the discussion in
Chapter 4
about how we come prepared to make inferences. Just as we tend to generalize some matters but not others, so there seem to be “basins of attraction” directing us to certain beliefs. Some ideas will prove contagious, but not others; some forms of superstitions will spread, but not others; some types of religious beliefs will dominate, but not others. The anthropologist, cognitive scientist, and philosopher Dan Sperber has proposed the following idea on the epidemiology of representations. What people call “memes,” ideas that spread and that compete with one another using people as carriers, are not truly like genes. Ideas spread because, alas, they have for carriers self-serving agents who are interested in them, and interested in distorting them in the replication process. You do not make a cake for the sake of merely replicating a recipe—you try to make
your
own cake, using ideas from others to improve it. We humans are not photocopiers. So contagious mental categories must be those in which we are prepared to believe, perhaps even programmed to believe. To be contagious, a mental category must agree with our nature.


================================================================================
CHAPTER/SECTION 235 (Item 240)
================================================================================

NOBODY IS SAFE IN EXTREMISTAN
There is something extremely naïve about all these models of the dynamics of concentration I’ve presented so far, particularly the socioeconomic ones. For instance, although Merton’s idea includes luck, it misses an additional layer of randomness. In all these models the winner stays a winner.
Now, a loser might always remain a loser, but a winner could be unseated by someone new popping up out of nowhere. Nobody is safe.
Preferential-attachment theories are intuitively appealing, but they do not account for the possibility of being supplanted by newcomers—what every schoolchild knows as the decline of civilizations. Consider the logic of cities: How did Rome, with a population of 1.2 million in the first century
A.D
., end up with a population of twelve thousand in the third? How did Baltimore, once a principal American city, become a relic? And how did Philadelphia come to be overshadowed by New York?
A Brooklyn Frenchman
When I started trading foreign exchange, I befriended a fellow named Vincent who exactly resembled a Brooklyn trader, down to the mannerisms of Fat Tony, except that he spoke the French version of Brooklynese. Vincent taught me a few tricks. Among his sayings were “Trading may have princes, but nobody stays a king” and “The people you meet on the way up, you will meet again on the way down.”
There were theories when I was a child about class warfare and struggles by innocent individuals against powerful monster-corporations capable of swallowing the world. Anyone with intellectual hunger was fed these theories, which were inherited from the Marxist belief that the tools of exploitation were self-feeding, that the powerful would grow more and more powerful, furthering the unfairness of the system. But one had only to look around to see that these large corporate monsters dropped like flies. Take a cross section of the dominant corporations at any particular time; many of them will be out of business a few decades later, while firms nobody ever heard of will have popped onto the scene from some garage in California or from some college dorm.
Consider the following sobering statistic. Of the five hundred largest U.S. companies in 1957, only seventy-four were still part of that select group, the Standard and Poor’s 500, forty years later. Only a few had disappeared in mergers; the rest either shrank or went bust.
Interestingly, almost all these large corporations were located in the most capitalist country on earth, the United States. The more socialist a country’s orientation, the easier it was for the large corporate monsters to stick around. Why did capitalism (and not socialism) destroy these ogres?
In other words, if you leave companies alone, they tend to get eaten up. Those in favor of economic freedom claim that beastly and greedy corporations
pose no threat because competition keeps them in check. What I saw at the Wharton School convinced me that the real reason includes a large share of something else: chance.
But when people discuss chance (which they rarely do), they usually only look at their own luck. The luck
of others
counts greatly. Another corporation may luck out thanks to a blockbuster product and displace the current winners. Capitalism is, among other things, the revitalization of the world thanks to the opportunity to be lucky. Luck is the grand equalizer, because almost everyone can benefit from it. The socialist governments protected their monsters and, by doing so, killed potential newcomers in the womb.
Everything is transitory. Luck both made and unmade Carthage; it both made and unmade Rome.
I said earlier that randomness is bad, but it is not always so. Luck is far more egalitarian than even intelligence. If people were rewarded strictly according to their abilities, things would still be unfair—people don’t choose their abilities. Randomness has the beneficial effect of reshuffling society’s cards, knocking down the big guy.
In the arts, fads do the same job. A newcomer may benefit from a fad, as followers multiply thanks to a preferential attachment–style epidemic. Then, guess what? He too becomes history. It is quite interesting to look at the acclaimed authors of a particular era and see how many have dropped out of consciousness. It even happens in countries such as France where the government supports established reputations, just as it supports ailing large companies.
When I visit Beirut, I often spot in relatives’ homes the remnants of a series of distinctively white-leather-bound “Nobel books.” Some hyperactive salesman once managed to populate private libraries with these beautifully made volumes; many people buy books for decorative purposes and want a simple selection criterion. The criterion this series offered was one book by a Nobel winner in literature every year—a simple way to build the ultimate library. The series was supposed to be updated every year, but I presume the company went out of business in the eighties. I feel a pang every time I look at these volumes: Do you hear much today about Sully Prudhomme (the first recipient), Pearl Buck (an American woman), Romain Rolland, Anatole France (the last two were the most famous French authors of their generations), St. John Perse, Roger Martin du Gard, or Frédéric Mistral?
The Long Tail
I have said that nobody is safe in Extremistan. This has a converse: nobody is threatened with complete extinction either. Our current environment allows the little guy to bide his time in the antechamber of success—as long as there is life, there is hope.
This idea was recently revived by Chris Anderson, one of a very few who get the point that the dynamics of fractal concentration has another layer of randomness. He packaged it with his idea of the “long tail,” about which in a moment. Anderson is lucky not to be a professional statistician (people who have had the misfortune of going through conventional statistical training think we live in Mediocristan). He was able to take a fresh look at the dynamics of the world.
True, the Web produces acute concentration. A large number of users visit just a few sites, such as Google, which, at the time of this writing, has total market dominance. At no time in history has a company grown so dominant so quickly—Google can service people from Nicaragua to southwestern Mongolia to the American West Coast, without having to worry about phone operators, shipping, delivery, and manufacturing. This is the ultimate winner-take-all case study.
People forget, though, that before Google, Alta Vista dominated the search-engine market. I am prepared to revise the Google metaphor by replacing it with a new name for future editions of this book.
What Anderson saw is that the Web causes something
in addition
to concentration. The Web enables the formation of a reservoir of proto-Googles waiting in the background. It also promotes the
inverse Google
, that is, it allows people with a technical specialty to find a small, stable audience.
Recall the role of the Web in Yevgenia Krasnova’s success. Thanks to the Internet, she was able to bypass conventional publishers. Her publisher with the pink glasses would not even have been in business had it not been for the Web. Let’s assume that Amazon.com does not exist, and that you have written a sophisticated book. Odds are that a very small bookstore that carries only 5,000 volumes will not be interested in letting your “beautifully crafted prose” occupy premium shelf space. And the megabookstore, such as the average American Barnes & Noble, might stock 130,000 volumes, which is still not sufficient to accommodate marginal titles. So your work is stillborn.
Not so with Web vendors. A Web bookstore can carry a near-infinite
number of books since it need not have them physically in inventory. Actually, nobody needs to have them physically in inventory since they can remain in digital form until they are needed in print, an emerging business called print-on-demand.
So as the author of this little book, you can sit there, bide your time, be available in search engines, and perhaps benefit from an occasional epidemic. In fact, the quality of readership has improved markedly over the past few years thanks to the availability of these more sophisticated books. This is a fertile environment for diversity.
*
Plenty of people have called me to discuss the idea of the long tail, which seems to be the exact opposite of the concentration implied by scalability. The long tail implies that the small guys, collectively, should control a large segment of culture and commerce, thanks to the niches and subspecialties that can now survive thanks to the Internet. But, strangely, it can also imply a large measure of inequality: a large base of small guys and a very small number of supergiants, together representing a share of the world’s culture—with some of the small guys, on occasion, rising to knock out the winners. (This is the “double tail”: a large tail of the small guys, a small tail of the big guys.)
The role of the long tail is fundamental in changing the dynamics of success, destabilizing the well-seated winner, and bringing about another winner. In a snapshot this will always be Extremistan, always ruled by the concentration of type-2 randomness; but it will be an ever-changing Extremistan.
The long tail’s contribution is not yet numerical; it is still confined to the Web and its small-scale online commerce. But consider how the long tail could affect the future of culture, information, and political life. It could free us from the dominant political parties, from the academic system, from the clusters of the press—anything that is currently in the hands of ossified, conceited, and self-serving authority. The long tail will help foster cognitive diversity. One highlight of the year 2006 was to find in my
mailbox a draft manuscript of a book called
Cognitive Diversity: How Our Individual Differences Produce Collective Benefits
, by Scott Page. Page examines the effects of cognitive diversity on problem solving and shows how variability in views and methods acts like an engine for tinkering. It works like evolution. By subverting the big structures we also get rid of the Platonified
one way
of doing things—in the end, the bottom-up theory-free empiricist should prevail.
In sum, the long tail is a by-product of Extremistan that makes it somewhat less unfair: the world is made no less unfair for the little guy, but it now becomes extremely unfair for the big man. Nobody is truly established. The little guy is very subversive.
Naïve Globalization
We are gliding into disorder, but not necessarily bad disorder. This implies that we will see more periods of calm and stability, with most problems concentrated into a small number of Black Swans.
Consider the nature of past wars. The twentieth century was not the deadliest (in percentage of the total population), but it brought something new: the beginning of the Extremistan warfare—a small probability of a conflict degenerating into total decimation of the human race, a conflict from which nobody is safe anywhere.
A similar effect is taking place in economic life. I spoke about globalization in
Chapter 3
; it is here, but it is not all for the good: it creates interlocking fragility, while reducing volatility and giving the appearance of stability. In other words it creates devastating Black Swans. We have never lived before under the threat of a global collapse. Financial institutions have been merging into a smaller number of very large banks. Almost all banks are now interrelated. So the financial ecology is swelling into gigantic, incestuous, bureaucratic banks (often Gaussianized in their risk measurement)—when one falls, they all fall.
*
The increased concentration among banks seems to have the effect of making financial crisis less likely, but when they happen they are more global in scale and hit us very hard. We have moved from a diversified ecology of small banks, with varied lending policies, to a more homogeneous framework of firms that all resemble one another. True, we now have fewer failures, but when they occur … I shiver at the thought. I rephrase here: we will have fewer but more severe crises. The rarer the event, the less we know about its odds. It means that we know less and less about the possibility of a crisis.
And we have some idea how such a crisis would happen. A network is an assemblage of elements called nodes that are somehow connected to one another by a link; the world’s airports constitute a network, as does the World Wide Web, as do social connections and electricity grids. There is a branch of research called “network theory” that studies the organization of such networks and the links between their nodes, with such researchers as Duncan Watts, Steven Strogatz, Albert-Laszlo Barabasi, and many more. They all understand Extremistan mathematics and the inadequacy of the Gaussian bell curve. They have uncovered the following property of networks: there is a concentration among a few nodes that serve as central connections. Networks have a natural tendency to organize themselves around an extremely concentrated architecture: a few nodes are extremely connected; others barely so. The distribution of these connections has a scalable structure of the kind we will discuss in
Chapters 15
and
16
. Concentration of this kind is not limited to the Internet; it appears in social life (a small number of people are connected to others), in electricity grids, in communications networks. This seems to make networks more robust: random insults to most parts of the network will not be consequential since they are likely to hit a poorly connected spot. But it also makes networks more vulnerable to Black Swans. Just consider what would happen if there is a problem with a major node. The electricity blackout experienced in the northeastern United States during August 2003, with its consequential mayhem, is a perfect example of what could take place if one of the big banks went under today.
But banks are in a far worse situation than the Internet. The financial industry has no significant long tail! We would be far better off if there were a different ecology, in which financial institutions went bust on occasion and were rapidly replaced by new ones, thus mirroring the diversity
of Internet businesses and the resilience of the Internet economy. Or if there were a long tail of government officials and civil servants coming to reinvigorate bureaucracies.


================================================================================
CHAPTER/SECTION 236 (Item 241)
================================================================================

REVERSALS AWAY FROM EXTREMISTAN
There is, inevitably, a mounting tension between our society, full of concentration, and our classical idea of aurea mediocritas, the golden mean, so it is conceivable that efforts may be made to reverse such concentration. We live in a society of one person, one vote, where progressive taxes have been enacted precisely to weaken the winners. Indeed, the rules of society can be easily rewritten by those at the bottom of the pyramid to prevent concentration from hurting them. But it does not require voting to do so—religion could soften the problem. Consider that before Christianity, in many societies the powerful had many wives, thus preventing those at the bottom from accessing wombs, a condition that is not too different from the reproductive exclusivity of alpha males in many species. But Christianity reversed this, thanks to the one man–one woman rule. Later, Islam came to limit the number of wives to four. Judaism, which had been polygenic, became monogamous in the Middle Ages. One can say that such a strategy has been successful—the institution of tightly monogamous marriage (with no official concubine, as in the Greco-Roman days), even when practiced the “French way,” provides social stability since there is no pool of angry, sexually deprived men at the bottom fomenting a revolution just so they can have the chance to mate.
But I find the emphasis on economic inequality, at the expense of other types of inequality, extremely bothersome. Fairness is not exclusively an economic matter; it becomes less and less so when we are satisfying our basic material needs. It is pecking order that matters! The superstars will always be there. The Soviets may have flattened the economic structure, but they encouraged their own brand of übermensch. What is poorly understood, or denied (owing to its unsettling implications), is the absence of a role for the
average
in intellectual production. The disproportionate share of the very few in intellectual influence is even more unsettling than the unequal distribution of wealth—unsettling because, unlike the income gap, no social policy can eliminate it. Communism could conceal or compress income discrepancies, but it could not eliminate the superstar system in intellectual life.
It has even been shown, by Michael Marmot of the Whitehall Studies,
that those at the top of the pecking order live longer, even when adjusting for disease. Marmot’s impressive project shows how social rank alone can affect longevity. It was calculated that actors who win an Oscar tend to live on average about five years longer than their peers who don’t. People live longer in societies that have flatter social gradients. Winners kill their peers as those in a steep social gradient live shorter lives, regardless of their economic condition.
I do not know how to remedy this (except through religious beliefs). Is insurance against your peers’ demoralizing success possible? Should the Nobel Prize be banned? Granted the Nobel medal in economics has not been good for society or knowledge, but even those rewarded for
real
contributions in medicine and physics too rapidly displace others from our consciousness, and steal longevity away from them. Extremistan is here to stay, so we have to live with it, and find the tricks that make it more palatable.
*
These scalable laws were already discussed in the scriptures: “For onto everyone that hath shall be given, and he shall have abundance; but from him that hath not shall be taken away even that which he hath.” Matthew (Matthew 25:29, King James Version).
*
Much of the perception of the importance of precocity in the career of researchers can be owed to the misunderstanding of the perverse role of this effect, especially when reinforced by bias. Enough counterexamples, even in fields like mathematics meant to be purely a “young man’s game,” illustrate the age fallacy: simply, it is necessary to be successful early, and even very early at that.
*
The Web’s bottom-up feature is also making book reviewers more accountable. While writers were helpless and vulnerable to the arbitrariness of book reviews, which can distort their messages and, thanks to the confirmation bias, expose small irrelevant weak points in their text, they now have a much stronger hand. In place of the moaning letter to the editor, they can simply post their review of a review on the Web. If attacked ad hominem, they can reply ad hominem and go directly after the credibility of the reviewer, making sure that their statement shows rapidly in an Internet search or on Wikipedia, the bottom-up encyclopedia.
*
As if we did not have enough problems, banks are now more vulnerable to the Black Swan and the ludic fallacy than ever before with “scientists” among their staff taking care of exposures. The giant firm J. P. Morgan put the entire world at risk by introducing in the nineties RiskMetrics, a phony method aiming at managing people’s risks, causing the generalized use of the ludic fallacy, and bringing Dr. Johns into power in place of the skeptical Fat Tonys. (A related method called “Value-at-Risk,” which relies on the quantitative measurement of risk, has been spreading.) Likewise, the government-sponsored institution Fanny Mae, when I look at their risks, seems to be sitting on a barrel of dynamite, vulnerable to the slightest hiccup. But not to worry: their large staff of scientists deemed these events “unlikely.”


================================================================================
CHAPTER/SECTION 237 (Item 242)
================================================================================

Chapter Fifteen
THE BELL CURVE, THAT GREAT INTELLECTUAL FRAUD
*
Not worth a pastis—Quételet’s error—The average man is a monster—Let’s deify it—Yes or no—Not so literary an experiment
Forget everything you heard in college statistics or probability theory. If you never took such a class, even better. Let us start from the very beginning.


================================================================================
CHAPTER/SECTION 238 (Item 243)
================================================================================

THE GAUSSIAN AND THE MANDELBROTIAN
I was transiting through the Frankfurt airport in December 2001, on my way from Oslo to Zurich.
I had time to kill at the airport and it was a great opportunity for me to buy dark European chocolate, especially since I have managed to successfully convince myself that airport calories don’t count. The cashier handed me, among other things, a ten deutschmark bill, an (illegal) scan of which can be seen on the next page. The deutschmark banknotes were going to be put out of circulation in a matter of days, since Europe was switching to the euro. I kept it as a valedictory. Before the arrival of the euro, Europe had plenty of national currencies, which was good for printers, money changers, and of course currency traders like this (more or less) humble author. As I was eating my dark European chocolate and wistfully looking at the bill, I almost choked. I suddenly noticed, for the first time, that there was something curious about it. The bill bore the portrait of Carl Friedrich Gauss and a picture of his Gaussian bell curve.
The last ten deutschmark bill, representing Gauss and, to his right, the bell curve of Mediocristan.
The striking irony here is that the last possible object that can be linked to the German currency is precisely such a curve: the reichsmark (as the currency was previously called) went from four per dollar to
four trillion
per dollar in the space of a few years during the 1920s, an outcome that tells you that the bell curve is meaningless as a description of the randomness in currency fluctuations. All you need to reject the bell curve is for such a movement to occur once, and only once—just consider the consequences. Yet there was the bell curve, and next to it Herr Professor Doktor Gauss, unprepossessing, a little stern, certainly not someone I’d want to spend time with lounging on a terrace, drinking pastis, and holding a conversation without a subject.
Shockingly, the bell curve is used as a risk-measurement tool by those regulators and central bankers who wear dark suits and talk in a boring way about currencies.
The Increase in the Decrease
The main point of the Gaussian, as I’ve said, is that most observations hover around the mediocre, the average; the odds of a deviation decline faster and faster (exponentially) as you move away from the average. If you must have only one single piece of information, this is the one: the dramatic increase in the speed of decline in the odds as you move away from the center, or the average. Look at the list below for an illustration of this. I am taking an example of a Gaussian quantity, such as height, and simplifying it a bit to make it more illustrative. Assume that the average height (men and women) is 1.67 meters, or 5 feet 7 inches. Consider what I call a
unit of deviation
here as 10 centimeters. Let us look at increments above 1.67 meters and consider the odds of someone being that tall.
*
10 centimeters taller than the average (i.e., taller than 1.77 m, or 5 feet 10): 1 in 6.3
20 centimeters taller than the average (i.e., taller than 1.87 m, or 6 feet 2): 1 in 44
30 centimeters taller than the average (i.e., taller than 1.97 m, or 6 feet 6): 1 in 740
40 centimeters taller than the average (i.e., taller than 2.07 m, or 6 feet 9): 1 in 32,000
50 centimeters taller than the average (i.e., taller than 2.17 m, or 7 feet 1): 1 in 3,500,000
60 centimeters taller than the average (i.e., taller than 2.27 m, or 7 feet 5): 1 in 1,000,000,000
70 centimeters taller than the average (i.e., taller than 2.37 m, or 7 feet 9): 1 in 780,000,000,000
80 centimeters taller than the average (i.e., taller than 2.47 m, or 8 feet 1): 1 in 1,600,000,000,000,000
90 centimeters taller than the average (i.e., taller than 2.57 m, or 8 feet 5): 1 in 8,900,000,000,000,000,000
100 centimeters taller than the average (i.e., taller than 2.67 m, or 8 feet 9): 1 in 130,000,000,000,000,000,000,000
… and,
110 centimeters taller than the average (i.e., taller than 2.77 m, or 9 feet 1): 1 in 36,000,000,000,000,000,000,000,000,000,000,000, 000,000,000,000,000,000,000,000,000,000,000,000,000,000,000, 000,000,000.
Note that soon after, I believe, 22 deviations, or 220 centimeters taller than the average, the odds reach a googol, which is 1 with 100 zeroes behind it.
The point of this list is to illustrate the acceleration. Look at the difference in odds between 60 and 70 centimeters taller than average: for a mere increase of four inches, we go from one in 1 billion people to one in 780 billion! As for the jump between 70 and 80 centimeters: an additional 4 inches above the average, we go from one in 780 billion to one in 1.6 million billion!
*
This precipitous decline in the odds of encountering something is what allows you to ignore outliers. Only one curve can deliver this decline, and it is the bell curve (and its nonscalable siblings).
The Mandelbrotian
By comparison, look at the odds of being rich in Europe. Assume that wealth there is scalable, i.e., Mandelbrotian. (This is not an accurate description of wealth in Europe; it is simplified to emphasize the logic of scalable distribution.)
†
Scalable Wealth Distribution
People with a net worth higher than €1 million: 1 in 62.5
Higher than €2 million: 1 in 250
Higher than €4 million: 1 in 1,000
Higher than €8 million: 1 in 4,000
Higher than €16 million: 1 in 16,000
Higher than €32 million: 1 in 64,000
Higher than €320 million: 1 in 6,400,000
The speed of the decrease here remains constant (or does not decline)!
When you double the amount of money you cut the incidence by a factor of four, no matter the level, whether you are at €8 million or €16 million. This, in a nutshell, illustrates the difference between Mediocristan and Extremistan.
Recall the comparison between the scalable and the nonscalable in
Chapter 3
. Scalability means that there is no headwind to slow you down.
Of course, Mandelbrotian Extremistan can take many shapes. Consider wealth in an extremely concentrated version of Extremistan; there, if you double the wealth, you halve the incidence. The result is quantitatively different from the above example, but it obeys the same logic.
Fractal Wealth Distribution with Large Inequalities
People with a net worth higher than €1 million: 1 in 63
Higher than €2 million: 1 in 125
Higher than €4 million: 1 in 250
Higher than €8 million: 1 in 500
Higher than €16 million: 1 in 1,000
Higher than €32 million: 1 in 2,000
Higher than €320 million: 1 in 20,000
Higher than €640 million: 1 in 40,000
If wealth were Gaussian, we would observe the following divergence away from €1 million.
Wealth Distribution Assuming a Gaussian Law
People with a net worth higher than €1 million: 1 in 63
Higher than €2 million: 1 in 127,000
Higher than €3 million: 1 in 14,000,000,000
Higher than €4 million: 1 in 886,000,000,000,000,000
Higher than €8 million: 1 in 16,000,000,000,000,000,000,000,000,000,000,000
Higher than €16 million: 1 in …
none of my computers is capable of handling the computation
.
What I want to show with these lists is the qualitative difference in the paradigms. As I have said, the second paradigm is scalable; it has no headwind. Note that another term for the scalable is power laws.
Just knowing that we are in a power-law environment does not tell us much. Why? Because we have to measure the coefficients in real life, which is much harder than with a Gaussian framework. Only the Gaussian yields its properties rather rapidly. The method I propose is a general way of viewing the world rather than a precise solution.
What to Remember
Remember this: the Gaussian–bell curve variations face a headwind that makes probabilities drop at a faster and faster rate as you move away from the mean, while “scalables,” or Mandelbrotian variations, do not have such a restriction. That’s pretty much most of what you need to know.
*
Inequality
Let us look more closely at the nature of inequality. In the Gaussian framework, inequality decreases as the deviations get larger—caused by the increase in the rate of decrease. Not so with the scalable: inequality stays the same throughout. The inequality among the superrich is the same as the inequality among the simply rich—it does not slow down.
†
Consider this effect. Take a random sample of any two people from the U.S. population who jointly earn $1 million per annum. What is the most likely breakdown of their respective incomes? In Mediocristan, the most likely combination is half a million each. In Extremistan, it would be $50,000 and $950,000.
The situation is even more lopsided with book sales. If I told you that two authors sold a total of a million copies of their books, the most likely combination is 993,000 copies sold for one and 7,000 for the other. This is far more likely than that the books each sold 500,000 copies.
For any large total, the breakdown will be more and more asymmetric
.
Why is this so? The height problem provides a comparison. If I told you that the total height of two people is fourteen feet, you would identify the most likely breakdown as seven feet each, not two feet and twelve feet; not even eight feet and six feet! Persons taller than eight feet are so rare that such a combination would be impossible.
Extremistan and the 80/20 Rule
Have you ever heard of the 80/20 rule? It is the common signature of a power law—actually it is how it all started, when Vilfredo Pareto made the observation that 80 percent of the land in Italy was owned by 20 percent of the people. Some use the rule to imply that 80 percent of the work is done by 20 percent of the people. Or that 80 percent worth of effort contributes to only 20 percent of results, and vice versa.
As far as axioms go, this one wasn’t phrased to impress you the most: it could easily be called the 50/01 rule, that is, 50 percent of the work comes from 1 percent of the workers. This formulation makes the world look even more unfair, yet the two formulae are exactly the same. How? Well, if there is inequality, then those who constitute the 20 percent in the 80/20 rule also contribute unequally—only a few of them deliver the lion’s share of the results. This trickles down to about one in a hundred contributing a little more than half the total.
The 80/20 rule is only metaphorical; it is not a rule, even less a rigid law. In the U.S. book business, the proportions are more like 97/20 (i.e., 97 percent of book sales are made by 20 percent of the authors); it’s even worse if you focus on literary nonfiction (twenty books of close to eight thousand represent half the sales).
Note here that it is not all uncertainty. In some situations you may have a concentration, of the 80/20 type, with very predictable and tractable
properties, which enables clear decision making, because you can identify
beforehand
where the meaningful 20 percent are. These situations are very easy to control. For instance, Malcolm Gladwell wrote in an article in
The New Yorker
that most abuse of prisoners is attributable to a very small number of vicious guards. Filter those guards out and your rate of prisoner abuse drops dramatically. (In publishing, on the other hand, you do not know beforehand which book will bring home the bacon. The same with wars, as you do not know beforehand which conflict will kill a portion of the planet’s residents.)
Grass and Trees
I’ll summarize here and repeat the arguments previously made throughout the book. Measures of uncertainty that are based on the bell curve simply disregard the possibility, and the impact, of sharp jumps or discontinuities and are, therefore, inapplicable in Extremistan. Using them is like focusing on the grass and missing out on the (gigantic) trees. Although unpredictable large deviations are rare, they cannot be dismissed as outliers because, cumulatively, their impact is so dramatic.
The traditional Gaussian way of looking at the world begins by focusing on the ordinary, and then deals with exceptions or so-called outliers as ancillaries. But there is a second way, which takes the exceptional as a starting point and treats the ordinary as subordinate.
I have emphasized that there are two varieties of randomness, qualitatively different, like air and water. One does not care about extremes; the other is severely impacted by them. One does not generate Black Swans; the other does. We cannot use the same techniques to discuss a gas as we would use with a liquid. And if we could, we wouldn’t call the approach “an approximation.” A gas does not “approximate” a liquid.
We can make good use of the Gaussian approach in variables for which there is a rational reason for the largest not to be too far away from the average. If there is gravity pulling numbers down, or if there are physical limitations preventing very large observations, we end up in Mediocristan. If there are strong forces of equilibrium bringing things back rather rapidly after conditions diverge from equilibrium, then again you can use the Gaussian approach. Otherwise, fuhgedaboudit. This is why much of economics is based on the notion of equilibrium: among other benefits, it allows you to treat economic phenomena as Gaussian.
Note that I am not telling you that the Mediocristan type of randomness
does not allow for
some
extremes. But it tells you that they are so rare that they do not play a significant role in the total. The effect of such extremes is pitifully small and decreases as your population gets larger.
To be a little bit more technical here, if you have an assortment of giants and dwarfs, that is, observations several orders of magnitude apart, you could still be in Mediocristan. How? Assume you have a sample of one thousand people, with a large spectrum running from the dwarf to the giant. You are likely to see many giants in your sample, not a rare occasional one. Your average will not be impacted by the occasional additional giant because some of these giants are expected to be part of your sample, and your average is likely to be high. In other words, the largest observation cannot be too far away from the average. The average will always contain both kinds, giants and dwarves, so that neither should be too rare—unless you get a megagiant or a microdwarf on very rare occasion. This would be Mediocristan with a large unit of deviation.
Note once again the following principle: the rarer the event, the higher the error in our estimation of its probability—even when using the Gaussian.
Let me show you how the Gaussian bell curve sucks randomness out of life—which is why it is popular. We like it because it allows certainties! How? Through averaging, as I will discuss next.
How Coffee Drinking Can Be Safe
Recall from the Mediocristan discussion in
Chapter 3
that no single observation will impact your total. This property will be more and more significant as your population increases in size. The averages will become more and more stable, to the point where all samples will look alike.
I’ve had plenty of cups of coffee in my life (it’s my principal addiction). I have never seen a cup jump two feet from my desk, nor has coffee spilled spontaneously on this manuscript without intervention (even in Russia). Indeed, it will take more than a mild coffee addiction to witness such an event; it would require more lifetimes than is perhaps conceivable—the odds are so small, one in so many zeroes, that it would be impossible for me to write them down in my free time.
Yet physical reality makes it possible for my coffee cup to jump—very unlikely, but possible. Particles jump around all the time. How come the coffee cup, itself composed of jumping particles, does not? The reason is, simply, that for the cup to jump would require that all of the particles jump in the
same
direction, and do so in lockstep several times in a row (with a compensating move of the table in the opposite direction). All several trillion particles in my coffee cup are not going to jump in the same direction; this is not going to happen in the lifetime of this universe. So I can safely put the coffee cup on the edge of my writing table and worry about more serious sources of uncertainty.
FIGURE 7: How the Law of Large Numbers Works
In Mediocristan, as your sample size increases, the observed average will present itself with less and less dispersion—as you can see, the distribution will be narrower and narrower. This, in a nutshell, is how everything in statistical theory works (or is supposed to work). Uncertainty in Mediocristan vanishes under averaging. This illustrates the hackneyed “law of large numbers.”
The safety of my coffee cup illustrates how the randomness of the Gaussian is tamable by averaging. If my cup were one large particle, or acted as one, then its jumping would be a problem. But my cup is the sum of trillions of very small particles.
Casino operators understand this well, which is why they never (if they do things right) lose money. They simply do not let one gambler make a massive bet, instead preferring to have plenty of gamblers make series of bets of limited size. Gamblers may bet a total of $20 million, but you needn’t worry about the casino’s health: the bets run, say, $20 on average; the casino caps the bets at a maximum that will allow the casino owners to sleep at night. So the variations in the casino’s returns are going to be ridiculously small, no matter the total gambling activity. You will not see anyone leaving the casino with $1 billion—in the lifetime of this universe.
The above is an application of the supreme law of Mediocristan: when you have plenty of gamblers, no single gambler will impact the total more than minutely.
The consequence of this is that variations around the average of the Gaussian, also called “errors,” are not truly worrisome. They are small and they wash out. They are domesticated fluctuations around the mean.
Love of Certainties
If you ever took a (dull) statistics class in college, did not understand much of what the professor was excited about, and wondered what “standard deviation” meant, there is nothing to worry about. The notion of standard deviation is meaningless outside of Mediocristan. Clearly it would have been more beneficial, and certainly more entertaining, to have taken classes in the neurobiology of aesthetics or postcolonial African dance, and this is easy to see empirically.
Standard deviations do not exist outside the Gaussian, or if they do exist they do not matter and do not explain much. But it gets worse. The Gaussian family (which includes various friends and relatives, such as the Poisson law) are the only class of distributions that the standard deviation (and the average) is sufficient to describe. You need nothing else. The bell curve satisfies the reductionism of the deluded.
There are other notions that have little or no significance outside of the Gaussian:
correlation
and, worse,
regression
. Yet they are deeply ingrained in our methods; it is hard to have a business conversation without hearing the word
correlation
.
To see how meaningless correlation can be outside of Mediocristan, take a historical series involving two variables that are patently from Extremistan, such as the bond and the stock markets, or two securities prices, or two variables like, say, changes in book sales of children’s books in the United States, and fertilizer production in China; or real-estate prices in New York City and returns of the Mongolian stock market. Measure correlation between the pairs of variables in different subperiods, say, for 1994, 1995, 1996, etc. The correlation measure will be likely to exhibit severe instability; it will depend on the period for which it was computed. Yet people talk about correlation as if it were something real, making it tangible, investing it with a physical property, reifying it.
The same illusion of concreteness affects what we call “standard” deviations. Take any series of historical prices or values. Break it up into
subsegments and measure its “standard” deviation. Surprised? Every sample will yield a different “standard” deviation. Then why do people talk about standard deviations? Go figure.
Note here that, as with the narrative fallacy, when you look at past data and compute one single correlation or standard deviation, you do not notice such instability.
How to Cause Catastrophes
If you use the term
statistically significant
, beware of the illusions of certainties. Odds are that someone has looked at his observation errors and assumed that they were Gaussian, which necessitates a Gaussian context, namely, Mediocristan, for it to be acceptable.
To show how endemic the problem of misusing the Gaussian is, and how dangerous it can be, consider a (dull) book called
Catastrophe
by Judge Richard Posner, a prolific writer. Posner bemoans civil servants’ misunderstandings of randomness and recommends, among other things, that government policy makers learn statistics … from economists. Judge Posner appears to be trying to foment catastrophes. Yet, in spite of being one of those people who should spend more time reading and less time writing, he can be an insightful, deep, and original thinker; like many people, he just isn’t aware of the distinction between Mediocristan and Extremistan, and he believes that statistics is a “science,” never a fraud. If you run into him, please make him aware of these things.


================================================================================
CHAPTER/SECTION 239 (Item 244)
================================================================================

QUÉTELET’S AVERAGE MONSTER
This monstrosity called the Gaussian bell curve is not Gauss’s doing. Although he worked on it, he was a mathematician dealing with a theoretical point, not making claims about the structure of reality like statistical-minded scientists. G. H. Hardy wrote in “A Mathematician’s Apology”:
The “real” mathematics of the “real” mathematicians, the mathematics of Fermat and Euler and Gauss and Abel and Riemann, is almost wholly “useless” (and this is as true of “applied” as of “pure” mathematics).
As I mentioned earlier, the bell curve was mainly the concoction of a gambler, Abraham de Moivre (1667–1754), a French Calvinist refugee
who spent much of his life in London, though speaking heavily accented English. But it is Quételet, not Gauss, who counts as one of the most destructive fellows in the history of thought, as we will see next.
Adolphe Quételet (1796–1874) came up with the notion of a physically average human,
l’homme moyen
. There was nothing
moyen
about Quételet, “a man of great creative passions, a creative man full of energy.” He wrote poetry and even coauthored an opera. The basic problem with Quételet was that he was a mathematician, not an empirical scientist, but he did not know it. He found harmony in the bell curve.
The problem exists at two levels.
Primo
, Quételet had a normative idea, to make the world fit his average, in the sense that the average, to him, was the “normal.” It would be wonderful to be able to ignore the contribution of the unusual, the “nonnormal,” the Black Swan, to the total. But let us leave that dream for utopia.
Secondo
, there was a serious associated empirical problem. Quételet saw bell curves everywhere. He was blinded by bell curves and, I have learned, again, once you get a bell curve in your head it is hard to get it out. Later, Frank Ysidro Edgeworth would refer to Quételesmus as the grave mistake of seeing bell curves everywhere.
Golden Mediocrity
Quételet provided a much needed product for the ideological appetites of his day. As he lived between 1796 and 1874, so consider the roster of his contemporaries: Saint-Simon (1760–1825), Pierre-Joseph Proudhon (1809–1865), and Karl Marx (1818–1883), each the source of a different version of socialism. Everyone in this post-Enlightenment moment was longing for the aurea mediocritas, the golden mean: in wealth, height, weight, and so on. This longing contains some element of wishful thinking mixed with a great deal of harmony and … Platonicity.
I always remember my father’s injunction that
in medio stat virtus
, “virtue lies in moderation.” Well, for a long time that was the ideal; mediocrity, in that sense, was even deemed golden. All-embracing mediocrity.
But Quételet took the idea to a different level. Collecting statistics, he started creating standards of “means.” Chest size, height, the weight of babies at birth, very little escaped his
standards
. Deviations from the norm, he found, became exponentially more rare as the magnitude of the deviation increased. Then, having conceived of this idea of the physical characteristics of
l’homme moyen
, Monsieur Quételet switched to
social matters.
L’homme moyen
had his habits, his consumption, his methods.
Through his construct of
l’homme moyen physique
and
l’homme moyen moral
, the physically and morally average man, Quételet created a range of deviance from the average that positions all people either to the left or right of center and, truly, punishes those who find themselves occupying the extreme left or right of the statistical bell curve. They became
abnormal
. How this inspired Marx, who cites Quételet regarding this concept of an average or normal man, is obvious: “Societal deviations in terms of the distribution of wealth for example, must be minimized,” he wrote in
Das Kapital
.
One has to give some credit to the scientific establishment of Quételet’s day. They did not buy his arguments at once. The philosopher/mathematician/economist Augustin Cournot, for starters, did not believe that one could establish a standard human on purely quantitative grounds. Such a standard would be dependent on the attribute under consideration. A measurement in one province may differ from that in another province. Which one should be the standard?
L’homme moyen
would be a monster, said Cournot. I will explain his point as follows.
Assuming there is something desirable in being an average man, he must have an unspecified specialty in which he would be more gifted than other people—he cannot be average in everything. A pianist would be better on average at playing the piano, but worse than the norm at, say, horseback riding. A draftsman would have better drafting skills, and so on.
The notion of a man deemed average is different from that of a man who is average in everything he does
. In fact, an exactly average human would have to be half male and half female. Quételet completely missed that point.
God’s Error
A much more worrisome aspect of the discussion is that in Quételet’s day, the name of the Gaussian distribution was
la loi des erreurs
, the law of errors, since one of its earliest applications was the distribution of errors in astronomic measurements. Are you as worried as I am? Divergence from the mean (here the median as well) was treated precisely as an error! No wonder Marx fell for Quételet’s ideas.
This concept took off very quickly. The
ought
was confused with the
is
, and this with the imprimatur of science. The notion of the average man is steeped in the culture attending the birth of the European middle class, the nascent post-Napoleonic shopkeeper’s culture, chary of excessive wealth and intellectual brilliance. In fact, the dream of a society with compressed outcomes is assumed to correspond to the aspirations of a rational human being facing a genetic lottery. If you had to pick a society to be born into for your next life, but could not know which outcome awaited you, it is assumed you would probably take no gamble; you would like to belong to a society without divergent outcomes.
One entertaining effect of the glorification of mediocrity was the creation of a political party in France called Poujadism, composed initially of a grocery-store movement. It was the warm huddling together of the semi-favored hoping to see the rest of the universe compress itself into their rank—a case of non-proletarian revolution. It had a grocery-store-owner mentality, down to the employment of the mathematical tools. Did Gauss provide the mathematics for the shopkeepers?
Poincaré to the Rescue
Poincaré himself was quite suspicious of the Gaussian. I suspect that he felt queasy when it and similar approaches to modeling uncertainty were presented to him. Just consider that the Gaussian was initially meant to measure astronomic errors, and that Poincaré’s ideas of modeling celestial mechanics were fraught with a sense of deeper uncertainty.
Poincaré wrote that one of his friends, an unnamed “eminent physicist,” complained to him that physicists tended to use the Gaussian curve because they thought mathematicians believed it a mathematical necessity; mathematicians used it because they believed that physicists found it to be an empirical fact.
Eliminating Unfair Influence
Let me state here that, except for the grocery-store mentality, I truly believe in the value of middleness and mediocrity—what humanist does not want to minimize the discrepancy between humans? Nothing is more repugnant than the inconsiderate ideal of the Übermensch! My true problem is epistemological. Reality is not Mediocristan, so we should learn to live with it.
“The Greeks Would Have Deified It”
The list of people walking around with the bell curve stuck in their heads, thanks to its Platonic purity, is incredibly long.
Sir Francis Galton, Charles Darwin’s first cousin and Erasmus Darwin’s grandson, was perhaps, along with his cousin, one of the last independent gentlemen scientists—a category that also included Lord Cavendish, Lord Kelvin, Ludwig Wittgenstein (in his own way), and to some extent, our überphilosopher Bertrand Russell. Although John Maynard Keynes was not quite in that category, his thinking epitomizes it. Galton lived in the Victorian era when heirs and persons of leisure could, among other choices, such as horseback riding or hunting, become thinkers, scientists, or (for those less gifted) politicians. There is much to be wistful about in that era: the authenticity of someone doing science for science’s sake, without direct career motivations.
Unfortunately, doing science for the love of knowledge does not necessarily mean you will head in the right direction. Upon encountering and absorbing the “normal” distribution, Galton fell in love with it. He was said to have exclaimed that if the Greeks had known about it, they would have deified it. His enthusiasm may have contributed to the prevalence of the use of the Gaussian.
Galton was blessed with no mathematical baggage, but he had a rare obsession with measurement. He did not know about the law of large numbers, but rediscovered it from the data itself. He built the quincunx, a pinball machine that shows the development of the bell curve—on which, more in a few paragraphs. True, Galton applied the bell curve to areas like genetics and heredity, in which its use was justified. But his enthusiasm helped thrust nascent statistical methods into social issues.
“Yes/No” Only Please
Let me discuss here the extent of the damage. If you’re dealing with qualitative inference, such as in psychology or medicine, looking for yes/no answers to which magnitudes don’t apply, then you can assume you’re in Mediocristan without serious problems. The impact of the improbable cannot be too large. You have cancer or you don’t, you are pregnant or you are not, et cetera. Degrees of deadness or pregnancy are not relevant (unless you are dealing with epidemics). But if you are dealing with aggregates, where magnitudes do matter, such as income, your wealth, return
on a portfolio, or book sales, then you will have a problem and get the wrong distribution if you use the Gaussian, as it does not belong there. One single number can disrupt all your averages; one single loss can eradicate a century of profits. You can no longer say “this is an exception.” The statement “Well, I can lose money” is not informational unless you can attach a quantity to that loss. You can lose all your net worth or you can lose a fraction of your daily income; there is a difference.
This explains why empirical psychology and its insights on human nature, which I presented in the earlier parts of this book, are robust to the mistake of using the bell curve; they are also lucky, since most of their variables allow for the application of conventional Gaussian statistics. When measuring how many people in a sample have a bias, or make a mistake, these studies generally elicit a yes/no type of result. No single observation, by itself, can disrupt their overall findings.
I will next proceed to a sui generis presentation of the bell-curve idea from the ground up.


================================================================================
CHAPTER/SECTION 240 (Item 245)
================================================================================

A (LITERARY) THOUGHT EXPERIMENT ON WHERE THE BELL CURVE COMES FROM
Consider a pinball machine like the one shown in
Figure 8
. Launch 32 balls, assuming a well-balanced board so that the ball has equal odds of falling right or left at any juncture when hitting a pin. Your expected outcome is that many balls will land in the center columns and that the number of balls will decrease as you move to the columns away from the center.
Next, consider a gedanken, a thought experiment. A man flips a coin and after each toss he takes a step to the left or a step to the right, depending on whether the coin came up heads or tails. This is called the random walk, but it does not necessarily concern itself with walking. You could identically say that instead of taking a step to the left or to the right, you would win or lose $1 at every turn, and you will keep track of the cumulative amount that you have in your pocket.
Assume that I set you up in a (legal) wager where the odds are neither in your favor nor against you. Flip a coin. Heads, you make $1, tails, you lose $1.
At the first flip, you will either win or lose.
At the second flip, the number of possible outcomes doubles. Case one: win, win. Case two: win, lose. Case three: lose, win. Case four: lose, lose. Each of these cases has equivalent odds, the combination of a single win and a single loss has an incidence twice as high because cases two and three, win-lose and lose-win, amount to the same outcome. And that is the key for the Gaussian. So much in the middle washes out—and we will see that there is a lot in the middle. So, if you are playing for $1 a round, after two rounds you have a 25 percent chance of making or losing $2, but a 50 percent chance of breaking even.
FIGURE 8: THE QUINCUNX (SIMPLIFIED)—A PINBALL MACHINE
Drop balls that, at every pin, randomly fall right or left. Above Is the most probable scenario, which greatly resembles the bell curve (a.k.a. Gaussian disribution).
Courtesy of Alexander Taleb
.
Let us do another round. The third flip again doubles the number of cases, so we face eight possible outcomes. Case 1 (it was win, win in the second flip) branches out into win, win, win and win, win, lose. We add a win or lose to the end of each of the previous results. Case 2 branches out into win, lose, win and win, lose, lose. Case 3 branches out into lose, win, win and lose, win, lose. Case 4 branches out into lose, lose, win and lose, lose, lose.
We now have eight cases, all equally likely. Note that again you can group the middling outcomes where a win cancels out a loss. (In Galton’s quincunx, situations where the ball falls left and then falls right, or vice
versa, dominate so you end up with plenty in the middle.) The net, or cumulative, is the following: 1)
three wins;
2) two wins, one loss, net
one win;
3) two wins, one loss, net
one win;
4) one win, two losses, net
one loss;
5) two wins, one loss, net
one win;
6) two losses, one win, net
one loss;
7) two losses, one win, net
one loss;
and, finally, 8)
three losses
.
Out of the eight cases, the case of three wins occurs once. The case of three losses occurs once. The case of one net loss (one win, two losses) occurs three times. The case of one net win (one loss, two wins) occurs three times.
Play one more round, the fourth. There will be sixteen equally likely outcomes. You will have one case of four wins, one case of four losses, four cases of two wins, four cases of two losses, and six break-even cases.
The quincunx (its name is derived from the Latin for five) in the pinball example shows the fifth round, with thirty-two possibilities, easy to track. Such was the concept behind the quincunx used by Francis Galton. Galton was both insufficiently lazy and a bit too innocent of mathematics; instead of building the contraption, he could have worked with simpler algebra, or perhaps undertaken a thought experiment like this one.
Let’s keep playing. Continue until you have forty flips. You can perform them in minutes, but we will need a calculator to work out the number of outcomes, which are taxing to our simple thought method. You will have about 1,099,511,627,776 possible combinations—more than one thousand billion. Don’t bother doing the calculation manually, it is two multiplied by itself forty times, since each branch doubles at every juncture. (Recall that we added a win and a lose at the end of the alternatives of the third round to go to the fourth round, thus doubling the number of alternatives.) Of these combinations, only one will be up forty, and only one will be down forty. The rest will hover around the middle, here zero.
We can already see that in this type of randomness extremes are exceedingly rare. One in 1,099,511,627,776 is up forty out of forty tosses. If you perform the exercise of forty flips once per hour, the odds of getting 40 ups in a row are so small that it would take quite a bit of forty-flip trials to see it. Assuming you take a few breaks to eat, argue with your friends and roommates, have a beer, and sleep, you can expect to wait close to four million lifetimes to get a 40-up outcome (or a 40-down outcome) just once. And consider the following. Assume you play one additional round, for a total of 41; to get 41 straight heads would take eight million lifetimes! Going from 40 to 41 halves the odds. This is a key attribute of the nonscalable framework to analyzing randomness: extreme deviations decrease at an increasing rate. You can expect to toss 50 heads in a row once in four billion lifetimes!
FIGURE 9: NUMBERS OF WINS TOSSED
Result of forty tosses. We see the proto-bell curve emerging.
We are not yet fully in a Gaussian bell curve, but we are getting dangerously close. This is still proto-Gaussian, but you can see the gist. (Actually, you will never encounter a Gaussian in its purity since it is a Platonic form—you just get closer but cannot attain it.) However, as you can see in
Figure 9
, the familiar bell shape is starting to emerge.
How do we get even closer to the perfect Gaussian bell curve? By refining the flipping process. We can either flip 40 times for $1 a flip or 4,000 times for ten cents a flip, and add up the results. Your expected risk is about the same in both situations—and that is a trick. The equivalence in the two sets of flips has a little nonintuitive hitch. We multiplied the number of bets by 100, but divided the bet size by 10—don’t look for a reason now, just assume that they are “equivalent.” The overall risk is equivalent, but now we have opened up the possibility of winning or losing 400 times in a row. The odds are about one in 1 with 120 zeroes after it, that is, one in 1,000,000,000,000,000,000,000,000,000,000,000,000, 000,000,000,000,000,000,000,000,000,000,000,000,000,000,000,000, 000,000,000,000,000,000,000,000,000,000,000,000 times.
Continue the process for a while. We go from 40 tosses for $1 each to 4,000 tosses for 10 cents, to 400,000 tosses for 1 cent, getting close and closer to a Gaussian.
Figure 10
shows results spread between −40 and 40, namely eighty plot points. The next one would bring that up to 8,000 points.
FIGURE 10: A MORE ABSTRACT VERSION: PLATO’S CURVE
An infinite number of tosses.
Let’s keep going. We can flip 4,000 times staking a tenth of a penny. How about 400,000 times at 1/1000 of a penny? As a Platonic form, the pure Gaussian curve is principally what happens when he have an infinity of tosses per round, with each bet infinitesimally small. Do not bother trying to visualize the results, or even make sense out of them. We can no longer talk about an “infinitesimal” bet size (since we have an infinity of these, and we are in what mathematicians call a continuous framework). The good news is that there is a substitute.
We have moved from a simple bet to something completely abstract. We have moved from observations into the realm of mathematics. In mathematics things have a purity to them.
Now, something completely abstract is not supposed to exist, so
please do not even make an attempt to understand
Figure 10
. Just be aware of its use. Think of it as a thermometer: you are not supposed to understand what the temperature
means
in order to talk about it. You just need to know the correspondence between temperature and comfort (or some other empirical consideration). Sixty degrees corresponds to pleasant weather; ten below is not something to look forward to. You don’t necessarily care about the actual speed of the collisions among particles that more technically explains temperature. Degrees are, in a way, a means for your mind to translate some external phenomena into a number. Likewise, the Gaussian bell curve is set so that 68.2 percent of the observations fall between minus one and plus one standard deviations away from the average. I repeat: do not even try to understand whether
standard deviation
is
average deviation
—it is not, and a large (too large) number of people
using the word
standard deviation
do not understand this point. Standard deviation is just a number that you scale things to, a matter of mere correspondence
if phenomena were Gaussian
.
These standard deviations are often nicknamed “sigma.” People also talk about “variance” (same thing: variance is the square of the sigma, i.e., of the standard deviation).
Note the symmetry in the curve. You get the same results whether the sigma is positive or negative. The odds of falling below −4 sigmas are the same as those of exceeding 4 sigmas, here 1 in 32,000 times.
As the reader can see, the main point of the Gaussian bell curve is, as I have been saying, that most observations hover around the mediocre, the mean, while the odds of a deviation decline faster and faster (exponentially) as you move away from the mean. If you need to retain one single piece of information, just remember this dramatic speed of decrease in the odds as you move away from the average. Outliers are increasingly unlikely. You can safely ignore them.
This property also generates the supreme law of Mediocristan: given the paucity of large deviations, their contribution to the total will be vanishingly small.
In the height example earlier in this chapter, I used units of deviations of ten centimeters, showing how the incidence declined as the height increased. These were one sigma deviations; the height table also provides an example of the operation of “scaling to a sigma” by using the sigma as a unit of measurement.
Those Comforting Assumptions
Note the central assumptions we made in the coin-flip game that led to the proto-Gaussian, or mild randomness.
First central assumption:
the flips are independent of one another. The coin has no memory. The fact that you got heads or tails on the previous flip does not change the odds of your getting heads or tails on the next one. You do not become a “better” coin flipper over time. If you introduce memory, or skills in flipping, the entire Gaussian business becomes shaky.
Recall our discussions in
Chapter 14
on preferential attachment and cumulative advantage. Both theories assert that winning today makes you more likely to win in the future. Therefore, probabilities are dependent on history, and the first central assumption leading to the Gaussian bell curve
fails in reality. In games, of course, past winnings are not supposed to translate into an increased probability of future gains—but not so in real life, which is why I worry about teaching probability from games. But when winning leads to more winning, you are far more likely to see forty wins in a row than with a proto-Gaussian.
Second central assumption:
no “wild” jump. The step size in the building block of the basic random walk is always known, namely one step. There is no uncertainty as to the size of the step. We did not encounter situations in which the move varied wildly.
Remember that if either of these two central assumptions is not met, your moves (or coin tosses) will not cumulatively lead to the bell curve. Depending on what happens, they can lead to the wild Mandelbrotian-style scale-invariant randomness.
“The Ubiquity of the Gaussian”
One of the problems I face in life is that whenever I tell people that the Gaussian bell curve is not ubiquitous in real life, only in the minds of statisticians, they require me to “prove it”—which is easy to do, as we will see in the next two chapters, yet nobody has managed to prove the opposite. Whenever I suggest a process that is not Gaussian, I am asked to justify my suggestion and to, beyond the phenomena, “give them the theory behind it.” We saw in
Chapter 14
the rich-get-richer models that were proposed in order to justify not using a Gaussian. Modelers were forced to spend their time writing theories on possible models that generate the scalable—as if they needed to be apologetic about it. Theory shmeory! I have an epistemological problem with that, with the need to justify the world’s failure to resemble an idealized model that someone blind to reality has managed to promote.
My technique, instead of studying the possible models generating non-bell curve randomness, hence making the same errors of blind theorizing, is to do the opposite: to know the bell curve as intimately as I can and identify where it can and cannot hold. I know where Mediocristan is. To me it is frequently (nay, almost always) the users of the bell curve who do not understand it well, and have to justify it, and not the opposite.
This ubiquity of the Gaussian is not a property of the world, but a problem in our minds, stemming from the way we look at it.
•   •   •
The next chapter will address the scale invariance of nature and address the properties of the fractal. The chapter after that will probe the misuse of the Gaussian in socioeconomic life and “the need to produce theories.”
I sometimes get a little emotional because I’ve spent a large part of my life thinking about this problem. Since I started thinking about it, and conducting a variety of thought experiments as I have above, I have not for the life of me been able to find anyone around me in the business and statistical world who was intellectually consistent in that he both accepted the Black Swan and rejected the Gaussian and Gaussian tools. Many people accepted my Black Swan idea but could not take it to its logical conclusion, which is that you cannot use one single measure for randomness called standard deviation (and call it “risk”); you cannot expect a
simple
answer to characterize uncertainty. To go the extra step requires courage, commitment, an ability to connect the dots, a desire to understand randomness fully. It also means not accepting other people’s wisdom as gospel. Then I started finding physicists who had rejected the Gaussian tools but fell for another sin: gullibility about precise predictive models, mostly elaborations around the preferential attachment of
Chapter 14
—another form of Platonicity. I could not find anyone with depth and scientific technique who looked at the world of randomness and understood its nature, who looked at calculations as an aid, not a principal aim. It took me close to a decade and a half to find that thinker, the man who made many swans gray: Mandelbrot—the great Benoît Mandelbrot.
*
The nontechnical (or intuitive) reader can skip this chapter, as it goes into some details about the bell curve. Also, you can skip it if you belong to the category of fortunate people who do not know about the bell curve.
*
I have fudged the numbers a bit for simplicity’s sake.
*
One of the most misunderstood aspects of a Gaussian is its fragility and vulnerability in the estimation of tail events. The odds of a 4 sigma move are twice that of a 4.15 sigma. The odds of a 20 sigma are a trillion times higher than those of a 21 sigma! It means that a small measurement error of the sigma will lead to a massive underestimation of the probability. We can be a trillion times wrong about some events.
†
My main point, which I repeat in some form or another throughout Part Three, is as follows. Everything is made easy, conceptually, when you consider that there are two, and only two, possible paradigms: nonscalable (like the Gaussian) and
other
(such as Mandebrotian randomness). The rejection of the application of the nonscalable is sufficient, as we will see later,
to eliminate a certain vision of the world
. This is like negative empiricism: I know a lot by determining what is wrong.
*
Note that variables may not be infinitely scalable; there could be a very, very remote upper limit—but we do not know where it is so we treat a given situation as if it were infinitely scalable. Technically, you cannot sell more of one book than there are denizens of the planet—but that upper limit is large enough to be treated as if it didn’t exist. Furthermore, who knows, by repackaging the book, you might be able to sell it to a person twice, or get that person to watch the same movie several times.
†
As I was revising this draft, in August 2006, I stayed at a hotel in Dedham, Massachusetts, near one of my children’s summer camps. There, I was a little intrigued by the abundance of weight-challenged people walking around the lobby and causing problems with elevator backups. It turned out that the annual convention of NAFA, the National Association for Fat Acceptance, was being held there. As most of the members were extremely overweight, I was not able to figure out which delegate was the heaviest: some form of equality prevailed among the very heavy (someone much heavier than the persons I saw would have been dead). I am sure that at the NARA convention, the National Association for Rich Acceptance, one person would dwarf the others, and, even among the superrich, a very small percentage would represent a large section of the total wealth.


================================================================================
CHAPTER/SECTION 241 (Item 246)
================================================================================

Chapter Sixteen
THE AESTHETICS OF RANDOMNESS
Mandelbrot’s library—Was Galileo blind?—Pearls to swine—Self-affinity—How the world can be complicated in a simple way, or, perhaps, simple in a very complicated way


================================================================================
CHAPTER/SECTION 242 (Item 247)
================================================================================

THE POET OF RANDOMNESS
It was a melancholic afternoon when I smelled the old books in Benoît Mandelbrot’s library. This was on a hot day in August 2005, and the heat exacerbated the musty odor of the glue of old French books bringing on powerful olfactory nostalgia. I usually succeed in repressing such nostalgic excursions, but not when they sneak up on me as music or smell. The odor of Mandelbrot’s books was that of French literature, of my parents’ library, of the hours spent in bookstores and libraries when I was a teenager when many books around me were (alas) in French, when I thought that Literature was above anything and everything. (I haven’t been in contact with many French books since my teenage days.) However abstract I wanted it to be, Literature had a physical embodiment, it had a smell, and this was it.
The afternoon was also gloomy because Mandelbrot was moving away, exactly when I had become entitled to call him at crazy hours just because I had a question, such as why people didn’t realize that the 80/20
could be 50/01. Mandelbrot had decided to move to the Boston area, not to retire, but to work for a research center sponsored by a national laboratory. Since he was moving to an apartment in Cambridge, and leaving his oversize house in the Westchester suburbs of New York, he had invited me to come take my pick of his books.
Even the titles of the books had a nostalgic ring. I filled up a box with French titles, such as a 1949 copy of Henri Bergson’s
Matière et mémoire
, which it seemed Mandelbrot bought when he was a student (the smell!).
After having mentioned his name left and right throughout this book, I will finally introduce Mandelbrot, principally as the first person with an academic title with whom I ever spoke about randomness without feeling defrauded. Other mathematicians of probability would throw at me theorems with Russian names such as “Sobolev,” “Kolmogorov,” Wiener measure, without which they were lost; they had a hard time getting to the heart of the subject or exiting their little box long enough to consider its empirical flaws. With Mandelbrot, it was different: it was as if we both originated from the same country, meeting after years of frustrating exile, and were finally able to speak in our mother tongue without straining. He is the only flesh-and-bones teacher I ever had—my teachers are usually books in my library. I had way too little respect for mathematicians dealing with uncertainty and statistics to consider any of them my teachers—in my mind mathematicians, trained for certainties, had no business dealing with randomness. Mandelbrot proved me wrong.
He speaks an unusually precise and formal French, much like that spoken by Levantines of my parents’ generation or Old World aristocrats. This made it odd to hear, on occasion, his accented, but very standard, colloquial American English. He is tall, overweight, which makes him look baby-faced (although I’ve never seen him eat a large meal), and has a strong physical presence.
From the outside one would think that what Mandelbrot and I have in common is wild uncertainty, Black Swans, and dull (and sometimes less dull) statistical notions. But, although we are collaborators, this is not what our major conversations revolve around. It is mostly matters literary and aesthetic, or historical gossip about people of extraordinary intellectual refinement. I mean refinement, not achievement. Mandelbrot could tell stories about the phenomenal array of hotshots he has worked with over the past century, but somehow I am programmed to consider scientists’ personae far less interesting than those of colorful erudites. Like me, Mandelbrot takes an interest in urbane individuals who combine traits
generally thought not to coexist together. One person he often mentions is Baron Pierre Jean de Menasce, whom he met at Princeton in the 1950s, where de Menasce was the roommate of the physicist Oppenheimer. De Menasce was exactly the kind of person I am interested in, the embodiment of a Black Swan. He came from an opulent Alexandrian Jewish merchant family, French and Italian–speaking like all sophisticated Levantines. His forebears had taken a Venetian spelling for their Arabic name, added a Hungarian noble title along the way, and socialized with royalty. De Menasce not only converted to Christianity, but became a Dominican priest and a great scholar of Semitic and Persian languages. Mandelbrot kept questioning me about Alexandria, since he was always looking for such characters.
True, intellectually sophisticated characters were exactly what I looked for in life. My erudite and polymathic father—who, were he still alive, would have only been two weeks older than Benoît M.—liked the company of extremely cultured Jesuit priests. I remember these Jesuit visitors occupying my chair at the dining table. I recall that one had a medical degree and a PhD in physics, yet taught Aramaic to locals in Beirut’s Institute of Eastern Languages. His previous assignment could have been teaching high school physics, and the one before that was perhaps in the medical school. This kind of erudition impressed my father far more than scientific assembly-line work. I may have something in my genes driving me away from
bildungsphilisters
.
Although Mandelbrot often expressed amazement at the temperament of high-flying erudites and remarkable but not-so-famous scientists, such as his old friend Carleton Gajdusek, a man who impressed him with his ability to uncover the causes of tropical diseases, he did not seem eager to trumpet his association with those we consider great scientists. It took me a while to discover that he had worked with an impressive list of scientists in seemingly every field, something a name-dropper would have brought up continuously. Although I have been working with him for a few years now, only the other day, as I was chatting with his wife, did I discover that he spent two years as the mathematical collaborator of the psychologist Jean Piaget. Another shock came when I discovered that he had also worked with the great historian Fernand Braudel, but Mandelbrot did not seem to be interested in Braudel. He did not care to discuss John von Neuman with whom he had worked as a postdoctoral fellow. His scale was inverted. I asked him once about Charles Tresser, an unknown physicist I met at a party who wrote papers on chaos theory and supplemented his researcher’s
income by making pastry for a shop he ran near New York City. He was emphatic:
“un homme extraordinaire,”
he called Tresser, and could not stop praising him. But when I asked him about a particular famous hotshot, he replied, “He is the prototypical
bon élève
, a student with good grades, no depth, and no vision.” That hotshot was a Nobel laureate.


================================================================================
CHAPTER/SECTION 243 (Item 248)
================================================================================

THE PLATONICITY OF TRIANGLES
Now, why am I calling this business Mandelbrotian, or fractal, randomness? Every single bit and piece of the puzzle has been previously mentioned by someone else, such as Pareto, Yule, and Zipf, but it was Mandelbrot who a) connected the dots, b) linked randomness to geometry (and a special brand at that), and c) took the subject to its natural conclusion. Indeed many mathematicians are famous today partly because he dug out their works to back up his claims—the strategy I am following here in this book. “I had to invent my predecessors, so people take me seriously,” he once told me, and he used the credibility of big guns as a rhetorical device. One can almost always ferret out predecessors for any thought. You can always find someone who worked on a part of your argument and use his contribution as your backup. The scientific association with a big idea, the “brand name,” goes to the one who connects the dots, not the one who makes a casual observation—even Charles Darwin, who uncultured scientists claim “invented” the survival of the fittest, was not the first to mention it. He wrote in the introduction of
The Origin of Species
that the facts he presented were not necessarily original; it was the consequences that he thought were “interesting” (as he put it with characteristic Victorian modesty). In the end it is those who derive consequences and seize the importance of the ideas, seeing their real value, who win the day. They are the ones who can talk about the subject.
So let me describe Mandelbrotian geometry.
The Geometry of Nature
Triangles, squares, circles, and the other geometric concepts that made many of us yawn in the classroom may be beautiful and pure notions, but they seem more present in the minds of architects, design artists, modern art buildings, and schoolteachers than in nature itself. That’s fine, except that most of us aren’t aware of this. Mountains are not triangles or pyramids;
trees are not circles; straight lines are almost never seen anywhere. Mother Nature did not attend high school geometry courses or read the books of Euclid of Alexandria. Her geometry is jagged, but with a logic of its own and one that is easy to understand.
I have said that we seem naturally inclined to Platonify, and to think exclusively in terms of studied material: nobody, whether a bricklayer or a natural philosopher, can easily escape the enslavement of such conditioning. Consider that the great Galileo, otherwise a debunker of falsehoods, wrote the following:
The great book of Nature lies ever open before our eyes and the true philosophy is written in it. … But we cannot read it unless we have first learned the language and the characters in which it is written. … It is written in mathematical language and the characters are triangles, circles and other geometric figures.
Was Galileo legally blind? Even the great Galileo, with all his alleged independence of mind, was not capable of taking a clean look at Mother Nature. I am confident that he had windows in his house and that he ventured outside from time to time: he should have known that triangles are not easily found in nature. We are so easily brainwashed.
We are either blind, or illiterate, or both. That nature’s geometry is not Euclid’s was so obvious, and nobody, almost nobody, saw it.
This (physical) blindness is identical to the ludic fallacy that makes us think casinos represent randomness.
Fractality
But first, a description of fractals. Then we will show how they link to what we call power laws, or scalable laws.
Fractal
is a word Mandelbrot coined to describe the geometry of the rough and
broken
—from the Latin
fractus
, the origin of
fractured. Fractality
is the repetition of geometric patterns at different scales, revealing smaller and smaller versions of themselves. Small parts resemble, to some degree, the whole. I will try to show in this chapter how the fractal applies to the brand of uncertainty that should bear Mandelbrot’s name: Mandelbrotian randomness.
The veins in leaves look like branches; branches look like trees; rocks
look like small mountains. There is no qualitative change when an object changes size. If you look at the coast of Britain from an airplane, it resembles what you see when you look at it with a magnifying glass. This character of self-affinity implies that one deceptively short and simple rule of iteration can be used, either by a computer or, more randomly, by Mother Nature, to build shapes of seemingly great complexity. This can come in handy for computer graphics, but, more important, it is how nature works. Mandelbrot designed the mathematical object now known as the Mandelbrot set, the most famous object in the history of mathematics. It became popular with followers of chaos theory because it generates pictures of ever increasing complexity by using a deceptively minuscule recursive rule;
recursive
means that something can be reapplied to itself infinitely. You can look at the set at smaller and smaller resolutions without
ever
reaching the limit; you will continue to see recognizable shapes. The shapes are never the same, yet they bear an affinity to one another, a strong family resemblance.
These objects play a role in aesthetics. Consider the following applications:
Visual arts:
Most computer-generated objects are now based on some version of the Mandelbrotian fractal. We can also see fractals in architecture, paintings, and many works of visual art—of course, not consciously incorporated by the work’s creator.
Music:
Slowly hum the four-note opening of Beethoven’s Fifth Symphony:
ta-ta-ta-ta
. Then replace each individual note with the same four-note opening, so that you end up with a measure of sixteen notes. You will see (or, rather, hear) that each smaller wave resembles the original larger one. Bach and Mahler, for instance, wrote submovements that resemble the larger movements of which they are a part.
Poetry:
Emily Dickinson’s poetry, for instance, is fractal: the large resembles the small. It has, according to a commentator, “a consciously made assemblage of dictions, metres, rhetorics, gestures, and tones.”
Fractals initially made Benoît M. a pariah in the mathematical establishment. French mathematicians were horrified. What? Images?
Mon dieu!
It was like showing a porno movie to an assembly of devout Eastern Orthodox grandmothers in my ancestral village of Amioun. So Mandelbrot spent time as an intellectual refugee at an IBM research center in upstate New York. It was a
f*** you money
situation, as IBM let him do whatever he felt like doing.
But the general public (mostly computer geeks) got the point. Mandelbrot’s book
The Fractal Geometry of Nature
made a splash when it came out a quarter century ago. It spread through artistic circles and led to studies in aesthetics, architectural design, even large industrial applications. Benoît M. was even offered a position as a professor of medicine! Supposedly the lungs are self-similar. His talks were invaded by all sorts of artists, earning him the nickname the Rock Star of Mathematics. The computer age helped him become one of the most influential mathematicians in history, in terms of the applications of his work, way before his acceptance by the ivory tower. We will see that, in addition to its universality, his work offers an unusual attribute: it is remarkably easy to understand.
A few words on his biography. Mandelbrot came to France from Warsaw in 1936, at the age of twelve. Owing to the vicissitudes of a clandestine life during Nazi-occupied France, he was spared some of the conventional Gallic education with its uninspiring algebraic drills, becoming largely self-taught. He was later deeply influenced by his uncle Szolem, a prominent member of the French mathematical establishment and holder of a chair at the Collège de France. Benoît M. later settled in the United States, working most of his life as an industrial scientist, with a few transitory and varied academic appointments.
The computer played two roles in the new science Mandelbrot helped conceive. First, fractal objects, as we have seen, can be generated with a simple rule applied to itself, which makes them ideal for the automatic activity of a computer (or Mother Nature). Second, in the generation of visual intuitions lies a dialectic between the mathematician and the objects generated.
Now let us see how this takes us to randomness. In fact, it is with probability that Mandelbrot started his career.
A Visual Approach to Extremistan/Mediocristan
I am looking at the rug in my study. If I examine it with a microscope, I will see a very rugged terrain. If I look at it with a magnifying glass, the terrain will be smoother but still highly uneven. But when I look at it from a standing position, it appears uniform—it is almost as smooth as a sheet of paper. The rug at eye level corresponds to Mediocristan and the law of large numbers: I am seeing the sum of undulations, and
these iron out
. This is like Gaussian randomness: the reason my cup of coffee does not
jump is that the sum of all of its moving particles becomes smooth. Likewise, you reach certainties by adding up small Gaussian uncertainties: this is the law of large numbers.
The Gaussian is not self-similar, and that is why my coffee cup does not jump on my desk.
Now, consider a trip up a mountain. No matter how high you go on the surface of the earth, it will remain jagged. This is even true at a height of 30,000 feet. When you are flying above the Alps, you will still see jagged mountains in place of small stones. So some surfaces are not from Mediocristan, and changing the resolution does not make them much smoother. (Note that this effect only disappears when you go up to more extreme heights. Our planet looks smooth to an observer from space, but this is because it is too small. If it were a bigger planet, then it would have mountains that would dwarf the Himalayas, and it would require observation from a greater distance for it to look smooth. Likewise, if the planet had a larger population, even maintaining the same average wealth, we would be likely to find someone whose net worth would vastly surpass that of Bill Gates.)
Figures 11
and
12
illustrate the above point: an observer looking at the first picture might think that a lens cap has fallen on the ground.
Recall our brief discussion of the coast of Britain. If you look at it from an airplane, its contours are not so different from the contours you see on the shore. The change in scaling does not alter the shapes or their degree of smoothness.
Pearls to Swine
What does fractal geometry have to do with the distribution of wealth, the size of cities, returns in the financial markets, the number of casualties in war, or the size of planets? Let us connect the dots.
The key here is that
the fractal has numerical or statistical measures that are (somewhat) preserved across scales
—the ratio is the same, unlike the Gaussian. Another view of such self-similarity is presented in
Figure 13
. As we saw in
Chapter 15
, the superrich are similar to the rich, only richer—wealth is scale independent, or, more precisely, of unknown scale dependence.
In the 1960s Mandelbrot presented his ideas on the prices of commodities and financial securities to the economics establishment, and the financial economists got all excited. In 1963 the then dean of the University of Chicago Graduate School of Business, George Shultz, offered him a professorship. This is the same George Shultz who later became Ronald Reagan’s secretary of state.
FIGURE 11:
Apparently, a lens cap has been dropped on the ground. Now turn the page.
Shultz called him one evening to rescind the offer.
At the time of writing, forty-four years later, nothing has happened in economics and social science statistics—except for some cosmetic fiddling that treats the world as if we were subject only to mild randomness—and yet Nobel medals were being distributed. Some papers were written offering “evidence” that Mandelbrot was wrong by people who do not get the central argument of this book—you can always produce data “corroborating” that the underlying process is Gaussian by finding periods that do not have rare events, just like you can find an afternoon during which no one killed anyone and use it as “evidence” of honest behavior. I will repeat that, because of the asymmetry with induction, just as it is easier to reject innocence than accept it, it is easier to reject a bell curve than accept it; conversely, it is more difficult to reject a fractal than to accept it. Why? Because a single event can destroy the argument that we face a Gaussian bell curve.
In sum, four decades ago, Mandelbrot gave pearls to economists and résumé-building philistines, which they rejected because the ideas were too good for them. It was, as the saying goes,
margaritas ante porcos
, pearls before swine.
FIGURE 12:
The object is not in fact a lens cap. These two photos illustrate scale invariance: the terrain is fractal. Compare it to man-made objects such as a car or a house.
Source: Professor Stephen W. Wheatcraft, University of Nevada, Reno
.
In the rest of this chapter I will explain how I can endorse Mandelbrotian fractals as a representation of much of randomness without necessarily accepting their precise use. Fractals should be the default, the approximation, the framework. They do not solve the Black Swan problem and do not turn all Black Swans into predictable events, but they significantly mitigate the Black Swan problem by making such large events conceivable. (It makes them gray. Why gray? Because only the Gaussian give you certainties. More on that, later.)


================================================================================
CHAPTER/SECTION 244 (Item 249)
================================================================================

THE LOGIC OF FRACTAL RANDOMNESS (WITH A WARNING)
*
I have shown in the wealth lists in
Chapter 15
the logic of a fractal distribution: if wealth doubles from 1 million to 2 million, the incidence of people with at least that much money is cut in four, which is an exponent of two. If the exponent were one, then the incidence of that wealth or more would be cut in two. The exponent is called the “power” (which is why some people use the term
power law)
. Let us call the number of occurrences higher than a certain level an “exceedance”—an exceedance of two million is the number of persons with wealth more than two million. One main property of these fractals (or another way to express their main property, scalability) is that the ratio of two exceedances
*
is going to be the ratio of the two numbers to the negative power of the power exponent. Let us illustrate this. Say that you “think” that only 96 books a year will sell more than 250,000 copies (which is what happened last year), and that you “think” that the exponent is around 1.5. You can extrapolate to estimate that around 34 books will sell more than 500,000 copies—simply 96 times (500,000/250,000)
−1.5
. We can continue, and note that around 12 books should sell more than a million copies, here 96 times (1,000,000/250,000)
−1.5
.
FIGURE 13: THE PURE FRACTAL STATISTICAL MOUNTAIN
The degree of inequality will be the same in all sixteen subsections of the graph. In the Gaussian world, disparities in wealth (or any other quantity) decrease when you look at the upper end—so billionaires should be more equal in relation to one another than millionaires are, and millionaires more equal in relation to one another than the middle class. This lack of equality at all wealth levels, in a nutshell, is statistical self-similarity.
TABLE 2: ASSUMED EXPONENTS FOR VARIOUS PHENOMENA
*
Phenomenon
Assumed Exponent (vague approximation)
Frequency of use of words
1.2
Number of hits on websites
1.4
Number of books sold in the U.S.
1.5
Telephone calls received
1.22
Magnitude of earthquakes
2.8
Diameter of moon craters
2.14
Intensity of solar flares
0.8
Intensity of wars
0.8
Net worth of Americans
1.1
Number of persons per family name
1
Population of U.S. cities
1.3
Market moves
3 (or lower)
Company size
1.5
People killed in terrorist attacks
2 (but possibly a much lower exponent)
*
Source: M.E.J. Newman (2005) and the author’s own calculations
.
Let me show the different measured exponents for a variety of phenomena.
Let me tell you upfront that these exponents mean very little in terms of numerical precision. We will see why in a minute, but just note for now that we do not
observe
these parameters; we simply guess them, or infer them for statistical information, which makes it hard at times to know the true parameters—if it in fact exists. Let us first examine the practical consequences of an exponent.
TABLE 3: THE MEANING OF THE EXPONENT
Exponent
Share of the top 1%
Share of the top 20%
1
99.99%
*
99.99%
1.1
66%
86%
1.2
47%
76%
1.3
34%
69%
1.4
27%
63%
1.5
22%
58%
2
10%
45%
2.5
6%
38%
3
4.6%
34%
Table 3
illustrates the impact of the highly improbable. It shows the contributions of the top 1 percent and 20 percent to the total. The lower the exponent, the higher those contributions. But look how sensitive the process is: between 1.1 and 1.3 you go from 66 percent of the total to 34 percent. Just a 0.2 difference in the exponent changes the result dramatically—and such a difference can come from a simple measurement error. This difference is not trivial: just consider that we have no precise idea what the exponent is because we cannot measure it directly. All we do is estimate from past data or rely on theories that allow for the building of some model that would give us some idea—but these models may have hidden weaknesses that prevent us from blindly applying them to reality.
So keep in mind that the 1.5 exponent is an approximation, that it is hard to compute, that you do not get it from the gods, at least not easily, and that you will have a monstrous sampling error. You will observe that the number of books selling above a million copies is not always going to be 12—It could be as high as 20, or as low as 2.
More significantly, this exponent begins to apply at some number called “crossover,” and addresses numbers larger than this crossover. It
may start at 200,000 books, or perhaps only 400,000 books. Likewise, wealth has different properties before, say, $600 million, when inequality grows, than it does below such a number. How do you know where the crossover point is? This is a problem. My colleagues and I worked with around 20 million pieces of financial data. We all had the same data set, yet we never agreed on exactly what the exponent was in our sets. We knew the data revealed a fractal power law, but we learned that one could not produce a precise number. But what we did know
—that the distribution is scalable and fractal
—was sufficient for us to operate and make decisions.
The Problem of the Upper Bound
Some people have researched and accepted the fractal “up to a point.” They argue that wealth, book sales, and market returns all have a certain level when things stop being fractal. “Truncation” is what they propose. I agree that there is a level where fractality
might
stop, but where? Saying that there is an upper limit
but I don’t know how high it is
, and saying
there is no limit
carry the same consequences in practice. Proposing an upper limit is highly unsafe. You may say, Let us cap wealth at $150 billion in our analyses. Then someone else might say, Why not $151 billion? Or why not $152 billion? We might as well consider that the variable is unlimited.
Beware the Precision
I have learned a few tricks from experience: whichever exponent I try to measure will be likely to be overestimated (recall that a higher exponent implies a smaller role for large deviations)—what you see is likely to be less Black Swannish than what you do not see. I call this the masquerade problem.
Let’s say I generate a process that has an exponent of 1.7. You do not see what is inside the engine, only the data coming out. If I ask you what the exponent is, odds are that you will compute something like 2.4. You would do so even if you had a million data points. The reason is that it takes a long time for some fractal processes to reveal their properties, and you underestimate the severity of the shock.
Sometimes a fractal can make you believe that it is Gaussian, particularly when the cutpoint starts at a high number. With fractal distributions,
extreme deviations of that kind are rare enough to smoke you: you don’t recognize the distribution as fractal.
The Water Puddle Revisited
As you have seen, we have trouble knowing the parameters of whichever model we assume runs the world. So with Extremistan, the problem of induction pops up again, this time even more significantly than at any previous time in this book. Simply, if a mechanism is fractal it can deliver large values; therefore the incidence of large deviations is possible, but how possible, how often they should occur, will be hard to know with any precision. This is similar to the water puddle problem: plenty of ice cubes could have generated it. As someone who goes from reality to possible explanatory models, I face a completely different spate of problems from those who do the opposite.
I have just read three “popular science” books that summarize the research in complex systems: Mark Buchanan’s
Ubiquity
, Philip Ball’s
Critical Mass
, and Paul Ormerod’s
Why Most Things Fail
. These three authors present the world of social science as full of power laws, a view with which I most certainly agree. They also claim that there is
universality
of many of these phenomena, that there is a wonderful similarity between various processes in nature and the behavior of social groups, which I agree with. They back their studies with the various theories on networks and show the wonderful correspondence between the so-called critical phenomena in natural science and the self-organization of social groups. They bring together processes that generate avalanches, social contagions, and what they call informational cascades, which I agree with.
Universality is one of the reasons physicists find power laws associated with critical points particularly interesting. There are many situations, both in dynamical systems theory and statistical mechanics, where many of the properties of the dynamics around critical points are independent of the details of the underlying dynamical system. The exponent at the critical point may be the same for many systems in the same group, even though many other aspects of the system are different. I almost agree with this notion of universality. Finally, all three authors encourage us to apply techniques from statistical physics, avoiding econometrics and Gaussian-style nonscalable distributions like the plague, and I couldn’t agree more.
But all three authors, by producing, or promoting precision, fall into the trap of not differentiating between the forward and the backward
processes (between the problem and the inverse problem)—to me, the greatest scientific and epistemological sin. They are not alone; nearly everyone who works with data but doesn’t make decisions on the basis of these data tends to be guilty of the same sin, a variation of the narrative fallacy. In the absence of a feedback process you look at models and think that they confirm reality. I believe in the ideas of these three books, but not in the way they are being used—and certainly not with the precision the authors ascribe to them. As a matter of fact, complexity theory should make us
more
suspicious of scientific claims of precise models of reality. It does not make all the swans white; that is predictable: it makes them gray, and only gray.
*
As I have said earlier, the world, epistemologically, is literally a different place to a bottom-up empiricist. We don’t have the luxury of sitting down to read the equation that governs the universe; we just observe data and make an assumption about what the real process might be, and “calibrate” by adjusting our equation in accordance with additional information. As events present themselves to us, we compare what we see to what we expected to see. It is usually a humbling process, particularly for someone aware of the narrative fallacy, to discover that history runs forward, not backward. As much as one thinks that businessmen have big egos, these people are often humbled by reminders of the differences between decision and results, between precise models and reality.
What I am talking about is opacity, incompleteness of information, the invisibility of the generator of the world. History does not reveal its mind to us—we need to guess what’s inside of it.
From Representation to Reality
The above idea links all the parts of this book. While many study psychology, mathematics, or evolutionary theory and look for ways to take it to the bank by applying their ideas to business, I suggest the exact opposite: study the intense, uncharted, humbling uncertainty in the markets as a means to get insights about the nature of randomness that is applicable to psychology, probability, mathematics, decision theory, and even statistical physics. You will see the sneaky manifestations of the narrative fallacy, the ludic fallacy, and the great errors of Platonicity, of going from representation to reality.
When I first met Mandelbrot I asked him why an established scientist like him who should have more valuable things to do with his life would take an interest in such a vulgar topic as finance. I thought that finance and economics were just a place where one learned from various empirical phenomena and filled up one’s bank account with
f*** you
cash before leaving for bigger and better things. Mandelbrot’s answer was,
“Data
, a gold mine of data.” Indeed, everyone forgets that he started in economics before moving on to physics and the geometry of nature. Working with such abundant data humbles us; it provides the intuition of the following error: traveling the road between representation and reality in the wrong direction.
The problem of the
circularity of statistics
(which we can also call the statistical regress argument) is as follows. Say you need past data to discover whether a probability distribution is Gaussian, fractal, or something else. You will need to establish whether you have enough data to back up your claim. How do we know if we have enough data? From the probability distribution—a distribution does tell you whether you have enough data to “build confidence” about what you are inferring. If it is a Gaussian bell curve, then a few points will suffice (the law of large numbers once again). And how do you know if the distribution is Gaussian? Well, from the data. So we need the data to tell us what the probability distribution is, and a probability distribution to tell us how much data we need. This causes a severe regress argument.
This regress does not occur if you
assume beforehand
that the distribution is Gaussian. It happens that, for some reason, the Gaussian yields its properties rather easily. Extremistan distributions do not do so. So selecting the Gaussian while invoking some general law appears to be convenient. The Gaussian is used as a default distribution for that very reason. As I keep repeating, assuming its application beforehand may work with a small number of fields such as crime statistics, mortality rates, matters from Mediocristan. But not for historical data of unknown attributes and not for matters from Extremistan.
Now, why aren’t statisticians who work with historical data aware of this problem? First, they do not like to hear that their entire business has been canceled by the problem of induction. Second, they are not confronted with the results of their predictions in rigorous ways. As we saw with the Makridakis competition, they are grounded in the narrative fallacy, and they do not want to hear it.


================================================================================
CHAPTER/SECTION 245 (Item 250)
================================================================================

ONCE AGAIN, BEWARE THE FORECASTERS
Let me take the problem one step higher up. As I mentioned earlier, plenty of fashionable models attempt to explain the genesis of Extremistan. In fact, they are grouped into two broad classes, but there are occasionally more approaches. The first class includes the simple rich-get-richer (or big-get-bigger) style model that is used to explain the lumping of people around cities, the market domination of Microsoft and VHS (instead of Apple and Betamax), the dynamics of academic reputations, etc. The second class concerns what are generally called “percolation models,” which address not the behavior of the individual, but rather the terrain in which he operates. When you pour water on a porous surface, the structure of that surface matters more than does the liquid. When a grain of sand hits a pile of other grains of sand, how the terrain is organized is what determines whether there will be an avalanche.
Most models, of course, attempt to be precisely predictive, not just descriptive; I find this infuriating. They are nice tools for illustrating the genesis of Extremistan, but I insist that the “generator” of reality does not appear to obey them closely enough to make them helpful in precise forecasting. At least to judge by anything you find in the current literature on the subject of Extremistan. Once again we face grave calibration problems, so it would be a great idea to avoid the common mistakes made while calibrating a nonlinear process. Recall that nonlinear processes have greater degrees of freedom than linear ones (as we saw in
Chapter 11
), with the implication that you run a great risk of using the wrong model. Yet once in a while you run into a book or articles advocating the application of models from statistical physics to reality. Beautiful books like Philip Ball’s illustrate and inform, but they should not lead to precise quantitative models. Do not take them at face value.
But let us see what we
can
take home from these models.
Once Again, a Happy Solution
First, in assuming a scalable, I accept that an arbitrarily large number is possible. In other words, inequalities should not stop above some
known
maximum bound.
Say that the book
The Da Vinci Code
sold around 60 million copies. (The Bible sold about a billion copies but let’s ignore it and limit our analysis to lay books written by individual authors.) Although we have
never known a lay book to sell 200 million copies, we can consider that the possibility is not zero. It’s small, but it’s not zero. For every three
Da Vinci Code
–style bestsellers, there might be one superbestseller, and though one has not happened so far, we cannot rule it out. And for every fifteen
Da Vinci Codes
there will be one superbestseller selling, say, 500 million copies.
Apply the same logic to wealth. Say the richest person on earth is worth $50 billion. There is a nonnegligible probability that next year someone with $100 billion or more will pop out of nowhere. For every three people with more than $50 billion, there could be one with $100 billion or more. There is a much smaller probability of there being someone with more than $200 billion—one third of the previous probability, but nevertheless not zero. There is even a minute, but not zero probability of there being someone worth more than $500 billion.
This tells me the following: I can make inferences about things that I do not see in my data, but these things should still belong to the realm of possibilities. There is an invisible bestseller out there, one that is absent from the past data but that you need to account for. Recall my point in
Chapter 13
: it makes investment in a book or a drug better than statistics on past data might suggest. But it can make stock market losses worse than what the past shows.
Wars are fractal in nature. A war that kills more people than the devastating Second World War is possible—not likely, but not a zero probability, although such a war has never happened in the past.
Second, I will introduce an illustration from nature that will help to make the point about precision. A mountain is somewhat similar to a stone: it has an affinity with a stone, a family resemblance, but it is not identical. The word to describe such resemblances is
self-affine
, not the precise
self-similar
, but Mandelbrot had trouble communicating the notion of affinity, and the term
self-similar
spread with its connotation of precise resemblance rather than family resemblance. As with the mountain and the stone, the distribution of wealth above $1 billion is not exactly the same as that below $1 billion, but the two distributions have “affinity.”
Third, I said earlier that there have been plenty of papers in the world of econophysics (the application of statistical physics to social and economic phenomena) aiming at such calibration, at pulling numbers from the world of phenomena. Many try to be predictive. Alas, we are not able to predict “transitions” into crises or contagions. My friend Didier Sornette attempts to build predictive models, which I love, except that I can
not use them to make predictions—but please don’t tell him; he might stop building them. That I can’t use them as he intends does not invalidate his work, it just makes the interpretations require broad-minded thinking, unlike models in conventional economics that are fundamentally flawed. We may be able to do well with some of Sornette’s phenomena, but not all.


================================================================================
CHAPTER/SECTION 246 (Item 251)
================================================================================

WHERE IS THE GRAY SWAN?
I have written this entire book about the Black Swan. This is not because I am in love with the Black Swan; as a humanist, I hate it. I hate most of the unfairness and damage it causes. Thus I would like to eliminate many Black Swans, or at least to mitigate their effects and be protected from them. Fractal randomness is a way to reduce these surprises, to make some of the swans appear possible, so to speak, to make us aware of their consequences, to make them gray.
But fractal randomness does not yield precise answers
. The benefits are as follows. If you know that the stock market
can
crash, as it did in 1987, then such an event is not a Black Swan. The crash of 1987 is not an outlier if you use a fractal with an exponent of three. If you know that biotech companies can deliver a megablockbuster drug, bigger than all we’ve had so far, then it won’t be a Black Swan, and you will not be surprised, should that drug appear.
Thus Mandelbrot’s fractals allow us to account for a few Black Swans, but not all. I said earlier that some Black Swans arise because we ignore sources of randomness. Others arise when we overestimate the fractal exponent. A gray swan concerns modelable extreme events, a black swan is about unknown unknowns.
I sat down and discussed this with the great man, and it became, as usual, a linguistic game. In
Chapter 9
I presented the distinction economists make between Knightian uncertainty (incomputable) and Knightian risk (computable); this distinction cannot be so original an idea to be absent in our vocabulary, and so we looked for it in French. Mandelbrot mentioned one of his friends and prototypical heroes, the aristocratic mathematician Marcel-Paul Schützenberger, a fine erudite who (like this author) was easily bored and could not work on problems beyond their point of diminishing returns. Schützenberger insisted on the clear-cut distinction in the French language between
hasard
and
fortuit. Hasard
, from the Arabic
az-zahr
, implies, like
alea
, dice—tractable randomness;
fortuit
is my Black Swan—the purely accidental and unforeseen. We went to the
Petit Robert
dictionary; the distinction effectively exists there.
Fortuit
seems to correspond to my epistemic opacity,
l’imprévu et non quantifiable; hasard
to the more ludic type of uncertainty that was proposed by the Chevalier de Méré in the early gambling literature. Remarkably, the Arabs may have introduced another word to the business of uncertainty:
rizk
, meaning property.
I repeat: Mandelbrot deals with gray swans; I deal with the Black Swan. So Mandelbrot domesticated many of my Black Swans, but not all of them, not completely. But he shows us a glimmer of hope with his method, a way to start thinking about the problems of uncertainty. You are indeed much safer if you know where the wild animals are.
*
The nontechnical reader can skip from here until the end of the chapter.
*
By using symmetry we could also examine the incidences below the number.
*
Clearly, you do not observe 100 percent in a finite sample
.
*
The defense mechanism when you question their work is to say that they “do science, not philosophy” and to berate my approach of worrying about model errors. This is a common trap: people think that science is about formulating predictions (even when wrong). To me, science is about how not to be a sucker.


================================================================================
CHAPTER/SECTION 247 (Item 252)
================================================================================

Chapter Seventeen
LOCKE’S MADMEN, OR BELL CURVES IN THE WRONG PLACES
*
What?—Anyone can become president—Alfred Nobel’s legacy—Those medieval days
I have in my house two studies: one real, with interesting books and literary material; the other nonliterary, where I do not enjoy working, where I relegate matters prosaic and narrowly focused. In the nonliterary study is a wall full of books on statistics and the history of statistics, books I never had the fortitude to burn or throw away; though I find them largely useless outside of their academic applications (Carneades, Cicero, and Foucher know a lot more about probability than all these pseudosophisticated volumes). I cannot use them in class because I promised myself never to teach trash, even if dying of starvation. Why can’t I use them? Not one of these books deals with Extremistan. Not one. The few books that do are not by statisticians but by statistical physicists. We are teaching people methods from Mediocristan and turning them loose in Extremistan. It is like developing a medicine for plants and applying it to humans. It is no wonder that we run the biggest risk of all: we handle
matters that belong
to Extremistan, but treated as if they belonged to Mediocristan
, as an “approximation.”
Several hundred thousand students in business schools and social science departments from Singapore to Urbana-Champaign, as well as people in the business world, continue to study “scientific” methods, all grounded in the Gaussian, all embedded in the ludic fallacy.
This chapter examines disasters stemming from the application of phony mathematics to social science. The real topic might be the dangers to our society brought about by the Swedish academy that awards the Nobel Prize.
Only Fifty Years
Let us return to the story of my business life. Look at the graph in
Figure 14
. In the last fifty years, the ten most extreme days in the financial markets represent half the returns. Ten days in fifty years. Meanwhile, we are mired in chitchat.
Clearly, anyone who wants more than the high number of six sigma as proof that markets are from Extremistan needs to have his head examined. Dozens of papers show the inadequacy of the Gaussian family of distributions and the scalable nature of markets. Recall that, over the years, I myself have run statistics backward and forward on 20 million pieces of data that made me despise anyone talking about markets in Gaussian terms. But people have a hard time making the leap to the consequences of this knowledge.
The strangest thing is that people in business usually agree with me when they listen to me talk or hear me make my case. But when they go to the office the next day they revert to the Gaussian tools so entrenched in their habits. Their minds are domain-dependent, so they can exercise critical thinking at a conference while not doing so in the office. Furthermore, the Gaussian tools give them numbers, which seem to be “better than nothing.” The resulting measure of future uncertainty satisfies our ingrained desire to simplify even if that means squeezing into one single number matters that are too rich to be described that way.
The Clerks’ Betrayal
I ended
Chapter 1
with the stock market crash of 1987, which allowed me to aggressively pursue my Black Swan idea. Right after the crash, when I stated that those using sigmas (i.e., standard deviations) as a measure of the degree of risk and randomness were charlatans, everyone agreed with me. If the world of finance were Gaussian, an episode such as the crash (more than twenty standard deviations) would take place every several billion lifetimes of the universe (look at the height example in
Chapter 15
). According to the circumstances of 1987, people accepted that rare events take place and are the main source of uncertainty. They were just unwilling to give up on the Gaussian as a central measurement tool—“Hey, we have nothing else.” People want a number to anchor on. Yet the two methods are logically incompatible.
FIGURE 14
By removing the ten biggest one-day moves from the U.S. stock market over the past fifty years, we see a huge difference in returns—and yet conventional finance sees these one-day jumps as mere anomalies. (This is only one of many such tests. While it is quite convincing on a casual read, there are many more-convincing ones from a mathematical standpoint, such as the incidence of 10 sigma events.)
Unbeknownst to me, 1987 was not the first time the idea of the Gaussian was shown to be lunacy. Mandelbrot proposed the scalable to the economics establishment around 1960, and showed them how the Gaussian curve did not fit prices
then
. But after they got over their excitement, they realized that they would have to relearn their trade. One of the influential economists of the day, the late Paul Cootner, wrote, “Mandelbrot, like Prime Minister Churchill before him, promised us not utopia, but blood, sweat, toil, and tears. If he is right, almost all our statistical tools are obsolete [or] meaningless.” I propose two corrections to Cootner’s statement. First, I would replace
almost all
with
all
. Second, I disagree with the blood and sweat business. I find Mandelbrot’s randomness considerably
easier to understand than the conventional statistics. If you come fresh to the business, do not rely on the old theoretical tools, and do not have a high expectation of certainty.
Anyone Can Become President
And now a brief history of the “Nobel” Prize in economics, which was established by the Bank of Sweden in honor of Alfred Nobel, who may be, according to his family who wants the prize abolished, now rolling in his grave with disgust. An activist family member calls the prize a public relations coup by economists aiming to put their field on a higher footing than it deserves. True, the prize has gone to some valuable thinkers, such as the empirical psychologist Daniel Kahneman and the thinking economist Friedrich Hayek. But the committee has gotten into the habit of handing out Nobel Prizes to those who “bring rigor” to the process with pseudoscience and phony mathematics.
After
the stock market crash, they rewarded two theoreticians, Harry Markowitz and William Sharpe, who built beautifully Platonic models on a Gaussian base, contributing to what is called Modern Portfolio Theory. Simply, if you remove their Gaussian assumptions and treat prices as scalable, you are left with hot air. The Nobel Committee could have tested the Sharpe and Markowitz models—they work like quack remedies sold on the Internet—but nobody in Stockholm seems to have thought of it. Nor did the committee come to us practitioners to ask us our opinions; instead it relied on an academic vetting process that, in some disciplines, can be corrupt all the way to the marrow. After that award I made a prediction: “In a world in which these two get the Nobel, anything can happen. Anyone can become president.”
So the Bank of Sweden and the Nobel Academy are largely responsible for giving credence to the use of the Gaussian Modern Portfolio Theory as institutions have found it a great cover-your-behind approach. Software vendors have sold “Nobel crowned” methods for millions of dollars. How could you go wrong using it? Oddly enough, everyone in the business world initially knew that the idea was a fraud, but people get used to such methods. Alan Greenspan, the chairman of the Federal Reserve bank, supposedly blurted out, “I’d rather have the opinion of a trader than a mathematician.” Meanwhile, the Modern Portfolio Theory started spreading. I will repeat the following until I am hoarse: it is contagion that determines the fate of a theory in social science, not its validity.
I only realized later that Gaussian-trained finance professors were taking
over business schools, and therefore MBA programs, and producing close to a hundred thousand students a year in the United States alone, all brainwashed by a phony portfolio theory. No empirical observation could halt the epidemic. It seemed better to teach students a theory based on the Gaussian than to teach them no theory at all. It looked more “scientific” than giving them what Robert C. Merton (the son of the sociologist Robert K. Merton we discussed earlier) called the “anecdote.” Merton wrote that before portfolio theory, finance was “a collection of anecdotes, rules of thumb, and manipulation of accounting data.” Portfolio theory allowed “the subsequent evolution from this conceptual potpourri to a rigorous economic theory.” For a sense of the degree of intellectual seriousness involved, and to compare neoclassical economics to a more honest science, consider this statement from the nineteenth-century father of modern medicine, Claude Bernard: “Facts for now, but with scientific aspirations for later.” You should send economists to medical school.
So the Gaussian
*
pervaded our business and scientific cultures, and terms such as
sigma, variance, standard deviation, correlation, R square
, and the eponymous
Sharpe ratio
, all directly linked to it, pervaded the lingo. If you read a mutual fund prospectus, or a description of a hedge fund’s exposure, odds are that it will supply you, among other information, with some quantitative summary claiming to measure “risk.” That measure will be based on one of the above buzzwords derived from the bell curve and its kin. Today, for instance, pension funds’ investment policy and choice of funds are vetted by “consultants” who rely on portfolio theory. If there is a problem, they can claim that they relied on standard scientific method.
More Horror
Things got a lot worse in 1997. The Swedish academy gave another round of Gaussian-based Nobel Prizes to Myron Scholes and Robert C. Merton, who had improved on an old mathematical formula and made it compatible with the existing grand Gaussian general financial equilibrium
theories—hence acceptable to the economics establishment. The formula was now “useable.” It had a list of long forgotten “precursors,” among whom was the mathematician and gambler Ed Thorp, who had authored the bestselling
Beat the Dealer
, about how to get ahead in blackjack, but somehow people believe that Scholes and Merton invented it, when in fact they just made it acceptable. The formula was my bread and butter. Traders, bottom-up people, know its wrinkles better than academics by dint of spending their nights worrying about their risks, except that few of them could express their ideas in technical terms, so I felt I was representing them. Scholes and Merton made the formula dependent on the Gaussian, but their “precursors” subjected it to no such restriction.
*
The postcrash years were entertaining for me, intellectually. I attended conferences in finance and mathematics of uncertainty; not once did I find a speaker, Nobel or no Nobel, who understood what he was talking about when it came to probability, so I could freak them out with my questions. They did “deep work in mathematics,” but when you asked them where they got their probabilities, their explanations made it clear that they had fallen for the ludic fallacy—there was a strange cohabitation of technical skills and absence of understanding that you find in idiot savants. Not once did I get an intelligent answer or one that was not ad hominem. Since I was questioning their entire business, it was understandable that I drew all manner of insults: “obsessive,” “commercial,” “philosophical,” “essayist,” “idle man of leisure,” “repetitive,” “practitioner” (this is an insult in academia), “academic” (this is an insult in business). Being on the receiving end of angry insults is not that bad; you can get quickly used to it and focus on what is
not
said. Pit traders are trained to handle angry rants. If you work in the chaotic pits, someone in a particularly bad mood from losing money might start cursing at you until he injures his vocal cords, then forget about it and, an hour later, invite you to his Christmas party. So you become numb to insults, particularly if you teach yourself to imagine that the person uttering them is a variant of a noisy ape with little personal control. Just keep your composure, smile, focus on analyzing the speaker not the message, and you’ll win the argument. An ad hominem
attack against an intellectual, not against an idea, is highly flattering. It indicates that the person does not have anything intelligent to say about your message.
The psychologist Philip Tetlock (the expert buster in
Chapter 10
), after listening to one of my talks, reported that he was struck by the presence of an acute state of cognitive dissonance in the audience. But how people resolve this cognitive tension, as it strikes at the core of everything they have been taught and at the methods they practice, and realize that they will continue to practice, can vary a lot. It was symptomatic that almost all people who attacked my thinking attacked a deformed version of it, like “it is all random and unpredictable” rather than “it is largely random,” or got mixed up by showing me how the bell curve works in some physical domains. Some even had to change my biography. At a panel in Lugano, Myron Scholes once got in to a state of rage, and went after a transformed version of my ideas. I could see pain in his face. Once, in Paris, a prominent member of the mathematical establishment, who invested part of his life on some minute sub-sub-property of the Gaussian, blew a fuse—right when I showed empirical evidence of the role of Black Swans in markets. He turned red with anger, had difficulty breathing, and started hurling insults at me for having desecrated the institution, lacking
pudeur
(modesty); he shouted “I am a member of the Academy of Science!” to give more strength to his insults. (The French translation of my book was out of stock the next day.) My best episode was when Steve Ross, an economist perceived to be an intellectual far superior to Scholes and Merton, and deemed a formidable debater, gave a rebuttal to my ideas by signaling small errors or approximations in my presentation, such as “Markowitz was not the first to …” thus certifying that he had no answer to my main point. Others who had invested much of their lives in these ideas resorted to vandalism on the Web. Economists often invoke a strange argument by Milton Friedman that states that models do not have to have realistic assumptions to be acceptable—giving them license to produce severely defective mathematical representations of reality. The problem of course is that these Gaussianizations do not have realistic assumptions and do not produce reliable results. They are neither realistic nor predictive. Also note a mental bias I encounter on the occasion: people mistake an event with a small probability, say, one in twenty years for a periodically occurring one. They think that they are safe if they are only exposed to it for ten years.
I had trouble getting the message about the difference between Mediocristan and Extremistan through—many arguments presented to me were
about how society has done well with the bell curve—just look at credit bureaus, etc.
The only comment I found unacceptable was, “You are right; we need you to remind us of the weakness of these methods, but you cannot throw the baby out with the bath water,” meaning that I needed to accept their reductive Gaussian distribution while also accepting that large deviations could occur—they didn’t realize the incompatibility of the two approaches. It was as if one could be half dead. Not one of these users of portfolio theory in twenty years of debates, explained
how
they could accept the Gaussian framework as well as large deviations. Not one.
Confirmation
Along the way I saw enough of the confirmation error to make Karl Popper stand up with rage. People would find data in which there were no jumps or extreme events, and show me a “proof” that one could use the Gaussian. This was exactly like my example of the “proof” that O. J. Simpson is not a killer in
Chapter 5
. The entire statistical business confused absence of proof with proof of absence. Furthermore, people did not understand the elementary asymmetry involved: you need one single observation to reject the Gaussian, but millions of observations will not fully confirm the validity of its application. Why? Because the Gaussian bell curve disallows large deviations, but tools of Extremistan, the alternative, do not disallow long quiet stretches.
I did not know that Mandelbrot’s work mattered outside aesthetics and geometry. Unlike him, I was not ostracized: I got a lot of approval from practitioners and decision makers, though not from their research staffs.
But suddenly I got the most unexpected vindication.


================================================================================
CHAPTER/SECTION 248 (Item 253)
================================================================================

IT WAS JUST A BLACK SWAN
Robert Merton, Jr., and Myron Scholes were founding partners in the large speculative trading firm called Long-Term Capital Management, or LTCM, which I mentioned in
Chapter 4
. It was a collection of people with top-notch résumés, from the highest ranks of academia. They were considered geniuses. The ideas of portfolio theory inspired their risk management of possible outcomes—thanks to their sophisticated “calculations.” They managed to enlarge the ludic fallacy to industrial proportions.
Then, during the summer of 1998, a combination of large events, triggered by a Russian financial crisis, took place that lay outside their models. It was a Black Swan. LTCM went bust and almost took down the entire financial system with it, as the exposures were massive. Since their models ruled out the possibility of large deviations, they allowed themselves to take a monstrous amount of risk. The ideas of Merton and Scholes, as well as those of Modern Portfolio Theory, were starting to go bust. The magnitude of the losses was spectacular, too spectacular to allow us to ignore the intellectual comedy. Many friends and I thought that the portfolio theorists would suffer the fate of tobacco companies: they were endangering people’s savings and would soon be brought to account for the consequences of their Gaussian-inspired methods.
None of that happened.
Instead, MBAs in business schools went on learning portfolio theory. And the option formula went on bearing the name Black-Scholes-Merton, instead of reverting to its true owners, Louis Bachelier, Ed Thorp, and others.
How to “Prove” Things
Merton the younger is a representative of the school of neoclassical economics, which, as we have seen with LTCM, represents most powerfully the dangers of Platonified knowledge.
*
Looking at his methodology, I see the following pattern. He starts with rigidly Platonic assumptions, completely unrealistic—such as the Gaussian probabilities, along with many more equally disturbing ones. Then he generates “theorems” and “proofs” from these. The math is tight and elegant. The theorems are compatible with other theorems from Modern Portfolio Theory, themselves compatible with still other theorems, building a grand theory of how people consume, save, face uncertainty, spend, and project the future. He assumes that we know the likelihood of events. The beastly word
equilibrium
is always present. But the whole edifice is like a game that is entirely closed, like Monopoly with all of its rules.
A scholar who applies such methodology resembles Locke’s definition of a madman: someone “reasoning correctly from erroneous premises.”
Now, elegant mathematics has this property: it is perfectly right, not 99 percent so. This property appeals to mechanistic minds who do not want to deal with ambiguities. Unfortunately you have to cheat somewhere to make the world fit perfect mathematics; and you have to fudge your assumptions somewhere. We have seen with the Hardy quote that professional “pure” mathematicians, however, are as honest as they come.
So where matters get confusing is when someone like Merton tries to be mathematical and airtight rather than focus on fitness to reality.
This is where you learn from the minds of military people and those who have responsibilities in security. They do not care about “perfect” ludic reasoning; they want realistic ecological assumptions. In the end, they care about lives.
I mentioned in
Chapter 11
how those who started the game of “formal thinking,” by manufacturing phony premises in order to generate “rigorous” theories, were Paul Samuelson, Merton’s tutor, and, in the United Kingdom, John Hicks. These two wrecked the ideas of John Maynard Keynes, which they tried to formalize (Keynes was interested in uncertainty, and complained about the mind-closing certainties induced by models). Other participants in the formal thinking venture were Kenneth Arrow and Gerard Debreu. All four were Nobeled. All four were in a delusional state under the effect of mathematics—what Dieudonné called “the music of reason,” and what I call Locke’s madness. All of them can be safely accused of having invented an imaginary world, one that lent itself to their mathematics. The insightful scholar Martin Shubik, who held that the degree of excessive abstraction of these models, a few steps beyond necessity, makes them totally unusable, found himself ostracized, a common fate for dissenters.
*
If you question what they do, as I did with Merton Jr., they will ask for “tight proof.” So they set the rules of the game, and you need to play by them. Coming from a practitioner background in which the principal asset is being able to work with messy, but empirically acceptable, mathematics, I cannot accept a pretense of science. I much prefer a sophisticated craft, focused on tricks, to a failed science looking for certainties. Or could these neoclassical model builders be doing something worse? Could it be that they are involved in what Bishop Huet calls the manufacturing of certainties?
TABLE 4: TWO WAYS TO APPROACH RANDOMNESS
Skeptical Empiricism and the a-Platonic School
The Platonic Approach
Interested in what lies outside the Platonic fold
Focuses on the inside of the Platonic fold
Respect for those who have the guts to say “I don’t know”
“You keep criticizing these models. These models are all we have.”
Fat Tony
Dr. John
Thinks of Black Swans as a dominant source of randomness
Thinks of ordinary fluctuations as a dominant source of randomness, with jumps as an afterthought
Bottom-up
Top-down
Would ordinarily not wear suits (except to funerals)
Wears dark suits, white shirts; speaks in a boring tone
Prefers to be broadly right
Precisely wrong
Minimal theory, consides theorizing as a disease to resist
Everything needs to fit some grand, general socioeconomic model and “the rigor of economic theory;” frowns on the “descriptive”
Does not believe that we can easily compute probabilities
Built their entire apparatus on the assumptions that we can compute probabilities
Model: Sextus Empiricus and the school of evidence-based, minimum-theory empirical medicine
Model: Laplacian mechanics, the world and the economy like a clock
Develops intuitions from practice, goes from observations to books
Relies on scientific papers, goes from books to practice
Not inspired by any science, uses messy mathematics and computational methods
Inspired by physics, relies on abstract mathematics
Ideas based on skepticism, on the unread books in the library
Ideas based on beliefs, on what they think they know
Assumes Extremistan as a starting point
Assumes Mediocristan as a starting point
Sophisticated craft
Poor science
Seeks to be approximately right across a broad set of eventualities
Seeks to be perfectly right in a narrow model, under precise assumptions
Let us see.
Skeptical empiricism advocates the opposite method. I care about the premises more than the theories, and I want to minimize reliance on theories, stay light on my feet, and reduce my surprises. I want to be broadly right rather than precisely wrong. Elegance in the theories is often indicative of Platonicity and weakness—it invites you to seek elegance for elegance’s sake. A theory is like medicine (or government): often useless, sometimes necessary, always self-serving, and on occasion lethal. So it needs to be used with care, moderation, and close adult supervision.
The distinction in the above table between my model modern, skeptical empiricist and what Samuelson’s puppies represent can be generalized across disciplines.
I’ve presented my ideas in finance because that’s where I refined them. Let us now examine a category of people expected to be more thoughtful: the philosophers.
*
This is a simple illustration of the general point of this book in finance and economics. If you do not believe in applying the bell curve to social variables, and if, like many professionals, you are already convinced that “modern” financial theory is dangerous junk science, you can safely skip this chapter.
*
Granted, the Gaussian has been tinkered with, using such methods as complementary “jumps,” stress testing, regime switching, or the elaborate methods known as GARCH, but while these methods represent a good effort, they fail to address the bell curve’s fundamental flaws. Such methods are not scale-invariant. This, in my opinion, can explain the failures of sophisticated methods in real life as shown by the Makridakis competition.
*
More technically, remember my career as an option professional. Not only does an option on a very long shot benefit from Black Swans, but it benefits disproportionately from them—something Scholes and Merton’s “formula” misses. The option payoff is so powerful that you do not have to be right on the odds: you can be wrong on the probability, but get a monstrously large payoff. I’ve called this the “double bubble”: the mispricing of the probability and that of the payoff.
*
I am selecting Merton because I found him very illustrative of academically stamped obscurantism. I discovered Merton’s shortcomings from an angry and threatening seven-page letter he sent me that gave me the impression that he was not too familiar with how we trade options, his very subject matter. He seemed to be under the impression that traders rely on “rigorous” economic theory—as if birds had to study (bad) engineering in order to fly.
*
Medieval medicine was also based on equilibrium ideas when it was top-down and similar to theology. Luckily its practitioners went out of business, as they could not compete with the bottom-up surgeons, ecologically driven former barbers who gained clinical experience, and after whom a-Platonic clinical science was born. If I am alive, today, it is because scholastic top-down medicine went out of business a few centuries ago.


================================================================================
CHAPTER/SECTION 249 (Item 254)
================================================================================

Chapter Eighteen
THE UNCERTAINTY OF THE PHONY
Philosophers in the wrong places—Uncertainty about (mostly) lunch—What I don’t care about—Education and intelligence
This final chapter of Part Three focuses on a major ramification of the ludic fallacy: how those whose job it is to make us aware of uncertainty fail us and divert us into bogus certainties through the back door.


================================================================================
CHAPTER/SECTION 250 (Item 255)
================================================================================

LUDIC FALLACY REDUX
I have explained the ludic fallacy with the casino story, and have insisted that the sterilized randomness of games does not resemble randomness in real life. Look again at
Figure 7
in
Chapter 15
. The dice average out so quickly that I can say with certainty that the casino will beat me in the very near long run at, say, roulette, as the noise will cancel out, though not the skills (here, the casino’s advantage). The more you extend the period (or reduce the size of the bets) the more randomness, by virtue of averaging, drops out of these gambling constructs.
The ludic fallacy is present in the following chance setups: random walk, dice throwing, coin flipping, the infamous digital “heads or tails” expressed as 0 or 1, Brownian motion (which corresponds to the movement of pollen particles in water), and similar examples. These setups generate
a quality of randomness that does not even qualify as randomness—
protorandomness
would be a more appropriate designation. At their core, all theories built around the ludic fallacy ignore a layer of uncertainty. Worse, their proponents do not know it!
One severe application of such focus on small, as opposed to large, uncertainty concerns the hackneyed
greater uncertainty principle
.
Find the Phony
The greater uncertainty principle states that in quantum physics, one cannot measure certain pairs of values (with arbitrary precision), such as the position and momentum of particles. You will hit a lower bound of measurement: what you gain in the precision of one, you lose in the other. So there is an incompressible uncertainty that, in theory, will defy science and forever remain an uncertainty. This minimum uncertainty was discovered by Werner Heisenberg in 1927. I find it ludicrous to present the uncertainty principle as having anything to do with uncertainty. Why? First, this uncertainty is Gaussian. On average, it will disappear—recall that no one person’s weight will significantly change the total weight of a thousand people. We may always remain uncertain about the future positions of small particles, but these uncertainties are very small and very numerous, and they average out—for Pluto’s sake, they average out! They obey the law of large numbers we discussed in
Chapter 15
. Most other types of randomness do not average out! If there is one thing on this planet that is not so uncertain, it is the behavior of a collection of subatomic particles! Why? Because, as I have said earlier, when you look at an object, composed of a collection of particles, the fluctuations of the particles tend to balance out.
But political, social, and weather events do not have this handy property, and we patently cannot predict them, so when you hear “experts” presenting the problems of uncertainty in terms of subatomic particles, odds are that the expert is a phony. As a matter of fact, this may be the best way to spot a phony.
I often hear people say, “Of course there are limits to our knowledge,” then invoke the greater uncertainty principle as they try to explain that “we cannot model everything”—I have heard such types as the economist Myron Scholes say this at conferences. But I am sitting here in New York, in August 2006, trying to go to my ancestral village of Amioun, Lebanon. Beirut’s airport is closed owing to the conflict between Israel and the Shiite
militia Hezbollah. There is no published airline schedule that will inform me when the war will end, if it ends. I can’t figure out if my house will be standing, if Amioun will still be on the map—recall that the family house was destroyed once before. I can’t figure out whether the war is going to degenerate into something even more severe. Looking into the outcome of the war, with all my relatives, friends, and property exposed to it, I face
true
limits of knowledge. Can someone explain to me why I should care about subatomic particles that, anyway, converge to a Gaussian? People can’t predict how long they will be happy with recently acquired objects, how long their marriages will last, how their new jobs will turn out, yet it’s subatomic particles that they cite as “limits of prediction.” They’re ignoring a mammoth standing in front of them in favor of matter even a microscope would not allow them to see.
Can Philosophers Be Dangerous to Society?
I will go further: people who worry about pennies instead of dollars can be dangerous to society. They mean well, but, invoking my Bastiat argument of
Chapter 8
, they are a threat to us. They are wasting our studies of uncertainty by focusing on the insignificant. Our resources (both cognitive and scientific) are limited, perhaps too limited. Those who distract us increase the risk of Black Swans.
This commoditization of the notion of uncertainty as symptomatic of Black Swan blindness is worth discussing further here.
Given that people in finance and economics are seeped in the Gaussian to the point of choking on it, I looked for financial economists with philosophical bents to see how their critical thinking allows them to handle this problem. I found a few. One such person got a PhD in philosophy, then, four years later, another in finance; he published papers in both fields, as well as numerous textbooks in finance. But I was disheartened by him: he seemed to have compartmentalized his ideas on uncertainty so that he had two distinct professions: philosophy and quantitative finance. The problem of induction, Mediocristan, epistemic opacity, or the offensive assumption of the Gaussian—these did not hit him as true problems. His numerous textbooks drilled Gaussian methods into students’ heads, as though their author had forgotten that he was a philosopher. Then he promptly remembered that he was when writing philosophy texts on seemingly scholarly matters.
The same context specificity leads people to take the escalator to the StairMasters, but the philosopher’s case is far, far more dangerous since he uses up our storage for critical thinking in a sterile occupation. Philosophers like to practice philosophical thinking on me-too subjects that other philosophers call philosophy, and they leave their minds at the door when they are outside of these subjects.
The Problem of Practice
As much as I rail against the bell curve, Platonicity, and the ludic fallacy, my principal problem is not so much with statisticians—after all, these are computing people, not thinkers. We should be far less tolerant of philosophers, with their bureaucratic apparatchiks closing our minds. Philosophers, the watchdogs of critical thinking, have duties beyond those of other professions.


================================================================================
CHAPTER/SECTION 251 (Item 256)
================================================================================

HOW MANY WITTGENSTEINS CAN DANCE ON THE HEAD OF A PIN?
A number of semishabbily dressed (but thoughtful-looking) people gather in a room, silently looking at a guest speaker. They are all professional philosophers attending the prestigious weekly colloquium at a New York–area university. The speaker sits with his nose drowned in a set of typewritten pages, from which he reads in a monotone voice. He is hard to follow, so I daydream a bit and lose his thread. I can vaguely tell that the discussion revolves around some “philosophical” debate about Martians invading your head and controlling your will, all the while preventing you from knowing it. There seem to be several theories concerning this idea, but the speaker’s opinion differs from those of other writers on the subject. He spends some time showing where his research on these head-hijacking Martians is unique. After his monologue (fifty-five minutes of relentless reading of the typewritten material) there is a short break, then another fifty-five minutes of discussion about Martians planting chips and other outlandish conjectures. Wittgenstein is occasionally mentioned (you can always mention Wittgenstein since he is vague enough to always seem relevant).
Every Friday, at four
P.M
., the paychecks of these philosophers will hit their respective bank accounts. A fixed proportion of their earnings, about 16 percent on average, will go into the stock market in the form of an automatic
investment into the university’s pension plan. These people are professionally employed in the business of questioning what we take for granted; they are trained to argue about the existence of god(s), the definition of truth, the redness of red, the meaning of meaning, the difference between the semantic theories of truth, conceptual and nonconceptual representations … Yet they believe blindly in the stock market, and in the abilities of their pension plan manager. Why do they do so? Because they accept that this is what people should do with their savings, because “experts” tell them so. They doubt their own senses, but not for a second do they doubt their automatic purchases in the stock market. This domain dependence of skepticism is no different from that of medical doctors (as we saw in
Chapter 8
).
Beyond this, they may believe without question that we can predict societal events, that the Gulag will toughen you a bit, that politicians know more about what is going on than their drivers, that the chairman of the Federal Reserve saved the economy, and so many such things. They may also believe that nationality matters (they always stick “French,” “German,” or “American” in front of a philosopher’s name, as if this has something to do with anything he has to say). Spending time with these people, whose curiosity is focused on regimented on-the-shelf topics, feels stifling.
Where Is Popper When You Need Him?
I hope I’ve sufficiently drilled home the notion that, as a practitioner, my thinking is rooted in the belief that you cannot go from books to problems, but the reverse, from problems to books. This approach incapacitates much of that career-building verbiage. A scholar should not be a library’s tool for making another library, as in the joke by Daniel Dennett.
Of course, what I am saying here has been said by philosophers before, at least by the real ones. The following remark is one reason I have inordinate respect for Karl Popper; it is one of the few quotations in this book that I am not attacking.
The degeneration of philosophical schools in its turn is the consequence of the mistaken belief that one can philosophize without having been compelled to philosophize by problems outside philosophy. …
Genuine philosophical problems are always rooted outside philosophy and they die if these roots decay. …
[emphasis mine] These roots are
easily forgotten by philosophers who “study” philosophy instead of being forced into philosophy by the pressure of nonphilosophical problems.
Such thinking may explain Popper’s success outside philosophy, particularly with scientists, traders, and decision makers, as well as his relative failure inside of it. (He is rarely studied by his fellow philosophers; they prefer to write essays on Wittgenstein.)
Also note that I do not want to be drawn into philosophical debates with my Black Swan idea. What I mean by Platonicity is not so metaphysical. Plenty of people have argued with me about whether I am against “essentialism” (i.e., things that I hold don’t have a Platonic essence), if I believe that mathematics would work in an alternative universe, or some such thing. Let me set the record straight. I am a no-nonsense practitioner; I am not saying that mathematics does not correspond to an objective structure of reality; my entire point is that we are, epistemologically speaking, putting the cart before the horse and, of the space of possible mathematics, risk using the wrong one and being blinded by it. I truly believe that there are some mathematics that work, but that these are not as easily within our reach as it seems to the “confirmators.”
The Bishop and the Analyst
I am most often irritated by those who attack the bishop but somehow fall for the securities analyst—those who exercise their skepticism against religion but not against economists, social scientists, and phony statisticians. Using the confirmation bias, these people will tell you that religion was horrible for mankind by counting deaths from the Inquisition and various religious wars. But they will not show you how many people were killed by nationalism, social science, and political theory under Stalinism or during the Vietnam War. Even priests don’t go to bishops when they feel ill: their first stop is the doctor’s. But we stop by the offices of many pseudo-scientists and “experts” without alternative. We no longer believe in papal infallibility; we seem to believe in the infallibility of the Nobel, though, as we saw in
Chapter 17
.
Easier Than You Think: The Problem of Decision Under Skepticism
I have said all along that there is a problem with induction and the Black Swan. In fact, matters are far worse: we may have no less of a problem with phony skepticism.
I can’t do anything to stop the sun from nonrising tomorrow (no matter how hard I try),
I can’t do anything about whether or not there is an afterlife,
I can’t do anything about Martians or demons taking hold of my brain.
But I have plenty of ways to avoid being a sucker. It is not much more difficult than that.
I conclude Part Three by reiterating that my antidote to Black Swans is precisely to be noncommoditized in my thinking. But beyond avoiding being a sucker, this attitude lends itself to a protocol of how to act—not how to think, but how to convert knowledge into action and figure out what knowledge is worth. Let us examine what to do or not do with this in the concluding section of this book.


================================================================================
CHAPTER/SECTION 252 (Item 258)
================================================================================

Chapter Nineteen
HALF AND HALF, OR HOW TO GET EVEN WITH THE BLACK SWAN
The other half—Remember Apelles—When missing a train can be painful
It is now time for a few last words.
Half the time I am a hyperskeptic; the other half I hold certainties and can be intransigent about them, with a very stubborn disposition. Of course I am hyperskeptic where others, particularly those I call
bildungsphilisters
, are gullible, and gullible where others seem skeptical. I am skeptical about confirmation—though only when errors are costly—not about disconfirmation. Having plenty of data will not provide confirmation, but a single instance can disconfirm. I am skeptical when I suspect wild randomness, gullible when I believe that randomness is mild.
Half the time I hate Black Swans, the other half I love them. I like the randomness that produces the texture of life, the positive accidents, the success of Apelles the painter, the potential gifts you do not have to pay for. Few understand the beauty in the story of Apelles; in fact, most people exercise their error avoidance by repressing the Apelles in them.
Half the time I am hyperconservative in the conduct of my own affairs; the other half I am hyperaggressive. This may not seem exceptional, except that my conservatism applies to what others call risk taking, and my aggressiveness to areas where others recommend caution.
I worry less about small failures, more about large, potentially terminal
ones. I worry far more about the “promising” stock market, particularly the “safe” blue chip stocks, than I do about speculative ventures—the former present invisible risks, the latter offer no surprises since you know how volatile they are and can limit your downside by investing smaller amounts.
I worry less about advertised and sensational risks, more about the more vicious hidden ones. I worry less about terrorism than about diabetes, less about matters people usually worry about because they are obvious worries, and more about matters that lie outside our consciousness and common discourse (I also have to confess that I do not worry a lot—I try to worry about matters I can do something about). I worry less about embarrassment than about missing an opportunity.
In the end this is a trivial decision making rule: I am very aggressive when I can gain exposure to positive Black Swans—when a failure would be of small moment—and very conservative when I am under threat from a negative Black Swan. I am very aggressive when an error in a model can benefit me, and paranoid when the error can hurt. This may not be too interesting except that it is exactly what other people do not do. In finance, for instance, people use flimsy theories to manage their risks and put wild ideas under “rational” scrutiny.
Half the time I am intellectual, the other half I am a no-nonsense practitioner. I am no-nonsense and practical in academic matters, and intellectual when it comes to practice.
Half the time I am shallow, the other half I want to avoid shallowness. I am shallow when it comes to aesthetics; I avoid shallowness in the context of risks and returns. My aestheticism makes me put poetry before prose, Greeks before Romans, dignity before elegance, elegance before culture, culture before erudition, erudition before knowledge, knowledge before intellect, and intellect before truth. But only for matters that are Black Swan free. Our tendency is to be very rational, except when it comes to the Black Swan.
Half the people I know call me irreverent (you have read my comments about your local Platonified professors), half call me fawning (you have seen my slavish devotion to Huet, Bayle, Popper, Poincaré, Montaigne, Hayek, and others).
Half the time I hate Nietzsche, the other half I like his prose.


================================================================================
CHAPTER/SECTION 253 (Item 259)
================================================================================

WHEN MISSING A TRAIN IS PAINLESS
I once received another piece of life-changing advice, which, unlike the advice I got from a friend in
Chapter 3
, I find applicable, wise, and empirically valid. My classmate in Paris, the novelist-to-be Jean-Olivier Tedesco, pronounced, as he prevented me from running to catch a subway, “I don’t run for trains.”
Snub your destiny. I have taught myself to resist running to keep on schedule. This may seem a very small piece of advice, but it registered. In refusing to run to catch trains, I have felt the true value of
elegance
and aesthetics in behavior, a sense of being in control of my time, my schedule, and my life.
Missing a train is only painful if you run after it!
Likewise, not matching the idea of success others expect from you is only painful if that’s what you are seeking.
You stand
above
the rat race and the pecking order, not
outside
of it, if you do so by choice.
Quitting a high-paying position, if it is
your
decision, will seem a better payoff than the utility of the money involved (this may seem crazy, but I’ve tried it and it works). This is the first step toward the stoic’s throwing a four-letter word at fate. You have far more control over your life if you decide on your criterion by yourself.
Mother Nature has given us some defense mechanisms: as in Aesop’s fable, one of these is our ability to consider that the grapes we cannot (or did not) reach are sour. But an aggressively stoic
prior
disdain and rejection of the grapes is even more rewarding. Be aggressive; be the one to resign, if you have the guts.
It is more difficult to be a loser in a game you set up yourself.
In Black Swan terms, this means that you are exposed to the improbable only if you let it control you. You always control what
you
do; so make this your end.


================================================================================
CHAPTER/SECTION 254 (Item 260)
================================================================================

THE END
But all these ideas, all this philosophy of induction, all these problems with knowledge, all these wild opportunities and scary possible losses, everything palls in front of the following metaphysical consideration.
I am sometimes taken aback by how people can have a miserable day or get angry because they feel cheated by a bad meal, cold coffee, a social rebuff, or a rude reception. Recall my discussion in
Chapter 8
on the difficulty
in seeing the true odds of the events that run your own life. We are quick to forget that just being alive is an extraordinary piece of good luck, a remote event, a chance occurrence of monstrous proportions.
Imagine a speck of dust next to a planet a billion times the size of the earth. The speck of dust represents the odds in favor of your being born; the huge planet would be the odds against it. So stop sweating the small stuff. Don’t be like the ingrate who got a castle as a present and worried about the mildew in the bathroom. Stop looking the gift horse in the mouth—remember that you are a Black Swan. And thank you for reading my book.


================================================================================
CHAPTER/SECTION 255 (Item 261)
================================================================================

Epilogue
YEVGENIA’S WHITE SWANS
Yevgenia Krasnova went into the long hibernation that was necessary for producing a new book. She stayed in New York City, where she found it easiest to find tranquillity, alone with her text. It was easiest to concentrate after long periods during which she was surrounded by crowds, hoping to run into Nero so she could make a snide remark to him, perhaps humiliate him, possibly win him back. She canceled her e-mail account, switched to writing longhand, since she found it soothing, and hired a secretary to type her text. She spent eight years writing, erasing, correcting, venting her occasional anger at the secretary, interviewing new secretaries, and quietly rewriting. Her apartment was full of smoke, with papers strewn on every surface. Like all artists she remained dissatisfied with the state of completion of her work, yet she felt that she had gone far deeper than with her first book. She laughed at the public who extolled her earlier work, for she now found it shallow, hurriedly completed, and undistilled.
When the new book, which was aptly called
The Loop
, came out, Yevgenia was wise enough to avoid the press and ignore her reviews, and stayed insulated from the external world. As expected by her publisher, the reviews were laudatory. But, strangely, few were buying. People must be talking about the book without reading it, he thought. Her fans had been waiting for it and talking about it for years. The publisher, who now owned a very large collection of pink glasses and led a flamboyant lifestyle, was presently betting the farm on Yevgenia. He had no other hits
and none in sight. He needed to score big to pay for his villa in Carpentras in Provence and his dues on the financial settlement with his estranged wife, as well as to buy a new convertible Jaguar (pink). He had been certain that he had a good shot with Yevgenia’s long-awaited book, and he could not figure out why almost everyone called it a masterpiece yet no one was buying it. A year and a half later,
The Loop
was effectively out of print. The publisher, now in severe financial distress, thought he knew the reason: the book was “too f***ing long!”—Yevgenia should have written a shorter one. After a long but soothing lachrymal episode, Yevgenia thought of the characters in the rainy novels of Georges Simenon and Graham Greene. They lived in a state of numbing and secure mediocrity. Second-rateness had charm, Yevgenia thought, and she had always preferred charm over beauty.
So Yevgenia’s second book too was a Black Swan.


================================================================================
CHAPTER/SECTION 256 (Item 263)
================================================================================

I
LEARNING FROM MOTHER NATURE, THE OLDEST AND THE WISEST
How to make friends among walking people—On becoming a grandmother—The charms of eco-Extremistan—Never small enough—Harvard-Soviet chic
I am writing this essay three years after the completion of
The Black Swan
—which I have kept intact except for a few clarifying footnotes. Since then, I’ve written a dozen “scholarly” papers around some aspects of the Black Swan idea. These are very, very boring to read, since almost all academic papers are made to bore, impress, provide credibility, intimidate even, be presented at meetings, but not to be read except by suckers (or detractors) or, even worse, graduate students. Also, I am making the “what to do next” more salient here—you can take a horse to water and, in addition, you may have to make it drink. So this essay will allow me to go deeper into some points. Like the main text itself, the beginning will be what is called literary, and progressively turn technical.
I owe the idea of this book-length essay to Danny Kahneman, toward whom I (and my ideas) have more debt than toward anyone else on this planet. He convinced me that I had obligations to try to make the horse drink.


================================================================================
CHAPTER/SECTION 257 (Item 264)
================================================================================

ON SLOW BUT LONG WALKS
Over the past three years, my life experienced a bit of change, mostly for the better. Like parties, a book puts you on the envelope of serendipity; it even gets you invited to more parties. During my dark days, I was called a trader in Paris (something extremely
vulgaire)
, a philosopher in London (meaning too theoretical), a prophet in New York (dissingly, because of my then false prophecy), and an economist in Jerusalem (something very materialistic). I now saw myself dealing with the stress of having to live up to the wholly undeserved designations of a prophet in Israel (a very, very ambitious project), a
philosophe
in France, an economist in London, and a trader in New York (where it is respectable).
Such exposure brought hate mail, at least one death threat (by former employees of the bankrupt firm Lehman Brothers
*
), which I found extremely flattering, and, worse than any threat of violence, hourly requests for interviews by Turkish and Brazilian journalists. I had to spend a lot of time writing personalized and courteous notes declining invitations to dinner with suit-wearing current hotshots, suit-wearing archeo-hotshots, suit-wearing proto-hotshots, and the nasty brand of suit-wearing namedroppers. But it also brought some benefits. I was contacted by like-minded persons, people I would have never dreamed of meeting in the past, or those I did not think existed before, in disciplines completely outside my normal circles, who helped me further my quest with the most unexpected of ideas. I was often reached by people I admired and whose work I knew well, and who became natural collaborators and critics; I will always remember the thrill of getting an unexpected e-mail from Spyros Makridakis of the M-Competition described in
Chapter 10
, the great debunker of misforecasting, or another one from Jon Elster, the scholar of rare erudition and insights who integrated the wisdom of the ancients into modern social science thinking. I’ve met novelists and philosophical thinkers whose works I had read and admired, like Louis de Bernières, Will Self, John Gray (the philosopher, not the pop psychologist), or Lord Martin Rees; in all four cases I had the peculiar need to pinch myself upon hearing them talking to me about
my own
book.
Then, through a chain of friends of friends, cappuccinos, dessert wines, and security lines at airports, I got to partake of and understand the
potency of oral knowledge, as discussions are vastly more powerful than just correspondence. People say things in person they would never put in print. I met Nouriel Roubini (to my knowledge the only professional economist who
really
predicted the crisis of 2008, and perhaps the only independent thinker in that business). I also found a variety of people I did not know existed,
good
economists (i.e., with scientific standards), like Michael Spence and Barkley Rosser. Also Peter Bevelin and Yechezkel Zilber kept feeding me the papers I was looking for without knowing it, the first in biology, the second in cognitive science—thus they nudged my thinking in the appropriate direction.
So I have been dialoguing with many people. My problem is that I found only two persons who can have a conversation during a long walk (and walk slowly): Spyros Makridakis and Yechezkel Zilber. Most people, alas, walk too fast, mistaking walking for exercise, not understanding that walking is to be done slowly, at such a pace that one forgets one is walking—so I need to keep going to Athens (where Spyros lives) in order to indulge in my favorite activity, being a flâneur.
My Mistakes
And of course people will scrutinize the text. After examining messages and reports, I do not feel I need to retract anything in the initial version, or to correct any error (outside of typos and minor factual mistakes), except for two related matters. The first fault was pointed out to me by Jon Elster. I had written that the narrative fallacy pervades historical analyses, since I believed that there was no such thing as a test of a historical statement by forecasting and falsification. Elster explained to me that there are situations in which historical theory can escape the narrative fallacy and be subjected to empirical rejection—areas in which we are discovering documents or archeological sites yielding information capable of countering a certain narrative.
So, in relation to his point, I realized that the history of Arabic thought was not so definitive and that I had fallen into the trap of ignoring the continuous changes in
past
history, that the past too was largely a prediction. I (accidentally) discovered that I had fallen for conventional wisdom in textbook scholarship on Arabic philosophy, a wisdom that was contradicted by existing documents. I had exaggerated the import of the debate between Averroës and Algazel. Like everyone I thought that 1) it was a big deal and, 2) it killed Arabic
falsafah
. It turned out to be one of the mis-conceptions
being recently debunked by researchers (such as Dimitri Gutas and George Saliba). Most of those who theorized about Arabic philosophy did not know Arabic, so they left many things to their imagination (like Leo Strauss, for example). I am a bit ashamed, because Arabic is one of my native languages, and here I was reporting from tenth-hand sources developed by scholars illiterate in Arabic (and sufficiently overconfident and lacking in erudition to not realize it). I fell for the confirmation bias seen by Gutas: “It seems that one always starts with a preconception of what Arabic philosophy should be saying, and then concentrating only on those passages which seem to be supporting such a bias, thereby appearing to corroborate the preconception on the basis of the texts themselves.”
Once again, beware of history.


================================================================================
CHAPTER/SECTION 258 (Item 265)
================================================================================

ROBUSTNESS AND FRAGILITY
Upon the completion of
The Black Swan
, I spent some time meditating on the items I raised in
Chapter 14
on the fragility of some systems with large concentration and illusions of stability—which had left me convinced that the banking system was the mother of all accidents waiting to happen. I explained in
Chapter 6
, with the story of the old elephants, that the best teachers of wisdom are naturally the eldest, simply because they may have picked up invisible tricks and heuristics that escape our epistemic landscape, tricks that helped them survive in a world more complex than the one we think we can understand. So being old implies a higher degree of resistance to Black Swans, though, as we saw with the turkey story, it is not a guaranteed proof—older is almost always more solid, but older is not necessarily perfect. But a few billion years is vastly more proof than a thousand days of survival, and the oldest system around is clearly Mother Nature.
That was, in a way, the reasoning behind the
epilogism
argument of the medical empiricists of the post-classical Levant (like Menodotus of Nicomedia), who were the only practitioners to merge skepticism and decision-making in the real world. They are also the only group of people to use philosophy for anything useful. They proposed
historia:
maximal recording of facts with minimal interpretation and theorizing, describing of facts without the
why
, and resisting universals. Their form of nontheoretical knowledge was degraded by the medieval Scholastics, who favored
more explicit learning.
Historia
, just the recording of facts, was inferior to
philosophia
or
scientia
. Even philosophy, until then, had more to do with decision-making wisdom than it does today, not with impressing a tenure committee, and medicine was where such wisdom was practiced (and learned):
Medicina soror philosophiae:
“Medicine, sister of Philosophy.”
*
Giving an ancillary status to a field that prefers particulars to universals is what formalized knowledge since the Scholastics has been doing, which necessarily gives short shrift to experience and age (too much accumulation of particulars), in favor of those who hold a PhD like Dr. John. This may work in classical physics, but not in the complex domain; it has killed a lot of patients in the history of medicine, particularly before clinical medicine was born, and is causing a lot of damage in the social domain, particularly at the time of writing.
The central things the old teachers communicate to you are, to use religious terms, dogmas (rules you need to execute without necessarily understanding them) not kerygmas (rules you can understand and that have a purpose clear to you).
Mother Nature is clearly a complex system, with webs of interdependence, nonlinearities, and a robust ecology (otherwise it would have blown up a long time ago). It is an old, very old person with an impeccable memory. Mother Nature does not develop Alzheimer’s—actually there is evidence that even humans would not easily lose brain function with age if they followed a regimen of stochastic exercise and stochastic fasting, took long walks, avoided sugar, bread, white rice, and stock market investments, and refrained from taking economics classes or reading such things as
The New York Times
.
Let me summarize my ideas about how Mother Nature deals with the Black Swan, both positive and negative—it knows much better than humans how to take advantage of positive Black Swans.
Redundancy as Insurance
First,
Mother Nature likes redundancies
, three different types of redundancies. The first, the simplest to understand, is defensive redundancy, the insurance type of redundancy that allows you to survive under adversity, thanks to the availability of spare parts. Look at the human body. We have two eyes, two lungs, two kidneys, even two brains (with the possible exception of corporate executives)—and each has more capacity than needed in ordinary circumstances. So redundancy
equals
insurance, and the apparent inefficiencies are associated with the costs of maintaining these spare parts and the energy needed to keep them around in spite of their idleness.
The exact opposite of redundancy is naïve optimization. I tell everyone to avoid attending (orthodox) economics classes and say that economics will fail us and blow us up (and, as we will see, we have proofs that it failed us; but, as I kept saying in the original text, we did not need them; all we needed was to look at the lack of scientific rigor—and of ethics). The reason is the following: It is largely based on notions of naïve optimization, mathematized (poorly) by Paul Samuelson—and this mathematics contributed massively to the construction of an error-prone society. An economist would find it
inefficient
to maintain two lungs and two kidneys: consider the costs involved in transporting these heavy items across the savannah. Such optimization would, eventually, kill you, after the first accident, the first “outlier.” Also, consider that if we gave Mother Nature to economists, it would dispense with individual kidneys: since we do not need them all the time, it would be more “efficient” if we sold ours and used a central kidney on a time-share basis. You could also lend your eyes at night since you do not need them to dream.
Almost every major idea in conventional economics (though a lesser number of minor ones) fails under the modification of some assumption, or what is called “perturbation,” when you change one parameter, or take a parameter heretofore assumed by the theory to be fixed and stable, and make it random. We call this “randomization” in the jargon. This is called the study of model error and examination of the consequences of such changes (my official academic specialty is now model error or “model risk”). For instance, if a model used for risk assumes that the type of randomness under consideration is from Mediocristan, it will ignore large deviations and encourage the building of a lot of risk that ignores large deviations; accordingly, risk management will be faulty. Hence the
metaphor of “sitting on a barrel of dynamite” I used concerning Fannie Mae (now bust).
For another example of egregious model error, take the notion of comparative advantage supposedly discovered by Ricardo and behind the wheels of globalization. The idea is that countries should focus, as a consultant would say, on “what they do best” (more exactly, on where they are missing the smallest number of opportunities); so one country should specialize in wine and the other in clothes, although one of them might be better at both. But do some perturbations and alternative scenarios: consider what would happen to the country specializing in wine if the price of wine fluctuated. Just a simple perturbation around this assumption (say, considering that the price of wine is random, and can experience Extremistan-style variations) makes one reach a conclusion the opposite of Ricardo’s. Mother Nature does not like overspecialization, as it limits evolution and weakens the animals.
This also explains why I found current ideas on globalization (such as those promoted by the journalist Thomas Friedman) one step too naïve, and too dangerous for society—unless one takes into account side effects. Globalization might give the appearance of efficiency, but the operating leverage and the degrees of interaction between parts will cause small cracks in one spot to percolate through the entire system. The result would be like a brain experiencing an epileptic seizure from too many cells firing at the same time. Consider that our brain, a well-functioning complex system, is not “globalized,” or, at least, not naïvely “globalized.”
The same idea applies to debt—it makes you fragile, very fragile under perturbations, particularly when we switch from the assumption of Mediocristan to that of Extremistan. We currently learn in business schools to engage in borrowing (by the same professors who teach the Gaussian bell curve, that Great Intellectual Fraud, among other pseudosciences), against all historical traditions, when all Mediterranean cultures developed through time a dogma against debt.
Felix qui nihil debet
goes the Roman proverb: “Happy is he who owes nothing.” Grandmothers who survived the Great Depression would have advised the exact opposite of debt: redundancy; they would urge us to have several years of income in cash before taking any personal risk—exactly my barbell idea of
Chapter 11
, in which one keeps high cash reserves while taking more aggressive risks but with a small portion of the portfolio. Had banks done that, there would have been no bank crises in history.
We have documents since the Babylonians showing the ills of debt;
Near Eastern religions banned debt. This tells me that one of the purposes of religion and tradition has been to enforce interdicts—simply to protect people against their own epistemic arrogance. Why? Debt implies a strong statement about the future, and a high degree of reliance on forecasts. If you borrow a hundred dollars and invest in a project, you still owe a hundred dollars even if you fail in the project (but you do a lot better in the event you succeed). So debt is dangerous if you have some overconfidence about the future and are Black Swan blind, which we all tend to be. And forecasting is harmful since people (especially governments)
borrow
in response to a forecast (or use the forecast as a cognitive excuse to borrow). My Scandal of Prediction (i.e., bogus predictions that seem to be there to satisfy psychological needs) is compounded by the Scandal of Debt: borrowing makes you more vulnerable to forecast errors.
Big is Ugly—and Fragile
Second,
Mother Nature does not like anything too big
. The largest land animal is the elephant, and there is a reason for that. If I went on a rampage and shot an elephant, I might be put in jail, and get yelled at by my mother, but I would hardly disturb the ecology of Mother Nature. On the other hand, my point about banks in
Chapter 14
—that if you shot a large bank, I would “shiver at the consequences” and that “if one falls, they all fall”—was subsequently illustrated by events: one bank failure, that of Lehman Brothers, in September 2008, brought down the entire edifice. Mother Nature does not limit the interactions between entities; it just limits the size of its units. (Hence my idea is not to stop globalization and ban the Internet; as we will see, much more stability would be achieved by stopping governments from helping companies when they become large and by giving back advantages to the small guy.)
But there is another reason for man-made structures not to get too large. The notion of “economies of scale”—that companies save money when they become large, hence more efficient—is often, apparently behind company expansions and mergers. It is prevalent in the collective consciousness without evidence for it; in fact, the evidence would suggest the opposite. Yet, for obvious reasons, people keep doing these mergers—they are not good for companies, they are good for Wall Street bonuses; a company getting larger is good for the CEO. Well, I realized that as they become larger, companies appear to be more “efficient,” but they are also much more vulnerable to outside contingencies, those contingencies commonly
known as “Black Swans” after a book of that name. All that under the illusion of more stability. Add the fact that when companies are large, they need to optimize so as to satisfy Wall Street analysts. Wall Street analysts (MBA types) will pressure companies to sell the extra kidney and ditch insurance to raise their “earnings per share” and “improve their bottom line”—hence eventually contributing to their bankruptcy.
Charles Tapiero and I have shown mathematically that a certain class of unforeseen errors and random shocks hurts large organisms vastly more than smaller ones. In another paper, we computed the costs to society of such size; don’t forget that companies, when they fall, cost us.
The problem with governments is that they will tend to support these fragile organisms “because they are large employers” and because they have lobbyists, the kind of phony but visible advertised contributions so decried by Bastiat. Large companies get government support and become progressively larger and more fragile, and, in a way, run government, another prophetic view of Karl Marx and Friedrich Engels. Hairdressers and small businesses on the other hand, fail without anyone caring about them; they need to be efficient and to obey the laws of nature.
Climate Change and “Too Big” Polluters
I have been asked frequently on how to deal with climate change in connection with the Black Swan idea and my work on decision making under opacity. The position I suggest should be based both on ignorance and on deference to the wisdom of Mother Nature, since it is older than us, hence wiser than us, and has been proven much smarter than scientists. We do not understand enough about Mother Nature to mess with her—and I do not trust the models used to forecast climate change. Simply, we are facing nonlinearities and magnifications of errors coming from the so-called butterfly effects we saw in
Chapter 11
, actually discovered by Lorenz using weather-forecasting models. Small changes in input, coming from measurement error, can lead to massively divergent projections—and that generously assumes that we have the right equations.
We have polluted for years, causing much damage to the environment, while the scientists currently making these complicated forecasting models were not sticking their necks out and trying to stop us from building these risks (they resemble those “risk experts” in the economic domain who fight the previous war)—these are the scientists now trying to impose the solutions on us. But the skepticism about models that I propose does not
lead to the conclusions endorsed by anti-environmentalists and pro-market fundamentalists. Quite the contrary: we need to be hyper-conservationists ecologically, since we do not know what we are harming
with
now. That’s the sound policy under conditions of ignorance and epistemic opacity. To those who say “We have no proof that we are harming nature,” a sound response is “We have no proof that we are not harming nature, either;” the burden of the proof is not on the ecological conservationist, but on someone disrupting an old system. Furthermore we should not “try to correct” the harm done, as we may be creating another problem we do not know much about currently.
One practical solution I have come up with, based on the nonlinearities in the damage (under the assumption that harm increases disproportionately with the quantities released), and using the same mathematical reasoning that led to my opposing the “too big” concept, is to spread the damage across pollutants—should we need to pollute, of course. Let us carry on a thought experiment.
Case 1:
You give the patient a dose of cyanide, hemlock, or some poisonous substance, assuming they are equally harmful—and assuming, for the case of this experiment, the absence of super-additivity (that is, no synergetic effects).
Case 2:
You give the patient a tenth of a dose of each of ten such substances, for the same total amount of poison.
Clearly we can see that Case 2, by spreading the poison ingested across substances, is at the worst equally harmful (if all the poisonous substances act in the same way), and at the best close to harmless to the patient.
Species Density
Mother Nature does not like too much connectivity and globalization—
(biological, cultural, or economic). One of the privileges I got as a result of the book was meeting Nathan Myhrvold, the type of person I wish were cloned so I could have one copy here in New York, one in Europe, and one in Lebanon. I started meeting with him regularly; every single meeting has led to a big idea, or the rediscovery of my own ideas through the brain of a more intelligent person—he could easily claim co-authorship of my next book. The problem is that, unlike Spyros and those very few others, he does not have his conversations while walking (though I met him in excellent restaurants).
Myhrvold enlightened me about an additional way to interpret and
prove how globalization takes us into Extremistan: the notion of species density. Simply, larger environments are more scalable than smaller ones—allowing the biggest to get even bigger, at the expense of the smallest, through the mechanism of preferential attachment we saw in
Chapter 14
. We have evidence that small islands have many more species per square meter than larger ones, and, of course, than continents. As we travel more on this planet, epidemics will be more acute—we will have a germ population dominated by a few numbers, and the successful killer will spread vastly more effectively. Cultural life will be dominated by fewer persons: we have fewer books per reader in English than in Italian (this includes bad books). Companies will be more uneven in size. And fads will be more acute. So will runs on the banks, of course.
Once again, I am not saying that we need to stop globalization and prevent travel. We just need to be aware of the side effects, the trade-offs—and few people are. I see the risks of a very strange acute virus spreading throughout the planet.
The Other Types of Redundancy
The other categories of redundancy, more complicated and subtle, explain how elements of nature exploit positive Black Swans (and have an additional toolkit for surviving negative ones). I will discuss this very briefly here, as it is mostly behind my next work on the exploitation of Black Swans, through
tinkering
or the domestication of uncertainty.
Functional redundancy, studied by biologists, is as follows: unlike organ redundancy—the availability of spare parts, where the same function can be performed by identical elements—very often the same function can be performed by two different structures. Sometimes the term
degeneracy
is used (by Gerald Edelman and Joseph Gally).
There is another redundancy: when an organ can be employed to perform a certain function that is not its current central one. My friend Peter Bevelin links this idea to the “spandrels of San Marco,” after an essay by Steven Jay Gould. There, the necessary space between arches in the Venetian cathedral of San Marco has led to art that is now central to our aesthetic experience while visiting the place. In what is now called the
spandrel effect
, an auxiliary offshoot of a certain adaptation leads to a new function. I can also see the adaptation as having a dormant potential function that could wake up in the right environment.
The best way to illustrate such redundancy is with an aspect of the life
story of the colorful philosopher of science Paul Feyerabend. Feyerabend was permanently impotent from a war injury, yet he married four times, and was a womanizer to the point of leaving a trail of devastated boyfriends and husbands whose partners he snatched, and an equally long one of broken hearts, including those of many of his students (in his day, certain privileges were allowed to professors, particularly flamboyant professors of philosophy). This was a particular achievement given his impotence. So there were other parts of the body that came to satisfy whatever it was that made women attached to him.
Mother Nature initially created the mouth to eat, perhaps to breathe, perhaps for some other function linked to the existence of the tongue. Then new functions emerged that were most probably not part of the initial plan. Some people use the mouth and tongue to kiss, or to do something more involved to which Feyerabend allegedly had recourse.
Over the past three years I became obsessed with the notion that, under epistemic limitations—some opacity concerning the future—progress (and survival) cannot take place without one of these types of redundancy. You don’t know today what may be needed tomorrow. This conflicts very sharply with the notion of teleological design we all got from reading Aristotle, which has shaped medieval Arabic-western thought. For Aristotle, an object had a clear purpose set by its designer. An eye was there to see, a nose to smell. This is a rationalistic argument, another manifestation of what I call Platonicity. Yet anything that has a secondary use, and one you did not pay for, will present an extra opportunity should a heretofore unknown application emerge or a new environment appear. The organism with the largest number of secondary uses is the one that will gain the most from environmental randomness and epistemic opacity!
Take aspirin. Forty years ago, aspirin’s raison d’être was its antipyretic (fever-reducing) effect. Later it was used for its analgesic (pain-reducing) effect. It has also been used for its anti-inflammatory properties. It is now used mostly as a blood thinner to avoid second (or first) heart attacks. The same thing applies to almost all drugs—many are used for secondary and tertiary properties.
I have just glanced at the desk in my business, nonliterary office (I separate the functional from the aesthetic). A laptop computer is propped up on a book, as I like to have some incline. The book is a French biography of the fiery Lou Andreas Salomé (Nietzsche’s and Freud’s friend) that I can very safely say I will never read; it was selected for its optimal thickness
for the task. This makes me reflect on the foolishness of thinking that books are there to be read and could be replaced by electronic files. Think of the spate of functional redundancies provided by books. You cannot impress your neighbors with electronic files. You cannot prop up your ego with electronic files. Objects seem to have invisible but significant auxiliary functions that we are not aware of consciously, but that allow them to thrive—and on occasion, as with decorator books, the auxiliary function becomes the principal one.
So when you have a lot of functional redundancies, randomness helps on balance, but under one condition—that you can benefit from the randomness more than you can be hurt by it (an argument I call more technically
convexity to uncertainty)
. This is certainly the case with many engineering applications, in which tools emerge from other tools.
Also, I am currently absorbed in the study of the history of medicine, which struggled under this Aristotelian illusion of purpose, with Galen’s rationalistic methods that killed so many people while physicians thought they were curing them. Our psychology conspires: people like to go to a precise destination, rather than face some degree of uncertainty, even if beneficial. And research itself, the way it is designed and funded, seems to be teleological, aiming for precise results rather than looking for maximal exposures to forking avenues.
I have given more complicated names to this idea, in addition to
convexity
, like
optionality
—since you have the option of taking the freebie from randomness—but this is still work in progress for me. The progress coming from the second type of randomness is what I call
tinkering
, or
bricolage
, the subject of my next book.
Distinctions Without a Difference, Differences Without a Distinction
Another benefit of duplication. I have, throughout this book, focused on the absence of practical distinctions between the various notions of luck, uncertainty, randomness, incompleteness of information, and fortuitous occurrences using the simple criterion of predictability, which makes them all functionally equal. Probability can be degrees of belief, what one uses to make a bet, or something more physical associated with true randomness (called “ontic,” on which later). To paraphrase Gerd Gigerenzer, a “50 percent chance of rain tomorrow” in London might mean that it will rain half the day, while in Germany it will mean that half the experts think
it will rain, and (I am adding), in Brooklyn, that the betting market at the bar is such that one would pay 50 cents to get a dollar if it rains.
For scientists, the treatment is the same. We use the same equation to describe a probability distribution, regardless of whether the probability is a degree of belief or something designed by Zeus, who, we believe, calls the shots. For us probabilists (persons who work with probability in a scientific context), the probability of an event, however it may be defined, is, simply, a weight between 0 and 1, called the measure of the set concerned. Giving different names and symbols would be distracting and would prevent the transfer of analytical results from one domain to another.
For a philosopher, it is altogether another matter. I had two lunches with the (analytical) philosopher Paul Boghossian, three years apart, one upon the completion of the first edition of
The Black Swan
, the second upon the completion of this essay. During the first conversation he said that, from a philosophical point of view, it is a mistake to conflate probability as a measure of someone’s rational degree of belief with probability as a property of events in the world. To me, this implied that we should not use the same mathematical language, say, the same symbol,
p
, and write down the same equation for the different types of probabilities. I spent three years wondering if he was right or wrong, whether this was a
good redundancy
. Then I had lunch with him again, though in a better (and even more friendly) restaurant.
He alerted me to a phrase philosophers use: “distinction without a difference.” Then I realized the following: that there are distinctions philosophers use that make sense philosophically, but do not seem to make sense in practice, but that may be necessary if you go deeper into the idea, and may make sense in practice under a change of environment.
For consider the opposite: differences without a distinction. They can be brutally misleading. People use the same term,
measuring
, for measuring a table using a ruler, and for measuring risk—when the second is a forecast, or something of the sort. And the word
measuring
conveys an illusion of knowledge that can be severely distorting: we will see that we are psychologically very vulnerable to terms used and how things are framed. So if we used
measuring
for the table, and
forecasting
for risk, we would have fewer turkeys blowing up from Black Swans.
Mixing vocabulary has been very common in history. Let me take the idea of chance again. At some point in history the same Latin word,
felix
(from
felicitas)
was used to designate both someone lucky and someone happy. (The conflation of happiness and luck was explainable in an antique
context: the goddess Felicitas represented both.) The English word
luck
comes from the Germanic
Glück
, happiness. An ancient would have seen the distinction between the two concepts as a waste, since all lucky people seem happy (not thinking that one could be happy without being lucky). But in a modern context we need to extricate luck from happiness—utility from probability—in order to perform any psychological analysis of decision making. (True, it is hard to disentangle the two from observing people making decisions in a probabilistic environment. People may be so fearful of bad things that may happen to them that they tend to overpay for insurance, which in turn may make us mistakenly think that they believe the adverse event has a high probability.) So we can see now that the absence of such precision made the language of the ancients quite confusing to us; but to the ancients, the distinction would have been a redundancy.


================================================================================
CHAPTER/SECTION 259 (Item 266)
================================================================================

A SOCIETY ROBUST TO ERROR
I will only very briefly discuss the crisis of 2008 (which took place after the publication of the book, and which was a lot of things, but
not
a Black Swan, only the result of fragility in systems built upon ignorance—and denial—of the notion of Black Swan events. You know with near certainty that a plane flown by an incompetent pilot will eventually crash).
Why briefly?
Primo
, this is not an economics book, but a book on the incompleteness of knowledge and the effects of high-impact uncertainty—it just so happens that economists are the most Black-Swan-blind species on the planet.
Secundo
, I prefer to talk about events
before
they take place, not
after
. But the general public confuses the prospective with the retrospective. The very same journalists, economists, and political experts who did not see the crisis coming provided abundant ex-post analyses about its inevitability. The other reason, the real one, is that the crisis of 2008 was not intellectually interesting enough to me—there is nothing in the developments that had not happened before, at a smaller scale (for example, banks losing in 1982 every penny they ever made). It was merely a financial opportunity for me, as I will discuss further down. Really, I reread my book and saw nothing to add to the text, nothing we had not already encountered at some point in history, like the earlier debacles, nothing I had learned from. Alas, nothing.
The corollary is obvious: since there is nothing new about the crisis of 2008, we will not learn from it and we will make the same mistake in the
future. And the evidence is there at the time of writing: the IMF continues to issue forecasts (not realizing that previous ones did not work and that the poor suckers relying on them are—once again—going to get in trouble); economics professors still use the Gaussian; the current administration is populated with those who are bringing model error into industrial proportion, making us rely on models even more than ever before.
*
But the crisis provides an illustration for the need for robustness, worth discussing here.
Over the past twenty-five hundred years of recorded ideas, only fools and Platonists (or, worse, the species called central bankers) have believed in engineered utopias. We will see in the section on the Fourth Quadrant that the idea is not to correct mistakes and eliminate randomness from social and economic life through monetary policy, subsidies, and so on.
The idea is simply to let human mistakes and miscalculations remain confined
, and to prevent their spreading through the system, as Mother Nature does. Reducing volatility and ordinary randomness increases exposure to Black Swans—it creates an artificial quiet.
My dream is to have a true Epistemocracy—that is, a society robust to expert errors, forecasting errors, and hubris, one that can be resistant to the incompetence of politicians, regulators, economists, central bankers, bankers, policy wonks, and epidemiologists. We cannot make economists more scientific; we cannot make humans more rational (whatever that means); we cannot make fads disappear. The solution is somewhat simple, once we isolate harmful errors, as we will see with the Fourth Quadrant.
So I am currently torn between (a) my desire to spend time mulling my ideas in European cafés and in the tranquility of my study, or looking for someone who can have a conversation while walking slowly in a nice urban setting, and (b) the feeling of obligation to engage in activism to robustify society, by talking to uninteresting people and being immersed in the cacophony of the unaesthetic journalistic and media world, going to Washington to watch phonies in suits walking around the streets, having to defend my ideas while making an effort to be smooth and hide my disrespect. This proved to be very disruptive to my intellectual life. But there
are tricks. One useful trick, I discovered, is to avoid listening to the question of the interviewer, and answer with whatever I have been thinking about recently. Remarkably, neither the interviewers nor the public notices the absence of correlation between question and answer.
I was once selected to be one of a group of a hundred who went to Washington to spend two days discussing how to solve the problems of the crisis that started in 2008. Almost all the biggies were included. After an hour of meeting, and during a speech by the prime minister of Australia, I walked out of the room because my pain became intolerable. My back would start hurting upon looking at the faces of these people. The center of the problem is that none of them knew the center of the problem.
This makes me convinced that there is a unique solution for the world, to be designed along very simple lines of robustness to Black Swans—it will explode otherwise.
So now I am disengaged. I am back in my library. I am not even experiencing any frustration, I don’t even care about how forecasters can blow up society, and I am not even capable of being annoyed by fools of randomness (to the contrary), perhaps thanks to another discovery linked to a particular application of the study of complex systems, Extremistan, and that science of long walks.
*
Lehman Brothers was a financial institution with great-looking offices that abruptly went bust during the crisis of 2008.
*
Empiricism is not about not having theories, beliefs, and causes and effects: it is about avoiding being a sucker, having a decided and preset bias about where you want your error to be—where the default is. An empiricist facing series of facts or data defaults to suspension of belief (hence the link between empiricism and the older skeptical Pyrrhonian tradition), while others prefer to default to a characterization or a theory. The entire idea is to avoid the
confirmation bias
(empiricists prefer to err on the side of the disconfirmation/falsification bias, which they discovered more than fifteen hundred years before Karl Popper).
*
Clearly the entire economics establishment, with about a million people on the planet involved in some aspect of economic analysis, planning, risk management, and forecasting, turned out to be turkeys owing to the simple mistake of not understanding the structure of Extremistan, complex systems, and hidden risks, while relying on idiotic risk measures and forecasts—all this in spite of past experience, as these things have never worked before.


================================================================================
CHAPTER/SECTION 260 (Item 267)
================================================================================

II
WHY I DO ALL THIS WALKING, OR HOW SYSTEMS BECOME FRAGILE
Relearn to walk—Temperance, he knew not—Will I catch Bob Rubin? Extremistan and Air France travel


================================================================================
CHAPTER/SECTION 261 (Item 268)
================================================================================

ANOTHER FEW BARBELLS
Again, thanks to the exposure the book has received, I was alerted to a new aspect of robustness in complex systems … by the most unlikely of sources. The idea came from two fitness authors and practitioners who integrated the notions of randomness and Extremistan (though of the Gray Swan variety) into our understanding of human diet and exercise. Curiously, the first person, Art De Vany, is the same one who studied Extremistan in the movies (in
Chapter 3
). The second, Doug McGuff, is a physician. And both can talk about fitness, particularly Art, who, at seventy-two, looks like what a Greek god would like to look like at forty-two. Both were referring to the ideas of
The Black Swan
in their works and connecting to it; and I had no clue.
I then discovered to my great shame the following. I had spent my life thinking about randomness; I had written three books on dealing with randomness (one technical); I was prancing about as the expert in the subject of randomness from mathematics to psychology. And I had missed
something central: living organisms (whether the human body or the economy)
need
variability and randomness. What’s more, they need the Extremistan type of variability, certain extreme stressors. Otherwise they become fragile. That, I completely missed.
*
Organisms need, to use the metaphor of Marcus Aurelius, to turn obstacles into fuel—just as fire does.
Brainwashed by the cultural environment and by my education, I was under the illusion that steady exercise and steady nutrition were a good thing for one’s health. I did not realize that I was falling into evil rationalistic arguments, the Platonic projection of wishes into the world. Worse, I had been brainwashed though I had all the facts in my head.
From predator-prey models (the so-called Lotka-Volterra type of population dynamics), I knew that populations will experience Extremistan-style variability, hence predators will necessarily go through periods of feast and famine. That’s us, humans—we had to have been designed to experience extreme hunger and extreme abundance. So our food intake had to have been fractal. Not a single one of those promoting the “three meals a day,” “eat in moderation” idea has tested it empirically to see whether it is healthier than intermittent fasts followed by large feasts.
†
But Near Eastern religions (Judaism, Islam, and Orthodox Christianity) knew it, of course—just as they knew the need for debt avoidance—and so they had fast days.
I also knew that the size of stones and trees was, up to a point, fractal (I even wrote about that in
Chapter 16
). Our ancestors mostly had to face very light stones to lift, mild stressors; once or twice a decade, they encountered the need to lift a huge stone. So where on earth does this idea of “steady” exercise come from? Nobody in the Pleistocene jogged for forty-two minutes three days a week, lifted weights every Tuesday and Friday with a bullying (but otherwise nice) personal trainer, and played tennis at eleven on Saturday mornings. Not hunters. We swung between extremes: we sprinted when chased or when chasing (once in a while in an extremely
exerting way), and walked about aimlessly the rest of the time. Marathon running is a modern abomination (particularly when done without emotional stimuli).
This is another application of the barbell strategy: plenty of idleness, some high intensity. The data shows that long, very long walks, combined with high-intensity exercise outperform just running.
I am not talking about “brisk walks” of the type you read about in the Health section of
The New York Times
. I mean walking without making any effort.
What’s more, consider the negative correlation between caloric expenditure and intake: we hunted in response to hunger; we did not eat breakfast to hunt, hunting accentuated our energy deficits.
If you deprive an organism of stressors, you affect its epigenetics and gene expression—some genes are up-regulated (or down-regulated) by contact with the environment. A person who does not face stressors will not survive should he encounter them. Just consider what happens to someone’s strength after he spends a year in bed, or someone who grows up in a sterile environment and then one day takes the Tokyo subway, where riders are squeezed like sardines.
Why am I using evolutionary arguments? Not because of the optimality of evolution, but entirely for epistemological reasons, how we should deal with a complex system with opaque causal links and complicated interactions. Mother Nature is not perfect, but has so far proven smarter than humans, certainly much smarter than biologists. So my approach is to combine evidence-based research (stripped of biological theory), with an a priori that Mother Nature has more authority than anyone.
After my
“Aha!”
flash, I embarked on an Extremistan barbell lifestyle under the guidance of Art De Vany: long, very long, slow, meditative (or conversational) walks in a stimulating urban setting, but with occasional (and random) very short sprints, during which I made myself angry imagining I was chasing the bankster Robert Rubin with a big stick, trying to catch him and bring him to human justice. I went to weight-lifting facilities in a random way for a completely stochastic workout—typically in hotels, when I was on the road. Like Gray Swan events, these were very, very rare, but highly consequential weight-lifting periods, after a day of semistarvation, leaving me completely exhausted. Then I would be totally sedentary for weeks and hang around cafés. Even the duration of the workouts remained random—but most often very short, less than fifteen minutes. I followed the path that minimized boredom, and remained very
polite with gym employees who described my workouts as “erratic.” I put myself through thermal variability as well, exposed, on occasion, to extreme cold without a coat. Thanks to transcontinental travel and jet lag, I underwent periods of sleep deprivation followed by excessive rest. When I went to places with good restaurants, for instance Italy, I ate in quantities that would have impressed Fat Tony himself, then skipped meals for a while without suffering. Then, after two and a half years of this apparently “unhealthy” regimen, I saw significant changes in my own physique on every possible criterion—the absence of unnecessary adipose tissue, the blood pressure of a twenty-one-year-old, and so on. I also have a clearer, much more acute mind.
So the main idea is to trade duration for intensity—for a hedonic gain. Recall the reasoning I presented in
Chapter 6
about hedonic effects. Just as people prefer large but sudden losses to small but regular ones, just as one becomes dulled to pain beyond a certain threshold, so unpleasant experiences, like working out without external stimuli (say in a gym), or spending time in New Jersey, need to be as concentrated and as intense as possible.
Another way to view the connection to the Black Swan idea is as follows. Classical thermodynamics produces Gaussian variations, while informational variations are from Extremistan. Let me explain. If you consider your diet and exercise as simple energy deficits and excesses, with a straight calorie-in, calorie-burned equation, you will fall into the trap of misspecifying the system into simple causal and mechanical links. Your food intake becomes the equivalent of filling up the tank of your new BMW. If, on the other hand, you look at food and exercise as activating metabolic signals, with potential metabolic cascades and nonlinearities from network effects, and with recursive links, then welcome to complexity, hence Extremistan. Both food and workouts provide your body with information about stressors in the environment. As I have been saying throughout, informational randomness is from Extremistan. Medicine fell into the trap of using simple thermodynamics, with the same physics envy, and the same mentality, and the same tools as economists did when they looked at the economy as a web of simple links.
*
And both humans and societies are complex systems.
But these lifestyle ideas do not come from mere self-experimentation
or some quack theory. All the results were completely expected from the evidence-based, peer-reviewed research that is available. Hunger (or episodic energy deficit) strengthens the body and the immune system and helps rejuvenate brain cells, weaken cancer cells, and prevent diabetes. It was just that the current thinking—in a way similar to economics—was out of sync with the empirical research. I was able to re-create 90 percent of the benefits of the hunter-gatherer lifestyle with minimal effort, without compromising a modern lifestyle, in the aesthetics of an urban setting (I get extremely bored in nature and prefer walking around the Jewish quarter of Venice to spending time in Bora Bora).
*
By the same argument we can lower 90 percent of Black Swan risks in economic life … by just eliminating speculative debt.
The only thing currently missing from my life is panic, from, say, finding a gigantic snake in my library, or watching the economist Myron Scholes, armed to the teeth, walk into my bedroom in the middle of the night. I lack what the biologist Robert Sapolsky calls the beneficial aspect of acute stress, compared to the deleterious one of dull stress—another barbell, for no stress plus a little bit of extreme stress is vastly better than a little bit of stress (like mortgage worries) all the time.
Some have argued that my health benefits come from long walks, about ten to fifteen hours a week (though nobody has explained to me why they would count as workouts since I walk slowly), while others claim that they come from my few minutes of sprinting; I’ve had the same problem explaining the inseparability of the two extremes as I did explaining economic deviations. If you have acute stressors, then periods of rest, how can you separate the stressors from the recovery? Extremistan is characterized by both polar extremes, a high share of low impact, a low share of high impact. Consider that the presence of concentration, here energy expenditure, necessitates that a high number of observations do not contribute to anything except to the dilution. Just as the condition that makes market volatility explained by bursts (say one day in five years represents half the variance) requires that most other days remain exceedingly
quiet. If one in a million authors makes half the sales, you need a lot of authors to sell no books.
This is the turkey trap I will discuss later: philistines (and Federal Reserve chairpersons) mistake periods of low volatility (caused by stabilization policies) for periods of low risk, not for switches into Extremistan.
Welcome to Gray Extremistan. Do not tamper too much with the complex system Mother Nature gave you: your body.
Beware Manufactured Stability
By a variant of the same reasoning we can see how the fear of volatility I mentioned earlier, leading to interference with nature so as to impose “regularity,” makes us more fragile across so many domains. Preventing small forest fires sets the stage for more extreme ones; giving out antibiotics when it is not very necessary makes us more vulnerable to severe epidemics—and perhaps to that big one, the grand infection that will be resistant to known antibiotics and will travel on Air France.
Which brings me to another organism: economic life. Our aversion to variability and desire for order, and our acting on those feelings, have helped precipitate severe crises. Making something artificially bigger (instead of letting it die early if it cannot survive stressors) makes it more and more vulnerable to a very severe collapse—as I showed with the Black Swan vulnerability associated with an increase in size. Another thing we saw in the 2008 debacle: the U.S. government (or, rather, the Federal Reserve) had been trying for years to iron out the business cycle, leaving us exposed to a severe disintegration. This is my argument against “stabilization” policies and the manufacturing of a nonvolatile environment. More on that, later. Next, I will discuss a few things about the Black Swan idea that do not appear to easily penetrate consciousness. Predictably.
*
There is a difference between stressors and toxic exposure that weakens organisms, like the radiation I discussed in
Chapter 8
with the story of the rats.
†
There is a sociology-of-science dimension to the problem. The science writer Gary Taubes has convinced me that the majority of dietary recommendations (about lowering fats in diets) stand against the evidence. I can understand how one can harbor beliefs about natural things without justifying them empirically; I fail to understand beliefs that contravene both nature and scientific evidence.
*
The financial equations used by the villains for the “random walk” is based on heat diffusion.
*
The argument often heard about primitive people living
on average
less than thirty years ignores the distribution around that average; life expectancy needs to be analyzed conditionally. Plenty died early, from injuries; many lived very long—and healthy—lives. This is exactly the elementary “fooled by randomness” mistake, relying on the notion of “average” in the presence of variance, that makes people underestimate risks in the stock market.


================================================================================
CHAPTER/SECTION 262 (Item 269)
================================================================================

III
MARGARITAS ANTE PORCOS
*
How to not sell books in airports—Mineral water in the desert—How to denigrate other people’s ideas and succeed at it
Let me start again.
The Black Swan
is about consequential epistemic limitations, both psychological (hubris and biases) and philosophical (mathematical) limits to knowledge, both individual and collective. I say “consequential” because the focus is on impactful rare events, as our knowledge, both empirical and theoretical, breaks down with those—the more remote the events, the less we can forecast them, yet they are the most impactful. So
The Black Swan
is about human error in some domains, swelled by a long tradition of scientism and a plethora of information that fuels confidence without increasing knowledge. It covers the expert problem—harm caused by reliance on scientific-looking charlatans, with or without equations, or regular noncharlatanic scientists with a bit more confidence about their methods than the evidence warrants. The focus is in not being the turkey in places where it matters, though there is nothing wrong in being a fool where that has no effect.


================================================================================
CHAPTER/SECTION 263 (Item 270)
================================================================================

MAIN ERRORS IN UNDERSTANDING THE MESSAGE
I will briefly state some of the difficulties in understanding the message and the ideas of this book, typically perpetrated by professionals, though, surprisingly, less by the casual reader, the amateur, my friend. Here is a list.
1) Mistaking the Black Swan (capitalized) for the logical problem. (Mistake made by U.K. intellectuals—intellectuals in other countries do not know enough analytical philosophy to make that mistake.)
*
2) Saying the maps we had were better than having no maps. (People who do not have experience in cartography, risk “experts,” or worse, employees of the Federal Reserve Bank of the United States.)
This is the strangest of errors. I know few people who would board a plane heading for La Guardia airport in New York City with a pilot who was using a map of Atlanta’s airport “because there is nothing else.” People with a functioning brain would rather drive, take the train, or stay home. Yet once they get involved in economics, they all prefer professionally to use in Extremistan the measures made for Mediocristan, on the ground that “we have nothing else.” The idea, well accepted by grandmothers, that one should pick a destination for which one has a good map, not travel and then find “the best” map, is foreign to PhDs in social science.
3) Thinking that a Black Swan should be a Black Swan to all observers. (Mistake made by people who have not spent a lot of time in Brooklyn and lack the street smarts and social intelligence to realize that
some
people are suckers.)
4) Not understanding the value of negative advice (“Don’t do”) and writing to me to ask me for something “constructive” or a “next step.” (Mistake usually made by chairmen of large companies and those who would like someday to become such chairmen.)
†
5) Not understanding that doing nothing can be much more preferable to doing something potentially harmful. (Mistake made by most people who are not grandmothers.)
6) Applying to my ideas labels
(skepticism, fat tails, power laws)
off a supermarket shelf and equating those ideas with inadequate research traditions (or, worse, claiming it was dealt with by “modal logic,” “fuzzy logic,” or whatever the person has vaguely heard of). (Mistake made by those with graduate degrees from both coasts.)
7) Thinking that
The Black Swan
is about the errors of using the bell curve, which supposedly everyone knew about, and that the errors can be remedied by substituting a number from the Mandelbrotian in place of another. (Mistake made by the pseudoscientific brand of tenured finance professors, like, say, Kenneth French.)
8) Claiming that “we knew all this” and “there is nothing new” in my idea during 2008, then, of course, going bust during the crisis. (Mistake made by the same type of tenured finance professors as before, but these went to work on Wall Street, and are now broke.)
9) Mistaking my idea for Popper’s notion of falsification—or taking any of my ideas and fitting them in a prepackaged category that sounds familiar. (Mistakes mostly made by sociologists, Columbia University political science professors, and others trying to be multidisciplinary intellectuals and learning buzzwords from Wikipedia.)
10) Treating probabilities (of future states) as measurable, like the temperature or your sister’s weight. (People who did a PhD at MIT or something like that, then went to work somewhere, and now spend time reading blogs.)
11) Spending energy on the difference between ontic and epistemic randomness—true randomness, and randomness that arises from incomplete information—instead of focusing on the more consequential difference between Mediocristan and Extremistan. (People with no hobby, no personal problems, no love, and too much free time.)
12) Thinking I am saying “Do not forecast” or “Do not use models,” rather than “Do not use sterile forecasts with huge error” and “Do not use models in the Fourth Quadrant.” (Mistake made by most people who forecast for a living.)
13) Mistaking what I say for “S**t happens” rather than “this is where s**t happens.” (Many former bonus earners.)
*
Indeed, the intelligent, curious, and open-minded amateur is my friend. A pleasant surprise for me was to discover that the sophisticated amateur who uses books for his own edification, and the journalist (unless, of course, he was employed by
The New York Times)
, could understand my idea much better than professionals. Professional readers, less genuine, either read too quickly or have an agenda. When reading for “work” or for the purpose of establishing their status (say, to write a review), rather than to satisfy a genuine curiosity, readers who have too much baggage (or perhaps not enough) tend to read rapidly and efficiently, scanning jargon terms and rapidly making associations with prepackaged ideas. This resulted early on in the squeezing of the ideas expressed in
The Black Swan
into a commoditized well-known framework, as if my positions could be squeezed into standard skepticism, empiricism, essentialism, pragmatism, Popperian falsificationism, Knightian uncertainty, behavioral economics, power laws, chaos theory, etc. But the amateurs saved my ideas. Thank you, reader.
As I wrote, missing a train is only painful if you are running after it. I was not looking to have a bestseller (I thought I had already had one with my previous book, and just wanted to produce a real thing), so I had to deal with a spate of harrying side effects. I watched as the book was initially treated, owing to its bestseller status, like the nonfiction “idea books,” journalistic through and through, castrated by a thorough and “competent” copy editor, and sold in airports to “thinking” businessmen. Giving these enlightened
Bildungsphilister
s, commonly called idea-book readers, a real book is like giving vintage Bordeaux to drinkers of Diet Coke and listening to their comments about it. Their typical complaint is that they want diet-book-style “actionable steps” or “better forecasting tools,” satisfying the profile of the eventual Black Swan victim. We will see further that, in an ailment similar to confirmation bias, charlatans provide the much demanded positive advice (what to do), as people do not value negative advice (what not to do). Now, “how not to go bust” does not appear to be valid advice, yet, given that over time only a minority of companies do not go bust, avoiding death is the best possible—and most robust—advice. (It is particularly good advice after your competitors get in trouble and you can go on legal pillages
of their businesses.)
*
Also, many readers (say, those who work in forecasting or banking) do not often understand that the “actionable step” for them is to simply quit their profession and do something more ethical.
In addition to playing into our mental biases, and telling people what they want to hear, these “idea books” often have an abhorrent definitive and investigative tone to their messages, like the reports of management consultants trying to make you believe that they told you more than they actually did. I came up with a simple compression test using a version of what is called Kolmogorov complexity, a measure of how much a message can be reduced without losing its integrity: try to reduce a book to the shortest length possible without losing any of its intended message or aesthetic effects. A Swiss friend (he does not seem to like to walk slowly and drags me on hikes in the Alps), an owner of a firm that abstracts books and sells the summaries to busy businesspeople, convinced me that his firm has a lofty mission, as almost all business books can be reduced to a few pages without any loss of their message and essence; novels and philosophical treatments cannot be compressed.
So a philosophical essay is a beginning, not an end. To me the very same meditation continues from book to book, compared to the work of a nonfiction writer, who will, say, move to another distinct and journalistically confined topic. I want my contribution to be a new way of viewing knowledge, the very beginning of a long investigation, the start of something real. Indeed, I am glad at the time of writing, a few years into the life of the book, to see the idea spread among thoughtful readers, inspiring like-minded scholars to go beyond it and seeding research in epistemology, engineering, education, defense, operations research, statistics, political theory, sociology, climate studies, medicine, law, aesthetics, and insurance (though not so much in the area in which
The Black Swan
found Black Swan–style near instant vindication, economics).
I was lucky that it only took a couple of years (and a severe financial
crisis) for the Republic of Letters to realize that
The Black Swan
was a philosophical tale.
How to Expunge One’s Crimes
My ideas went through two distinctive stages after the release of the book. In the first, as the book hit the bestseller list in almost every single country where it was published, many social scientists and finance practitioners fell into the trap of refuting me with the sole argument that I was selling too many books and that my book was accessible to readers; hence it could not reflect original and systematic thought, it was just a “popularization,” not worth reading let alone commenting upon.
The first change of regime came with the release of my more difficult mathematical, empirical, and scholarly work in a dozen articles in a variety of journals in an attempt to expiate my crime of having sold too many books.
*
Then, silence.
Still no refutation at the time of this writing; indeed, my paper on the Fourth Quadrant in the
International Journal of Forecasting
(which I simplify in this essay) produced incontrovertible evidence that most (perhaps all) “rigorous” papers in economics using fancy statistics are just hot air, partaking of a collective scam (with diffusion of responsibility), unusable for any form of risk management. Clearly, so far, in spite of a few smear campaigns, or, rather, attempts at a smear campaign (typically conducted by former Wall Street persons or Diet Coke drinkers), nobody has managed to present a formal (or even informal) refutation of the idea—neither of the logical-mathematical arguments nor of the empirical arguments.
But meanwhile I figured out something valuable in the packaging of the Black Swan idea. Just as in
Fooled by Randomness
I had argued (initially from personal experience) that a “70 percent chance of survival” is vastly different from a “30 percent chance of death,” I found out that telling researchers “This is where your methods work very well” is vastly better than telling them “This is what you guys don’t know.” So when I
presented to what was until then the most hostile crowd in the world, members of the American Statistical Association, a map of the four quadrants, and told them: your knowledge works beautifully in these three quadrants, but beware of the fourth one, as this is where the Black Swans breed, I received instant approval, support, offers of permanent friendship, refreshments (Diet Coke), invitations to come present at their sessions, even hugs. Indeed, that is how a series of research papers started using my work on where the Fourth Quadrant is located, etc. They tried to convince me that statisticians were not responsible for these aberrations, which come from people in the social sciences who apply statistical methods without understanding them (something I verified later, in formal experiments, to my great horror, as we will see further down).
The second change of regime came with the crisis of 2008. I kept getting invited to debates, but I stopped obliging, as it became hard for me to hear complicated arguments and restrain a smile, sometimes a smirk. Why a smile? Well, the vindication. Not the intellectual vindication of winning an argument, no: academia, I discovered, does not change its mind voluntarily, except perhaps in some real sciences such as physics. It was a different feeling: it is hard to focus on a conversation, especially when it is mathematical, when you have just personally earned several hundreds of times the annual salary of the researcher trying to tell you that you are “wrong,” by betting against his representation of the world.
A Desert Crossing
For I had undergone a difficult psychological moment, after the publication of
The Black Swan
, what the French call
traversée du désert
, when you go through the demoralizing desiccation and disorientation of crossing a desert in search of an unknown destination, or a more or less promised land. I had a rough time, shouting “Fire! Fire! Fire!” about the hidden risks in the system, and hearing people ignore the content and instead just criticize the presentation, as if they were saying “your diction in shouting ‘Fire!’ is bad.” For example, the curator of a conference known as TED (a monstrosity that turns scientists and thinkers into low-level entertainers, like circus performers) complained that my presentation style did not conform to his taste in slickness and kept my lecture on Black
Swans and fragility off the Web. Of course, he subsequently tried to claim credit for my warnings voiced before the crisis of 2008.
*
Most of the arguments offered were that “times are different,” invoking “the great moderation” by one Ben Bernanke (chairman of the Federal Reserve at the time of writing) who fell for the turkey-before-Thanksgiving trap of not understanding that moving into Extremistan comes through a drop in daily volatility.
Also when I was railing against models, social scientists kept repeating that they knew it and that there is a saying, “all models are wrong, but some are useful”—not understanding that the real problem is that “some are harmful.” Very harmful. As Fat Tony would say, “Tawk is cheap.” So Mark Spitznagel and I restarted the business of “robustifying” clients against the Black Swan (helping people get closer to the barbell of
Chapter 11
). We were convinced that the banking system was going to collapse under the weight of hidden risks—that such an event would be a white swan. It was moving from gray to white in color as the system was accumulating risks. The longer we had to wait for it, the more severe it would be. The collapse took place about a year and a half after the publication of the book. We had been expecting it and betting against the banking system for a long time (and protecting clients by making them Black Swan robust), but the reception of the Black Swan—and the absence of refutation that was not ad hominem—made us vastly more worried about the need for protection than ever before.
Like Antaeus, who lost strength when separated from contact with the earth, I needed connection to the real world, something real and applied, instead of focusing on winning arguments and trying to convince people of my point (people are almost always only convinced of what they already know). Sticking my neck out in the real world, lining up my life with my ideas by getting involved in trading, had a therapeutic effect, even apart from the vindication; just having a trade on the books gave me strength to not care. A few months before the onset of the crisis of 2008, I was attacked at a party by a Harvard psychologist who, in spite of his innocence of probability theory, seemed to have a vendetta against me and
my book. (The most vicious and bitter detractors tend to be those with a competing product on the bookstore shelves.) Having a trade on allowed me to laugh at him—or, what is even worse, made me feel some complicity with him, thanks to his anger. I wonder what would have happened to the psychological state of another author, identical to me in all respects except that he had no involvement with trading and risk taking. When you walk the walk, whether successful or not, you feel more indifferent and robust to people’s opinion, freer, more real.
Finally, I got something out of my debates: the evidence that Black Swan events are largely caused by people using measures way over their heads, instilling false confidence based on bogus results. In addition to my befuddlement concerning why people use measures from Mediocristan outside those measures’ applicability, and believe in them, I had the inkling of a much larger problem: that almost none of the people who worked
professionally
with probabilistic measures knew what they were talking about, which was confirmed as I got into debates and panels with many hotshots, at least four with “Nobels” in economics. Really. And this problem was measurable, very easily testable. You could have finance “quants,” academics, and students use and write papers and papers using the notion of “standard deviation,” yet not understand intuitively what it meant, so you could trip them up by asking them elementary questions about the nonmathematical, real conceptual meaning of their numbers. And trip them up we did. Dan Goldstein and I ran experiments on professionals using probabilistic tools, and were shocked to see that up to 97 percent of them failed elementary questions.
*
Emre Soyer and Robin Hogarth subsequently took the point and tested it in the use of an abhorrent field called econometrics (a field that, if any scientific scrutiny was applied to it, would not exist)—again, most researchers don’t understand the tools they are using.
Now that the book’s reception is off my chest, let us move into more analytical territory.
*
In Latin: “pearls before swine.”
*
Most intellectuals keep attributing the black swan expression to Popper or Mill, sometimes Hume, in spite of the quote by Juvenal. The Latin expression
niger cygnus
might even be more ancient, possibly of Etruscan origin.
†
One frequent confusion: people believe that I am suggesting that agents should bet on Black Swans taking place, when I am saying that they should avoid blowing up should a Black Swan take place. As we will see in section IV, I am advocating omission, not commission. The difference is enormous, and I have been completely swamped by people wondering if one can “bleed to death” making bets on the occurrence of Black Swans (like Nero, Giovanni Drogo, or the poor scientist with a rich brother-in-law). These people have made their choice for existential reasons, not necessarily economic ones, although the economics of such a strategy makes sense for a collective.
*
If most of the people mixed up about the message appear to be involved in economics and social science, while a much smaller share of readers come from those segments, it is because other members of society without such baggage get the book’s message almost immediately.
*
For instance, one anecdote that helps explain the crisis of 2008. One Matthew Barrett, former Chairman of Barclays Bank and Bank of Montreal (both of which underwent blowups from exposures to Extremistan using risk management methods for Mediocristan) complained, after all the events of 2008 and 2009, that
The Black Swan
did not tell him “what should I do about that?” and he “can’t run a business” worrying about Black Swan risks. The person has never heard of the notion of fragility and robustness to extreme deviations—which illustrates my idea that evolution does not work by teaching, but destroying.
*
So far, about fourteen scholarly (but very, very boring) articles. (They are boring both to read and to write!) The number keeps growing, though, and they are being published at a pace of three a year. Taleb (2007), Taleb and Pilpel (2007), Goldstein and Taleb (2007), Taleb (2008), Taleb (2009), Taleb, Goldstein and Spitznagel (2009), Taleb and Pilpel (2009), Mandelbrot and Taleb (2010), Makridakis and Taleb (2010), Taleb (2010), Taleb and Tapiero (2010a), Taleb and Tapiero (2010b), Taleb and Douady (2010), and Goldstein and Taleb (2010).
*
Although his is a bit extreme, this phoniness is not uncommon at all. Many intellectually honest people I had warned, and who had read my book, later blamed me for not telling them about the crisis—they just could not remember it. It is hard for a newly enlightened pig to recall that he has seen a pearl in the past but did not know what it was.
*
Dan Goldstein and I have been collaborating and running experiments about human intuitions with respect to different classes of randomness. He does not walk slowly.


================================================================================
CHAPTER/SECTION 264 (Item 271)
================================================================================

IV
ASPERGER AND THE ONTOLOGICAL BLACK SWAN
Are nerds more blind to swans? Social skills in Extremistan—On the immortality of Dr. Greenspan
If
The Black Swan
is about epistemic limitations, then, from this definition, we can see that it is not about some objectively defined phenomenon, like rain or a car crash—it is simply something that was not expected by a
particular
observer.
So I was wondering why so many otherwise intelligent people have casually questioned whether certain events, say the Great War, or the September 11, 2001, attack on the World Trade Center, were Black Swans, on the grounds that
some
predicted them. Of course the September 11 attack was a Black Swan to those victims who died in it; otherwise, they would not have exposed themselves to the risk. But it was certainly not a Black Swan to the terrorists who planned and carried out the attack. I have spent considerable time away from the weight-lifting room repeating that
a Black Swan for the turkey is not a Black Swan for the butcher
.
The same applies to the crisis of 2008, certainly a Black Swan to almost all economists, journalists, and financiers on this planet (including, predictably, Robert Merton and Myron Scholes, the turkeys of
Chapter 17
), but certainly not to this author. (Incidentally, as an illustration of another common mistake, almost none of those—very few—who seemed to
have “predicted” the event predicted its depth. We will see that, because of the atypicality of events in Extremistan, the Black Swan is not just about the occurrence of some event but also about its depth and consequences.)


================================================================================
CHAPTER/SECTION 265 (Item 272)
================================================================================

ASPERGER PROBABILITY
This consideration of an
objective
Black Swan, one that would be the same to all observers, aside from missing the point completely, seems dangerously related to the problem of underdevelopment of a human faculty called “theory of mind” or “folk psychology.” Some people, otherwise intelligent, have a deficiency of that human ability to impute to others knowledge that is different from their own. These, according to researchers, are the people you commonly see involved in engineering or populating physics departments. We saw one of them, Dr. John, in
Chapter 9
.
You can test a child for underdevelopment of the theory of mind using a variant of the “false-belief task.” Two children are introduced. One child puts a toy under the bed and leaves the room. During his absence, the second child—the subject—removes it and hides it in a box. You ask the subject: Where, upon returning to the room, will the other child look for the toy? Those under, say, the age of four (when the theory of mind starts developing), choose the box, while older children correctly say that the other child will look under the bed. At around that age, children start realizing that another person can be deprived of some of the information they have, and can hold beliefs that are different from their own. Now, this test helps detect mild forms of autism: as high as one’s intelligence may be, it can be difficult for many to put themselves in other people’s shoes and imagine the world on the basis of other people’s information. There is actually a name for the condition of a person who can be functional but suffers from a mild form of autism: Asperger syndrome.
The psychologist Simon Baron-Cohen has produced much research distinguishing between polar extremes in people’s temperament with respect to two faculties: ability to systematize, and ability to empathize and understand others. According to his research, purely systematizing persons suffer from a lack of theory of mind; they are drawn to engineering and similar occupations (and when they fail, to, say, mathematical economics); empathizing minds are drawn to more social (or literary) professions. Fat Tony, of course, would fall in the more social category. Males are overrepresented in the systematizing category; females dominate the other extreme.
Note the unsurprising, but very consequential fact that people with Asperger syndrome are highly averse to ambiguity.
Research shows that academics are overrepresented in the systematizing, Black-Swan-blind category; these are the people I called “Locke’s madmen” in
Chapter 17
. I haven’t seen any formal direct test of Black Swan foolishness and the systematizing mind, except for a calculation George Martin and I made in 1998, in which we found evidence that all the finance and quantitative economics professors from major universities whom we tracked and who got involved in hedge fund trading ended up making bets
against
Black Swans, exposing themselves to blowups. This preference was nonrandom, since between one third and one half of the nonprofessors had that investment style at the time. The best known such academics were, once again, the “Nobel”-crowned Myron Scholes and Robert C. Merton, whom God created so that I could illustrate my point about Black Swan blindness.
*
They all experienced problems during the crisis, discussed in that chapter, that brought down their firm Long Term Capital Management. Note that the very same people who make a fuss about discussions of Asperger as a condition not compatible with risk-bearing and the analysis of nonexplicit off-model risks, with its corresponding dangers to society, would be opposed to using a person with highly impaired eyesight as the driver of a school bus. All I am saying is that just as I read Milton, Homer, Taha Husain, and Borges (who were blind) but would prefer not to have them drive me on the Nice–Marseilles motorway, I elect to use tools made by engineers but prefer to have society’s risky decisions managed by someone who is not affected with risk-blindness.


================================================================================
CHAPTER/SECTION 266 (Item 273)
================================================================================

FUTURE BLINDNESS REDUX
Now recall the condition, described in
Chapter 12
, of not properly transferring between past and future, an autism-like condition in which people do not see second-order relations—the subject does not use the relation
between the past’s past and the past’s future to project the connection between today’s past and today’s future. Well, a gentleman called Alan Greenspan, the former chairman of the U.S. Federal Reserve Bank, went to Congress to explain that the banking crisis, which he and his successor Bernanke helped cause, could not have been foreseen because it “had never happened before.” Not a single member of congress was intelligent enough to shout, “Alan Greenspan, you have never died before, not in eighty years, not even once; does that make you immortal?” The abject Robert Rubin, the bankster I was chasing in Section II, a former secretary of the Treasury, used the same argument—but the fellow had written a long book on uncertainty (with, ironically, my publisher and the same staff used for
The Black Swan)
.
*
I discovered (but by then I was not even surprised) that no researcher has tested whether large deviations in economics can be predicted from past large deviations—whether large deviations have predecessors, that is. This is one of the elementary tests missing in the field, as elementary as checking whether a patient is breathing or whether a lightbulb is screwed in, but characteristically nobody seems to have tried to do it. It does not take a lot of introspection to figure out that big events don’t have big parents: the Great War did not have a predecessor; the crash of 1987, in which the market went down close to 23 percent in a single day, could not have been guessed from its worst predecessor, a one-day loss of around 10 percent—and this applies to almost all such events, of course. My results were that regular events can predict regular events, but that extreme events, perhaps because they are more acute when people are unprepared, are almost never predicted from narrow reliance on the past.
The fact that this notion is not obvious to people is shocking to me. It is particularly shocking that people do what are called “stress tests” by taking the worst possible
past
deviation as an anchor event to project the worst possible future deviation, not thinking that they would have failed
to account for that past deviation had they used the same method on the day before the occurrence of that past anchor event.
*
These people have PhDs in economics; some are professors—one of them is the chairman of the Federal Reserve (at the time of writing). Do advanced degrees make people blind to these elementary notions?
Indeed, the Latin poet Lucretius, who did not attend business school, wrote that we consider the biggest object of any kind that we have seen in our lives as the largest possible item:
et omnia de genere omni / Maxima quae vivit quisque, haec ingentia fingit
.


================================================================================
CHAPTER/SECTION 267 (Item 274)
================================================================================

PROBABILITY HAS TO BE SUBJECTIVE
†
This raises a problem that is worth probing in some depth. The fact that many researchers do not realize immediately that the Black Swan corresponds mainly to an incomplete map of the world, or that some researchers have to stress this subjective quality (Jochen Runde, for instance, wrote an insightful essay on the Black Swan idea, but one in which he felt he needed to go out of his way to stress its subjective aspect), takes us to the historical problem in the very definition of probability. Historically, there have been many approaches to the philosophy of probability. The notion that two people can have two different views of the world, then express them as different probabilities remained foreign to the research. So it took a while for scientific researchers to accept the non-Asperger notion that different people can, while being rational, assign different probabilities to different future states of the world. This is called “subjective probability.”
Subjective probability was formulated by Frank Plumpton Ramsey in 1925 and Bruno de Finetti in 1937. The take on probability by these two intellectual giants is that it can be represented as a quantification of the degree of belief (you set a number between 0 and 1 that corresponds to the strength of your belief in the occurrence of a given event), subjective to the
observer, who expresses it as rationally as he wishes under some constraints. These constraints of consistency in decision making are obvious: you cannot bet there is a 60 percent chance of snow tomorrow
and
a 50 percent chance that there will be no snow. The agent needs to avoid violating something called the Dutch book constraint: that is, you cannot express your probabilities inconsistently by engaging in a series of bets that lock in a certain loss, for example, by acting as if the probabilities of separable contingencies can add up to more than 100 percent.
There is another difference here, between “true” randomness (say the equivalent of God throwing a die) and randomness that results from what I call epistemic limitations, that is, lack of knowledge. What is called ontological (or ontic) uncertainty, as opposed to epistemic, is the type of randomness where the future is not implied by the past (or not even implied by anything). It is created every minute by the complexity of our actions, which makes the uncertainty much more fundamental than the epistemic one coming from imperfections in knowledge.
It means that there is no such thing as a long run for such systems, called “nonergodic” systems—as opposed to the “ergodic” ones. In an ergodic system, the probabilities of what may happen in the long run are not impacted by events that may take place, say, next year. Someone playing roulette in the casino can become very rich, but, if he keeps playing, given that the house has an advantage, he will eventually go bust. Someone rather unskilled will eventually fail. So ergodic systems are invariant, on average, to paths, taken in the intermediate term—what researchers call absence of path dependency. A nonergodic system has no real long-term properties—it is prone to path dependency.
I believe that the distinction between epistemic and ontic uncertainty is important philosophically, but entirely irrelevant in the real world. Epistemic uncertainty is so hard to disentangle from the more fundamental one. This is the case of a “distinction without a difference” that (unlike the ones mentioned earlier) can mislead because it distracts from the real problems: practitioners make a big deal out of it instead of focusing on epistemic constraints. Recall that skepticism is costly, and should be available when needed.
There is no such thing as a “long run” in practice; what matters is what happens before the long run. The problem of using the notion of “long run,” or what mathematicians call the asymptotic property (what happens when you extend something to infinity), is that it usually makes us blind to what happens before the long run, which I will discuss later as
preasymptotics
. Different functions have different preasymptotics, according to speed of convergence to that asymptote. But, unfortunately, as I keep repeating to students,
life takes place in the preasymptote
, not in some Platonic long run, and some properties that hold in the preasymptote (or the short run) can be markedly divergent from those that take place in the long run. So theory, even if it works, meets a short-term reality that has more texture. Few understand that there is generally no such thing as a reachable
long run
except as a mathematical construct to solve equations; to assume a long run in a complex system, you need to also assume that nothing new will emerge. In addition, you may have a perfect model of the world, stripped of any uncertainty concerning the analytics of the representation, but have a small imprecision in one of the parameters to input in it. Recall Lorenz’s butterfly effect of
Chapter 11
. Such minutely small uncertainty, at the level of the slightest parameter, might, because of nonlinearities, percolate to a huge uncertainty at the level of the output of the model. Climate models, for instance, suffer from such nonlinearities, and even if we had the right model (which we, of course, don’t), a small change in one of the parameters, called calibration, can entirely reverse the conclusions.
We will discuss preasymptotics further when we look at the distinctions between different classes of probability distributions. I will say for now that many of these mathematical and philosophical distinctions are entirely overblown, Soviet-Harvard-style, top-down, as people start with a model and then impose it on reality and start categorizing, rather than start with reality and look at what fits it, in a bottom-up way.
Probability on a Thermometer
This distinction, misused in practice, resembles another deficient separation discussed earlier, between what economists call Knightian risk (computable) and Knightian uncertainty (uncomputable). This assumes that something is computable, when really everything is more or less incomputable (and rare events more so). One has to have a mental problem to think that probabilities of future events are “measurable” in the same sense that the temperature is measurable by a thermometer. We will see in the following section that small probabilities are less computable, and that this matters when the associated payoffs are consequential.
Another deficiency I need to point out concerns a strangely unrealistic and unrigorous research tradition in social science, “rational expectations,”
in which observers are shown to rationally converge on the same inference when supplied with the same data, even if their initial hypotheses were markedly different (by a mechanism of updating called Bayesian inference). Why unrigorous? Because one needs a very quick check to see that people do not converge to the same opinions in reality. This is partly, as we saw in
Chapter 6
, because of psychological distortions such as the confirmation bias, which cause divergent interpretation of the data. But there is a mathematical reason why people do not converge to the same opinion: if you are using a probability distribution from Extremistan, and I am using a distribution from Mediocristan (or a different one from Extremistan), then we will never converge, simply because if you suppose Extremistan you do not update (or change your mind) that quickly. For instance, if you assume Mediocristan and do not witness Black Swans, you may eventually rule them out. Not if you assume we are in Extremistan.
To conclude, assuming that “randomness” is not epistemic and subjective, or making a big deal about the distinction between “ontological randomness” and “epistemic randomness,” implies some scientific autism, that desire to systematize, and a fundamental lack of understanding of randomness itself. It assumes that an observer can reach omniscience and can compute odds with perfect realism and without violating consistency rules. What is left becomes “randomness,” or something by another name that arises from aleatory forces that cannot be reduced by knowledge and analysis.
There is an angle worth exploring: why on earth do adults accept these Soviet-Harvard-style top-down methods without laughing, and actually go to build policies in Washington based on them, against the record, except perhaps to make readers of history laugh at them and diagnose new psychiatric conditions? And, likewise, why do we default to the assumption that events are experienced by people in the same manner? Why did we ever take notions of “objective” probability seriously?
After this foray into the psychology of the perception of the dynamics of time and events, let us move to our central point, the very core of our program, into what I have aggressively called the most useful problem in philosophy. The most useful, sadly.
*
Robert Merton, the villain of
Chapter 17
, a person said to be of a highly mechanistic mind (down to his interest in machinery and his use of mechanical metaphors to represent uncertainty), seems to have been created for the sole purpose of providing an illustration of dangerous Black Swan foolishness. After the crisis of 2008, he defended the risk taking caused by economists, giving the argument that “it was a Black Swan” simply because he did not see it coming, therefore, he said, the theories were fine. He did not make the leap that, since we do not see these events coming, we need to be robust to them. Normally, such people exit the gene pool; academic tenure holds them a bit longer.
*
The argument can actually be used to satisfy moral hazard and dishonest (probabilistically disguised) profiteering. Rubin had pocketed more than $100 million from Citigroup’s earning of profits from hidden risks that blow up only occasionally. After he blew up, he had an excuse—“It never happened before.” He kept his money; we, the taxpayers, who include schoolteachers and hairdressers, had to bail the company out and pay for the losses. This I call the moral hazard element in paying bonuses to people who are not robust to Black Swans, and who we knew
beforehand
were not robust to the Black Swan. This
beforehand
is what makes me angry.
*
It is indeed the absence of higher order representation—the inability to accept statements like “Is my method for assessing what is right or wrong right or wrong?”—that, we will see in the next section, is central when we deal with probability, that causes Dr. Johns to be suckers for measures and believe in them without doubting their beliefs. They fail to understand the metaprobability, the higher order probability—that is, the probability that the probability they are using may not be True.
†
The nontechnical reader should skip the rest of this section.


================================================================================
CHAPTER/SECTION 268 (Item 275)
================================================================================

V
(PERHAPS) THE MOST USEFUL PROBLEM IN THE HISTORY OF MODERN PHILOSOPHY
Small may not be the idea, after all—Where to find the powder room—Predict and perish—On school buses and intelligent textbooks
I am going to be blunt. Before
The Black Swan
(and associated papers) most of epistemology and decision theory was, to an actor in the real world, just sterile mind games and foreplay. Almost all the history of thought is about what we know, or think we know.
The Black Swan
is the
very first attempt
(that I know of) in the history of thought to provide a map of where we get hurt by what we don’t know, to set systematic limits to the fragility of knowledge—and to provide exact locations where these maps no longer work.
To answer the most common “criticism” by economists and (now bankrupt) bankers I mentioned in Section III, I am not saying “S**t happens,” I am saying “S**t happens in the Fourth Quadrant,” which is as different as mistaking prudence and caution for paranoia.
Furthermore, to be more aggressive, while limits like those attributed to Gödel bear massive philosophical consequences, but we can’t do much about them, I believe that the limits to empirical and statistical knowledge I have shown have sensible (if not vital) importance
and
we can do a lot with them in terms of solutions, by categorizing decisions based on the severity of the potential estimation error of the pair probability times consequence.
For instance, we can use it to build a safer society—to robustify what lies in the Fourth Quadrant.


================================================================================
CHAPTER/SECTION 269 (Item 276)
================================================================================

LIVING IN TWO DIMENSIONS
A vexing problem in the history of human thought is finding one’s position on the boundary between skepticism and gullibility, or how to believe and how to
not
believe. And how to make decisions based on these beliefs, since beliefs without decisions are just sterile. So this is not an epistemological problem (i.e., focusing on what is true or false); it is one of decision, action, and commitment.
Clearly, you cannot doubt everything and function; you cannot believe everything and survive. Yet the philosophical treatment of the problem has been highly incomplete, and, worse, has not improved much over the centuries, if it has improved at all. One class of thinkers, say the Cartesians, or the academic skeptics some eighteen centuries before them, in their own way, started with the rejection of everything upfront, with some even more radical, such as the Pyrrhonians, rejecting so much that they even reject skepticism as too dogmatic. The other class, say the medieval Scholastics or the modern-day pragmatists, starts with the fixation of beliefs, or some beliefs. While the medieval thinkers stop there, in an Aristotelian way, the early pragmatists, with the great thinker Charles Sanders Peirce, provided a ray of hope. They proposed to update and correct beliefs as a continuous work in progress (albeit under a known structure of probability, as Peirce believed in the existence and attainability of an ergodic, long-run, reachable state of convergence to truth). That brand of pragmatism (initially called pragmaticism) viewed knowledge as a rigorous interplay between anti-skepticism and fallibilism, i.e., between the two categories of what to doubt and what to accept. The application to my field, probability, and perhaps the most sophisticated version of the program, lies in the dense, difficult, deep, and brilliant forays of Isaac Levi into decision theory with the notion of corpus of belief, doxastic commitment, distance from expectation, and credal probabilities.
A ray of hope, perhaps, but still not even close. Not even remotely close to anything useful.
Think of living in a three-dimensional space while under the illusion of being in two dimensions. It may work well if you are a worm, certainly not if you happen to be a bird. Of course, you will not be aware of the truncation—and will be confronted with many mysteries, mysteries that
you cannot possibly clear up without adding a dimension, no matter how sophisticated you may get. And, of course, you will feel helpless at times. Such was the fate of knowledge all these centuries, when it was locked in two dimensions too simplistic to be of any use outside of classrooms. Since Plato only philosophers have spent time discussing what Truth was, and for a reason: it is unusable in practice. By focusing on the True/False distinction, epistemology remained, with very few exceptions, prisoner of an inconsequential, and highly incomplete, 2-D framework. The third missing dimension is, of course, the consequence of the True, and the severity of the False, the expectation. In other words,
the payoff from decisions
, the impact and magnitude of the result of such a decision. Sometimes one may be wrong and the mistake may turn out to be inconsequential. Or one may be right, say, on such a subject as the sex of angels, and it may turn out to be of no use beyond intellectual stamp collecting.
The simplified, philistinified, academified, and glorified notion of “evidence” becomes useless. With respect to Black Swans, you act to protect yourself from negative ones (or expose yourself to positive ones) even though you may have
no evidence
that they can take place, just as we check people for weapons before they board a plane even though we have
no evidence
that they are terrorists. This focus on off-the-shelf commoditized notions such as “evidence,” is a problem with people who claim to use “rigor” yet go bust on occasion.
A probabilistic world has trouble with “proof” as it is, but in a Black Swan world things are a lot worse.
Indeed, I know of almost no decision that is based on notions of True/False.
Once you start examining the payoff, the result of decisions, you will see clearly that the consequences of some errors may be benign, those of others may be severe. And you pretty much know which is which beforehand. You know which errors are consequential and which ones are not so much.
But first let us look at a severe problem in the derivation of knowledge about probabilities.


================================================================================
CHAPTER/SECTION 270 (Item 277)
================================================================================

THE DEPENDENCE ON THEORY FOR RARE EVENTS
During my
deserto
period, when I was getting severe but entertaining insults, I found myself debating a gentleman then employed by a firm called Lehman Brothers. That gentleman had made a statement in
The Wall
Street Journal
saying that events we saw in August 2007 should have happened once every ten thousand years. Sure enough, we had three such events three days in a row.
The Wall Street Journal
ran his picture and if you look at it, you can safely say, “He does not look ten thousand years old.” So where is he getting his “once in ten thousand years” probability? Certainly not from personal experience; certainly not from the records of Lehman Brothers—his firm had not been around for ten thousand years, and of course it didn’t stay around for another ten thousand years, as it went under right after our debate. So, you know that he’s getting his small probabilities from a theory.
The more remote the event, the less we can get empirical data (assuming generously that the future will resemble the past) and the more we need to rely on theory
.
Consider that the frequency of rare events cannot be estimated from empirical observation for the very reason that
they are rare
. We thus need a prior model representation for that; the rarer the event, the higher the error in estimation from standard inductive methods (say, frequency sampling from counting past occurrences), hence the higher the dependence on an a priori representation that extrapolates into the space of low-probability events (which necessarily are not seen often).
*
But even outside of small probabilities, the a priori problem is always present. It seems salient with respect to rare events, but it pervades probabilistic knowledge. I will present two versions I have been working on with two collaborators, Avital Pilpel, a philosopher of science (he walks fast), and Raphael Douady, a mathematician (he is sometimes a good walker, when he is not busy).
Epimenides the Cretan
Avital Pilpel and I expressed the regress argument as follows, as the epistemic problem of risk management, but the argument can be generalized to any form of probabilistic knowledge. It is a problem of
self-reference
by probability measures.
We can state it in the following way. If we need data to obtain a probability distribution to gauge knowledge about the future behavior of the distribution from its past results, and if, at the same time, we need a probability distribution to gauge data sufficiency and whether or not it is predictive of
the future, then we face a severe regress loop. This is a problem of self-reference akin to that of Epimenides the Cretan stating whether or not Cretans are liars. Indeed, it is too uncomfortably close to the Epimenides situation, since a probability distribution is used to assess the degree of truth but cannot reflect on its own degree of truth and validity. And, unlike many problems of self-reference, those related to risk assessment have severe consequences. The problem is more acute with small probabilities.
An Undecidability Theorem
This problem of self-reference, published with Pilpel after
The Black Swan
, went unnoticed as such. So Raphael Douady and I re-expressed the philosophical problem mathematically, and it appears vastly more devastating in its practical implications than the Gödel problem.
Raphael is, among the people I know, perhaps the man with the greatest mathematical erudition—he may have more mathematical culture than anyone in modern times, except perhaps for his late father, Adrien Douady.
At the time of writing, we may have produced a formal proof using mathematics, and a branch of mathematics called “measure theory” that was used by the French to put rigor behind the mathematics of probability. The paper is provisionally called
“Undecidability: On the inconsistency of estimating probabilities from a sample without binding a priori assumptions on the class of acceptable probabilities.”
It’s the Consequences …
Further, we in real life do not care about simple, raw probability (whether an event happens or does not happen); we worry about consequences (the size of the event; how much total destruction of lives or wealth, or other losses, will come from it; how much benefit a beneficial event will bring). Given that the less frequent the event, the more severe the consequences (just consider that the hundred-year flood is more severe, and less frequent, than the ten-year flood; the bestseller of the decade ships more copies than the bestseller of the year), our estimation of the
contribution
of the rare event is going to be massively faulty (contribution is probability times effect; multiply that by estimation error); and nothing can remedy it.
*
So the rarer the event, the less we know about its role—and the more we need to compensate for that deficiency with an extrapolative, generalizing theory. It will lack in rigor in proportion to claims about the rarity of the event. Hence theoretical and model error are more consequential in the tails; and, the good news,
some representations are more fragile than others
.
I showed that this error is more severe in Extremistan, where rare events are more consequential, because of a lack of scale, or a lack of asymptotic ceiling for the random variable. In Mediocristan, by comparison, the collective effect of regular events dominates and the exceptions are rather inconsequential—we know their effect, and it is very mild because one can diversify thanks to the “law of large numbers.” Let me provide once again an illustration of Extremistan. Less than 0.25 percent of all the companies listed in the world represent around half the market capitalization, a less than minuscule percentage of novels on the planet accounts for approximately half of fiction sales, less than 0.1 percent of drugs generate a little more than half the pharmaceutical industry’s sales—and less than 0.1 percent of risky events will cause at least half the damages and losses.
From Reality to Representation
*
Let me take another angle. The passage from theory to the real world presents two distinct difficulties: inverse problems and pre-asymptotics.
Inverse Problems
. Recall how much more difficult it is to re-create an ice cube from the results of the puddle (reverse engineering) than to forecast the shape of the puddle. In fact, the solution is not unique: the ice cube can be of very many shapes. I have discovered that the Soviet-Harvard method of viewing the world (as opposed to the Fat Tony style) makes us commit the error of confusing the two arrows (from ice cube to puddle; from puddle to ice cube). It is another manifestation of the error of Platonicity, of thinking that the Platonic form you have in your mind is the one you are observing outside the window. We see a lot of evidence of confusion of the two arrows in the history of medicine, the rationalistic medicine based on Aristotelian teleology, which I discussed earlier. This
confusion is based on the following rationale. We assume that we know the logic behind an organ, what it was made to do, and thus that we can use this logic in our treatment of the patient. It has been very hard in medicine to shed our theories of the human body. Likewise, it is easy to construct a theory in your mind, or pick it up from Harvard, then go project it on the world. Then things are very simple.
This problem of confusion of the two arrows is very severe with probability, particularly with small probabilities.
*
As we showed with the undecidability theorem and the self-reference argument, in real life we do not observe probability distributions. We just observe events. So I can rephrase the results as follows: we do not know the statistical properties—until, of course, after the fact. Given a set of observations, plenty of statistical distributions can correspond to the exact same realizations—each would extrapolate differently outside the set of events from which it was derived. The inverse problem is more acute when more theories, more distributions can fit a set of data, particularly in the presence of nonlinearities or nonparsimonious distributions.
†
Under nonlinearities, the families of possible models/parametrization explode in numbers.
‡
But the problem gets more interesting in some domains. Recall the Casanova problem in
Chapter 8
. For environments that tend to produce negative Black Swans, but no positive Black Swans (these environments are called negatively skewed), the problem of small probabilities is worse. Why? Clearly, catastrophic events will be necessarily absent from the data, since the survivorship of the variable itself will depend on such effect. Thus such distributions will let the observer become prone to overestimation of stability and underestimation of potential volatility and risk.
This point—that things have a bias to appear more stable and less risky in the past, leading us to surprises—needs to be taken seriously, particularly in the medical field. The history of epidemics, narrowly studied, does not suggest the risks of the great plague to come that will dominate the planet. Also I am convinced that in doing what we are to the environment, we greatly underestimate the potential instability we will experience somewhere from the cumulative damage we have done to nature.
One illustration of this point is playing out just now. At the time of writing, the stock market has proved much, much riskier than innocent retirees were led to believe from historical discourses showing a hundred years of data. It is down close to 23 percent for the decade ending in 2010, while the retirees were told by finance charlatans that it was expected to rise by around 75 percent over that time span. This has bankrupted many pension plans (and the largest car company in the world), for they truly bought into that “empirical” story—and of course it has caused many disappointed people to delay their retirement. Consider that we are suckers and will gravitate toward
those variables that are unstable but that appear stable
.
Preasymptotics
. Let us return to Platonicity with a discussion of preasymptotics, what happens in the short term. Theories are, of course, a bad thing to start with, but they can be worse in some situations when they were derived in idealized situations, the asymptote, but are used outside the asymptote (its limit, say infinity or the infinitesimal). Mandelbrot and I showed how some asymptotic properties do work well preasymptotically in Mediocristan, which is why casinos do well; matters are different in Extremistan.
Most statistical education is based on these asymptotic, Platonic properties, yet we live in the real world, which rarely resembles the asymptote. Statistical theorists know it, or claim to know it, but not your regular user of statistics who talks about “evidence” while writing papers. Furthermore, this compounds what I called the ludic fallacy: most of what students
of mathematical statistics do is assume a structure similar to the closed structures of games, typically with a priori known probability. Yet the problem we have is not so much making computations once you know the probabilities, but finding the true distribution for the horizon concerned. Many of our knowledge problems come from this tension between a priori and a posteriori.
Proof in the Flesh
There is no reliable way to compute small probabilities
. I argued philosophically the difficulty of computing the odds of rare events. Using almost all available economic data—and I used economic data because that’s where the clean data was—I showed the impossibility of computing
from the data
the measure of how far away from the Gaussian one was. There is a measure called kurtosis that the reader does not need to bother with, but that represents “how fat the tails are,” that is, how much rare events play a role. Well, often, with ten thousand pieces of data, forty years of daily observations, one single observation represents 90 percent of the kurtosis! Sampling error is too large for any statistical inference about how non-Gaussian something is, meaning that if you miss a single number, you miss the whole thing. The instability of the kurtosis implies that a certain class of statistical measures should be totally disallowed. This proves that everything relying on “standard deviation,” “variance,” “least square deviation,” etc., is bogus.
Further, I also showed that it is impossible to use fractals to get acceptably precise probabilities—simply because a very small change in what I called the “tail exponent” in
Chapter 16
, coming from observation error, would make the probabilities change by a factor of 10, perhaps more.
Implication: the need to avoid exposure to small probabilities in a certain domain. We simply cannot compute them.


================================================================================
CHAPTER/SECTION 271 (Item 278)
================================================================================

FALLACY OF THE SINGLE EVENT PROBABILITY
Recall from
Chapter 10
, with the example of the behavior of life expectancy, that the conditional expectation of additional life drops as one advances in age (as you get older you are expected to live a smaller number of years; this comes from the fact that there is an asymptotic “soft” ceiling to how old a human can get). Expressing it in units of standard deviations, the conditional expectation of a Mediocristani Gaussian variable,
conditional on it being higher than a threshold of 0, is .8 (standard deviations). Conditional on it being higher than a threshold of 1, it will be 1.52. Conditional on it being higher than 2, it will be 2.37. As you see, the two numbers should converge to each other as the deviations become large, so conditional on it being higher than 10 standard deviations, a random variable will be expected to be just 10.
In Extremistan, things work differently. The conditional expectation of an increase in a random variable does not converge to the threshold as the variable gets larger. In the real world, say with stock returns (and all economic variables), conditional on a loss being worse than 5 units, using any unit of measure (it makes little difference), it will be around 8 units. Conditional that a move is more than 50 units, it should be around 80 units, and if we go all the way until the sample is depleted, the average move worse than 100 units is 250 units! This extends to all areas in which I found sufficient samples. This tells us that there is “no” typical failure and “no” typical success. You may be able to predict the occurrence of a war, but you will not be able to gauge its effect! Conditional on a war killing more than 5 million people, it should kill around 10 million (or more). Conditional on it killing more than 500 million, it would kill a billion (or more, we don’t know). You may correctly predict that a skilled person will get “rich,” but, conditional on his making it, his wealth can reach $1 million, $10 million, $1 billion, $10 billion—there is no typical number. We have data, for instance, for predictions of drug sales, conditional on getting things right. Sales estimates are totally uncorrelated to actual sales—some drugs that were correctly predicted to be successful had their sales underestimated by up to 22 times.
This absence of “typical” events in Extremistan is what makes something called prediction markets (in which people are assumed to make bets on events) ludicrous, as they consider events to be binary. “A war” is meaningless: you need to estimate its damage—and no damage is typical. Many predicted that the First World War would occur, but nobody really predicted its magnitude. One of the reasons economics does not work is that the literature is almost completely blind to this point.
Accordingly, Ferguson’s methodology (mentioned in
Chapter 1
) in looking at the prediction of events as expressed in the price of war bonds is sounder than simply counting predictions, because a bond, reflecting the costs to the governments involved in a war, is priced to cover the probability of an event
times
its consequences, not just the probability of an event.
So we should not focus on whether someone “predicted” an event without his statement having consequences attached to it.
Associated with the previous fallacy is the mistake of thinking that my message is that these Black Swans are necessarily more probable than assumed by conventional methods. They are mostly
less
probable, but have bigger effects. Consider that, in a winner-take-all environment, such as the arts, the odds of success are low, since there are fewer successful people, but the payoff is disproportionately high. So, in a fat-tailed environment, rare events can be less frequent (their probability is lower), but they are so powerful that their contribution to the total pie is more substantial.
The point is mathematically simple, but does not register easily. I’ve enjoyed giving graduate students in mathematics the following quiz (to be answered intuitively, on the spot). In a Gaussian world, the probability of exceeding one standard deviation is around 16 percent. What are the odds of exceeding it under a distribution of fatter tails (with the same mean and variance)? The right answer: lower, not higher—the number of deviations drops, but the few that take place matter more. It was puzzling to see that most graduate students get it wrong.
Back to stress testing again. At the time of writing, the U.S. government is having financial institutions stress-tested by assuming large deviations and checking the results against the capitalization of these firms. But the problem is, Where did they get the numbers? From the past? This is so flawed, since the past, as we saw, is no indication of future deviations in Extremistan. This comes from the atypicality of extreme deviations. My experience of stress testing is that it reveals little about the risks—but the risks can be used to assess the degree of model error.
Psychology of Perception of Deviations
Fragility of Intuitions About the Typicality of the Move
. Dan Goldstein and I ran a series of experiments about the intuitions of agents concerning such conditional expectations. We posed questions of the following sort: What is the average height of humans who are taller than six feet? What the average weight of people heavier than 250 pounds? We tried with a collection of variables from Mediocristan, including the above-mentioned height and weight, to which we added age, and we asked participants to guess variables from Extremistan, such as market capitalization (what is the average size of companies with capitalization in excess of $5 billion?)
and stock performance. The results show that, clearly, we have good intuitions when it comes to Mediocristan, but horribly poor ones when it comes to Extremistan—yet economic life is almost all Extremistan. We do not have good intuition for that atypicality of large deviations. This explains both foolish risk taking and how people can underestimate opportunities.
Framing the Risks
. Mathematically equivalent statements, I showed earlier with my example of survival rates, are not psychologically so. Worse, even professionals are fooled and base their decisions on their perceptual errors. Our research shows that the way a risk is framed sharply influences people’s understanding of it. If you say that, on average, investors will lose all their money every thirty years, they are more likely to invest than if you tell them they have a 3.3 percent chance of losing a certain amount every year.
The same is true of airplane rides. We have asked experimental participants: “You are on vacation in a foreign country and are considering flying a local airline to see a special island. Safety statistics show that, if you fly once a year, there will be on average one crash every thousand years on this airline. If you don’t take the trip, it is unlikely you’ll visit this part of the world again. Would you take the flight?” All the respondents said they would. But when we changed the second sentence so it read, “Safety statistics show that, on average, one in a thousand flights on this airline have crashed,” only 70 percent said they would take the flight. In both cases, the chance of a crash is 1 in 1,000; the latter formulation simply sounds more risky.


================================================================================
CHAPTER/SECTION 272 (Item 279)
================================================================================

THE PROBLEM OF INDUCTION AND CAUSATION IN THE COMPLEX DOMAIN
What Is Complexity?
I will simplify here with a functional definition of complexity—among many more complete ones. A complex domain is characterized by the following: there is a great degree of interdependence between its elements, both temporal (a variable depends on its past changes), horizontal (variables depend on one another), and diagonal (variable A depends on the past history of variable B). As a result of this interdependence, mechanisms are subjected to positive, reinforcing feedback loops, which cause “fat tails.” That is, they prevent the working of the Central Limit Theorem that, as we saw in
Chapter 15
, establishes Mediocristan thin tails under summation and aggregation of elements and causes “convergence to the Gaussian.” In lay terms, moves are exacerbated
over time instead of being dampened by counterbalancing forces. Finally, we have nonlinearities that accentuate the fat tails.
So, complexity implies Extremistan. (The opposite is not necessarily true.)
As a researcher, I have only focused on the Extemistan element of complexity theory, ignoring the other elements except as a backup for my considerations of unpredictability. But complexity has other consequences for the conventional analyses, and for causation.
Induction
Let us look again, from a certain angle, at the problem of “induction.” It becomes one step beyond archaic in a modern environment, making the Black Swan problem even more severe. Simply, in a complex domain, the discussion of induction versus deduction becomes too marginal to the real problems (except for a limited subset of variables, even then); the entire Aristotelian distinction misses an important dimension (similar to the one discussed earlier concerning the atypicality of events in Extremistan). Even other notions such as “cause” take on a different meaning, particularly in the presence of circular causality and interdependence.
*
The probabilistic equivalent is the move from a conventional random walk model (with a random variable moving in a fixed terrain and not interacting with other variables around it), to percolation models (where the terrain itself is stochastic, with different variables acting on one another).
Driving the School Bus Blindfolded
Alas, at the time of writing, the economics establishment is still ignorant of the presence of complexity, which degrades predictability. I will not get too involved in my outrage—instead of doing a second
deserto
, Mark Spitznagel and I are designing another risk management program to robustify portfolios against model error, error mostly stemming from the
government’s error in the projection of deficits, leading to excessive borrowing and possible hyperinflation.
I was once at the World Economic Forum in Davos; at one of my sessions, I illustrated interdependence in a complex system and the degradation of forecasting, with the following scheme: unemployment in New York triggered by Wall Street losses, percolating and generating unemployment in, say, China, then percolating back into unemployment in New York, is not analyzable analytically, because the feedback loops produced monstrous estimation errors. I used the notion of “convexity,” a disproportionate nonlinear response stemming from a variation in input (as the tools for measuring error rates go out of the window in the presence of convexity). Stanley Fisher, the head of the central bank of Israel, former IMF hotshot, co-author of a classic macroeconomics textbook, came to talk to me after the session to critique my point about such feedback loops causing unpredictability. He explained that we had input-output matrices that were good at calculating such feedbacks, and he cited work honored by the “Nobel” in economics. The economist in question was one Vassili Leontieff, I presume. I looked at him with the look “He is arrogant, but does not know enough to understand that he is not even wrong” (needless to say, Fisher was one of those who did not see the crisis coming). It was hard to get the message across that, even if econometric methods could track the effects of feedback loops in normal times (natural, since errors are small), such models said nothing about large disturbances. And I will repeat, large disturbances are everything in Extremistan.
The problem is that if I am right, Fisher’s textbook, and his colleagues’ textbooks, should be dispensed with. As should almost every prediction method that uses mathematical equations.
I tried to explain the problems of errors in monetary policy under nonlinearities: you keep adding money with no result … until there is hyperinflation. Or nothing. Governments should not be given toys they do not understand.
*
The “a priori” I am using here differs from the philosophical “a priori” belief, in the sense that it is a theoretical starting point, not a belief that is nondefeasible by experience.
*
Interestingly, the famous paper by Reverend Bayes that led to what we call Bayesian inference did not give us “probability” but expectation (expected average). Statisticians had difficulties with the concept so extracted probability from payoff. Unfortunately, this reduction led to the reification of the concept of probability, its adherents fogetting that probability is not natural in real life.
*
The intelligent reader who gets the idea that rare events are not computable can skip the remaining parts of this section, which will be extremely technical. It is meant to prove a point to those who studied too much to be able to see things with clarity.
*
This is an extremely technical point (to skip). The problem of the unknown distribution resembles, in a way, Bertrand Russell’s central difficulty in logic with the “this sentence is true” issue—a sentence cannot contain its own truth predicate. We need to apply Tarski’s solution: for every language, a metalanguage will take care of predicates of true and false about that language. With probability, simply, a metaprobability assigns degrees of credence to every probability—or, more generally, a probability distribution needs to be subordinated to a metaprobability distribution giving, say, the probability of a probability distribution being the wrong one. But luckily I have been able to express this with the available mathematical tools. I have played with this metadistribution problem in the past, in my book
Dynamic Hedging
(1997). I started putting an error rate on the Gaussian (by having my true distribution draw from two or more Gaussians, each with different parameters) leading to nested distributions almost invariably producing some class of Extremistan. So, to me, the variance of the distribution is, epistemologically, a measure of lack of knowledge about the average; hence the variance of variance is, epistemologically, a measure of lack of knowledge about the lack of knowledge of the mean—and the variance of variance is analog to the fourth moment of the distribution, and its kurtosis, which makes such uncertainty easy to express mathematically. This shows that: fat tails = lack of knowledge about lack of knowledge.
†
A Gaussian distribution is parsimonious (with only two parameters to fit). But the problem of adding layers of possible jumps, each with a different probability, opens up endless possibilities of combinations of parameters.
‡
One of the most common (but useless) comments I hear is that some solutions can come from “robust statistics.” I wonder how using these techniques can create information where there is none.
*
One consequence of the absence of “typicality” for an event on causality is as follows: Say an event can cause a “war.” As we saw, such war will still be undefined, since it may kill three people or a billion. So even in situations where we can identify cause and effect, we will know little, since the effect will remain atypical. I had severe problems explaining this to historians (except for Niall Ferguson) and political scientists (except for Jon Elster). Please explain this point (very politely) to your professor of Near and Middle Eastern studies.


================================================================================
CHAPTER/SECTION 273 (Item 280)
================================================================================

VI
THE FOURTH QUADRANT, THE SOLUTION TO THAT MOST USEFUL OF PROBLEMS
*
Did Aristotle walk slowly?—Will they follow the principles?—How to manufacture a Ponzi scheme and get credit for it
It is much more sound to take risks you can measure than to measure the risks you are taking.
There is a specific spot on the map, the Fourth Quadrant, in which the problem of induction, the pitfalls of empiricism come alive—the place where, I repeat, absence of evidence does not line up with evidence of absence. This section will allow us to base our decision on sounder epistemological grounds.
David Freedman, RIP
First, I need to pay homage to someone to whom knowledge has a large debt. The late Berkeley statistician David Freedman, who perhaps better than anyone uncovered the defects of statistical knowledge, and the inapplicability of some of the methods, sent me a farewell gift. He was supposed
to be present at the meeting of the American Statistical Association that I mentioned earlier, but canceled because of illness. But he prepared me for the meeting, with a message that changed the course of the Black Swan idea: be prepared; they will provide you with a certain set of self-serving arguments and you need to respond to them. The arguments were listed in his book in a section called “The Modelers’ Response.” I list most of them below.
The Modelers’ Response:
We know all that. Nothing is perfect. The assumptions are reasonable. The assumptions don’t matter. The assumptions are conservative. You can’t prove the assumptions are wrong. We’re only doing what everybody else does. The decision-maker has to be better off with us than without us. The models aren’t totally useless. You have to do the best you can with the data. You have to make assumptions in order to make progress. You have to give the models the benefit of the doubt. Where’s the harm?
This gave me the idea of using the approach “This is where your tools work,” instead of the “This is wrong” approach I was using before. The change in style is what earned me the hugs and supply of Diet Coke and helped me get my message across. David’s comments also inspired me to focus more on iatrogenics, harm caused by the need to use quantitative models.
David Freedman passed away a few weeks after the meeting.
*
Thank you, David. You were there when the Black Swan needed you. May you and your memory rest in peace.
Which brings us to the solution. After all this undecidability, the situation is not dire at all. Why? We, simply, can build a map of where these errors are more severe, what to watch out for.


================================================================================
CHAPTER/SECTION 274 (Item 281)
================================================================================

DECISIONS
When you look at the generator of events, you can tell a priori which environment can deliver large events (Extremistan) and which environment
cannot deliver them (Mediocristan). This is the only a priori assumption we need to make. The only one.
So that’s that.
I
. The first type of decision is simple, leading to a “binary” exposure: that is, you just care about whether something is true or false. Very true or very false does not bring you additional benefits or damage. Binary exposures do not depend on high-impact events as their payoff is limited. Someone is either pregnant or not pregnant, so if the person is “extremely pregnant” the payoff would be the same as if she were “slightly pregnant.” A statement is “true” or “false” with some confidence interval. (I call these M0 as, more technically, they depend on what is called the zero
th
moment, namely on the probability of events, and not on their magnitude—you just care about “raw” probability.) A biological experiment in the laboratory and a bet with a friend about the outcome of a soccer game belong to this category.
Clearly, binary outcomes are not very prevalent in life; they mostly exist in laboratory experiments and in research papers. In life, payoffs are usually open-ended, or, at least, variable.
II
. The second type of decision is more complex and entails more openended exposures. You do not just care about frequency or probability, but about the impact as well, or, even more complex, some function of the impact. So there is another layer of uncertainty of impact. An epidemic or a war can be mild or severe. When you invest you do not care how many times you gain or lose, you care about the cumulative, the expectation: how many times you gain or lose
times
the amount made or lost. There are even more complex decisions (for instance, when one is involved with debt) but I will skip them here.
We also care about which
A
. Event generators belong to Mediocristan (i.e., it is close to impossible for very large deviations to take place), an a priori assumption.
B
. Event generators belong to Extremistan (i.e., very large deviations are possible, or even likely).
Which provides the four quadrants of the map.


================================================================================
CHAPTER/SECTION 275 (Item 282)
================================================================================

THE FOURTH QUADRANT, A MAP
First Quadrant
. Simple binary payoffs, in Mediocristan: forecasting is safe, life is easy, models work, everyone should be happy. These situations are, unfortunately, more common in laboratories and games than in real life. We rarely observe these in payoffs in economic decision making. Examples: some medical decisions (concerning one single patient, not a population), casino bets, prediction markets.
TABLE 1: TABLEAU OF DECISIONS BY PAYOFF
M0 “True/False”
M1 Expectations
Medical results for one person (health, not epidemics)
Epidemics (number of persons infected)
Psychology experiments (yes/no answers)
Intellectual and artistic success (defined as book sales, citations, etc.)
Life/Death (for a single person, not for n persons)
Climate effects (any quantitative metric)
Symmetric bets in roulette
War damage (number of casualties)
Prediction markets
Security, terrorism, natural catastrophes (number of victims)
General risk management
Finance: performance of a nonleveraged investment (say, a retirement account)
Insurance (measures of expected losses)
Economics (policy)
Casinos
Second Quadrant
. Complex payoffs in Mediocristan: statistical methods may work satisfactorily, though there are some risks. True, use of Mediocristan models may not be a panacea, owing to preasymptotics, lack of independence, and model error. There clearly are problems here, but these have been addressed extensively in the literature, particularly by David Freedman.
Third Quadrant
. Simple payoffs in Extremistan: there is little harm in being wrong, because the possibility of extreme events does not impact the payoffs. Don’t worry too much about Black Swans.
Fourth Quadrant, the Black Swan Domain
. Complex payoffs in Extremistan:
that is where the problem resides; opportunities are present too. We need to avoid prediction of remote payoffs, though not necessarily ordinary ones. Payoffs from remote parts of the distribution are more difficult to predict than those from closer parts.
*
Actually, the Fourth Quadrant has two parts: exposures to positive or negative Black Swans. I will focus here on the negative one (exploiting the positive one is too obvious, and has been discussed in the story of Apelles the painter, in
Chapter 13
).
TABLE 2: THE FOUR QUADRANTS
The recommendation is to move from the Fourth Quadrant into the third one. It is not possible to change the distribution; it is possible to change the exposure, as will be discussed in the next section.
What I can rapidly say about the Fourth Quadrant is that all the skepticism associated with the Black Swan problem should be focused there. A general principle is that, while in the first three quadrants you can use
the best
model or theory you can find, and rely on it, doing so is dangerous in the Fourth Quadrant: no theory or model should be better than just any theory or model.
In other words, the Fourth Quadrant is
where the difference between absence of evidence and evidence of absence becomes acute
.
Next let us see how we can exit the Fourth Quadrant or mitigate its effects.
*
This section should be skipped by those who are not involved in social science, business, or, something even worse, public policy. Section VII will be less mundane.
*
David left me with a second surprise gift, the best gift anyone gave me during my
deserto:
he wrote, in a posthumous paper, that “efforts by statisticians to refute Taleb proved unconvincing,” a single sentence which turned the tide and canceled out hundreds of pages of mostly ad hominem attacks, as it alerted the reader that there was no refutation, that the criticisms had no substance. All you need is a single sentence like that to put the message back in place.
*
This is a true philosophical a priori since when you assume events belong to Extremistan (because of the lack of structure to the randomness), no additional empirical observations can possibly change your mind, since the property of Extremistan is to hide the possibility of Black Swan events—what I called earlier the masquerade problem.


================================================================================
CHAPTER/SECTION 276 (Item 283)
================================================================================

VII
WHAT TO DO WITH THE FOURTH QUADRANT
NOT USING THE WRONG MAP: THE NOTION OF IATROGENICS
So for now I can produce phronetic rules (in the Aristotelian sense of
phronesis
, decision-making wisdom). Perhaps the story of my life lies in the following dilemma. To paraphrase Danny Kahneman, for psychological comfort some people would rather use a map of the Pyrénées while lost in the Alps than use nothing at all. They do not do so explicitly, but they actually do worse than that while dealing with the future and using risk measures. They would prefer a defective forecast to nothing. So providing a sucker with a probabilistic measure does a wonderful job of making him take more risks. I was planning to do a test with Dan Goldstein (as part of our general research programs to understand the intuitions of humans in Extremistan). Danny (he is great to walk with, but he does not do aimless strolling,
“flâner”)
insisted that doing our own experiments was not necessary. There is plenty of research on anchoring that proves the toxicity of giving someone a wrong numerical estimate of risk. Numerous experiments provide evidence that professionals are significantly influenced by numbers that they know to be irrelevant to their decision, like writing down the last four digits of one’s social security number before making a numerical estimate of potential market moves. German judges, very respectable people, who rolled dice before sentencing issued sentences 50 percent longer when the dice showed a high number, without being conscious of it.
Negative Advice
Simply, don’t get yourself into the Fourth Quadrant, the Black Swan Domain. But it is hard to heed this sound advice.
Psychologists distinguish between acts of commission (what we do) and acts of omission. Although these are economically equivalent for the bottom line (a dollar not lost is a dollar earned), they are not treated equally in our minds. However, as I said, recommendations of the style “Do not do” are more robust empirically. How do you live long? By avoiding death. Yet people do not realize that success consists mainly in avoiding losses, not in trying to derive profits.
Positive advice is usually the province of the charlatan. Bookstores are full of books on how someone became successful; there are almost no books with the title
What I Learned Going Bust
, or
Ten Mistakes to Avoid in Life
.
Linked to this need for positive advice is the preference we have to
do something rather than nothing
, even in cases when doing something is harmful.
I was recently on TV and some empty-suit type kept bugging me for precise advice on how to pull out of the crisis. It was impossible to communicate my “what not to do” advice, or to point out that my field is error avoidance not emergency room surgery, and that it could be a stand-alone discipline, just as worthy. Indeed, I spent twelve years trying to explain that in many instances it was better—and wiser—to have no models than to have the mathematical acrobatics we had.
Unfortunately such lack of rigor pervades the place where we expect it the least: institutional science. Science, particularly its academic version, has never liked negative results, let alone the statement and advertising of its own limits. The reward system is not set up for it. You get respect for doing funambulism or spectator sports—following the right steps to become “the Einstein of Economics” or “the next Darwin” rather than give society something real by debunking myths or by cataloguing where our knowledge stops.
Let me return to Gödel’s limit. In some instances we accept the limits of knowledge, trumpeting, say, Gödel’s “breakthrough” mathematical limit because it shows elegance in formulation and mathematical prowess—though the importance of this limit is dwarfed by our practical limits in forecasting climate changes, crises, social turmoil, or the fate of the endowment funds that will finance research into such future “elegant” limits.
This is why I claim that my Fourth Quadrant solution is the most applied of such limits.
Iatrogenics and the Nihilism Label
Let’s consider medicine (that sister of philosophy), which only started saving lives less than a century ago (I am generous), and to a lesser extent than initially advertised in the popular literature, as the drops in mortality seem to arise much more from awareness of sanitation and the (random) discovery of antibiotics rather than from therapeutic contributions. Doctors, driven by the beastly illusion of control, spent a long time killing patients, not considering that “doing nothing” could be a valid option (it was “nihilistic”)—and research compiled by Spyros Makridakis shows that they still do to some extent, particularly in the overdiagnoses of some diseases.
The nihilism label has always been used to harm. Practitioners who were conservative and considered the possibility of letting nature do its job, or who stated the limits of our medical understanding, were until the 1960s accused of “therapeutic nihilism.” It was deemed “unscientific” to avoid embarking on a course of action based on an incomplete understanding of the human body—to say, “This is the limit; this is where my body of knowledge stops.” It has been used against this author by intellectual fraudsters trying to sell products.
The very term
iatrogenics
, i.e., the study of the harm caused by the healer, is not widespread—I have never seen it used outside medicine. In spite of my lifelong obsession with what is called type 1 error, or the false positive, I was only introduced to the concept of iatrogenic harm very recently, thanks to a conversation with the essayist Bryan Appleyard. How can such a major idea remain hidden from our consciousness? Even in medicine, that is, modern medicine, the ancient concept “Do no harm” sneaked in very late. The philosopher of science Georges Canguilhem wondered why it was not until the 1950s that the idea came to us. This, to me, is a mystery: how professionals can cause harm for such a long time in the name of knowledge and get away with it.
Sadly, further investigation shows that these iatrogenics were mere rediscoveries after science grew too arrogant by the Enlightenment. Alas, once again, the elders knew better—Greeks, Romans, Byzantines, and Arabs had a built-in respect for the limits of knowledge. There is a treatise by the medieval Arab philosopher and doctor Al-Ruhawi which betrays
the familiarity of these Mediterranean cultures with iatrogenics. I have also in the past speculated that religion saved lives by taking the patient away from the doctor. You could satisfy your illusion of control by going to the Temple of Apollo rather than seeing the doctor. What is interesting is that the ancient Mediterraneans may have understood the trade-off very well and may have accepted religion partly as a tool to tame the illusion of control.
You cannot do anything with knowledge unless you know where it stops, and the costs of using it. Post-Enlightenment science, and its daughter superstar science, were lucky to have done well in (linear) physics, chemistry, and engineering. But at some point we need to give up on elegance to focus on something that was given short shrift for a very long time: the maps showing what current knowledge and current methods do not do for us; and a rigorous study of generalized scientific iatrogenics, what harm can be caused by science (or, better, an exposition of what harm has been done by science). I find it the most respectable of pursuits.
Iatrogenics of Regulators
. Alas, the call for more (unconditional) regulation of economic activity appears to be a normal response. My worst nightmares have been the results of regulators. It was they who promoted the reliance on ratings by credit agencies and the “risk measurement” that fragilized the system as bankers used them to build positions that turned sour. Yet every time there is a problem, we do the Soviet-Harvard thing of more regulation, which makes investment bankers, lawyers, and former-regulators-turned-Wall-Street-advisers rich. They also serve the interest of other groups.


================================================================================
CHAPTER/SECTION 277 (Item 284)
================================================================================

PHRONETIC RULES: WHAT IS WISE TO DO (OR NOT DO) IN REAL LIFE TO MITIGATE THE FOURTH QUADRANT IF YOU CAN’T BARBELL?
The most obvious way to exit the Fourth Quadrant is by “truncating,” cutting certain exposures by purchasing insurance, when available, putting oneself in the “barbell” situation described in
Chapter 13
. But if you are not able to barbell, and cannot avoid the exposure, as with, say, climate notions, exposure to epidemics, and similar items from the previous table, then we can subscribe to the following rules of “wisdom” to increase robustness.
1. Have respect for time and nondemonstrative knowledge
.
Recall my respect for Mother Earth—simply because of its age. It takes much, much longer for a series of data in the Fourth Quadrant to reveal its properties. I had been railing that compensation for bank executives, who are squarely in the Fourth Quadrant, is done on a short-term window, say yearly, for things that blow up every five, ten, or fifteen years, causing a mismatch between observation window and window of a sufficient length to reveal the properties. Bankers get rich in spite of long-term negative returns.
Things that have worked for a long time are preferable—they are more likely to have reached their ergodic states. At the worst, we don’t know how long they’ll last.
*
Remember that the burden of proof lies on someone disturbing a complex system, not on the person protecting the status quo.
2. Avoid optimization; learn to love redundancy
.
I’ve discussed redundancy and optimization in Section I. A few more things to say.
Redundancy (in terms of having savings and cash under the mattress) is the opposite of debt. Psychologists tell us that getting rich does not bring happiness—if you spend your savings. But if you hide it under the mattress, you are less vulnerable to a Black Swan.
Also, for example, one can buy insurance, or construct it, to robustify a portfolio.
Overspecialization also is not a great idea. Consider what can happen to you if your job disappears completely. Someone who is a Wall Street analyst (of the forecasting kind) moonlighting as a belly dancer will do a lot better in a financial crisis than someone who is just an analyst.
3. Avoid prediction of small-probability payoffs—though not necessarily of ordinary ones
.
Obviously, payoffs from remote events are more difficult to predict.
4. Beware the “atypicality” of remote events
.
There are suckers’ methods called “scenario analysis” and “stress testing”—usually based on the past (or on some “make sense” theory). Yet (I showed earlier how) past shortfalls do not predict subsequent shortfalls, so we do not know what exactly to stress-test for. Likewise, “prediction markets” do not function here, since bets do not protect an open-ended exposure. They might work for a binary election, but not in the Fourth Quadrant.
5. Beware moral hazard with bonus payments
.
It’s optimal to make a series of bonuses by betting on hidden risks in the Fourth Quadrant, then blow up and write a thank-you letter. This is called the moral hazard argument. Bankers are always rich because of this bonus mismatch. In fact, society ends up paying for it. The same applies to company executives.
6. Avoid some risk metrics
.
Conventional metrics, based on Mediocristan, adjusted for large deviations, don’t work. This is where suckers fall in the trap—one far more extensive than just assuming something other than the Gaussian bell curve. Words like “standard deviation” are not stable and do not measure anything in the Fourth Quadrant. Neither do “linear regression” (the errors are in the Fourth Quadrant), “Sharpe ratio,” Markowitz optimal portfolio, ANOVA shmanova, Least square, and literally anything mechanistically pulled out of a statistics textbook. My problem has been that people can accept the role of rare events, agree with me,
and
still use these metrics, which leads me to wonder if this is a psychological disorder.
7. Positive or negative Black Swan?
Clearly the Fourth Quadrant can present positive or negative exposures to the Black Swan; if the exposure is negative, the true mean is more likely to be underestimated by measurement of past realizations, and the total potential is likewise poorly gauged.
Life expectancy of humans is not as long as we suspect (under globalization) because the data are missing something central: the big epidemic
(which far outweighs the gains from cures). The same, as we saw, with the return on risky investments.
On the other hand, research ventures show a less rosy past history. A biotech company (usually) faces positive uncertainty, while a bank faces almost exclusively negative shocks.
Model errors benefit those exposed to positive Black Swans. In my new research, I call that being “concave” or “convex” to model error.
8. Do not confuse absence of volatility with absence of risk
.
Conventional metrics using volatility as an indicator of stability fool us, because the evolution into Extremistan is marked by a lowering of volatility—and a greater risk of big jumps. This has fooled a chairman of the Federal Reserve called Ben Bernanke—as well as the entire banking system. It will fool again.
9. Beware presentations of risk numbers
.
I presented earlier the results showing how risk perception is subjected to framing issues that are acute in the Fourth Quadrant. They are much more benign elsewhere.
*
Most of the smear campaign I mentioned earlier revolves around misrepresentation of the insurance-style properties and performance of the hedging strategies for the barbell and “portfolio robustification” associated with Black Swan ideas, a misrepresentation perhaps made credible by the fact that when one observes returns on a short-term basis, one sees nothing relevant except shallow frequent variations (mainly losses). People just forget to cumulate properly and remember frequency rather than total. The real returns, according to the press, were around 60 percent in 2000 and more than 100 percent in 2008, with relatively shallow losses and profits otherwise, so it would be child’s play to infer that returns would be in the triple digits over the past decade (all you need is one good jump). The Standard and Poor’s 500 was down 23 percent over the same ten-year period.


================================================================================
CHAPTER/SECTION 278 (Item 285)
================================================================================

VIII
THE TEN PRINCIPLES FOR A BLACK-SWAN-ROBUST SOCIETY
*
I wrote the following “ten principles” mostly for economic life to cope with the Fourth Quadrant, in the aftermath of the crisis.
1. What is fragile should break early, while it’s still small
.
Nothing should ever become too big to fail. Evolution in economic life helps those with the maximum amount of hidden risks become the biggest.
2. No socialization of losses and privatization of gains
.
Whatever may need to be bailed out should be nationalized; whatever does not need a bailout should be free, small, and risk-bearing. We got ourselves into the worst of capitalism and socialism. In France, in the 1980s, the socialists took over the banks. In the United States in the 2000s, the banks took over the government. This is surreal.
3. People who were driving a school bus blindfolded (and crashed it) should never be given a new bus
.
The economics establishment (universities, regulators, central bankers, government officials, various organizations staffed with economists) lost
its legitimacy with the failure of the system in 2008. It is irresponsible and foolish to put our trust in their ability to get us out of this mess. It is also irresponsible to listen to advice from the “risk experts” and business school academia still promoting their measurements, which failed us (such as Value-at-Risk). Find the smart people whose hands are clean.
4. Don’t let someone making an “incentive” bonus manage a nuclear plant—or your financial risks
.
Odds are he would cut every corner on safety to show “profits” from these savings while claiming to be “conservative.” Bonuses don’t accommodate the hidden risks of blowups. It is the asymmetry of the bonus system that got us here. No incentives without disincentives: capitalism is about rewards and punishments, not just rewards.
5. Compensate complexity with simplicity
.
Complexity from globalization and highly networked economic life needs to be countered by simplicity in financial products. The complex economy is already a form of leverage. It’s the leverage of efficiency. Adding debt to that system produces wild and dangerous gyrations and provides no room for error. Complex systems survive thanks to slack and redundancy, not debt and optimization. Capitalism cannot avoid fads and bubbles. Equity bubbles (as in 2000) have proved to be mild; debt bubbles are vicious.
6. Do not give children dynamite sticks, even if they come with a warning label
.
Complex financial products need to be banned because nobody understands them, and few are rational enough to know it. We need to protect citizens from themselves, from bankers selling them “hedging” products, and from gullible regulators who listen to economic theorists.
7. Only Ponzi schemes should depend on confidence. Governments should never need to “restore confidence.”
In a Ponzi scheme (the most famous being the one perpetrated by Bernard Madoff), a person borrows or takes funds from a new investor to repay an existing investor trying to exit the investment.
Cascading rumors are a product of complex systems. Governments cannot stop the rumors. Simply, we need to be in a position to shrug off rumors, be robust to them.
8. Do not give an addict more drugs if he has withdrawal pains
.
Using leverage to cure the problems of too much leverage is not homeopathy, it’s denial. The debt crisis is not a temporary problem, it’s a structural one. We need rehab.
9. Citizens should not depend on financial assets as a repository of value and should not rely on fallible “expert” advice for their retirement
.
Economic life should be definancialized. We should learn not to use markets as warehouses of value: they do not harbor the certainties that normal citizens can require, in spite of “expert” opinions. Investments should be for entertainment. Citizens should experience anxiety from their own businesses (which they control), not from their investments (which they do not control).
10. Make an omelet with the broken eggs
.
Finally, the crisis of 2008 was not a problem to fix with makeshift repairs, any more than a boat with a rotten hull can be fixed with ad hoc patches. We need to rebuild the new hull with new (stronger) material; we will have to remake the system before it does so itself. Let us move voluntarily into a robust economy by helping what needs to be broken break on its own, converting debt into equity, marginalizing the economics and business school establishments, shutting down the “Nobel” in economics, banning leveraged buyouts, putting bankers where they belong, clawing back the bonuses of those who got us here (by claiming restitution of the funds paid to, say, Robert Rubin or banksters whose wealth has been subsidized by taxpaying schoolteachers), and teaching people to navigate a world with fewer certainties.
Then we will see an economic life closer to our biological environment: smaller firms, a richer ecology, no speculative leverage—a world in which entrepreneurs, not bankers, take the risks, and in which companies are born and die every day without making the news.
After this foray into business economics, let us now move to something less vulgar.
*
This passage was published as an editorial in 2009 in the
Financial Times
. Some editor—who no doubt had not read
The Black Swan
—changed my “Black-Swan-robust” into “Black-Swan-proof.” There is no such thing as Black Swan proof, but robust is good enough.


================================================================================
CHAPTER/SECTION 279 (Item 286)
================================================================================

IX
AMOR FATI: HOW TO BECOME INDESTRUCTIBLE
And now, reader, time to part again.
I am in Amioun, the village of my ancestors. Sixteen out of sixteen great-great-grandparents, eight out of eight great-grandparents, and four out of four grandparents are buried in the area, almost all within a four-mile radius. Not counting the great-uncles, cousins, and other relatives. They are all resting in cemeteries in the middle of groves of olive trees in the Koura valley at the base of Mount Lebanon, which rises so dramatically that you can see the snow above you only twenty miles away.
Today, at dusk, I went to St. Sergius, locally called Mar Sarkis, from the Aramaic, the cemetery of my side of the family, to say hello to my father and my uncle Dédé, who so much disliked my sloppy dressing during my rioting days. I am sure Dédé is still offended with me; the last time he saw me in Paris he calmly dropped that I was dressed like an Australian: so the real reason for my visit to the cemetery was more self-serving. I wanted to prepare myself for where I will go next.
This is my plan B. I kept looking at the position of my own grave. A Black Swan cannot so easily destroy a man who has an idea of his final destination.
I felt robust.
*   *   *
I am carrying Seneca on all my travels, in the original, as I relearned Latin—reading him in English, that language desecrated by economists and the bureaucrats of the Federal Reserve Bank of the United States, did not feel right. Not on this occasion. It would be equivalent to reading Yeats in Swahili.
Seneca was the great teacher and practitioner of Stoicism, who transformed Greek-Phoenician Stoicism from metaphysical and theoretical discourse into a practical and moral program of living, a way to reach the
summum bonum
, an untranslatable expression depicting a life of supreme moral qualities, as perceived by the Romans. But, even apart from this unreachable aim, he has practical advice, perhaps the only advice I can see transfer from words to practice. Seneca is the one who (with some help from Cicero) taught Montaigne that
to philosophize is to learn how to die
. Seneca is the one who taught Nietzsche the
amor fati
, “love fate,” which prompted Nietzsche to just shrug and ignore adversity, mistreatment by his critics, and his disease, to the point of being bored by them.
For Seneca, Stoicism is about dealing with loss, and finding ways to overcome our loss aversion—how to become less dependent on what you have. Recall the “prospect theory” of Danny Kahneman and his colleagues: if I gave you a nice house and a Lamborghini, put a million dollars in your bank account, and provided you with a social network, then, a few months later, took everything away, you would be much worse off than if nothing had happened in the first place.
Seneca’s credibility as a moral philosopher (to me) came from the fact that, unlike other philosophers, he did not denigrate the value of wealth, ownership, and property because he was poor. Seneca was said to be one of the wealthiest men of his day. He just made himself ready to lose everything every day. Every day. Although his detractors claim that in real life he was not the Stoic sage he claimed to be, mainly on account of his habit of seducing married women (with non-Stoic husbands), he came quite close to it. A powerful man, he just had many detractors—and, if he fell short of his Stoic ideal, he came much closer to it than his contemporaries. And, just as it is harder to have good qualities when one is rich than when one is poor, it is harder to be a Stoic when one is wealthy, powerful, and respected than when one is destitute, miserable, and lonely.
Nihil Perditi
In Seneca’s Epistle IX, Stilbo’s country was captured by Demetrius, called the Sacker of Cities. Stilbo’s children and his wife were killed. Stilbo was asked what his losses were.
Nihil perditi
, I have lost nothing, he answered.
Omnia mea mecum sunt!
My goods are all with me. The man had reached the Stoic self-sufficiency, the robustness to adverse events, called
apatheia
in Stoic jargon. In other words,
nothing that might be taken from him did he consider to be a good
.
Which includes one’s own life. Seneca’s readiness to lose everything extended to his own life. Suspected of partaking in a conspiracy, he was asked by the emperor Nero to commit suicide. The record says that he executed his own suicide in an exemplary way, unperturbed, as if he had prepared for it every day.
Seneca ended his essays (written in the epistolary form) with
vale
, often mistranslated as “farewell.” It has the same root as “value” and “valor” and means both “be strong (i.e., robust)” and “be worthy.”
Vale
.


================================================================================
CHAPTER/SECTION 280 (Item 287)
================================================================================

GLOSSARY
Academic libertarian:
someone (like myself) who considers that knowledge is subjected to strict rules but not institutional authority, as the interest of organized knowledge is self-perpetuation, not necessarily truth (as with governments). Academia can suffer from an acute
expert problem
(q.v.), producing cosmetic but fake knowledge, particularly in
narrative disciplines
(q.v.), and can be a main source of Black Swans.
Apelles-style strategy:
A strategy of seeking gains by collecting positive accidents from maximizing exposure to “good Black Swans.”
Barbell strategy:
a method that consists of taking both a defensive attitude and an excessively aggressive one at the same time, by protecting assets from all sources of uncertainty while allocating a small portion for high-risk strategies.
Bildungsphilister:
a philistine with cosmetic, nongenuine culture. Nietzsche used this term to refer to the dogma-prone newspaper reader and opera lover with cosmetic exposure to culture and shallow depth. I extend it to the buzzword-using researcher in nonexperimental fields who lacks in imagination, curiosity, erudition, and culture and is closely centered on his ideas, on his “discipline.” This prevents him from seeing the conflicts between his ideas and the texture of the world.
Black Swan blindness:
the underestimation of the role of the Black Swan, and occasional overestimation of a specific one.
Black Swan ethical problem:
Owing to the nonrepeatable aspect of the Black Swan, there is an asymmetry between the rewards of those who prevent and those who cure.
Confirmation error (or Platonic confirmation):
You look for instances that confirm your beliefs, your construction (or model)—and find them.
Empty-suit problem (or “expert problem”):
Some professionals have no differential abilities from the rest of the population, but for some reason, and against their empirical records, are believed to be experts: clinical psychologists, academic economists, risk “experts,” statisticians, political analysts, financial “experts,” military analysts, CEOs, et cetera. They dress up their expertise in beautiful language, jargon, mathematics, and often wear expensive suits.
Epilogism:
A theory-free method of looking at history by accumulating facts with minimal generalization and being conscious of the side effects of making causal claims.
Epistemic arrogance:
Measure the difference between what someone actually knows and how much he thinks he knows. An excess will imply arrogance, a deficit humility. An epistemocrat is someone of epistemic humility, who holds his own knowledge in greatest suspicion.
Epistemic opacity:
Randomness is the result of incomplete information at some layer. It is functionally indistinguishable from “true” or “physical” randomness.
Extremistan:
the province where the total can be conceivably impacted by a single observation.
Fallacy of silent evidence:
Looking at history, we do not see the full story, only the rosier parts of the process.
Fooled by randomness:
the general confusion between luck and determinism, which leads to a variety of superstitions with practical consequences, such as the belief that higher earnings in some professions are generated by skills when there is a significant component of luck in them.
Future blindness:
our natural inability to take into account the properties of the future—like autism, which prevents one from taking into account the existence of the minds of others.
Locke’s madman:
someone who makes impeccable and rigorous reasoning from faulty premises—such as Paul Samuelson, Robert Merton the minor, and Gerard Debreu—thus producing phony models of uncertainty that make us vulnerable to Black Swans.
Lottery-ticket fallacy:
the naïve analogy equating an investment in collecting
positive Black Swans to the accumulation of lottery tickets. Lottery tickets are not scalable.
Ludic fallacy (or uncertainty of the nerd):
the manifestation of the Platonic fallacy in the study of uncertainty; basing studies of chance on the narrow world of games and dice. A-Platonic randomness has an additional layer of uncertainty concerning the rules of the game in real life. The bell curve (Gaussian), or GIF (Great Intellectual Fraud), is the application of the ludic fallacy to randomness.
Mandelbrotian Gray Swan:
Black Swans that we can somewhat take into account—earthquakes, blockbuster books, stock market crashes—but for which it is not possible to completely figure out the properties and produce precise calculations.
Mediocristan:
the province dominated by the mediocre, with few extreme successes or failures. No single observation can meaningfully affect the aggregate. The bell curve is grounded in Mediocristan. There is a qualitative difference between Gaussians and scalable laws, much like gas and water.
Narrative discipline:
the discipline that consists in fitting a convincing and well-sounding story to the past. Opposed to experimental discipline.
Narrative fallacy:
our need to fit a story or pattern to a series of connected or disconnected facts. The statistical application is data mining.
Nerd knowledge:
the belief that what cannot be Platonized and studied does not exist at all, or is not worth considering. There even exists a form of skepticism practiced by the nerd.
Platonic fold:
the place where our Platonic representation enters into contact with reality and you can see the side effects of models.
Platonicity:
the focus on those pure, well-defined, and easily discernible objects like triangles, or more social notions like friendship or love, at the cost of ignoring those objects of seemingly messier and less tractable structures.
Probability distribution:
the model used to calculate the odds of different events, how they are “distributed.” When we say that an event is distributed according to the bell curve, we mean that the Gaussian bell curve can help provide probabilities of various occurrences.
Problem of induction:
the logical-philosophical extension of the Black Swan problem.
Randomness as incomplete information:
simply, what I cannot guess is random because my knowledge about the causes is incomplete, not necessarily because the process has truly unpredictable properties.
Retrospective distortion:
examining past events without adjusting for the forward passage of time. It leads to the illusion of posterior predictability.
Reverse-engineering problem:
It is easier to predict how an ice cube would melt into a puddle than, looking at a puddle, to guess the shape of the ice cube that may have caused it. This “inverse problem” makes narrative disciplines and accounts (such as histories) suspicious.
Round-trip fallacy:
the confusion of absence of evidence of Black Swans (or something else) for evidence of absence of Black Swans (or something else). It affects statisticians and other people who have lost part of their reasoning by solving too many equations.
Scandal of prediction:
the poor prediction record in some forecasting entities (particularly narrative disciplines) mixed with verbose commentary and a lack of awareness of their own dire past record.
Scorn of the abstract:
favoring contextualized thinking over more abstract, though more relevant, matters. “The death of one child is a tragedy; the death of a million is a statistic.”
Statistical regress argument (or the problem of the circularity of statistics):
We need data to discover a probability distribution. How do we know if we have enough? From the probability distribution. If it is a Gaussian, then a few points of data will suffice. How do we know it is a Gaussian? From the data. So we need the data to tell us what probability distribution to assume, and we need a probability distribution to tell us how much data we need. This causes a severe regress argument, which is somewhat shamelessly circumvented by resorting to the Gaussian and its kin.
Uncertainty of the deluded:
people who tunnel on sources of uncertainty by producing precise sources like the great uncertainty principle, or similar, less consequential matters, to real life; worrying about subatomic particles while forgetting that we can’t predict tomorrow’s crises.


================================================================================
CHAPTER/SECTION 281 (Item 288)
================================================================================

To Benoît Mandelbrot,
a Roman among Greeks


================================================================================
CHAPTER/SECTION 282 (Item 289)
================================================================================

ACKNOWLEDGMENTS FOR THE FIRST EDITION
I derived an unexpected amount of enjoyment in writing this book—in fact, it just wrote itself—and I want the reader to experience the same. I would like to thank the following friends.
I built up a large debt toward Peter Bevelin, an erudite and pure “thinking doer” with extreme curiosity who spends his waking hours chasing ideas and spotting the papers I am usually looking for; he scrutinized the text. Yechezkel Zilber, a Jerusalem-based idea-starved autodidact who sees the world
ab ovo
, from the egg, asked very tough questions, to the point of making me ashamed of the formal education I received and uncomfortable for not being a true autodidact like him—it is thanks to no-nonsense people that I am grounding my Black Swan idea in academic libertarianism. The scholar Philip Tetlock, who knows more about prediction than anyone since the Delphic times, went through the manuscript and scrutinized my arguments. Phil is so valuable and thorough that he was even more informational with the absence of comments than he was with his comments. I owe a big debt to Danny Kahneman who, in addition to the long conversations on my topics of human nature (and noting with horror that I remembered almost every comment), put me in contact with Phil Tetlock. I thank Maya Bar Hillel for inviting me to address the Society of Judgment and Decision Making at their annual meeting in Toronto in No
vember 2005—thanks to the generosity of the researchers there, and the stimulating discussions, I came back having taken away far more than I gave. Robert Shiller asked me to purge some “irreverent” comments, but the fact that he criticized the aggressiveness of the delivery, but not the content, was quite informational. Mariagiovanna Muso was the first to become conscious of the Black Swan effect on the arts and sent me along the right lines of research in sociology and anthropology. I had long discussions with the literary scholar Mihai Spariosu on Plato, Balzac, ecological intelligence, and cafés in Bucharest. Didier Sornette, always a phone call away, kept e-mailing me papers on various unadvertised, but highly relevant, subjects in statistical physics. Jean-Philippe Bouchaud offered a great deal of help on the problems associated with the statistics of large deviations. Michael Allen wrote a monograph for writers looking to get published, based on the ideas of
Chapter 8
—I subsequently rewrote
Chapter 8
through the eyes of a writer looking at his lot in life. Mark Blyth was always helpful as a sounding board, reader, and adviser. My friends at the DoD, Andy Marshall and Andrew Mays, supplied me with ideas and questions. Paul Solman, a voracious mind, went through the manuscript with severe scrutiny. I owe the term
Extremistan
to Chris Anderson, who found my earlier designation too bookish. Nigel Harvey guided me through the literature on forecasting.
I plied the following scientists with questions: Terry Burnham, Robert Trivers, Robyn Dawes, Peter Ayton, Scott Atran, Dan Goldstein, Alexander Reisz, Art De Vany, Raphael Douady, Piotr Zielonka, Gur Huberman, Elkhonon Goldberg, and Dan Sperber. Ed Thorp, the true living owner of the “Black-Scholes formula” was helpful; I realized, speaking to him, that economists ignore intellectual productions outside their club—regardless how valuable. Lorenzo Perilli was extremely generous with his comments about Menodotus and helped correct a few errors. Duncan Watts allowed me to present the third part of this book at a Columbia University seminar in sociology and collect all manner of comments. David Cowan supplied the graph in the Poincaré discussion, making mine pale by comparison. I also benefited from James Montier’s wonderful brief pieces on human nature. Bruno Dupire, as always, provides the best walking conversations.
It does not pay to be the loyal friend of a pushy author too close to his manuscript. Marie-Christine Riachi was given the thankless task of reading chapters in inverse order; I only gave her the incomplete pieces and, of those, only the ones (then) patently lacking in clarity. Jamil Baz received
the full text every time but chose to read it backwards. Laurence Zuriff read and commented on every chapter. Philip Halperin, who knows more about risk management than anyone (still) alive, offered wonderful comments and observations. Other victims: Cyrus Pirasteh, Bernard Oppetit, Pascal Boulard, Guy Riviere, Joelle Weiss, Didier Javice, Andreea Munteanu, Andrei Pokrovsky, Philippe Asseily, Farid Karkaby, George Nasr, Alina Stefan, George Martin, Stan Jonas, and Flavia Cymbalista. I also thank Linda Eckstein and Justin Fox (for the market graph), as well as Paul Kaju, Martin Pomp, and Lea Beresford.
I received helpful comments from the voracious intellectual Paul Solman (who went through the manuscript with a microscope). I owe a lot to Phil Rosenczweig, Avishai Margalit, Peter Forbes, Michael Schrage, Driss Ben Brahim, Vinay Pande, Antony Van Couvering, Nicholas Vardy, Brian Hinchcliffe, Aaron Brown, Espen Haug, Neil Chriss, Zvika Afik, Shaiy Pilpel, Paul Kedrosky, Reid Bernstein, Claudia Schmid, Jay Leonard, Shellwyn Weston, Tony Glickman, Paul Johnson, Chidem Kurdas (and the NYU Austrian economists), Charles Babbitt, plus so many anonymous persons I have forgotten about
*
…
Ralph Gomory and Jesse Ausubel of the Sloan Foundation run a research funding program called the Known, the Unknown, and the Unknowable. They offered their moral and financial help for the promotion of my ideas—I took the invaluable moral option. I also thank my business partners, coauthors, and intellectual associates: Espen Haug, Mark Spitznagel, Benoît Mandelbrot, Tom Witz, Paul Wilmott, Avital Pilpel, and Emanuel Derman. I also thank John Brockman and Katinka Matson for making this book possible, and Max Brockman for his comments on the draft. I thank Cindy, Sarah, and Alexander for their tolerance. In addition, Alexander helped with the graphs and Sarah worked on the bibliography. Mark Fandetti, Mark Horowitz, Bruce Waxman, Spiros Makridakis, Jack Schwagger, and Elie Ayache helped with the more technical typos. The readers Jonathan Skinner, Harry Thayer, and David Evans helped correct technical and factual mistakes. I thank Linda Eckstein and Justin Fox for suggesting to Mandelbrot and me the graph of the SP500.
I tried to give my editor, Will Murphy, the impression of being an unbearably stubborn author, only to discover that I was fortunate that he was an equally stubborn editor (but good at hiding it). He protected me from the intrusions of the standardizing editors. They have an uncanny ability to inflict maximal damage by breaking the internal rhythm of one’s prose with the minimum of changes. Will M. is also the right kind of party animal. I was also flattered that Daniel Menaker took the time to edit my text. I also thank Janet Wygal and Steven Meyers. The staff at Random House was accommodating—but they never got used to my phone pranks (like my trying to pass for Bernard-Henri Lévy). One of the highlights of my writing career was a long lunch with William Goodlad, my editor at Penguin, and Stefan McGrath, the managing director of the group. I suddenly realized that I could not separate the storyteller in me from the scientific thinker; as a matter of fact, the story came first to my mind, rather than as an after-the-fact illustration of the concept.
Part Three of this book inspired my class lectures at the University of Massachusetts at Amherst. I thank Dean Tom O’Brien for his support and encouragement. He loved to see me shake up indoctrinated Ph.D. students. I also thank my second home, the Courant Institute of Mathematical Sciences of New York University, for allowing me to lecture for three quarters of a decade.
It is unfortunate that one learns most from people one disagrees with—something Montaigne encouraged half a millennium ago but is rarely practiced. I discovered that it puts your arguments through robust seasoning since you know that these people will identify the slightest crack—and you get information about the limits of their theories as well as the weaknesses of your own. I tried to be more graceful with my detractors than with my friends—particularly those who were (and stayed) civilized. So, over my career, I learned a few tricks from a series of public debates, correspondence, and discussions with Robert C. Merton, Steve Ross, Myron Scholes, Philippe Jorion, and dozens of others (though, aside from Elie Ayache’s critique, the last time I heard something remotely new against my ideas was in 1994). These debates were valuable since I was looking for the extent of the counterarguments to my Black Swan idea and trying to figure out how my detractors think—or what they did not think about. Over the years I have ended up reading more material from those I disagree with than from those whose opinion I share—I read more Samuelson than Hayek, more Merton (the younger) than Merton (the elder), more Hegel than Montaigne, and more Descartes than Sextus. It is
the duty of every author to represent the ideas of his adversaries as faithfully as possible.
My greatest accomplishment in life is to have managed to befriend people, such as Elie Ayache and Jim Gatheral, in spite of some intellectual disagreements.
Most of this book was written during a peripatetic period when I freed myself of (almost) all business obligations, routines, and pressures, and went on meditative urban walks in a variety of cities where I gave a series of lectures on the Black Swan idea.
*
I wrote it largely in cafés—my preference has always been for dilapidated (but elegant) cafés in regular neighborhoods, as unpolluted with persons of commerce as possible. I also spent much time in Heathrow Terminal 4, absorbed in my writing to the point that I forgot about my allergy to the presence of strained businessmen around me.
*
I lost his business card, but would like to warmly thank a scientist traveling to Vienna aboard British Airways flight 700 on December 11, 2003, for suggesting the billiard ball illustration in
Chapter 11
. All I know about him is that he was fifty-two, gray-haired, English-born, wrote poetry on yellow notepads, and was traveling with seven suitcases since he was moving in with his thirty-five-year-old Viennese girlfriend.
*
It is impossible to go very deep into an idea when you run a business, no matter the number of hours the occupation entails—simply put, unless you are insensitive, the worries and feelings of responsibility occupy precious cognitive space. You may be able to study, meditate, and write if you are an employee, but not when you own a business—unless you are of an irresponsible nature. I thank my partner, Mark Spitznagel, for allowing me—thanks to the clarity of his mind and his highly systematic, highly disciplined, and well engineered approach—to gain exposure to high-impact rare events without my having to get directly involved in business activities.


================================================================================
CHAPTER/SECTION 283 (Item 290)
================================================================================

NOTES
BEHIND THE CURTAIN: ADDITIONAL NOTES, TECHNICAL COMMENTS, REFERENCES, AND READING RECOMMENDATIONS
I separate topics thematically; so general references will mostly be found in the chapter in which they first occur. I prefer to use a logical sequence here rather than stick to chapter division.


================================================================================
CHAPTER/SECTION 284 (Item 291)
================================================================================

PROLOGUE and CHAPTER 1
Bell curve
: When I write
bell curve
I mean the Gaussian bell curve, a.k.a. normal distribution. All curves look like bells, so this is a nickname. Also, when I write
the Gaussian basin
I mean all distributions that are similar and for which the improbable is inconsequential and of low impact (more technically, nonscalable—all moments are finite). Note that the visual presentation of the bell curve in histogram form masks the contribution of the remote event, as such an event will be a point to the far right or far left of the center.
Diamonds
: See Eco (2002).
Platonicity
: I’m simply referring to incurring the risk of using a wrong form—not that forms don’t exist. I am not against essentialisms; I am often skeptical of our reverse engineering and identification of the right form. It is an inverse problem!
Empiricist
: If I call myself an empiricist, or an empirical philosopher, it is because I am just suspicious of confirmatory generalizations and hasty theorizing. Do not confuse this with the British empiricist tradition. Also, many statisticians, as we will see with the Makridakis competition, call themselves “empirical” researchers, but are in fact just the opposite—they fit theories to the past.
Mention of Christ
: See Flavius Josephus’s
The Jewish War
.
Great War and prediction
: Ferguson (2006b).
Hindsight bias (retrospective distortion)
: See Fischhoff (1982b).
Historical fractures
: Braudel (1985), p. 169, quotes a little known passage from Gautier. He writes, “‘This long history,’ wrote Emile-Félix Gautier, ‘lasted a dozen centuries, longer than the entire history of France. Encountering the first Arab sword, the Greek language and thought, all that heritage went up in smoke, as if it never happened.’” For discussions of discontinuity, see also Gurvitch (1957), Braudel (1953), Harris (2004).
Religions spread as bestsellers
: Veyne (1971). See also Veyne (2005).
Clustering in political opinions
: Pinker (2002).
Categories
: Rosch (1973, 1978). See also Umberto Eco’s
Kant and the Platypus
.
Historiography and philosophy of history
: Bloch (1953), Carr (1961), Gaddis (2002), Braudel (1969, 1990), Bourdé and Martin (1989), Certeau (1975),
Muqaddamat
Ibn Khaldoun illustrate the search for causation, which we see already present in Herodotus. For philosophy of history, Aron (1961), Fukuyama (1992). For postmodern views, see Jenkins (1991). I show in Part Two how historiographers are unaware of the epistemological difference between forward and backward processes (i.e., between projection and reverse engineering).
Information and markets
: See Shiller (1981, 1989), DeLong et al. (1991), and Cutler et al. (1989). The bulk of market moves does not have a “reason,” just a contrived explanation.
Of descriptive value for crashes
: See Galbraith (1997), Shiller (2000), and Kindleberger (2001).


================================================================================
CHAPTER/SECTION 285 (Item 292)
================================================================================

CHAPTER 3
Movies
: See De Vany (2002). See also Salganik et al. (2006) for the contagion in music buying.
Religion and domains of contagion
: See Boyer (2001).
Wisdom (madness) of crowds
: Collectively, we can both get wiser or far more foolish. We may collectively have intuitions for Mediocristan-related matters, such as the weight of an ox (see Surowiecki, 2004), but my conjecture is that we fail in more complicated predictions (economic variables for which crowds incur pathologies—two heads are worse than one). For decision errors and groups, see Sniezek and Buckley (1993). Classic: Charles Mackay’s
Extraordinary Popular Delusions and the Madness of Crowds
.
Increase in the severity of events
: Zajdenweber (2000).
Modern life
: The nineteenth-century novelist Émile Zola welcomed the arrival of the market for culture in the late 1800s, of which he seemed to be one of the first beneficiaries. He predicted that the writers’ and artists’ ability to exploit the commercial system freed them from a dependence on patrons’ whims. Alas, this was accompanied with more severe concentration—very few people benefited from the system. Lahire (2006) shows how most writers, throughout history, have starved. Remarkably, we have ample data from France about the literary tradition.


================================================================================
CHAPTER/SECTION 286 (Item 293)
================================================================================

CHAPTER 4
Titanic
: The quote is from Dave Ingram’s presentation at the Enterprise Risk Management Symposium in Chicago on May 2, 2005. For more on LTCM, see Lowenstein (2000), Dunbar (1999).
Hume’s exposition
: Hume (1748, 2000).
Sextus Empriricus
: “It is easy, I think, to reject the method of induction (
). For since by way of it they want to make universals convincing on the basis of particulars, they will do this surveying all the particulars or some of them. But if some, the induction will be infirm, it being that some of the particulars omitted in the induction should be contrary to the universal; and if all, they will labor at an impossible task, since the particulars and infinite are indeterminate. Thus in either case it results, I think, that induction totters.”
Outline of Pyrrhonism
, Book II, p. 204.
Bayle
: The
Dictionnaire historique et critique
is long (twelve volumes, close to 6,000 pages) and heavy (40 pounds), yet it was an intellectual bestseller in its day, before being supplanted by the
philosophes
. It can be downloaded from the French Bibliothèque Nationale at
www.bn.fr
.
Hume’s inspiration from Bayle
: See Popkin (1951, 1955). Any reading of Bishop Huet (further down) would reveal the similarities with Hume.
Pre-Bayle thinkers
:
Dissertation sur la recherche de la vérité
, Simon Foucher, from around 1673. It is a delight to read. It makes the heuristics and biases tradition look like the continuation of the pre-Enlightenment prescientific revolution atmosphere.
Bishop Huet and the problem of induction
: “Things cannot be known with perfect certainty because their causes are infinite,” wrote Pierre-Daniel Huet in his
Philosophical Treatise on the Weaknesses of the Human Mind
. Huet, former bishop of Avranches, wrote this under the name Théocrite de Pluvignac, Seigneur de la Roche, Gentilhomme de Périgord. The chapter has another exact presentation of what became later known as “Hume’s problem.” That was in 1690, when the future David Home (later Hume) was minus twenty-two, so of no possible influence on Monseigneur Huet.
Brochard’s work
: I first encountered the mention of Brochard’s work (1888) in Nietzsche’s
Ecce Homo
, in a comment where he also describes the skeptics as straight talkers. “An excellent study by Victor Brochard,
Les sceptiques grecs
, in which my Laertiana are also employed. The skeptics! the only
honourable
type among the two and five fold ambiguous philosopher crowd!”
More
trivia: Brochard taught Proust (see Kristeva, 1998).
Brochard seems to have understood Popper’s problem (a few decades before Popper’s birth). He presents the views of the negative empiricism of Menodotus of Nicomedia in similar terms to what we would call today “Popperian” empiricism. I wonder if Popper knew anything about Menodotus. He does not seem to quote him anywhere. Brochard published his doctoral thesis,
De l’erreur
, in 1878 at the University of Paris, on the subject of error—wonderfully modern.
Epilogism
: We know very little about Menodotus except for attacks on his beliefs by his detractor Galen in the extant Latin version of the
Outline of Empiricism (Subfiguratio empírica)
, hard to translate:
Memoriam et sensum et vocans
epilogismum
hoc tertium, multotiens autem et preter memoriam nihil aliud ponens quam
epilogismum. (In addition to perception and recollection, the third method is
epilogism sensum
, as the practitioner has, besides memory, nothing other than
epilogism
senses; Perilli’s correction.
But there is hope. Perilli (2004) reports that, according to a letter by the translator Is-haq Bin Hunain, there may be a “transcription” of Menodotus’s work in Arabic somewhere for a scholar to find.
Pascal
: Pascal too had an idea of the confirmation problem and the asymmetry of inference. In his preface to the
Traité du vide
, Pascal writes (and I translate):
In the judgment they made that nature did not tolerate a vacuum, they only meant nature in the state in which they knew it, since, so claim so in general, it would not be sufficient to witness it in a hundred different encounters, nor in a thousand, not in any other number no matter how large, since it would be a single case that would deny the general definition, and if one was contrary, a single one …
Hume’s biographer
: Mossner (1970). For a history of skepticism, Victor Cousin’s lectures
Leçons d’histoire de la philosophie à la Sorbonne
(1828) and Hippolyte Taine’s
Les philosophes classiques
, 9th edition (1868, 1905). Popkin (2003) is a modern account. Also see Heckman (2003) and Bevan (1913). I have seen nothing in the modern philosophy of probability linking it to skeptical inquiry.
Sextus
: See Popkin (2003), Sextus, House (1980), Bayle, Huet, Annas and Barnes (1985), and Julia Anna and Barnes’s introduction in Sextus Empiricus (2000). Favier (1906)
is hard to find; the only copy I located, thanks to Gur Huberman’s efforts, was rotten—it seems that it has not been consulted in the past hundred years.
Menodotus of Nicomedia and the marriage between empiricism and skepticism
: According to Brochard (1887), Menodotus is responsible for the mixing of empiricism and Pyrrhonism. See also Favier (1906). See skepticism about this idea in Dye (2004), and Perilli (2004).
Function not structure; empirical tripod
: There are three sources, and three only, for experience to rely upon: observation, history (i.e., recorded observation), and judgment by analogy.
Algazel
: See his
Tahafut al falasifah
, which is rebutted by Averroës, a.k.a. Ibn-Rushd, in
Tahafut Attahafut
.
Religious skeptics
: There is also a medieval Jewish tradition, with the Arabic-speaking poet Yehuda Halevi. See Floridi (2002).
Algazel and the ultimate/proximate causation
: “… their determining, from the sole observation, of the nature of the necessary relationship between the cause and the effect, as if one could not witness the effect without the attributed cause of the cause without the same effect.”
(Tahafut
)
At the core of Algazel’s idea is the notion that if you drink because you are thirsty, thirst should not be seen as a
direct
cause. There may be a greater scheme being played out; in fact, there
is
, but it can only be understood by those familiar with evolutionary thinking. See Tinbergen (1963, 1968) for a modern account of the proximate. In a way, Algazel builds on Aristotle to attack him. In his
Physics
, Aristotle had already seen the distinction between the different layers of cause (formal, efficient, final, and material).
Modern discussions on causality
: See Reichenbach (1938), Granger (1999), and Pearl (2000).
Children and natural induction: See
Gelman and Coley (1990), Gelman and Hirschfeld (1999), and Sloman (1993).
Natural induction
: See Hespos (2006), Clark and Boyer (2006), Inagaki and Hatano (2006), Reboul (2006). See summary of earlier works in Plotkin (1998).


================================================================================
CHAPTER/SECTION 287 (Item 294)
================================================================================

CHAPTERS 5–7
“Economists”
: What I mean by “economists” are most members of the mainstream, neoclassical economics and finance establishment in universities—not fringe groups such as the Austrian or the Post-Keynesian schools.
Small numbers
: Tversky and Kahneman (1971), Rabin (2000).
Domain specificity
: Williams and Connolly (2006). We can see it in the usually overinterpreted Wason Selection Test: Wason (1960, 1968). See also Shaklee and Fischhoff (1982), Barron Beaty, and Hearshly (1988). Kahneman’s “They knew better” in Gilovich et al. (2002).
Updike
: The blurb is from Jaynes (1976).
Brain hemispheric specialization
: Gazzaniga and LeDoux (1978), Gazzaniga et al. (2005). Furthermore, Wolford, Miller, and Gazzaniga (2000) show probability matching by the left brain. When you supply the right brain with, say, a lever that produces desirable goods 60% of the time, and another lever 40%, the right brain will correctly push the first lever as the optimal policy. If, on the other hand, you supply the left brain with the same options, it will push the first lever 60 percent of the time and the other one 40—it will refuse to accept randomness. Goldberg (2005) argues that the specialty is along different lines: left-brain damage does not bear severe effects in children, unlike right-brain lesions, while this is the reverse for the elderly. I thank Elkhonon Goldberg for referring me to Snyder’s work; Snyder (2001). The experiment is from Snyder et al. (2003).
Sock selection and retrofit explanation
: The experiment of the socks is presented in Carter (1999); the original paper appears to be Nisbett and Wilson (1977). See also Montier (2007).
Astebro
: Astebro (2003). See “Searching for the Invisible Man,”
The Economist
, March 9, 2006. To see how the overconfidence of entrepreneurs can explain the high failure rate, see Camerer (1995).
Dopamine
: Brugger and Graves (1997), among many other papers. See also Mohr et al. (2003) on dopamine asymmetry.
Entropy and information
: I am purposely avoiding the notion of entropy because the way it is conventionally phrased makes it ill-adapted to the type of randomness we experience in real life. Tsallis entropy works better with fat tails.
Notes on George Perec
: Eco (1994).
Narrativity and illusion of understanding
: Wilson, Gilbert, and Centerbar (2003): “Helplessness theory has demonstrated that if people feel that they cannot control or predict their environments, they are at risk for severe motivational and cognitive deficits, such as depression.” For the writing down of a diary, see Wilson (2002) or Wegner (2002).
E. M. Forster’s example
: reference in Margalit (2002).
National character
: Terracciano et al. (2005) and Robins (2005) for the extent of individual variations. The illusion of nationality trait, which I usually call the “nationality heuristic,” does connect to the halo effect: see Rosenzweig (2006) and Cialdini (2001). See Anderson (1983) for the ontology of nationality.
Consistency bias
: What psychologists call the consistency bias is the effect of revising memories in such a way to make sense with respect to subsequent information. See Schacter (2001).
Memory not like storage on a computer
: Rose (2003), Nader and LeDoux (1999).
The myth of repressed memory
: Loftus and Ketcham (2004).
Chess players and disconfirmation
: Cowley and Byrne (2004).
Quine’s problem
: Davidson (1983) argues in favor of local, but against total, skepticism.
Narrativity
: Note that my discussion is not existential here, but merely practical, so my idea is to look at narrativity as an informational compression, nothing more involved philosophically (like whether a self is sequential or not). There is a literature on the “narrative self”—Bruner (2002) or whether it is necessary—see Strawson (1994) and his attack in Strawson (2004). The debate: Schechtman (1997), Taylor (1999), Phelan (2005). Synthesis in Turner (1996).
“Postmodernists” and the desirability of narratives
: See McCloskey (1990) and Frankfurter and McGoun (1996).
Narrativity of sayings and proverbs
: Psychologists have long examined the gullibility of people in social settings when faced with well-sounding proverbs. For instance, experiments have been made since the 1960s where people are asked whether they believe that a proverb is right, while another cohort is presented with the opposite meaning. For a presentation of the hilarious results, see Myers (2002).
Science as a narrative
: Indeed scientific papers can succeed by the same narrativity bias that “makes a story.” You need to get attention. Bushman and Wells (2001).
Discovering probabilities
: Barron and Erev (2003) show how probabilities are underestimated when they are not explicitly presented. Also personal communication with Barron.
Risk and probability
: See Slovic, Fischhoff, and Lichtenstein (1976), Slovic et al. (1977), and Slovic (1987). For risk as analysis and risk as feeling theory, see Slovic et al. (2002, 2003), and Taleb (2004c). See Bar-Hillel and Wagenaar (1991)
Link between narrative fallacy and clinical knowledge
: Dawes (1999) has a message for economists: see here his work on interviews and the concoction of a narrative. See also Dawes (2001) on the retrospective effect.
Two systems of reasoning
: See Sloman (1996, 2002), and the summary in Kahneman and Frederick (2002). Kahneman’s Nobel lecture sums it all up; it can be found at
www.nobel.se
. See also Stanovich and West (2000).
Risk and emotions
: Given the growing recent interest in the emotional role in behavior, there has been a growing literature on the role of emotions in both risk bearing and
risk avoidance: the “risk as feeling” theory. See Loewenstein et al. (2001) and Slovic et al. (2003a). For a survey see Slovic et al. (2003b) and see also Slovic (1987). For a discussion of the “affect heuristic,” see Finucane et al. (2000). For modularity, see Bates (1994).
Emotions and cognition
: For the effect of emotions on cognition, see LeDoux (2002). For risk, see Bechara et al. (1994).
Availability heuristic (how easily things come to mind)
: See Tversky and Kahneman (1973).
Real incidence of catastrophes
: For an insightful discussion, see Albouy (2002), Zajdenweber (2000), or Sunstein (2002).
Terrorism exploitation of the sensational
: See the essay in Taleb (2004c).
General books on psychology of decision making (heuristics and biases)
: Baron (2000) is simply the most comprehensive on the subject. Kunda (1999) is a summary from the standpoint of social psychology (sadly, the author died prematurely); shorter: Plous (1993). Also Dawes (1988) and Dawes (2001). Note that a chunk of the original papers are happily compiled in Kahneman et al. (1982), Kahneman and Tversky (2000), Gilovich et al. (2002), and Slovic (2001a and 2001b). See also Myers (2002) for an account on intuition and Gigerenzer et al. (2000) for an ecological presentation of the subject. The most complete account in economics and finance is Montier (2007), where his beautiful summary pieces that fed me for the last four years are compiled—not being an academic, he gets straight to the point. See also Camerer, Loewenstein, and Rabin (2004) for a selection of technical papers. A recommended review article on clinical “expert” knowledge is Dawes (2001).
More general psychology of decision presentations
: Klein (1998) proposes an alternative model of intuition. See Cialdini (2001) for social manipulation. A more specialized work, Camerer (2003), focuses on game theory.
General review essays and comprehensive books in cognitive science
: Newell and Simon (1972), Varela (1988), Fodor (1983), Marr (1982), Eysenck and Keane (2000), Lakoff and Johnson (1980). The
MIT Encyclopedia of Cognitive Science
has review articles by main thinkers.
Evolutionary theory and domains of adaptation
: See the original Wilson (2000), Kreps and Davies (1993), and Burnham (1997, 2003). Very readable: Burnham and Phelan (2000). The compilation of Robert Trivers’s work is in Trivers (2002). See also Wrangham (1999) on wars.
Politics
: “The Political Brain: A Recent Brain-imaging Study Shows That Our Political Predilections Are a Product of Unconscious Confirmation Bias,” by Michael Shermer,
Scientific American
, September 26, 2006.
Neurobiology of decision making
: For a general understanding of our knowledge about the brain’s architecture: Gazzaniga et al. (2002). Gazzaniga (2005) provides literary summaries of some of the topics. More popular: Carter (1999). Also recommended: Ratey (2001), Ramachandran (2003), Ramachandran and Blakeslee (1998), Carter (1999, 2002), Conlan (1999), the very readable Lewis, Amini, and Lannon (2000), and Goleman (1995). See Glimcher (2002) for probability and the brain. For the emotional brain, the three books by Damasio (1994, 2000, 2003), in addition to LeDoux (1998) and the more detailed LeDoux (2002), are the classics. See also the shorter Evans (2002). For the role of vision in aesthetics, but also in interpretation, Zeki (1999).
General works on memory
: In psychology, Schacter (2001) is a review work of the memory biases with links to the hindsight effects. In neurobiology, see Rose (2003) and Squire and Kandel (2000). A general textbook on memory (in empirical psychology) is Baddeley (1997).
Intellectual colonies and social life
: See the account in Collins (1998) of the “lineages” of philosophers (although I don’t think he was aware enough of the Casanova problem to take into account the bias making the works of solo philosophers less likely to survive). For an illustration of the aggressiveness of groups, see Uglow (2003).
Hyman Minsky’s work
: Minsky (1982).
Asymmetry
: Prospect theory (Kahneman and Tversky [1979] and Tversky and Kahneman [1992]) accounts for the asymmetry between bad and good random events, but it also shows that the negative domain is convex while the positive domain is concave, meaning that a loss of 100 is less painful than 100 losses of 1 but that a gain of 100 is also far less pleasurable than 100 times a gain of 1.
Neural correlates of the asymmetry
: See Davidson’s work in Goleman (2003), Lane et al. (1997), and Gehring and Willoughby (2002). Csikszentmihalyi (1993, 1998) further explains the attractiveness of steady payoffs with his theory of “flow.”
Deferred rewards and its neural correlates
: McLure et al. (2004) show the brain activation in the cortex upon making a decision to defer, providing insight on the limbic impulse behind immediacy and the cortical activity in delaying. See also Loewenstein et al. (1992), Elster (1998), Berridge (2005). For the neurology of preferences in Capuchin monkeys, Chen et al. (2005).
Bleed or blowup
: Gladwell (2002) and Taleb (2004c). Why bleed is painful can be explained by dull stress; Sapolsky et al. (2003) and Sapolsky (1998). For how companies like steady returns, Degeorge and Zeckhauser (1999). Poetics of hope: Mihailescu (2006).
Discontinuities and jumps
: Classified by René Thom as constituting seven classes; Thom (1980).
Evolution and small probabilities
: Consider also the naïve evolutionary thinking positing the “optimality” of selection. The founder of sociobiology, the great E. O. Wilson, does not agree with such optimality when it comes to rare events. In Wilson (2002), he writes:
The human brain evidently evolved to commit itself emotionally only to a small piece of geography, a limited band of kinsmen, and two or three generations into the future. To look neither far ahead nor far afield is elemental in a Darwinian sense.
We are innately inclined to ignore any distant possibility not yet requiring examination. It is, people say, just good common sense
. Why do they think in this shortsighted way?
The reason is simple: it is a hardwired part of our Paleolithic heritage. For hundreds of millennia, those who worked for short-term gain within a small circle of relatives and friends lived longer and left more offspring—even when their collective striving caused their chiefdoms and empires to crumble around them. The long view that might have saved their distant descendants required a vision and extended altruism instinctively difficult to marshal.
See also Miller (2000):
“Evolution has no foresight. It lacks the long-term vision of drug company management. A species can’t raise venture capital to pay its bills while its research team … This makes it hard to explain innovations.”
Note that neither author considered my age argument.


================================================================================
CHAPTER/SECTION 288 (Item 295)
================================================================================

CHAPTER 8
Silent evidence bears the name
wrong reference class
in the nasty field of philosophy of probability,
anthropic bias
in physics, and
survivorship bias
in statistics (economists present the interesting attribute of having rediscovered it a few times while being severely fooled by it).
Confirmation
: Bacon says in
On Truth
, “No pleasure is comparable to the standing upon the vantage ground of truth (a hill not to be commanded and where the air is always clear and serene), and to see the errors, and wanderings, and mists, and tempests, in the vale below.” This easily shows how great intentions can lead to the confirmation fallacy.
Bacon did not understand the empiricists
: He was looking for the golden mean. Again, from
On Truth
:
There are three sources of error and three species of false philosophy; the sophistic, the empiric and the superstitious. … Aristotle affords the most eminent instance of the first; for he corrupted natural philosophy by logic—thus he formed the world of categories. … Nor is much stress to be laid on his frequent recourse to experiment in his books on animals, his problems and other treatises, for he had already decided, without having properly consulted experience as the basis of his decisions and axioms. … The empiric school produces dogmas of a more deformed and monstrous nature than the sophistic or theoretic school; not being founded in the light of common notions (which however poor and superstitious, is yet in a manner universal and of general tendency), but in the confined obscurity of a few experiments.
Bacon’s misconception may be the reason it took us a while to understand that they treated history (and experiments) as mere and vague “guidance,” i.e., epilogy.
Publishing
: Allen (2005), Klebanoff (2002), Epstein (2001), de Bellaigue (2004), and Blake (1999). For a funny list of rejections, see Bernard (2002) and White (1982). Michael Korda’s memoir, Korda (2000), adds some color to the business. These books are anecdotal, but we will see later that books follow steep scale-invariant structures with the implication of a severe role for randomness.
Anthropic bias
: See the wonderful and comprehensive discussion in Bostrom (2002). In physics, see Barrow and Tipler (1986) and Rees (2004). Sornette (2004) has Gott’s derivation of survival as a power law. In finance, Sullivan et al. (1999) discuss survivorship bias. See also Taleb (2004a). Studies that ignore the bias and state inappropriate conclusions: Stanley and Danko (1996) and the more foolish Stanley (2000).
Manuscripts and the Phoenicians
: For survival and science, see Cisne (2005). Note that the article takes into account physical survival (like fossil), not cultural, which implies a selection bias. Courtesy Peter Bevelin.
Stigler’s law of eponymy
: Stigler (2002).
French book statistics
:
Lire
, April 2005.
Why dispersion matters
: More technically, the distribution of the extremum (i.e., the maximum or minimum) of a random variable depends more on the variance of the process than on its mean. Someone whose weight tends to fluctuate a lot is more likely to show you a picture of himself very thin than someone else whose weight is on average lower but remains constant. The mean (read skills) sometimes plays a very, very small role.
Fossil record
: I thank the reader Frederick Colbourne for his comments on this subject. The literature calls it the “pull of the recent,” but has difficulty estimating the effects, owing to disagreements. See Jablonski et al. (2003).
Undiscovered public knowledge
: Here is another manifestation of silent evidence: you can actually do lab work sitting in an armchair, just by linking bits and pieces of research by people who labor apart from one another and miss on connections. Using bibliographic analysis, it is possible to find links between published information that had not been known previously by researchers. I “discovered” the vindication of the armchair in Fuller (2005). For other interesting discoveries, see Spasser (1997) and Swanson (1986a, 1986b, 1987).
Crime
: The definition of economic “crime” is something that comes in hindsight. Regulations, once enacted, do not run retrospectively, so many activities causing excess are never sanctioned (e.g., bribery).
Bastiat
: See Bastiat (1862–1864).
Casanova
: I thank the reader Milo Jones for pointing out to me the exact number of volumes. See Masters (1969).
Reference point problem
: Taking into account background information requires a form of thinking in
conditional
terms that, oddly, many scientists (especially the better ones) are incapable of handling. The difference between the two odds is called, simply, conditional probability. We are computing the probability of surviving
conditional
on our being in the sample itself. Simply put, you cannot compute probabilities if your survival is part of the condition of the realization of the process.
Plagues
: See McNeill (1976).


================================================================================
CHAPTER/SECTION 289 (Item 296)
================================================================================

CHAPTER 9
Intelligence and Nobel
: Simonton (1999). If IQ scores correlate, they do so very weakly with subsequent success.
“Uncertainty”
: Knight (1923). My definition of such risk (Taleb, 2007c) is that it is a normative situation, where we can be certain about probabilities, i.e., no metaprobabilities. Whereas, if randomness and risk result from epistemic opacity, the difficulty in seeing causes, then necessarily the distinction is bunk. Any reader of Cicero would recognize it as his probability; see epistemic opacity in his
De Divinatione
, Liber primus, LVI, 127:
Qui enim teneat causas rerum futurarum, idem necesse est omnia teneat quae futura sint. Quod cum nemo facere nisi deus possit, relinquendum est homini, ut signis quibusdam consequentia declarantibus futura praesentiat.
“He who knows the causes will understand the future, except that, given that nobody outside God possesses such faculty …”
Philosophy and epistemology of probability
: Laplace.
Treatise
, Keynes (1920), de Finetti (1931), Kyburg (1983), Levi (1970), Ayer, Hacking (1990, 2001), Gillies (2000), von Mises (1928), von Plato (1994), Carnap (1950), Cohen (1989), Popper (1971), Eatwell et al. (1987), and Gigerenzer et al. (1989).
History of statistical knowledge and methods
: I found no intelligent work in the history of statistics, i.e., one that does not fall prey to the ludic fallacy or Gaussianism. For a conventional account, see Bernstein (1996) and David (1962).
General books on probability and information theory
: Cover and Thomas (1991); less technical but excellent, Bayer (2003). For a probabilistic view of information theory: the posthumous Jaynes (2003) is the only mathematical book other than de Finetti’s work that I can recommend to the general reader, owing to his Bayesian approach and his allergy for the formalism of the idiot savant.
Poker
: It escapes the ludic fallacy; see Taleb (2006a).
Plato’s normative approach to left and right hands
: See McManus (2002).
Nietzsche’s
bildungsphilister
: See van Tongeren (2002) and Hicks and Rosenberg (2003). Note that because of the confirmation bias academics will tell you that intellectuals “lack rigor,” and will bring examples of those who do, not those who don’t.
Economics books that deal with uncertainty
: Carter et al. (1962), Shackle (1961, 1973), Hayek (1994). Hirshleifer and Riley (1992) fits uncertainty into neoclassical economics.
Incomputability
: For earthquakes, see Freedman and Stark (2003) (courtesy of Gur Huberman).
Academia and philistinism
: There is a round-trip fallacy; if academia means rigor (which I doubt, since what I saw called “peer reviewing” is too often a masquerade), nonacademic does not imply nonrigorous. Why do I doubt the “rigor”? By the confirmation bias they show you their contributions yet in spite of the high number of laboring academics, a relatively minute fraction of our results come from them. A disproportionately high number of contributions come from freelance researchers and those dissingly called amateurs: Darwin, Freud, Marx, Mandelbrot, even the early Einstein. Influence on the part of an academic is usually accidental. This even held in the Middle
Ages and the Renaissance, see Le Goff (1985). Also, the Enlightenment figures (Voltaire, Rousseau, d’Holbach, Diderot, Montesquieu) were all nonacademics at a time when academia was large.


================================================================================
CHAPTER/SECTION 290 (Item 297)
================================================================================

CHAPTER 10
Overconfidence
: Albert and Raiffa (1982) (though apparently the paper languished for a decade before formal publication). Lichtenstein and Fischhoff (1977) showed that overconfidence can be influenced by item difficulty; it typically diminishes and turns into underconfidence in easy items (compare with Armelius [1979]). Plenty of papers since have tried to pin down the conditions of calibration failures or robustness (be they task training, ecological aspects of the domain, level of education, or nationality): Dawes (1980), Koriat, Lichtenstein, and Fischhoff (1980), Mayseless and Kruglanski (1987), Dunning et al. (1990), Ayton and McClelland (1997), Gervais and Odean (1999), Griffin and Varey (1996), Juslin (1991, 1993, 1994), Juslin and Olsson (1997), Kadane and Lichtenstein (1982), May (1986), McClelland and Bolger (1994), Pfeifer (1994), Russo and Schoernaker (1992), Klayman et al. (1999). Note the decrease (unexpectedly) in overconfidence under group decisions: see Sniezek and Henry (1989)—and solutions in Plous (1995). I am suspicious here of the Mediocristan/Extremistan distinction and the unevenness of the variables. Alas, I found no paper making this distinction. There are also solutions in Stoll (1996), Arkes et al. (1987). For overconfidence in finance, see Thorley (1999) and Barber and Odean (1999). For cross-boundaries effects, Yates et al. (1996, 1998), Angele et al. (1982). For simultaneous overconfidence and underconfidence, see Erev, Wallsten, and Budescu (1994).
Frequency vs. probability—the ecological problem
: Hoffrage and Gigerenzer (1998) think that overconfidence is less significant when the problem is expressed in frequencies as opposed to probabilities. In fact, there has been a debate about the difference between “ecology” and laboratory; see Gigerenzer et al. (2000), Gigerenzer and Richter (1990), and Gigerenzer (1991). We are “fast and frugal” (Gigerenzer and Goldstein [1996]). As far as the Black Swan is concerned, these problems of ecology do not arise: we do not live in an environment in which we are supplied with frequencies or, more generally, for which we are fit. Also in ecology, Spariosu (2004) for the ludic aspect, Cosmides and Tooby (1990). Leary (1987) for Brunswikian ideas, as well as Brunswik (1952).
Lack of awareness of ignorance
: “In short, the same knowledge that underlies the ability to produce correct judgment is also the knowledge that underlies the ability to recognize correct judgment. To lack the former is to be deficient in the latter.” From Kruger and Dunning (1999).
Expert problem in isolation
: I see the expert problem as indistinguishable from Matthew effects and Extremism fat tails (more later), yet I found no such link in the literatures of sociology and psychology.
Clinical knowledge and its problems
: See Meehl (1954) and Dawes, Faust, and Meehl (1989). Most entertaining is the essay “Why I Do Not Attend Case Conferences” in Meehl (1973). See also Wagenaar and Keren (1985, 1986).
Financial analysts, herding, and forecasting
: See Guedj and Bouchaud (2006), Abarbanell and Bernard (1992), Chen et al. (2002), De Bondt and Thaler (1990), Easterwood and Nutt (1999), Friesen and Weller (2002), Foster (1977), Hong and Kubik (2003), Jacob et al. (1999), Lim (2001), Liu (1998), Maines and Hand (1996), Mendenhall (1991), Mikhail et al. (1997, 1999), Zitzewitz (2001), and El-Galfy and Forbes (2005). For a comparison with weather forecasters (unfavorable): Tyszka and Zielonka (2002).
Economists and forecasting
: Tetlock (2005), Makridakis and Hibon (2000), Makridakis et al. (1982), Makridakis et al. (1993), Gripaios (1994), Armstrong (1978, 1981);
and rebuttals by McNees (1978), Tashman (2000), Blake et al. (1986), Onkal et al. (2003), Gillespie (1979), Baron (2004), Batchelor (1990, 2001), Dominitz and Grether (1999). Lamont (2002) looks for reputational factors: established forecasters get worse as they produce more radical forecasts to get attention—consistent with Tetlock’s hedgehog effect. Ahiya and Doi (2001) look for herd behavior in Japan. See McNees (1995), Remus et al. (1997), O’Neill and Desai (2005), Bewley and Fiebig (2002), Angner (2006), Bénassy-Quéré (2002); Brender and Pisani (2001) look at the Bloomberg consensus; De Bondt and Kappler (2004) claim evidence of weak persistence in fifty-two years of data, but I saw the slides in a presentation, never the paper, which after two years might never materialize. Overconfidence, Braun and Yaniv (1992). See Hahn (1993) for a general intellectual discussion. More general, Clemen (1986, 1989). For Game theory, Green (2005).
Many operators, such as James Montier, and many newspapers and magazines (such as
The Economist)
, run casual tests of prediction. Cumulatively, they must be taken seriously since they cover more variables.
Popular culture
: In 1931, Edward Angly exposed forecasts made by President Hoover in a book titled
Oh Yeah?
Another hilarious book is Cerf and Navasky (1998), where, incidentally, I got the pre-1973 oil-estimation story.
Effects of information
: The major paper is Bruner and Potter (1964). I thank Danny Kahneman for discussions and pointing out this paper to me. See also Montier (2007), Oskamp (1965), and Benartzi (2001). These biases become ambiguous information (Griffin and Tversky [1992]). For how they fail to disappear with expertise and training, see Kahneman and Tversky (1982) and Tversky and Kahneman (1982). See Kunda (1990) for how preference-consistent information is taken at face value, while preference-inconsistent information is processed critically.
Planning fallacy
: Kahneman and Tversky (1979) and Buehler, Griffin, and Ross (2002). The planning fallacy shows a consistent bias in people’s planning ability, even with matters of a repeatable nature—though it is more exaggerated with nonrepeatable events.
Wars
: Trivers (2002).
Are there incentives to delay?
: Flyvbjerg et al. (2002).
Oskamp
: Oskamp (1965) and Montier (2007).
Task characteristics and effect on decision making
: Shanteau (1992).
Epistēmē
vs
.
Technē
: This distinction harks back to Aristotle, but it recurs then dies? down—it most recently recurs in accounts such as tacit knowledge in “know how.” See Ryle (1949), Polanyi (1958/1974), and Mokyr (2002).
Catherine the Great
: The number of lovers comes from Rounding (2006).
Life expectancy
:
www.annuityadvantage.com/lifeexpectancy.htm
. For projects, I have used a probability of exceeding with a power-law exponent of 3/2: f=
Kx
3/2
. Thus the conditional expectation of
x
, knowing that
x
exceeds
a


================================================================================
CHAPTER/SECTION 291 (Item 298)
================================================================================

CHAPTERS 11–13
Serendipity
: See Koestler (1959) and Rees (2004). Rees also has powerful ideas on fore-castability. See also Popper’s comments in Popper (2002), and Waller (2002a), Cannon (1940), Mach (1896) (cited in Simonton [1999]), and Merton and Barber (2004). See Simonton (2004) for a synthesis. For serendipity in medicine and anesthesiology, see Vale et al. (2005).
“Renaissance man”
: See
www.bell-labs.com/project/feature/archives/cosmology/
.
Laser
: As usual, there are controversies as to who “invented” the technology. After a successful discovery, precursors are rapidly found, owing to the retrospective distortion.
Charles Townsend won the Nobel prize, but was sued by his student Gordon Gould, who held that he did the actual work (see
The Economist
, June 9, 2005).
Darwin/Wallace
: Quammen (2006).
Popper’s attack on historicism
: See Popper (2002). Note that I am reinterpreting Popper’s idea in a modern manner here, using my own experiences and knowledge, not commenting on comments about Popper’s work—with the consequent lack of fidelity to his message. In other words, these are not directly Popper’s arguments, but largely mine phrased in a Popperian framework. The conditional expectation of an unconditional expectation is an unconditional expectation.
Forecast for the future a hundred years earlier
: Bellamy (1891) illustrates our mental projections of the future. However, some stories might be exaggerated: “A Patently False Patent Myth still! Did a patent official really once resign because he thought nothing was left to invent? Once such myths start they take on a life of their own.”
Skeptical Inquirer
, May–June, 2003.
Observation by Peirce
: Olsson (2006), Peirce (1955).
Predicting and explaining
: See Thom (1993).
Poincaré
: The three body problem can be found in Barrow-Green (1996), Rollet (2005), and Galison (2003). On Einstein, Pais (1982). More recent revelations in Hladik (2004).
Billiard balls
: Berry (1978) and Pisarenko and Sornette (2004).
Very general discussion on “complexity”
: Benkirane (2002), Scheps (1996), and Ruelle (1991). For limits, Barrow (1998).
Hayek
: See
www.nobel.se
. See Hayek (1945, 1994). Is it that mechanisms do not correct themselves from railing by influential people, but either by mortality of the operators, or something even more severe, by being put out of business? Alas, because of contagion, there seems to be little logic to how matters improve; luck plays a part in how soft sciences evolve. See Ormerod (2006) for network effects in “intellectuals and socialism” and the power-law distribution in influence owing to the scale-free aspect of the connections—and the consequential arbitrariness. Hayek seems to have been a prisoner of Weber’s old differentiation between
Natur-Wissenschaften
and
Geistes Wissenschaften
—but thankfully not Popper.
Insularity of economists
: Pieters and Baumgartner (2002). One good aspect of the insularity of economists is that they can insult me all they want without any consequence: it appears that only economists read other economists (so they can write papers for other economists to read). For a more general case, see Wallerstein (1999). Note that Braudel fought “economic history.” It was history.
Economics as religion
: Nelson (2001) and Keen (2001). For methodology, see Blaug (1992). For high priests and lowly philosophers, see Boettke, Coyne, and Leeson (2006). Note that the works of Gary Becker and the Platonists of the Chicago School are all marred by the confirmation bias: Becker is quick to show you situations in which people are moved by economic incentives, but does not show you cases (vastly more numerous) in which people don’t care about such materialistic incentives.
The smartest book I’ve seen in economics is Gave et al. (2005) since it transcends the constructed categories in academic economic discourse (one of the authors is the journalist Anatole Kaletsky).
General theory
: This fact has not deterred “general theorists.” One hotshot of the Platonifying variety explained to me during a long plane ride from Geneva to New York that the ideas of Kahneman and his colleagues must be rejected because they do not allow us to develop a general equilibrium theory, producing “time-inconsistent preferences.” For a minute I thought he was joking: he blamed the psychologists’ ideas and human incoherence for interfering with his ability to build his Platonic model.
Samuelson
: For his optimization, see Samuelson (1983). Also Stiglitz (1994).
Plato’s dogma on body symmetry
: “Athenian Stranger to Cleinias: In that the right and left hand are supposed to be by nature differently suited for our various uses of them;
whereas no difference is found in the use of the feet and the lower limbs; but in the use of the hands we are, as it were, maimed by the folly of nurses and mothers; for although our several limbs are by nature balanced, we create a difference in them by bad habit,” in Plato’s
Laws
. See McManus (2002).
Drug companies
: Other such firms, I was told, are run by commercial persons who tell researchers where they find a “market need” and ask them to “invent” drugs and cures accordingly—which accords with the methods of the dangerously misleading Wall Street security analysts. They formulate projections as if they know what they are going to find.
Models of the returns on innovations
: Sornette and Zajdenweber (1999) and Silverberg and Verspagen (2005).
Evolution on a short leash
: Dennet (2003) and Stanovich and West (2000).
Montaigne
: We don’t get much from the biographies of a personal essayist; some information in Frame (1965) and Zweig (1960).
Projectibility and the grue paradox
: See Goodman (1955). See also an application (or perhaps misapplication) in King and Zheng (2005).
Constructionism
: See Berger and Luckmann (1966) and Hacking (1999).
Certification vs, true skills or knowledge
: See Donhardt (2004). There is also a franchise protection. Mathematics may not be so necessary a tool for economics, except to protect the franchise of those economists who know math. In my father’s days, the selection process for the mandarins was made using their abilities in Latin (or Greek). So the class of students groomed for the top was grounded in the classics and knew some interesting subjects. They were also trained in Cicero’s highly probabilistic view of things—and selected on erudition, which carries small side effects. If anything it allows you to handle fuzzy matters. My generation was selected according to mathematical skills. You made it based on an engineering mentality; this produced mandarins with mathematical, highly structured, logical minds, and, accordingly, they will select their peers based on such criteria. So the papers in economics and social science gravitated toward the highly mathematical and protected their franchise by putting high mathematical barriers to entry. You could also smoke the general public who is unable to put a check on you. Another effect of this franchise protection is that it might have encouraged putting “at the top” those idiot-savant-like researchers who lacked in erudition, hence were insular, parochial, and closed to other disciplines.
Freedom and determinism
: a speculative idea in Penrose (1989) where only the quantum effects (with the perceived indeterminacy there) can justify consciousness.
Projectibility
: uniqueness assuming least squares or MAD.
Chaos theory and the backward/forward confusion
: Laurent Firode’s
Happenstance
, a.k.a.
Le battement d’ailes du papillon / The Beating of a Butterfly’s Wings
(2000).
Autism and perception of randomness
: See Williams et al. (2002).
Forecasting and misforecasting errors in hedonic states
: Wilson, Meyers, and Gilbert (2001), Wilson, Gilbert, and Centerbar (2003), and Wilson et al. (2005). They call it “emotional evanescence.”
Forecasting and consciousness
: See the idea of “aboutness” in Dennett (1995, 2003) and Humphrey (1992). However, Gilbert (2006) believes that we are not the only animal that forecasts—which is wrong as it turned out. Suddendorf (2006) and Dally, Emery, and Clayton (2006) show that animals too forecast!
Russell’s comment on Pascal’s wager
: Ayer (1988) reports this as a private communication.
History
: Carr (1961), Hexter (1979), and Gaddis (2002). But I have trouble with historians throughout, because they often mistake the forward and the backward processes. Mark Buchanan’s
Ubiquity
and the quite confused discussion by Niall Ferguson in
Nature
. Neither of them seem to realize the problem of calibration with power laws. See also Ferguson,
Why Did the Great War?
, to gauge the extent of the forward-backward problems.
For the traditional nomological tendency, i.e., the attempt to go beyond cause into a general theory, see
Muqaddamah
by Ibn Khaldoun. See also Hegel’s
Philosophy of History
.
Emotion and cognition
: Zajonc (1980, 1984).
Catastrophe insurance
: Froot (2001) claims that insurance for remote events is overpriced. How he determined this remains unclear (perhaps by backfitting or bootstraps), but reinsurance companies have not been making a penny selling “overpriced” insurance.
Postmodernists
: Postmodernists do not seem to be aware of the differences between narrative and prediction.
Luck and serendipity in medicine
: Vale et al. (2005). In history, see Cooper (2004). See also Ruffié (1977). More general, see Roberts (1989).
Affective forecasting
: See Gilbert (1991), Gilbert et al. (1993), and Montier (2007).


================================================================================
CHAPTER/SECTION 292 (Item 299)
================================================================================

CHAPTERS 14–17
This section will also serve another purpose. Whenever I talk about the Black Swan, people tend to supply me with anecdotes. But these anecdotes are just corroborative: you need to show that
in the aggregate
the world is dominated by Black Swan events. To me, the rejection of nonscalable randomness is sufficient to establish the role and significance of Black Swans.
Matthew effects
: See Merton (1968, 1973a, 1988). Martial, in his
Epigrams: “Semper pauper eris, si pauper es, Aemiliane./Dantur opes nullis (nunc) nisi divitibus.”
(Epigr. V 81). See also Zuckerman (1997, 1998).
Cumulative advantage and its consequences on social fairness
: review in DiPrete et al. (2006). See also Brookes-Gun and Duncan (1994), Broughton and Mills (1980), Dannefer (2003), Donhardt (2004), Hannon (2003), and Huber (1998). For how it may explain precocity, see Elman and O’Rand (2004).
Concentration and fairness in intellectual careers
: Cole and Cole (1973), Cole (1970), Conley (1999), Faia (1975), Seglen (1992), Redner (1998), Lotka (1926), Fox and Kochanowski (2004), and Huber (2002).
Winner take all
: Rosen (1981), Frank (1994), Frank and Cook (1995), and Attewell (2001).
Arts
: Bourdieu (1996), Taleb (2004e).
Wars
: War is concentrated in an Extremistan manner: Lewis Fry Richardson noted last century the uneveness in the distribution of casualties (Richardson [1960]).
Modern wars
: Arkush and Allen (2006). In the study of the Maori, the pattern of fighting with clubs was sustainable for many centuries—modern tools cause 20,000 to 50,000 deaths a year. We are simply not made for technical warfare. For an anecdotal and causative account of the history of a war, see Ferguson (2006).
S&P 500
: See Rosenzweig (2006).
The long tail
: Anderson (2006).
Cognitive diversity
: See Page (2007). For the effect of the Internet on schools, see Han et al. (2006).
Cascades
: See Schelling (1971, 1978) and Watts (2002). For information cascades in economics, see Bikhchandani, Hirshleifer, and Welch (1992) and Shiller (1995). See also Surowiecki (2004).
Fairness
: Some researchers, like Frank (1999), see arbitrary and random success by others as no different from pollution, which necessitates the enactment of a tax. De Vany, Taleb, and Spitznagel (2004) propose a market-based solution to the problem of allocation through the process of voluntary self-insurance and derivative products. Shiller (2003) proposes cross-country insurance.
The mathematics of preferential attachment
: This argument pitted Mandelbrot against the cognitive scientist Herbert Simon, who formalized Zipf’s ideas in a 1955 paper (Simon [1955]), which then became known as the Zipf-Simon model. Hey, you need to allow for people to fall from favor!
Concentration
: Price (1970). Simon’s “Zipf derivation,” Simon (1955). More general bibliometrics, see Price (1976) and Glänzel (2003).
Creative destruction revisited
: See Schumpeter (1942).
Networks
: Barabási and Albert (1999), Albert and Barabási (2000), Strogatz (2001, 2003), Callaway et al. (2000), Newman et al. (2000), Newman, Watts, and Strogatz (2000), Newman (2001), Watts and Strogatz (1998), Watts (2002, 2003), and Amaral et al. (2000). It supposedly started with Milgram (1967). See also Barbour and Reinert (2000), Barthélémy and Amaral (1999). See Boots and Sasaki (1999) for infections. For extensions, see Bhalla and Iyengar (1999). Resilence, Cohen et al. (2000), Barabási and Bonabeau (2003), Barabási (2002), and Banavar et al. (2000). Power laws and the Web, Adamic and Huberman (1999) and Adamic (1999). Statistics of the Internet: Huberman (2001), Willinger et al. (2004), and Faloutsos, Faloutsos, and Faloutsos (1999). For DNA, see Vogelstein et al. (2000).
Self-organized criticality
: Bak (1996).
Pioneers of fat tails
: For wealth, Pareto (1896), Yule (1925, 1944). Less of a pioneer Zipf (1932, 1949). For linguistics, see Mandelbrot (1952).
Pareto
: See Bouvier (1999).
Endogenous vs. exogenous
: Sornette et al. (2004).
Sperber’s work
: Sperber (1996a, 1996b, 1997).
Regression
: If you hear the phrase
least square regression
, you should be suspicious about the claims being made. As it assumes that your errors wash out rather rapidly, it underestimates the total possible error, and thus overestimates what knowledge one can derive from the data.
The notion of central limit
: very misunderstood: it takes a long time to reach the central limit—so as we do not live in the asymptote, we’ve got problems. All various random variables (as we started in the example of Chapter 16 with a +1 or −1, which is called a Bernouilli draw) under summation (we did sum up the wins of the 40 tosses) become Gaussian. Summation is key here, since we are considering the results of adding up the 40 steps, which is where the Gaussian, under the first and second central assumptions becomes what is called a “distribution.” (A distribution tells you how you are likely to have your outcomes spread out, or distributed.) However, they may get there at different speeds. This is called the central limit theorem: if you add random variables coming from these individual tame jumps, it will lead to the Gaussian.
Where does the central limit not work? If you do not have these central assumptions, but have jumps of random size instead, then we would not get the Gaussian. Furthermore, we sometimes converge very slowly to the Gaussian. For preasymptotics and scalability, Mandelbrot and Taleb (2007a), Bouchaud and Potters (2003). For the problem of working outside asymptotes, Taleb (2007).
Aureas mediocritas
: historical perspective, in Naya and Pouey-Mounou (2005) aptly called
Éloge de la médiocrité
.
Reification (hypostatization)
: Lukacz, in Bewes (2002).
Catastrophes
: Posner (2004).
Concentration and modern economic life
: Zajdenweber (2000).
Choices of society structure and compressed outcomes
: The classical paper is Rawls (1971), though Frohlich, Oppenheimer, and Eavy (1987a, 1987b), as well as Lissowski, Tyszka, and Okrasa (1991), contradict the notion of the desirability of Rawl’s veil (though by experiment). People prefer maximum average income subjected to a floor constraint on some form of equality for the poor, inequality for the rich type of environment.
Gaussian contagion
: Quételet in Stigler (1986). Francis Galton (as quoted in Ian Hacking’s
The Taming of Chance)
: “I know of scarcely anything so apt to impress the imagination as the wonderful form of cosmic order expressed by ‘the law of error.’”
“Finite variance” nonsense
: Associated with CLT is an assumption called “finite variance” that is rather technical: none of these building-block steps can take an infinite value if you square them or multiply them by themselves. They need to be bounded
at some number. We simplified here by making them all one single step, or finite standard deviation. But the problem is that some fractal payoffs may have finite variance, but still not take us there rapidly. See Bouchaud and Potters (2003).
Lognormal
: There is an intermediate variety that is called the lognormal, emphasized by one Gibrat (see Sutton [1997]) early in the twentieth century as an attempt to explain the distribution of wealth. In this framework, it is not quite that the wealthy get wealthier, in a pure preferential attachment situation, but that if your wealth is at 100 you will vary by 1, but when your wealth is at 1,000, you will vary by 10. The relative changes in your wealth are Gaussian. So the lognormal superficially resembles the fractal, in the sense that it may tolerate some large deviations, but it is dangerous because these rapidly taper off at the end. The introduction of the lognormal was a very bad compromise, but a way to conceal the flaws of the Gaussian.
Extinctions
: Sterelny (2001). For extinctions from abrupt fractures, see Courtillot (1995) and Courtillot and Gaudemer (1996). Jumps: Eldredge and Gould.
FRACTALS, POWER LAWS, and SCALE-FREE DISTRIBUTIONS
Definition
: Technically,
P>x= K x
-α
where α is supposed to be the power-law exponent. It is said to be scale free, in the sense that it does not have a characteristic scale: relative deviation of
does not depend on x, but on n—for
x
“large enough.” Now, in the other class of distribution, the one that I can intuitively describe as nonscalable, with the typical shape p(x) = Exp[-a x], the scale will be a.
Problem of “how large”
: Now the problem that is usually misunderstood. This scalability might stop somewhere, but I do not know where, so I might consider it infinite. The statements
very large and I don’t know how large
and
infinitely large
are epistemologically substitutable. There might be a point at which the distributions flip. This will show once we look at them more graphically.
Log P>x = -α Log X +C
t
for a scalable. When we do a log-log plot (i.e., plot P>x and x on a logarithmic scale), as in
Figures 15
and
16
, we should see a straight line.
Fractals and power laws
: Mandelbrot (1975, 1982). Schroeder (1991) is imperative. John Chipman’s unpublished manuscript
The Paretian Heritage
(Chipman [2006]) is the best review piece I’ve seen. See also Mitzenmacher (2003).
“To come very near true theory and to grasp its precise application are two very different things as the history of science teaches us. Everything of importance has been said before by somebody who did not discover it.” Whitehead (1925).
Fractals in poetry
: For the quote on Dickinson, see Fulton (1998).
Lacunarity
: Brockman (2005). In the arts, Mandelbrot (1982).
Fractals in medicine
: “New Tool to Diagnose and Treat Breast Cancer,”
Newswise
, July 18, 2006.
General reference books in statistical physics
: The most complete (in relation to fat tails) is Sornette (2004). See also Voit (2001) or the far deeper Bouchaud and Potters (2002) for financial prices and econophysics. For “complexity” theory, technical books: Bocarra (2004), Strogatz (1994), the popular Ruelle (1991), and also Prigogine (1996).
Fitting processes
: For the philosophy of the problem, Taleb and Pilpel (2004). See also Pisarenko and Sornette (2004), Sornette et al. (2004), and Sornette and Ide (2001).
Poisson jump
: Sometimes people propose a Gaussian distribution with a small probability of a “Poisson” jump. This may be fine, but how do you know how large the jump is going to be? Past data might not tell you how large the jump is.
Small sample effect
: Weron (2001). Officer (1972) is quite ignorant of the point.
Recursivity of statistics
: Taleb and Pilpel (2004), Blyth et al. (2005).
Biology
: Modern molecular biology pioneers Salvador Luria and Max Delbrück witnessed a clustering phenomenon with the occasional occurrence of extremely large mutants in a bacterial colony, larger than all other bacteria.
Thermodynamics
: Entropy maximization without the constraints of a second moment
The two exhaustive domains of attraction: vertical or straight line with slopes either negative infinity or constant negative α. Note that since probabilities need to add up to 1 (even in France) there cannot be other alternatives to the two basins, which is why I narrow it down to these two exclusively.
FIGURE 15: TYPICAL DISTRIBUTION WITH POWER-LAW TAILS (HERE A STUDENT T)
FIGURE 16
My ideas are made very simple with this clean cut polarization—added to the problem of not knowing which basin we are in owing to the scarcity of data on the far right.
leads to a Levy-stable distribution—Mandelbrot’s thesis of 1952 (see Mandelbrot [1997a]). Tsallis’s more sophisticated view of entropy leads to a Student T.
Imitation chains and pathologies
: An informational cascade is a process where a purely rational agent elects a particular choice ignoring his own private information (or judgment) to follow that of others. You run, I follow you, because you may be aware of a danger I may be missing. It is efficient to do what others do instead of having to reinvent the wheel every time. But this copying the behavior of others can lead to imitation chains. Soon everyone is running in the same direction, and it can be for spurious reasons. This behavior causes stock market bubbles and the formation of massive cultural fads. Bikhchandani et al. (1992). In psychology, see Hansen and Donoghue (1977). In biology/selection, Dugatkin (2001), Kirpatrick and Dugatkin (1994).
Self-organized criticality
: Bak and Chen (1991), Bak (1996).
Economic variables
: Bundt and Murphy (2006). Most economic variables seem to follow a “stable” distribution. They include foreign exchange, the GDP, the money supply, interest rates (long and short term), and industrial production.
Statisticians not accepting scalability
: Flawed reasoning mistaking for sampling error in the tails for a boundedness: Perline (2005), for instance, does not understand the difference between absence of evidence and evidence of absence.
Time series and memory
: You can have “fractal memory,” i.e., the effect of past events on the present has an impact that has a “tail.” It decays as power-law, not exponentially.
Marmott’s work
: Marmott (2004).


================================================================================
CHAPTER/SECTION 293 (Item 300)
================================================================================

CHAPTER 18
Economists
: Weintraub (2002), Szenberg (1992).
Portfolio theory and modern finance
: Markowitz (1952, 1959), Huang and Litzenberger (1988) and Sharpe (1994, 1996). What is called the Sharpe ratio is meaningless outside of Mediocristan. The contents of Steve Ross’s book (Ross [2004]) on “neoclassical finance” are completely canceled if you consider Extremistan in spite of the “elegant” mathematics and the beautiful top-down theories. “Anecdote” of Merton minor in Merton (1992).
Obsession with measurement
: Crosby (1997) is often shown to me as convincing evidence that measuring was a great accomplishment not knowing that it applied to Mediocristan and Mediocristan only. Bernstein (1996) makes the same error.
Power laws in finance
: Mandelbrot (1963), Gabaix et al. (2003), and Stanley et al. (2000). Kaizoji and Kaizoji (2004), Véhel and Walter (2002). Land prices: Kaizoji (2003). Magisterial: Bouchaud and Potters (2003).
Equity premium puzzle
: If you accept fat tails, there is no equity premium puzzle. Benartzi and Thaler (1995) offer a psychological explanation, not realizing that variance is not the measure. So do many others.
Covered writes
: a sucker’s game as you cut your upside—conditional on the upside being breached, the stock should rally a lot more than intuitively accepted. For a representative mistake, see Board et al. (2000).
Nobel family
: “Nobel Descendant Slams Economics Prize,”
The Local
, September 28, 2005, Stockholm.
Double bubble
: The problem of derivatives is that if the underlying security has mild fat tails and follows a mild power law (i.e., a tail exponent of three or higher), the derivative will produce far fatter tails (if the payoff is in squares, then the tail exponent of the derivatives portfolio will be half that of the primitive). This makes the Black-Scholes-Merton equation twice as unfit!
Poisson busting
: The best way to figure out the problems of the Poisson as a substitute for a scalable is to calibrate a Poisson and compute the errors out of sample. The same applies to methods such as GARCH—they fare well in sample, but horribly, horribly
outside (even a trailing three-month past historical volatility or mean deviation will outperform a GARCH of higher orders).
Why the Nobel
: Derman and Taleb (2005), Haug (2007).
Claude Bernard and experimental medicine
:
“Empiricism pour le présent, avec direction a aspiration scientifique pour l’avenir.”
From Claude Bernard,
Principe de la médecine expérimentale
. See also Fagot-Largeault (2002) and Ruffié (1977). Modern evidence-based medicine: Ierodiakonou and Vandenbroucke (1993) and Vandenbroucke (1996) discuss a stochastic approach to medicine.


================================================================================
CHAPTER/SECTION 294 (Item 301)
================================================================================

CHAPTER 19
Popper quote
: From
Conjectures and Refutations
, pages 95–97.
The lottery paradox
: This is one example of scholars not understanding the high-impact rare event. There is a well-known philosophical conundrum called the “lottery paradox,” originally posed by the logician Henry Kyburg (see Rescher [2001] and Clark [2002]), which goes as follows: “I do not believe that any ticket will win the lottery, but I do believe that all tickets will win the lottery.” To me (and a regular person) this statement does not seem to have anything strange in it. Yet for an academic philosopher trained in classical logic, this is a paradox. But it is only so if one tries to squeeze probability statements into commonly used logic that dates from Aristotle and is
all or nothing
. An
all or nothing
acceptance and rejection (“I believe” or “I do not believe”) is inadequate with the highly improbable. We need shades of belief, degrees of faith you have in a statement other than 100% or 0%.
One final philosophical consideration. For my friend the options trader and Talmudic scholar Rabbi Tony Glickman: life is convex and to be seen as a series of derivatives. Simply put, when you cut the negative exposure, you limit your vulnerability to unknowledge, Taleb (2005).


================================================================================
CHAPTER/SECTION 295 (Item 302)
================================================================================

BIBLIOGRAPHY
Abarbanell, Jeffery S., and Victor L. Bernard, 1992, “Test of Analysts’ Overreaction/Underreaction of Earnings Information as an Explanation for Anomalous Stock Price Behavior.”
Journal of Finance
47: 1181–1207.
Aczel, Amir D, 2004,
Chance: A Guide to Gambling, Love, the Stock Market, and Just About Everything Else
. New York: Thunder’s Mouth Press.
Adamic, Lada, 1999, “The Small World Web.”
Lecture Notes in Computational Science
1696: 443–452.
Adamic, Lada, and Bernardo A. Huberman, 1999, “The Nature of Markets in the World Wide Web.”
Quarterly Journal of Electronic Commerce
1: 5–12.
Albert, R., and A.-L. Barabási, 2000, “Topology of Evolving Networks: Local Events and Universality.”
Physical Review Letters
85: 5234–5237.
Albert, R., H. Jeong, and A.-L. Barabási, 2000, “Error and Attack Tolerance of Complex Networks.”
Nature
406: 378–382.
Albouy, François-Xavier, 2002,
Le temps des catastrophes
. Paris: Descartes & Cie.
Al-Ghazali, 1989, “Mikhtarat Min Ahthar Al-Ghazali.” In Saliba, Jamil,
Tarikh Al Falsafa Al Arabiah
. Beirut: Al Sharikah Al Ahlamiah Lilk-itab.
Allen, Mark S., 2006, “Transformations in Maori Warfare: Toa, Pa, and Pu.” In Elizabeth N. Arkush and Mark W. Allen, 2006.
Allen, Michael, 2003,
The Truth About Writing
. Wiltshire: Kingsfield Publications.
———, 2005,
On the Survival of Rats in the Slushpile: Essays and Criticism
. Wiltshire: Kingsfield Publications.
Allport, D. A., 1975, “The State of Cognitive Psychology.”
Quarterly Journal of Experimental Psychology
27: 141–152.
Allwood, C. M., and H. Montgomery, 1987, “Response Selection Strategies and Realism of Confidence Judgments.”
Organizational Behavior and Human Decision Processes
39: 365–383.
Alpert, M., and H. Raiffa, 1982, “A Progress Report on the Training of Probability Assessors.” In D. Kahneman, P. Slovic, and A. Tversky, eds., 1982.
Amaral, L. A. N., A. Scala, M. Barthélémy, and H. E. Stanley, 2000, “Classes of Behavior of Small-world Networks.”
Proceedings of the National Academy of Science
97: 11149–11152.
Anderson, Benedict, 1983,
Imagined Communities
. New York: Verso.
Anderson, Chris, 2006,
The Long Tail
. New York: Hyperion.
Anderson, N. H., 1986, “A Cognitive Theory of Judgment and Decision.” In B. Brehmer, H. Jungermann, P. Lourens, and G. Sevón, eds.,
New Directions in Research on Decision Making
. Amsterdam: North-Holland.
Angele, U., B. Beer-Binder, R. Berger, C. Bussmann, H. Kleinbölting, and B. Mansard, 1982,
Über- und Unterschätzung des eigenen Wissens in Abhängigkeit von Geschlecht und Bildungsstand (Overestimation and Underestimation of One’s Knowledge as a Function of Sex and Education)
. Unpublished manuscript, University of Konstanz, Federal Republic of Germany.
Angner, Erik, 2006, “Economists as Experts: Overconfidence in Theory and Practice.”
Journal of Economic Methodology
13(1): 1–24.
Annas, Julia, and Julian Barnes, 1985,
Modes of Skepticism
. Cambridge: Cambridge University Press.
Arkes, H. R., C. Christensen, C. Lai, and C. Blumer, 1987, “Two Methods of Reducing Overconfidence.”
Organizational Behavior and Human Decision Processes
39: 133–144.
Arkes, H. R., and K. R. Hammond, 1986,
Judgment and Decision Making: An Interdisciplinary Reader
. Cambridge: Cambridge University Press.
Arkush, Elizabeth N., and Mark W. Allen, eds., 2006,
The Archaeology of Warfare: Prehistories of Raiding and Conquest
. Gainesville: University of Florida Press.
Armelius, B., and K. Armelius, 1974, “The Use of Redundancy in Multiple-cue Judgments: Data from a Suppressor–variable task.
American Journal of Psychology
87: 385–392.
Armelius, K., 1979, “Task Predictability and Performance as Determinants of Confidence in Multiple-cue Judgments.”
Scandinavian Journal of Psychology
20: 19–25.
Armstrong, J. Scott, 1978, “Are Econometricians Useful? Folklore Versus Fact.”
Journal of Business
51(4): 549–564.
———, 1981, “How Expert Are the Experts?”
Inc.
, Dec. 1981: 15–16.
Aron, Raymond, 1961,
Dimensions de la conscience historique
. Paris: Agora.
Arrow, Kenneth, 1987, “Economic Theory and the Postulate of Rationality.” In J. Eatwell, M. Milgate, and P. Newman, eds., 1987, 2: 69–74.
Arthur, Brian W., 1994,
Increasing Returns and Path Dependence in the Economy
. Ann Arbor: University of Michigan Press.
Astebro, Thomas, 2003, “The Return to Independent Invention: Evidence of Unrealistic Optimism, Risk Seeking or Skewness Loving?”
Economic Journal
113(484): 226–239.
Ashiya, Masahiro, and Takero Doi, 2001, “Herd Behavior of Japanese Economists.”
Journal of Economic Behavior and Organization
46: 343–346.
Attewell, P., 2001, “The Winner-take-all High School: Organizational Adaptations to Educational Stratification.”
Sociology of Education
74: 267–295.
Ayache, E., 2004a, “The Back of Beyond,”
Wilmott
(Spring): 26–29.
———. 2004b, “A Beginning, in the End,”
Wilmott
(Winter): 6–11.
Ayer, A. J., 1958,
The Problem of Knowledge
. London: Penguin Books.
———, 1972,
Probability and Evidence
. New York: Columbia University Press.
———, 1988,
Voltaire
. London: Faber and Faber.
Ayton, P., and A. G. R. McClelland, 1997, “How Real Is Overconfidence?”
Journal of Behavioral Decision Making
10: 153–285.
Baddeley, Alan, 1997,
Human Memory: Theory and Practice
. London: Psychology Press.
Bak, Per, 1996,
How Nature Works
. New York: Copernicus.
Bak, P., and K. Chen, 1991, “Self-organized criticality.”
Scientific American
264: 46–53.
Ball, Philip, 2004,
Critical Mass: How One Thing Leads to Another
. London: Arrow Books.
———, 2006, “Econophysics: Culture Crash.”
Nature
441: 686–688.
Banavar, J. R., F. Colaiori, A. Flammini, A. Maritan, and A. Rinaldo, 2000, “A Topology of the Fittest Transportation Network.”
Physical Review Letters
84: 4745–4748.
Barabási, Albert-László, 2002,
Linked: The New Science of Networks
. Boston: Perseus Publishing.
Barabási, Albert-László, and Réka Albert, 1999, “Emergence of Scaling in Random Networks.”
Science
286: 509–512.
Barabási, Albert-László, Réka Albert, and H. Jeong, 1999, “Mean-field Theory for Scale-free Random Networks.”
Physica A
272: 173–197.
Barabási, Albert-László, and Eric Bonabeau, 2003, “Scale-free Networks.”
Scientific American
288(5): 50–59.
Baranski, J. V., and W. M. Petrusic, 1994, “The Calibration and Resolution of Confidence in Perceptual Judgments.”
Perception and Psychophysics
55: 412–428.
Barber, B. M., and T. Odean, 1999, “Trading Is Hazardous to Your Wealth: The Common Stock Investment Performance of Individual Investors.” Working Paper.
Barbour, A. D., and G. Reinert, 2000, “Small worlds.” Preprint cond-mat/0006001 at
http://xxx.lanl.gov
.
Bar-Hillel, M., and W. A. Wagenaar, 1991, “The perception of randomness.”
Advances in Applied
Mathematics
12(4): 428–454.
Baron, Jonathan, 2000,
Thinking and Deciding
, 3rd ed. New York: Cambridge University Press.
Baron-Cohen, S., Leslie, A. M., and Frith, U., 1985. “Does the Autistic Child Have a ‘theory of mind’?”
Cognition
, 21, 37–46.
Barron, G., and I. Erev, 2003, “Small Feedback-based Decisions and Their Limited Correspondence to Description-based Decisions.”
Journal of Behavioral Decision Making
16: 215–233.
Barrow, John D., 1998,
Impossibility: The Limits of Science and the Science of Limits
. London: Vintage.
Barrow, John D., and Frank J. Tipler, 1986,
The Anthropic Cosmological Principle
. Oxford: Oxford University Press.
Barrow-Green, June, 1996,
Poincaré and the Three Body Problem. History of Mathematics
, Vol. 11, American Mathematical Society.
Barthélémy, M., and L. A. N. Amaral, 1999, “Small-world Networks: Evidence for a Crossover Picture.”
Physical Review Letters
82: 3180–3183.
Bastiat, Frédéric, 1862–1864,
Oeuvres complètes de Frédéric Bastiat
, 6 vols. Paris: Guillaumin.
Batchelor, R. A., 1990, “All Forecasters Are Equal.”
Journal of Business and Economic Statistics
8(1): 143–144.
———, 2001, “How Useful Are the Forecasts of Intergovernmental Agencies? The IMF and OECD Versus the Consensus.”
Applied Economics
33(2): 225–235.
Bates, Elisabeth, 1994, “Modularity, Domain Specificity, and the Development of Language.” In D. C. Gajdusek, G. M. McKhann, and C. L. Bolis, eds.,
Evolution and Neurology of Language: Discussions in Neuroscience
10: 1–2, 136–149.
Bauman, A. O., R. B. Deber, and G. G. Thompson, 1991, “Overconfidence Among Physicians and Nurses: The ‘micro certainty, macro certainty’ phenomenon.”
Social Science and Medicine
32: 167–174.
Bayer, Hans Christian, 2003,
Information: The New Language of Science
. London: Orion Books, Ltd.
Bechara, A., A. R. Damasio, H. Damasio, and S. W. Anderson, 1994, “Insensitivity to Future Consequences Following Damage to Human Prefrontal Cortex.”
Cognition
50: 1–3, 7–15.
Becker, Lawrence C., 1998,
A New Stoicism
. Princeton, N.J.: Princeton University Press.
Bellamy, Edward, 1891,
Cent ans après, ou l’an 2000
, trad. de l’anglais par Paul Rey; avec une préf. par M. Théodore Reinach. Paris: E. Dentu.
Benartzi, Shlomo, 2001. “Excessive Extrapolation and the Allocation of 401(k) Accounts to Company Stock,”
Journal of Finance
56(5): 1,747–1,764
Benartzi, Shlomo, and Richard Thaler, 1995, “Myopic Loss Aversion and the Equity Premium Puzzle.”
Quarterly Journal of Economics
110(1): 73–92.
Bénassy-Quéré, Agnès, 2002,
“Euro/dollar: tout le monde peut se tromper.” La Lettre du CEPII
215.
Benkirane, R., 2002,
La complexité, vertiges et promesses: 18 histoires de sciences
. Paris: Le Pommier.
Berger, Peter L., and Thomas Luckmann, 1966,
The Social Construction of Reality: A Treatise in the Sociology of Knowledge
. New York: Anchor Books.
Bernard, André, 2002,
Rotten Rejections: The Letters That Publisher Wish They’d Never Sent
. London: Chrysalis Books.
Bernard, Claude, 1878,
La science expérimentale
. Paris: J.-B. Baillière.
Bernoulli, Daniel, 1954, “Exposition of a New Theory on the Measurement of Risk.”
Econometrica
22(1): 23–36.
Bernstein, Peter L., 1996,
Against the Gods: The Remarkable Story of Risk
. New York: Wiley.
Berridge, Kent C., 2003, “Irrational Pursuits: Hyper-incentives from a Visceral Brain.” In I. Brocas and J. Carillo, eds., 2003.
Berry, M., 1978, “Regular and Irregular Motion, in Topics in Nonlinear Mechanics,” ed. S. Jorna,
American Institute of Physics Conference Proceedings
No. 46, 16–120.
Bevan, Edwyn, 1913,
Stoics and Sceptics
. Chicago: Ares Publishers, Inc.
Bewes, Timothy, 2002,
Reification: or The Anxiety of Late Capitalism
. London: Verso.
Bewley, Ronald A., and Denzil G. Fiebig, 2002, “On the Herding Instinct of Interest Rate Forecasters.”
Empirical Economics
27(3): 403–425.
Bhalla, U. S., and R. Iyengar, 1999, “Emergent Properties of Networks of Biological Signalling Pathways.
Science
283: 381–387.
Bharat, Barot, 2004, “How Accurate are the Swedish Forecasters on GDP-Growth, CPI-Inflation and Unemployment?, 1993–2001.”
Brussels Economic Review/Cahiers Economiques de Bruxelles
47, 2 Editions du DULBEA, Université libre de Bruxelles, 249–278.
Bikhchandani, Sushil, David Hirshleifer, and Ivo Welch, 1992, “A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades.”
Journal of Political Economy
100 (5): 992–1026.
Binmore, K., 1999, “Why Experiment in Economics?”
Economic Journal
109(453): 16–24.
Birnbaum, M. H., 1983, “Base Rates in Bayesian Inference: Signal Detection Analysis of the Cab Problem.”
American Journal of Psychology
96(1): 85–94.
Björkman, M., 1987, “A Note on Cue Probability Learning: What Conditioning Data Reveal About Cue Contrast.”
Scandinavian Journal of Psychology
28: 226–232.
———, 1994, “Internal Cue Theory: Calibration and Resolution of Confidence in General Knowledge.”
Organizational Behavior and Human Decision Processes
58: 386–405.
Bjorkman, M., P. Juslin, and A. Winman, 1993, “Realism of Confidence in Sensory Discrimination: The Underconfidence Phenomenon.”
Perception and Psychophysics
54: 75–81.
Blake, Carole, 1999,
From Pitch to Publication
. London: Pan.
Blake, David, Michael Beenstock, and Valerie Brasse, 1986, “The Performance of UK Exchange Rate Forecasters.”
Economic Journal
96(384): 986–999.
Blaug, Mark, 1992,
The Methodology of Economics
, 2nd ed. Cambridge: Cambridge University Press.
Bloch, Marc, 1953,
The Historian’s Craft
. New York: Vintage Books.
Blyth, M. R. Abdelal, and Cr. Parsons, 2005,
Constructivist Political Economy
. Preprint, forthcoming, 2006: Oxford University Press.
Board, J., C. Sutcliffe, and E. Patrinos, 2000, “Performance of Covered Calls.”
European Journal of Finance
6(1): 1–17.
Bocarra, Nino, 2004,
Modeling Complex Systems
. Heidelberg: Springer.
Boettke, Peter J., Christopher J. Coyne, and Peter T. Leeson, 2006, “High Priests and Lowly Philosophers: The Battle for the Soul of Economics,” a forthcoming article in the
Case Western Law Review
.
Boghossian, Paul, 2006,
Fear of Knowledge: Against Relativism and Constructivism
. Oxford: Oxford University Press.
Boots, M., and A. Sasaki, 1999, “‘Small worlds’ and the Evolution of Virulence: Infection Occurs Locally and at a Distance,”
Proceedings of the Royal Society of London
B266: 1933–1938.
Bostrom, Nick, 2002,
Anthropic Bias: Observation Selection Effects in Science and Philosophy
. London: Routledge.
Bouchaud, J.-P., and M. Potters, 2003,
Theory of Financial Risks and Derivatives Pricing: From Statistical Physics to Risk Management
, 2nd ed. Cambridge: Cambridge University Press.
Bourdé, Guy, and Hervé Martin, 1989,
Les écoles historiques
. Paris: Éditions du Seuil.
Bourdieu, Pierre, 1992,
Les règles de l’art
. Paris: Éditions du Seuil.
———, 1996,
Sur la télévision suivi de l’emprise du journalisme
. Paris: Raison d’Agir.
———, 2000,
Esquisse d’une théorie de la pratique
. Paris: Éditions de Seuil.
Bouvier, Alban, ed., 1999,
Pareto aujourd’hui
. Paris: Presses Universitaires de France.
Boyer, Pascal, 2001,
Religion Explained: The Evolutionary Origins of Religious Thought
. New York: Basic Books.
Braudel, Fernand, 1953, “Georges Gurvitch ou la discontinuité du social.”
Annales E.S.C
. 8: 347–361.
———, 1969,
Écrits sur l’histoire
. Paris: Flammarion.
———, 1985,
La Méditerranée: L’espace et l’histoire
. Paris: Flammarion.
———, 1990,
Écrits sur l’histoire II
. Paris: Flammarion.
Braun, P. A., and I. Yaniv, 1992, “A Case Study of Expert Judgment: Economists’ Probabilities Versus Base-rate Model Forecasts.”
Journal of Behavioral Decision Making
5: 217–231.
Brehmer, B., and C. R. B. Joyce, eds., 1988,
Human Judgment: The SJT View
. Amsterdam: North-Holland.
Brender, A., and F. Pisani, 2001,
Les Marchés et la croissance
. Economica.
Brenner, L. A., D. J. Koehler, V. Liberman, and A. Tversky, 1996, “Overconfidence in Probability and Frequency Judgments: A Critical Examination.”
Organizational Behavior and Human Decision Processes
65: 212–219.
Brocas, I., and J. Carillo, eds., 2003,
The Psychology of Economic Decisions
, Vol. 1:
Rationality and Well-being
. Oxford: Oxford University Press.
Brochard, Victor, 1878,
De l’erreur
. Paris: Université de Paris.
———, 1888,
Les sceptiques grecs
. Paris: Imprimerie Nationale.
Brock, W. A., and P. J. F. De Lima, 1995, “Nonlinear Time Series, Complexity Theory, and Finance.” University of Wisconsin, Madison—Working Papers 9523.
Brock, W. A., D. A. Hsieh, and B. LeBaron, 1991,
Nonlinear Dynamics, Chaos, and Instability: Statistical Theory and Economic Evidence
. Cambridge, Mass.: The MIT Press.
Brockman, John, 2005, Discussion with Benoît Mandelbrot,
www.edge.org
.
Brookes-Gunn, J., and G. Duncan, 1994,
Consequences of Growing Up Poor
. New York: Russell Sage.
Broughton, W., and E. W. Mills, 1980, “Resource Inequality and Accumulative Advantage: Stratification in the Ministry.”
Social Forces
58: 1289–1301.
Brugger, P., and R. E. Graves, 1997, “Right Hemispatial Inattention and Magical Ideation.”
European Archive of Psychiatry and Clinical Neuroscience
247(1): 55–57.
Bruner, Jerome, 1994, “The ‘Remembered’ Self.” In Ulric Neisser and Robyn Fivush, eds.,
The Remembering Self: Construction and Accuracy in the Self-Narrative
. Cambridge: Cambridge University Press.
———, 2002,
Making Stories: Law, Literature, Life
. New York: Farrar, Straus & Giroux.
Bruner, Jerome S., and Mary C. Potter, 1964, “Interference in Visual Recognition”
Science
144(3617): 424–425.
Brunswik, E., 1952,
The Conceptual Framework of Psychology
. Chicago: The University of Chicago Press.
———, 1955, “Representative Design and Probabilistic Theory in a Functional Psychology.”
Psychological Review
62: 193–217.
Buchanan, Mark, 2001,
Ubiquity: Why Catastrophes Happen
. New York: Three Rivers Press.
———, 2002,
Nexus: Small Worlds and the Groundbreaking Theory of Networks
. New York: W. W. Norton and Company.
Budescu, D. V., I. Erev, and T. S. Wallsten, 1997, “On the Importance of Random Error in the Study of Probability Judgment. Part I: New Theoretical Developments.”
Journal of Behavioral Decision Making
10: 157–171.
Buehler, R., D. Griffin, and M. Ross, 2002, “Inside the Planning Fallacy: The Causes and Consequences of Optimistic Time Predictions.” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Bundt, Thomas, and Robert P. Murphy, 2006, “Are Changes in Macroeconomic Variables Normally Distributed? Testing an Assumption of Neoclassical Economics.” Preprint, NYU Economics Department.
Burnham, Terence C., 1997,
Essays on Genetic Evolution and Economics
. New York: Dissertation.com.
———, 2003, “Caveman Economics.” Preprint, Harvard Business School.
Burnham, T., and J. Phelan, 2000,
Mean Genes
. Boston: Perseus Publishing.
Bushman, B. J., and G. L. Wells, 2001, “Narrative Impressions of Literature: The Availability Bias
and the Corrective Properties of Meta-analytic Approaches.”
Personality and Social Psychology Bulletin
27: 1123–1130.
Callaway, D. S., M. E. J. Newman, S. H. Strogatz, and D. J. Watts, 2000, “Network Robustness and Fragility: Percolation on Random Graphs.”
Physical Review Letters
85: 5468–5471.
Camerer, C., 1995, “Individual Decision Making.” In John H. Kagel and Alvin E. Roth, eds.,
The Handbook of Experimental Economics
. Princeton, N.J.: Princeton University Press.
———, 2003,
Behavioral Game Theory: Experiments in Strategic Interaction
. Princeton, N.J.: Princeton University Press.
Camerer, Colin F., George Loewenstein, and D. Prelec, 2003, “Neuroeconomics: How Neuroscience Can Inform Economics.” Caltech Working Paper.
Camerer, Colin F., George Loewenstein, and Matthew Rabin, 2004,
Advances in Behavioral Economics
. Princeton, N.J.: Princeton University Press.
Cannon, Walter B., 1940, “The Role of Chance in Discovery.”
Scientific Monthly
50: 204–209.
Carnap, R., 1950,
The Logical Foundations of Probability
. Chicago: The University of Chicago Press.
———, 1966,
Philosophical Foundations of Physics
. New York: Basic Books.
Carr, Edward Hallett, 1961,
What Is History?
New York: Vintage Books.
Carter, C. F., G. P. Meredith, and G. L. S. Shackle, 1962,
Uncertainty and Business Decisions
. Liverpool: Liverpool University Press.
Carter, Rita, 1999,
Mapping the Mind
. Berkeley: University of California Press.
———, 2002,
Exploring Consciousness
. Berkeley: University of California Press.
Casanova, Giovanni Giacomo, 1880,
Mémoires de J. Casanova de Seingalt
. Paris: Garnier Frères.
Casscells, W., A. Schoenberger, and T. Grayboys, 1978, “Interpretation by Physicians of Clinical Laboratory Results.”
New England Journal of Medicine
299: 999–1000.
Cerf, Christopher, and Victor Navasky, 1998,
The Expert Speaks: The Definitive Compendium of Authoritative Misinformation
. New York: Villard Books.
Certeau, Michel de, 1975,
L’Ecriture de l’histoire
. Paris: Gallimard.
Chamley, Christophe P., 2004,
Rational Herds: Economic Models of Social Learning
. Cambridge: Cambridge University Press.
Chancellor, Edward, 1999,
Devil Take the Hindmost: A History of Financial Speculation
. New York: Farrar, Straus & Giroux.
Chartier, Roger, 1996,
Culture et société. L’ordre des livres, XVIe–XVIIIe
. Paris: Albin Michel.
Chen, Keith, Venkat Lakshminarayanan, and Laurie Santos, 2005, “The Evolution of Our Preferences: Evidence from Capuchin Monkey Trading Behavior.” Cowles Foundation Discussion Paper No. 1524.
Chen, Qi, Jennifer Francis, and Wei Jiang, 2002, “Investor Learning About Analyst Predictive Ability.” Working Paper, Duke University.
Cherniak, C., 1994, “Component Placement Optimization in the Brain.”
Journal of Neuroscience
14: 2418–2427.
Chipman, John, 2006, “The Paretian Heritage.” Working Paper, University of Minnesota.
Cialdini, Robert B., 2001,
Influence: Science and Practice
. Boston: Allyn and Bacon.
Cisne, John L., 2005, “Medieval Manuscripts’ ‘Demography’ and Classic Texts’ Extinction.”
Science
307(5713): 1305–1307.
Clark, Barrett, and Pascal Boyer, 2006,
“Causal Inferences: Evolutionary Domains and Neural Systems.”
Interdisciplines Conference on Causality, see
www.interdiscplines.org
.
Clark, Michael, 2002,
Paradoxes from A to Z
. London: Routledge.
Clemen, R. T., 1986, “Calibration and the Aggregation of Probabilities.”
Management Science
32: 312–314.
———, 1989, “Combining Forecasts: A Review and Annotated Bibliography.”
International Journal of Forecasting
5: 559–609.
Cohen, L. J., 1989,
The Philosophy of Induction and Probability
. Oxford: Clarendon Press.
Cohen, R., K. Erez, D. ben-Avraham, and S. Havlin, 2000, “Resilience of the Internet to Random Breakdowns.”
Physical Review Letters
85: 4626–4628.
Cole, J. R., and S. Cole, 1973,
Social Stratification in Science
. Chicago: The University of Chicago Press.
Cole, J. R., and B. Singer, 1991, “A Theory of Limited Differences: Explaining the Productivity
Puzzle in Science.” In J. C. H. Zuckerman and J. Bauer, eds.,
The Outer Circle: Women in the Scientific Community
. New York: W. W. Norton and Company.
Cole, Peter, 2002,
Access to Philosophy: The Theory of Knowledge
. London: Hodder and Stoughton.
Cole, S., 1970, “Professional Standing and the Reception of Scientific Discoveries.”
American Journal of Sociology
76: 286–306.
Cole, S., J. C. Cole, and G. A. Simon, 1981, “Chance and Consensus in Peer Review.”
Science
214: 881–886.
Collins, Randall, 1998,
The Sociology of Philosophies: A Global Theory of Intellectual Change
. Cambridge, Mass.: The Belknap Press of Harvard University Press.
Conley, D., 1999,
Being Black, Living in the Red: Race, Wealth and Social Policy in America
. Los Angeles: University of California Press.
Cooper, John M., 2004,
Knowledge, Nature, and the Good
, Chapter 1: “Method and Science in on Ancient Medicine.” Princeton, N.J.: Princeton University Press.
Cootner, Paul H., 1964,
The Random Character of Stock Market Prices
. London: Risk Books.
Cosmides, L., and J. Tooby, 1990, “Is the Mind a Frequentist?” Paper presented at the 31st annual meeting of the Psychonomics Society, New Orleans, La.
———, 1992, “Cognitive Adaptations for Social Exchange.” In Jerome H. Barkow, Leda Cosmides, and John Tooby, eds.,
The Adapted Mind
. Oxford: Oxford University Press.
———, 1996, “Are Humans Good Intuitive Statisticians After All? Rethinking Some Conclusions from the Literature on Judgment and Uncertainty.”
Cognition
58(1): 187–276.
Courtillot, V., 1995,
La vie en catastrophes
. Paris: Fayard.
Courtillot, V., and Y. Gaudemer, 1996, “Effects of Mass-Extinctions on Biodiversity.”
Nature
381: 146–147.
Cousin, Victor, 1820,
Cours d’histoire de la philosophie morale au dix-huitième siècle
. Paris: Ladrange.
Cover, T. M., and J. A. Thomas, 1991,
Elements of Information Theory
. New York: Wiley.
Cowley, Michelle, and Ruth M. J. Byrne, 2004, “Chess Master’s Hypothesis Testing.” In Kenneth Forbus, Dedre Gentner, and Terry Regier, eds.,
Proceedings of 26th Annual Conference of the Cognitive Science Society, CogSci 2004
, Mahwah, N.J.: Lawrence Erlbaum.
Crosby, Alfred W., 1997,
The Measure of Reality: Quantification and Western Society, 1250–1600
. Cambridge: Cambridge University Press.
Csikszentmihalyi, Mihaly, 1993,
Flow: The Psychology of Optimal Experience
. New York: Perennial Press.
———, 1998,
Finding Flow: The Psychology of Engagement with Everyday Life
. New York: Basic Books.
Cutler, David, James Poterba, and Lawrence Summers, 1989, “What Moves Stock Prices?”
Journal of Portfolio Management
15: 4–12.
Dally J. M., N. J. Emery, and N. S. Clayton, 2006, “Food-Catching Western Scrub-Jays Keep Track of Who Was Watching When.”
Science
312 (5780): 1,662–1,665.
Damasio, Antonio, 1994,
Descartes’ Error: Emotion, Reason, and the Human Brain
. New York: Avon Books.
———, 2000,
The Feeling of What Happens: Body and Emotion in the Making of Consciousness
. New York: Harvest Books.
———, 2003,
Looking for Spinoza: Joy, Sorrow and the Feeling Brain
. New York: Harcourt.
Dannefer, D., 1987, “Aging as Intracohort Differentiation: Accentuation, the Matthew Effect and the Life Course.”
Sociological Forum
2: 211–236.
———, 2003, “Cumulative Advantage/Disadvantage and the Life Course: Cross-fertilizing Age and Social Science.”
Journal of Gerontology Series B: Psychological Sciences and Social Sciences
58: 327–337.
Darwin, Charles, 1859,
On Natural Selection
. London: Penguin Books, Great Ideas.
Daston, L. J., 1988,
Classical Probability in the Enlightenment
. Princeton, N.J.: Princeton University Press.
David, Florence Nightingale, 1962,
Games, Gods, and Gambling: A History of Probability and Statistical Ideas
. Oxford: Oxford University Press.
Dawes, Robyn M., 1980, “Confidence in Intellectual Judgments vs. Confidence in Perceptual Judgments.” In E. D. Lantermann and H. Feger, eds.,
Similarity and Choice: Papers in Honor of Clyde Coombs
. Bern, Switzerland: Huber.
———,1988,
Rational Choice in an Uncertain World
. New York: Harcourt.
———, 1989, “Measurement Models for Rating and Comparing Risks: The Context of AIDS.”
Conference Proceedings Health Services Research Methodology: A Focus on AIDS
, September 1989.
———, 1999, “A Message from Psychologists to Economists: Mere Predictability Doesn’t Matter Like It Should, Without a Good Story Appended to It.”
Journal of Economic Behavior and Organization
. 39: 29–40.
———, 2001a, “Clinical Versus Actuarial Judgment.”
International Encyclopedia of the Social and Behavioral Sciences
2048–2051.
———, 2001b,
Everyday Irrationality: How Pseudo-Scientists, Lunatics, and the Rest of Us Systematically Fail to Think Rationally
. Oxford: Westview Press.
———, 2002, “The Ethics of Using or Not Using Statistical Prediction Rules in Psychological Practice and Related Consulting Activities.”
Philosophy of Science
69: 178–184.
Dawes, Robyn M., D. Faust, and P. E. Meehl, 1989, “Clinical Versus Actuarial Judgment.”
Science
243: 1668–1674.
Dawes, Robyn M., R. Fildes, M. Lawrence, and K. Ord, 1994, “The Past and the Future of Forecasting Research.”
International Journal of Forecasting
10: 151–159.
Dawes, Robyn M., and T. L. Smith, 1985, “Attitude and Opinion Measurement.” In G. Lindzey and E. Aronson,
The Handbook of Social Psychology
, Vol. 1. Hillsdale, N.J.: Lawrence Erlbaum.
de Bellaigue, Eric, de., 2004,
British Book Publishing as a Business Since the 1960s
. London: The British Library.
De Bondt, Werner, and Andreas Kappler, 2004, “Luck, Skill, and Bias in Economists’ Forecasts.”
Working Paper, Driehaus Center for Behavioral Finance, DePaul University.
De Bondt, Werner F. M., and Richard M. Thaler, 1990, “Do Security Analysts Overreact?”
American Economic Review
80: 52–57.
Debreu, Gerard, 1959,
Theorie de la valeur
, Dunod, tr.
Theory of Value
. New York: Wiley. de Finetti, Bruno, 1931, 1989, “Probabilism.”
Erkenntnis
31: 169–223.
———, 1975, 1995,
Filosophia della probabilita
. Milan: Il Saggiatore.
Degeorge, François, Jayendu Patel, and Richard Zeckhauser, 1999, “Earnings Management to Exceed Thresholds.”
Journal of Business
72(1): 1–33.
DeLong, Bradford, Andrei Shleifer, Lawrence Summers, and Robert J. Waldmann, 1991. “The Survival of Noise Traders in Financial Markets.”
Journal of Business
64(1): 1–20.
Dennett, Daniel C., 1995,
Darwin’s Dangerous Idea: Evolution and the Meanings of Life
. New York: Simon & Schuster.
———, 2003,
Freedom Evolves
. New York: Penguin Books.
Derman, E., and N. N. Taleb, 2005, “The Illusions of Dynamic Replication.”
Quantitative Finance
5: 323–326.
De Vany, Arthur, 2002,
Hollywood Economics: Chaos in the Movie Industry
. London: Routledge.
De Vany, Arthur, Nassim Nicholas Taleb, and Mark Spitznagel, 2004, “Can We Shield Artists from Wild Uncertainty?” presented at the Fort Lauderdale Film Festival Scholar’s Workshop, June 2004.
DiPrete, Thomas A., and Greg Eirich, 2006, “Cumulative Advantage as a Mechanism for Inequality: A Review of Theoretical and Empirical Developments.”
Annual Review of Sociology
32: 271–297.
Dominitz, Jeff, and David Grether, 1999, “I Know What You Did Last Quarter: Economic Forecasts of Professional Forecasters.” Working Paper, Caltech.
Donhardt, Gary L., 2004, “In Search of the Effects of Academic Achievement in Postgraduation Earnings.”
Research in Higher Education
45(3): 271–284.
Dugatkin, Lee Alan, 2001,
The Imitation Factor: Evolution Beyond the Gene
. New York: Simon & Schuster.
Dunbar, Nicholas, 1999,
Inventing Money: The Story of Long-Term Capital Management and the Legends Behind It
. Chichester, England: John Wiley & Sons, Ltd.
Dunning, D., D. W. Griffin, J. Milojkovic, and L. Ross, 1990, “The Overconfidence Effect in Social Prediction.”
Journal of Personality and Social Psychology
58: 568–581.
Dye, Guillaume, 2004, A review of Lorenzo Perilli’s
Menodoto di Nicomedia
, Munich and Leipzig: K. G. Saur, in
Bryn Mawr Classical Review
, December 20.
Easterwood, John C., and Stacey R. Nutt, 1999, “Inefficiency in Analysts’ Earnings Forecasts: Systematic Misreaction or Systematic Optimism?”
Journal of Finance
54: 1777–1797.
Eatwell, J., M. Milgate, and P. Newman, eds., 1987,
The New Palgrave: A Dictionary of Economics
. London: Macmillan.
Eco, Umberto, 1992,
How to Travel with a Salmon and Other Essays
. San Diego: Harcourt.
———, 1994,
Six Walks in the Fictional Woods
. Cambridge, Mass.: Harvard University Press.
———, 2000,
Kant and the Platypus: Essays on Language and Cognition
. New York: Harvest Books.
———, 2002,
On Literature
. Orlando: Harcourt Books.
———, 2003,
Mouse or Rat? Translation as Negotiation
. London: Orion Books.
Einhorn, H. J., and R. M. Hogarth, 1981, “Behavioral Decision Theory: Processes of Judgment and Choice.”
Annual Review of Psychology
32: 53–88.
Ekeland, Ivar, 1990,
Mathematics of the Unexpected
. Chicago: The University of Chicago Press.
Eldredge, Niles, and Stephen Jay Gould, 1972, “Punctuated Equilibria: An Alternative to Phyletic Gradualism.”
Models in Paleobiology
, ed., T.J.M. Schopf. New York: Freeman.
El-Galfy, A. M., and W. P. Forbes, 2005, “An Evaluation of U.S. Security Analysts Forecasts, 1983–1999.” Working Paper.
Elman, C., and A. M. O’Rand, 2004, “The Race Is to the Swift: Socioeconomic Origins, Adult Education, and Wage Attainment.”
American Journal of Sociology
110: 123–160.
Elster, Jon, 2009, “Excessive Ambitions,” in
Capitalism and Society
, forthcoming.
Empiricus, Sextus, 1997,
Esquisses pyrrhoniennes
. Paris: Éditions du Seuil.
———, 2002,
Contre les professeurs
. Paris: Éditions du Seuil.
Epstein, Jason, 2001,
Book Business
. London: W. W. Norton.
Erev, I., T. S. Wallsten, and D. V. Budescu, 1994, “Simultaneous Over- and Underconfidence: The Role of Error in Judgment Processes.”
Psychological Review
101: 519–528.
Estoup, J. B., 1916,
Gammes Stenographique
. Paris: Institut Stenographique de France.
Evans, Dylan, 2002,
Emotions: The Science of Sentiment
. Oxford: Oxford University Press.
Eysenck, M. W., and M. T. Keane, 2000,
Cognitive Psychology
, 4th ed. London: Psychology Press.
Fagot-Largeault, Anne, 2002,
Philosophie des sciences biologiques et medicales
. Paris: College de France.
Faia, M., 1975, “Productivity Among Scientists: A Replication and Elaboration.”
American Sociological Review
40: 825–829.
Faloutsos, M., P. Faloutsos, and C. Faloutsos, 1999, “On Power-law Relationships of the Internet Topology.”
Computer Communications Review
29: 251–262.
Favier, A., 1906,
Un médecin grec du deuxième siècle ap. J.-C., précurseur de la méthode expérimentale moderne: Ménodote de Nicomédie
. Paris: Jules Roisset.
Ferguson, Niall, 2005,
1914: Why the World Went to War
. London: Penguin.
———, 2006a,
The War of the World: History’s Age of Hatred
. London: Allen Lane.
———, 2006b, “Political Risk and the International Bond Market Between the 1848 Revolution and the Outbreak of the First World War.”
Economic History Review
59(1): 70–112.
Ferraro, K. F., and J. A. Kelley-Moore, 2003, “Cumulative Disadvantage and Health: Long-term Consequences of Obesity?”
American Sociological Review
68: 707–729.
Feyerabend, Paul, 1987,
Farewell to Reason
. London: Verso.
Finucane, M. L., A. Alhakami, P. Slovic, and S. M. Johnson, 2000, “The Affect a Heuristic in Judgments of Risks and Benefits.”
Journal of Behavioral Decision Making
13: 1–17.
Fischhoff, Baruch, 1982a, “Debiasing.” In D. Kahneman, P. Slovic, and A. Tversky, eds.,
Judgment Under Uncertainty: Heuristics and Biases
. Cambridge: Cambridge University Press.
———, 1982b, “For Those Condemned to Study the Past: Heuristics and Biases in Hindsight.” In D. Kahneman, P. Slovic, and A. Tversky,
Judgment Under Uncertainty: Heuristics and Biases
. Cambridge: Cambridge University Press.
Fischhoff, B., and D. MacGregor, 1983, “Judged Lethality: How Much People Seem to Know Depends on How They Are Asked.”
Risk Analysis
3: 229–236.
Fischhoff, Baruch, Paul Slovic, and Sarah Lichtenstein, 1977, “Knowing with Certainty: The Appropriateness of Extreme Confidence.”
Journal of Experimental Psychology
3(4): 552–564.
Floridi, Luciano, 2002,
The Transmission and Recovery of Pyrrhonism
. Oxford: Oxford University Press.
Flyvbjerg, Bent, Mette Skamris Holm, and Søren Buhl, 2002, “Underestimating Costs in Public Works Projects—Error or Lie.”
American Journal of Planning
68(3),
http://home.planet.nl/~viss1197/japaflyvbjerg.pdf
.
Fodor, Jerry A., 1983,
The Modularity of Mind: An Essay on Faculty Psychology
. Cambridge, Mass.: The MIT Press.
Foster, George, 1977, “Quarterly Accounting Data: Time-series Properties and Predictive Ability Results.”
Accounting Review
52: 1–21.
Fox, M. A., and P. Kochanowski, 2004, “Models of Superstardom: An Application of the Lotka and Yule Distributions.”
Popular Music and Society
27: 507–522.
Frame, Donald M., 1965,
Montaigne: A Biography
. New York: Harcourt Brace and World.
Frank, Jerome D., 1935, “Some Psychological Determinants of the Level of Aspiration.”
American Journal of Psychology
47: 285–293.
Frank, Robert, 1994, “Talent and the Winner-Take-All Society.” A review of Derek Bok’s
The Cost of Talent: How Executives and Professionals Are Paid and How It Affects America
, New York: The Free Press, 1993, in
The American Prospect
5(17),
www.prospect.org/print/V5/17/frank-r.html
.
Frank, Robert H., 1985,
Choosing the Right Pond: Human Behavior and the Quest for Status
. Oxford: Oxford University Press.
Frank, Robert H., and P. J. Cook, 1995,
The Winner-Take-All Society: Why the Few at the Top Get So Much More Than the Rest of Us
. New York: The Free Press.
Frankfurter, G. M., and E. G. McGoun, 1996,
Toward Finance with Meaning: The Methodology of Finance: What It Is and What It Can Be
. Greenwich, Conn.: JAI Press.
Freedman, D. A., and P. B. Stark, 2003, “What Is the Chance of an Earthquake?” Technical Report 611 of the Department of Statistics, University of California, Berkeley, September 2001, revised January 2003.
Friesen, Geoffrey, and Paul A. Weller, 2002, “Quantifying Cognitive Biases in Analyst Earnings Forecasts.” Working Paper, University of Iowa.
Frohlich, N., J. A. Oppenheimer, and C. L. Eavy, 1987a, “Laboratory Results on Rawls’s Distributive Justice.”
British Journal of Political Science
17: 1–21.
———, 1987b, “Choices of Principles of Distributive Justice in Experimental Groups.”
American Journal of Political Science
31(3): 606–636.
Froot, K. A., 2001, “The Market for Catastrophe Risk: A Clinical Examination,”
Journal of Financial Economics
60(2–3): 529–571.
Fukuyama, Francis, 1992,
The End of History and the Last Man
. New York: The Free Press.
Fuller, Steve, 2005,
The Intellectual
. London: Icon Books.
Fulton, Alice, 1998, “Fractal Amplifications: Writing in Three Dimensions.”
Thumbscrew
12 (winter).
Gabaix, X., P. Gopikrishnan, V. Plerou, and H. E. Stanley, 2003, “A Theory of Power-law Distributions in Financial Market Fluctuations.”
Nature
423: 267–270.
Gaddis, John Lewis, 2002,
The Landscape of History: How Historians Map the Past
. Oxford: Oxford University Press.
Galbraith, John Kenneth, 1997,
The Great Crash 1929
. New York: Mariner Books.
Galison, Peter, 2003,
Einstein’s Clocks, Poincaré’s Maps: Empires of Time
. New York: W. W. Norton and Company.
Gave, Charles, Anatole Kaletsky, and Louis-Vincent Gave, 2005,
Our Brave New World
. London: GaveKal Research.
Gazzaniga, M. S., R. Ivry, and G. R. Mangun, 2002,
Cognitive Neuroscience: The Biology of the Mind
, 2nd ed. New York: W. W. Norton and Company.
Gazzaniga, Michael, and Joseph LeDoux, 1978,
The Integrated Mind
. Plenum Press.
Gazzaniga, Michael S., 2005,
The Ethical Brain
. New York: Dana Press.
Gehring, W. J., and A. R. Willoughby, 2002, “The Medial Frontal Cortex and the Rapid Processing of Monetary Gains and Losses.”
Science
295: 2279–2282.
Gelman, S. A., 1988, “The Development of Induction Within Natural Kind and Artifact Categories.”
Cognitive Psychology
20: 65–95.
Gelman, S. A., and J. D. Coley, 1990, “The Importance of Knowing a Dodo Is a Bird: Categories and Inferences in Two-year-old Children.”
Developmental Psychology
26: 796–804.
Gelman, S. A., and L. A. Hirschfeld, 1999, “How Biological Is Essentialism?” In D. L. Medin and S. Atran, eds.,
Folkbiology
. Cambridge, Mass.: The MIT Press.
Gelman, S. A., and E. M. Markman, 1986, “Categories and Induction in Young Children.”
Cognition
23: 183–209.
Gervais, Simon, and Terrance Odean, 1999, “Learning to Be Overconfident.” Working Paper, University of Pennsylvania.
Gigerenzer, G., P. M. Todd, and the ABC Research Group, 2000,
Simple Heuristics That Make Us Smart
. Oxford: Oxford University Press.
Gigerenzer, Gerd, 1984, “External Validity of Laboratory Experiments: The Frequency-Validity Relationship.”
American Journal of Psychology
97: 185–195.
———, 1987, “Survival of the Fittest Probabilist: Brunswik, Thurstone, and the Two Disciplines of Psychology.” In L. Krüger, G. Gigerenzer, and M. S. Morgan, eds.,
The Probabilistic Revolution
, Vol. 2:
Ideas in the Sciences
. Cambridge, Mass.: The MIT Press.
———, 1991, “From Tools to Theories: A Heuristic of Discovery in Cognitive Psychology.”
Psychological Review
98(2): 254–267.
Gigerenzer, G., J. Czerlinski, and L. Martignon, 2002, “How Good Are Fast and Frugal Heuristics?” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Gigerenzer, G., and D. G. Goldstein, 1996, “Reasoning the Fast and Frugal Way: Models of Bounded Rationality.”
Psychological Review
103: 650–669.
Gigerenzer, Gerd, W. Hell, and H. Blank, 1988, “Presentation and Content: The Use of Base Rates as a Continuous Variable.”
Journal of Experimental Psychology: Human Perception and Performance
14: 513–525.
Gigerenzer, G., U. Hoffrage, and H. Kleinbolting, 1991, “Probabilistic Mental Models: A Brunswikian Theory of Confidence.”
Psychological Review
98: 506–528.
Gigerenzer, G., and H. R. Richter, 1990, “Context Effects and Their Interaction with Development: Area Judgments.”
Cognitive Development
5: 235–264.
Gigerenzer, G., Z. Swijtink, T. Porter, L. J. Daston, J. Beatty, and L. Krüger, 1989,
The Empire of Chance: How Probability Changed Science and Everyday Life
. Cambridge: Cambridge University Press.
Gilbert, D., E. Pinel, T. D. Wilson, S. Blumberg, and T. Weatley, 2002, “Durability Bias in Affective Forecasting.” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Gilbert, Daniel, 2006,
Stumbling on Happiness
. New York: Knopf.
Gilbert, Daniel T., 1991, “How Mental Systems Believe.”
American Psychologist
46: 107–119.
Gilbert, Daniel T., Romin W. Tafarodi, and Patrick S. Malone, 1993, “You Can’t Not Believe Everything You Read.”
Journal of Personality and Social Psychology
65: 221–233.
Gillespie, John V., 1979, Review of William Ascher’s
Forecasting: An Appraisal for Policy-Makers and Planners
in
The American Political Science Review
73(2): 554–555.
Gillies, Donald, 2000,
Philosophical Theories of Probability
. London: Routledge.
Gilovich, T., D. Griffin, and D. Kahneman, eds., 2002,
Heuristics and Biases: The Psychology of Intuitive Judgment
. Cambridge: Cambridge University Press.
Gladwell, Malcolm, 1996, “The Tipping Point: Why Is the City Suddenly So Much Safer—Could It Be That Crime Really Is an Epidemic?”
The New Yorker
, June 3.
———, 2000,
The Tipping Point: How Little Things Can Make a Big Difference
. New York: Little, Brown.
———, 2002, “Blowing Up: How Nassim Taleb Turned the Inevitability of Disaster into an Investment Strategy.”
The New Yorker
, April 22 and 29.
Glänzel, W., 2003,
Bibliometrics as a Research Field: A Course on the Theory and Application of Bibliometric Indicators
. Preprint.
Gleik, James, 1987,
Chaos: Making a New Science
. London: Abacus.
Glimcher, Paul, 2002,
Decisions, Uncertainty, and the Brain: The Science of Neuroeconomics
. Cambridge, Mass.: The MIT Press.
Goldberg, Elkhonon, 2001,
The Executive Brain: Frontal Lobes and the Civilized Mind
. Oxford: Oxford University Press.
———, 2005,
The Wisdom Paradox: How Your Mind Can Grow Stronger as Your Brain Grows Older
. New York: Gotham.
Goldstein, D. G. and N. N. Taleb, 2007, “We Don’t Quite Know What We Are Talking About When We Talk About Volatility,”
Journal of Portfolio Management
, summer 2007.
Goleman, Daniel, 1995,
Emotional Intelligence: Why It Could Matter More Than IQ
. New York: Bantam Books.
———, 2003,
Destructive Emotions, How Can We Overcome Them? A Scientific Dialogue with the Dalai Lama
. New York: Bantam.
Goodman, N., 1955,
Fact, Fiction, and Forecast
. Cambridge, Mass.: Harvard University Press.
———, 1972, “Seven Strictures on Similarity.” In N. Goodman, ed.,
Problems and Projects
. New York: Bobbs-Merrill.
Gopnik, A., 2004, C. Glymour, D. M. Sobel, L. E. Schulz, T. Kushnir, and D. Danks, D., press, “A Theory of Causal Learning in Children: Causal Maps and Bayes Nets.”
Psychological Review
111: 3–32.
Granger, Clive W. J., 1999,
Empirical Modeling in Economics: Specification and Evaluation
. Cambridge: Cambridge University Press.
Gray, John, 2002,
Straw Dogs: Thoughts on Humans and Other Animals
. London: Granta Books.
Green, Jack, 1962,
Fire the Bastards!
New York: Dalkey Archive Press.
Green, K. C. 2005, “Game Theory, Simulated Interaction, and Unaided Judgement for Forecasting Decisions in Conflicts: Further Evidence.”
International Journal of Forecasting
21: 463–472.
Griffin, D. W., and A. Tversky, 1992, “The Weighing of Evidence and the Determinants of Confidence.”
Cognitive Psychology
24: 411–435.
Griffin, D. W., and C. A. Varey, 1996, “Towards a Consensus on Overconfidence.”
Organizational Behavior and Human Decision Processes
65: 227–231.
Gripaios, Peter, 1994, “The Use and Abuse of Economic Forecasts.”
Management Decision
32(6): 61–64.
Guedj, Olivier, and Jean-Philippe Bouchaud, 2006, “Experts’ Earning Forecasts: Bias, Herding and Gossamer Information,” forthcoming.
Guglielmo, Cavallo, and Roger Chartier, 1997,
Histoire de la lecture dans le monde occidental
. Paris: Éditions du Seuil.
Gurvitch, Georges, 1957, “Continuité et discontinuité en histoire et sociologie.”
Annales E.S.C.:
73–84.
———, 1966,
The Social Framework of Knowledge
. New York: Harper Torchbooks.
Gutas, Dimitri, 1998,
Greek Thought, Arabic Culture, the Graeco-Arabic Translation Movement in Baghdad and Early ’Abbasid Society (2nd–4th/8th–10th centuries)
, London: Routledge.
Hacking, Ian, 1965,
Logic of Statistical Inference
. Cambridge: Cambridge University Press.
———, 1983,
Representing and Intervening: Introductory Topics in the Philosophy of Natural Science
. Cambridge: Cambridge University Press.
———, 1990,
The Taming of Chance
. Cambridge: Cambridge University Press.
———, 1999,
The Social Construction of What?
Cambridge, Mass.: Harvard University Press.
———, 2001,
An Introduction to Probability and Inductive Logic
. Cambridge: Cambridge University Press.
Hahn, Frank, 1993, “Predicting the Economy.” In Leo Howe and Alan Wain, eds., 1993.
Hannon, L., 2003, “Poverty, Delinquency, and Educational Attainment: Cumulative Disadvantage or Disadvantage Saturation?”
Sociological Inquiry
73: 575–594.
Hansen, R. D., and J. M. Donoghue, 1977, “The Power of Consensus: Information Derived from One’s Own and Others’ Behavior.”
Journal of Personality and Social Psychology
35: 294–302.
Hardy, G. H., 1940,
A Mathematician’s Apology
. Cambridge: Cambridge University Press.
Harris, Olivia, 2004, “Braudel: Historical Time and the Horror of Discontinuity.”
History Workshop Journal
57: 161–174.
Harvey, N., 1997, “Confidence in Judgment.”
Trends in Cognitive Science
1: 78–82.
Hasher, L., and R. T. Zacks, 1979, “Automatic and Effortful Processes in Memory.”
Journal of Experimental Psychology: General
108: 356–388.
Haug, Espen, 2007,
Derivatives: Models on Models
. New York: Wiley.
Haug, E. G., and N. N. Taleb, 2008, “Why We Have Never Used the Black-Scholes-Merton Option Pricing Formula,” Wilmott Hausman, Daniel M., ed., 1994,
The Philosophy of Economics: An Anthology
, 2nd ed. New York: Cambridge University Press.
Hayek, F. A., 1945, “The Use of Knowledge in Society.”
American Economic Review
35(4): 519–530.
———, 1994,
The Road to Serfdom
. Chicago: The University of Chicago Press.
Hecht, Jennifer Michael, 2003,
Doubt: A History
. New York: Harper Collins.
Hempel, C., 1965,
Aspects of Scientific Explanation
. New York: The Free Press.
Henderson, Bill, and André Bernard, eds.,
Rotten Reviews and Rejections
. Wainscott, N.Y.: Pushcart.
Hespos, Susan, 2006, “Physical Causality in Human Infants.” Interdisciplines Conference on Causality,
www.interdisciplines.org
.
Hexter, J. H., 1979,
On Historians, Reappraisals of Some of the Masters of Modern History
. Cambridge, Mass.: Harvard University Press.
Hicks, Steven V., and Alan Rosenberg, 2003, “The ‘Philosopher of the Future’ as the Figure of Disruptive Wisdom.”
Journal of Nietzsche Studies
25: 1–34.
Hilton, Denis, 2003, “Psychology and the Financial Markets: Applications to Understanding and Remedying Irrational Decision-making.” In I. Brocas and J. Carillo, eds., 2003.
Hintzman, D. L., G. Nozawa, and M. Irmscher, 1982, “Frequency as a Nonpropositional Attribute of Memory.”
Journal of Verbal Learning and Verbal Behavior
21: 127–141.
Hirshleifer, J., and J. G. Riley, 1992,
The Analytics of Uncertainty and Information
. Cambridge: Cambridge University Press.
Hladik, Jean, 2004,
Comment le jeune et ambitieux Einstein s’est approprié la relativité restreinte de Poincaré
. Paris: Ellipses.
Hoffrage, U., and G. Gigerenzer, 1998, “Using Natural Frequencies to Improve Diagnostic Inferences.”
Academic Medicine
73(5): 538–540.
Hong, Harrison, and Jeffrey Kubik, 2003, “Analyzing the Analysts: Career Concerns and Biased Earnings Forecasts.”
Journal of Finance
58(1): 313–351.
Hopfield, J. J., 1994, “Neurons, Dynamics, and Computation.”
Physics Today
47: 40–46.
Horkheimer, Max, and Theodor W. Adorno, 2002,
Dialectic of Enlightenment: Philosophical Fragments
. Stanford: Stanford University Press.
House, D. K., 1980, “The Life of Sextus Empiricus.”
The Classical Quarterly, New Series
30(1): 227–238.
Howe, Leo, and Alan Wain, eds., 1993,
Predicting the Future
. Cambridge: Cambridge University Press.
Hsee, C. K., and Y. R. Rottenstreich, 2004, “Music, Pandas and Muggers: On the Affective Psychology of Value.”
Journal of Experimental Psychology
, forthcoming.
Hsieh, David A., 1991, “Chaos and Nonlinear Dynamics: Application to Financial Markets.”
Journal of Finance
46(5): 1839–1877.
Huang, C. F., and R. H. Litzenberger, 1988,
Foundations for Financial Economics
. New York/Amsterdam/London: North-Holland.
Huber, J. C., 1998, “Cumulative Advantage and Success-Breeds-Success: The Value of Time Pattern Analysis.”
Journal of the American Society for Information Science and Technology
49: 471–476.
———, 2002, “A New Model That Generates Lotka’s Law.”
Journal of the American Society for Information Science and Technology
53: 209–219.
Huberman, Bernardo A., 2001,
The Laws of the Web: Patterns in the Ecology of Information
. Cambridge, Mass.: The MIT Press.
Hume, David, 1748, 2000,
A Treatise of Human Nature: Being an Attempt to Introduce the Experimental Method of Reasoning into Moral Subjects
. Oxford: Oxford University Press.
Humphrey, Nicholas, 1992,
A History of the Mind: Evolution and the Birth of Consciousness
. New York: Copernicus.
Husserl, Edmund, 1954,
The Crisis of European Sciences and Transcendental Phenomenology
. Evanston, Ill.: Northwestern University Press.
Ierodiakonou, K., and J. P. Vandenbroucke, 1993, “Medicine as a Stochastic Art.”
Lancet
341: 542–543. Inagaki, Kayoko, and Giyoo Hatano, 2006, “Do Young Children Possess Distinct Causalities for the Three Core Domains of Thought?” Interdisciplines Conference on Causality,
www.interdisciplines.org
.
Jablonski, D., K. Roy, J. W. Valentine, R. M. Price, and P. S. Anderson, 2003, “The Impact of the Pull of the Recent on the History of Marine Diversity.”
Science
300(5622): 1133–1135.
Jacob, John, Thomas Lys, and Margaret Neale, 1999, “Expertise in Forecasting Performance of Security Analysts.”
Journal of Accounting and Economics
28: 51–82.
Jaynes, E. T., 2003,
Probability Theory: The Logic of Science
. Cambridge: Cambridge University Press.
Jaynes, Julian, 1976,
The Origin of Consciousness in the Breakdown of the Bicameral Mind
. New York: Mariner Books.
Jenkins, Keith, 1991,
Re-Thinking History
. London: Routledge.
Jeong, H., B. Tombor, R. Albert, Z. N. Oltavi, and A.-L. Barabási, 2000, “The Large-scale Organization of Metabolic Networks.”
Nature
407: 651–654.
Joung, Wendy, Beryl Hesketh, and Andrew Neal, 2006, “Using ‘War Stories’ to Train for Adaptive Performance: Is It Better to Learn from Error or Success?”
Applied Psychology: An International Review
55(2): 282–302.
Juslin, P., 1991,
Well-calibrated General Knowledge: An Ecological Inductive Approach to Realism of Confidence
. Manuscript submitted for publication. Uppsala, Sweden.
———, 1993, “An Explanation of the Hard-Easy Effect in Studies of Realism of Confidence in One’s General Knowledge.”
European Journal of Cognitive Psychology
5:55–71.
———, 1994, “The Overconfidence Phenomenon as a Consequence of Informal Experimenter-guided Selection of Almanac Items.”
Organizational Behavior and Human Decision Processes
57: 226–246.
Juslin, P., and H. Olsson, 1997, “Thurstonian and Brunswikian Origins of Uncertainty in Judgment: A Sampling Model of Confidence in Sensory Discrimination.”
Psychological Review
104: 344–366.
Juslin, P., H. Olsson, and M. Björkman, 1997, “Brunswikian and Thurstonian Origins of Bias in Probability Assessment: On the Interpretation of Stochastic Components of Judgment.”
Journal of Behavioral Decision Making
10: 189–209.
Juslin, P., H. Olsson, and A. Winman, 1998, “The Calibration Issue: Theoretical Comments on Suantak, Bolger, and Ferrell.”
Organizational Behavior and Human Decision Processes
73: 3–26.
Kadane, J. B., and S. Lichtenstein, 1982, “A Subjectivist View of Calibration.” Report No. 82–86, Eugene, Ore.: Decision Research.
Kahneman, D., 2003, “Why People Take Risks.” In
Gestire la vulnerabilità e l’incertezza; un incontro internazionale fra studiosi e capi di impresa
. Rome: Italian Institute of Risk Studies.
Kahneman, D., E. Diener, and N. Schwarz, eds., 1999,
Well-being: The Foundations of Hedonic Psychology
. New York: Russell Sage Foundation.
Kahneman, D., and S. Frederick, 2002, “Representativeness Revisited: Attribute Substitution in Intuitive Judgment.” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Kahneman, D., J. L. Knetsch, and R. H. Thaler, 1986, “Rational Choice and the Framing of Decisions.”
Journal of Business
59(4): 251–278.
Kahneman, D., and D. Lovallo, 1993, “Timid Choices and Bold Forecasts: A Cognitive Perspective on Risk-taking.”
Management Science
39: 17–31.
Kahneman, D., and A. Tversky, 1972, “Subjective Probability: A Judgment of Representativeness.”
Cognitive Psychology
3: 430–454.
———, 1973, “On the Psychology of Prediction.”
Psychological Review
80: 237–251.
———, 1979, “Prospect Theory: An Analysis of Decision Under Risk.”
Econometrica
46(2): 171–185.
———, 1982, “On the Study of Statistical Intuitions.” In D. Kahneman, P. Slovic, and A. Tversky, eds.,
Judgment Under Uncertainty: Heuristics and Biases
. Cambridge: Cambridge University Press.
———, 1996, “On the Reality of Cognitive Illusions.”
Psychological Review
103: 582–591.
———, eds., 2000,
Choices, Values, and Frames
. Cambridge: Cambridge University Press.
———, 1991, “Anomalies: The Endowment Effect, Loss Aversion, and Status Quo Bias.” In D. Kahneman and A. Tversky, eds., 2000.
Kaizoji, Taisei, 2003, “Scaling Behavior in Land Markets.”
Physica A: Statistical Mechanics and Its Applications
326(1–2): 256–264.
Kaizoji, Taisei, and Michiyo Kaizoji, 2004, “Power Law for Ensembles of Stock Prices.”
Physica A: Statistical Mechanics and Its Applications
344(1–2),
Applications of Physics in Financial Analysis
4 (APFA4) (December 1): 240–243.
Katz, J. Sylvan, 1999, “The Self-similar Science System.”
Research Policy
28(5): 501–517.
Keen, Steve, 2001,
Debunking Economics: The Naked Emperor of the Social Classes
. London: Pluto Press.
Kemp, C., and J. B. Tenenbaum, 2003, “Theory-based Induction.”
Proceedings of the Twenty-fifth Annual Conference of the Cognitive Science Society
, Boston, Mass.
Keren, G., 1988, “On the Ability of Assessing Non-verdical Perceptions: Some Calibration Studies.”
Acta Psychologica
67: 95–119.
———, 1991, “Calibration and Probability Judgments: Conceptual and Methodological Issues.”
Acta Psychologica
77: 217–273.
Keynes, John Maynard, 1920,
Treatise on Probability
. London: Macmillan.
———, 1937, “The General Theory.”
Quarterly Journal of Economics
51: 209–233.
Kidd, John B., 1970, “The Utilization of Subjective Probabilities in Production Planning.”
Acta Psychologica
34(2/3): 338–347.
Kim, E. Han, Adair Morse, and Luigi Zingales, 2006, “Are Elite Universities Losing Their Competitive Edge?” NBER Working Paper 12245.
Kindleberger, Charles P., 2001,
Manias, Panics, and Crashes
. New York: Wiley.
King, Gary, and Langche Zeng, 2005, “When Can History Be Our Guide? The Pitfalls of Counterfactual Inference.” Working Paper, Harvard University.
Kirkpatrick, Mark, and Lee Alan Dugatkin, 1994, “Sexual Selection and the Evolutionary Effects of Copying Mate Choice.”
Behavioral Evolutionary Sociobiology
34: 443–449.
Klayman, J., 1995, “Varieties of Confirmation Bias.” In J. Busemeyer, R. Hastie, and D. L. Medin, eds.,
Decision Making from a Cognitive Perspective. The Psychology of Learning and Motivation
32: 83–136. New York: Academic Press.
Klayman, J., and Y.-W. Ha, 1987, “Confirmation, Disconfirmation, and Information in Hypothesis Testing.”
Psychological Review
94: 211–228.
Klayman, Joshua, Jack B. Soll, Claudia Gonzalez-Vallejo, and Sema Barlas, 1999, “Overconfidence: It Depends on How, What, and Whom You Ask.”
Organizational Behavior and Human Decision Processes
79(3): 216–247.
Klebanoff, Arthur, 2002,
The Agent
. London: Texere.
Klein, Gary, 1998,
Sources of Power: How People Make Decisions
. Cambridge: The MIT Press.
Knight, Frank, 1921, 1965,
Risk, Uncertainty and Profit
. New York: Harper and Row.
Koehler, J. J., B. J. Gibbs, and R. M. Hogarth, 1994, “Shattering the Illusion of Control: Multishot Versus Single-shot Gambles.”
Journal of Behavioral Decision Making
7: 183–191.
Koestler, Arthur, 1959,
The Sleepwalkers: A History of Man’s Changing Vision of the Universe
. London: Penguin.
Korda, Michael, 2000,
Another Life: A Memoir of Other People
. New York: Random House.
Koriat, A., S. Lichtenstein, and B. Fischhoff, 1980, “Reasons for Confidence.”
Journal of Experimental Psychology: Human Learning and Memory
6: 107–118.
Kreps, J., and N. B. Davies, 1993,
An Introduction to Behavioral Ecology
, 3rd ed. Oxford: Blackwell Scientific Publications.
Kristeva, Julia, 1998,
Time and Sense
. New York: Columbia University Press.
Kruger, J., and D. Dunning, 1999, “Unskilled and Unaware of It: How Difficulties in Recognizing One’s Own Incompetence Lead to Inflated Self-Assessments.”
Journal of Personality and Social Psychology
77(6): 1121–1134.
Kunda, Ziva, 1990, “The Case for Motivated Reasoning.”
Psychological Bulletin
108: 480–498.
———, 1999,
Social Cognition: Making Sense of People
. Cambridge: The MIT Press.
Kurz, Mordecai, 1997, “Endogenous Uncertainty: A Unified View of Market Volatility.” Working Paper: Stanford University Press.
Kyburg, Henry E., Jr., 1983,
Epistemology and Inference
. Minneapolis: University of Minnesota Press.
Lad, F., 1984, “The Calibration Question.”
British Journal of the Philosophy of Science
35: 213–221.
Lahire, Bernard, 2006,
La condition littéraire
. Paris: Editions La Découverte.
Lakoff, George, and Mark Johnson, 1980,
Metaphors We Live By
. Chicago: The University of Chicago Press.
Lamont, Owen A., 2002, “Macroeconomic Forecasts and Microeconomic Forecasters.”
Journal of Economic Behavior and Organization
48(3): 265–280.
Lane, R. D., E. M. Reiman, M. M. Bradley, P. J. Lang, G. L. Ahern, R. J. Davidson, and G. E. Schwartz, 1997, “Neuroanatomical correlates of pleasant and unpleasant emotion.”
Neuropsychologia
35(11): 1437–1444.
Langer, E. J., 1975, “The Illusion of Control.”
Journal of Personality and Social Psychology
32: 311–328.
Larrick, R. P., 1993, “Motivational Factors in Decision Theories: The Role of Self-Protection.”
Psychological Bulletin
113: 440–450.
Leary, D. E., 1987, “From Act Psychology to Probabilistic Functionalism: The Place of Egon Brunswik in the History of Psychology.” In M. G. Ash and W. R. Woodward, eds.,
Psychology in Twentieth-century Thought and Society
. Cambridge: Cambridge University Press.
LeDoux, Joseph, 1998,
The Emotional Brain: The Mysterious Underpinnings of Emotional Life
. New York: Simon & Schuster.
———, 2002,
Synaptic Self: How Our Brains Become Who We Are
. New York: Viking.
Le Goff, Jacques, 1985,
Les intellectuels au moyen age
. Paris: Points Histoire.
Levi, Isaac, 1970,
Gambling with Truth
. Cambridge, Mass.: The MIT Press.
Lichtenstein, Sarah, and Baruch Fischhoff, 1977, “Do Those Who Know More Also Know More About How Much They Know? The Calibration of Probability Judgments.”
Organizational Behavior and Human Performance
20: 159–183.
Lichtenstein, Sarah, and Baruch Fischhoff, 1981, “The Effects of Gender and Instructions on Calibration.”
Decision Research Report
81–5. Eugene, Ore.: Decision Research.
Lichtenstein, Sarah, Baruch Fischhoff, and Lawrence Phillips, 1982, “Calibration of Probabilities: The State of the Art to 1980.” In D. Kahneman, P. Slovic, and A. Tversky, eds.,
Judgment Under Uncertainty: Heuristics and Biases
. Cambridge: Cambridge University Press.
Lim, T., 2001, “Rationality and Analysts’ Forecast Bias.”
Journal of Finance
56(1): 369–385.
Lissowski, Grzegorz, Tadeusz Tyszka, and Wlodzimierz Okrasa, 1991, “Principles of Distributive Justice: Experiments in Poland and America.”
Journal of Conflict Resolution
35(1): 98–119.
Liu, Jing, 1998, “Post-Earnings Announcement Drift and Analysts’ Forecasts.” Working Paper, UCLA.
Loewenstein, G. F., E. U. Weber, C. K. Hsee, and E. S. Welch, 2001, “Risk as Feelings.”
Psychological Bulletin
127: 267–286.
Loewenstein, George, 1992, “The Fall and Rise of Psychological Explanations in the Economics of Intertemporal Choice.” In George Loewenstein and Jon Elster, eds.,
Choice over Time
. New York: Russell Sage Foundation.
Loftus, Elizabeth F., and Katherine Ketcham, 1994,
The Myth of Repressed Memory: False Memories and Allegations and Sexual Abuse
. New York: St. Martin’s Press.
Lotka, Alfred J., 1926, “The Frequency Distribution of Scientific Productivity.”
Journal of the Washington Academy of Sciences
16(12): 317–323.
Lowenstein, R., 2000,
When Genius Failed: The Rise and Fall of Long-Term Capital Management
. New York: Random House.
Lucas, Robert E., 1978, “Asset Prices in an Exchange Economy.”
Econometrica
46: 1429–1445.
Luce, R. D., and H. Raiffa, 1957,
Games and Decisions: Introduction and Critical Survey
. New York: Wiley.
Mach, E., 1896, “On the Part Played by Accident in Invention and Discovery.”
Monist
6: 161–175.
Machina, M. J., and M. Rothschild, 1987, “Risk.” In J. Eatwell, M. Milgate, and P. Newman, eds., 1987.
Magee, Bryan, 1985,
Philosophy and the Real World: An Introduction to Karl Popper
. La Salle, Ill.: Open Court Books.
———, 1997,
Confessions of a Philosopher
. London: Weidenfeld & Nicolson.
Maines, L. A., and J. R. Hand, 1996, “Individuals’ Perceptions and Misperceptions of Time-series Properties of Quarterly Earnings.”
Accounting Review
71: 317–336.
Makridakis, S., A. Andersen, R. Carbone, R. Fildes, M. Hibon, R. Lewandowski, J. Newton, R. Parzen, and R. Winkler, 1982, “The Accuracy of Extrapolation (Time Series) Methods: Results of a Forecasting Competition.”
Journal of Forecasting
1: 111–153.
Makridakis, S., C. Chatfield, M. Hibon, M. Lawrence, T. Mills, K. Ord, and L. F. Simmons, 1993, “The M2–Competition: A Real-Time Judgmentally Based Forecasting Study” (with commentary).
International Journal of Forecasting
5: 29.
Makridakis, S., and M. Hibon, 2000, “The M3-Competition: Results, Conclusions and Implications.”
International Journal of Forecasting
16: 451–476.
Makridakis, S., and N. N. Taleb, 2009, “Decision Making and Planning Under Low Levels of Predictability,”
International Journal of Forecasting
25(4).
Mandelbrot, B., 1963, “The Variation of Certain Speculative Prices.”
Journal of Business
36(4): 394–419.
Mandelbrot, Benoît, 1965, “Information Theory and Psycholinguistics.” In B. Wolman and E. Nagel, eds.,
Scientific Psychology: Principles and Approaches
. New York: Basic Books.
———, 1975,
Les objets fractals: forme, hasard, et dimension
. Paris: Flammarion.
———, 1982,
The Fractal Geometry of Nature
. New York: W. H. Freeman and Company.
———, 1997a,
Fractales, hasard et finance
. Paris: Flammarion.
———, 1997b,
Fractals and Scaling in Finance: Discontinuity, Concentration, Risk
. New York: Springer-Verlag.
Mandelbrot, Benoît, and Nassim Nicholas Taleb, 2006a, “A Focus on the Exceptions That Prove the Rule.” In
Mastering Uncertainty: Financial Times Series
.
———, 2006b, “Matematica della sagessa.”
Il Sole 24 Ore
, October 9.
———, 2007a, “Random Jump Not Random Walk.” Manuscript.
———, 2007b, “Mild vs. Wild Randomness: Focusing on Risks that Matter.” Forthcoming in Frank Diebold, Neil Doherty, and Richard Herring, eds.,
The Known, the Unknown and the Unknowable in Financial Institutions
. Princeton, N.J.: Princeton University Press.
———2010, “Random Jump, Not Random Walk,” in Francis Diebold and Richard Herring, eds.,
The Known, the Unknown, and the Unknowable
. Princeton: Princeton University Press.
Mandler, J. M., and L. McDonough, 1998, “Studies in Inductive Inference in Infancy.”
Cognitive Psychology
37: 60–96.
Margalit, Avishai, 2002,
The Ethics of Memory
. Cambridge, Mass.: Harvard University Press.
Markowitz, Harry, 1952, “Portfolio Selection.”
Journal of Finance
(March): 77–91.
———, 1959,
Portfolio Selection: Efficient Diversification of Investments
, 2nd ed. New York: Wiley.
Marmott, Michael, 2004,
The Status Syndrome: How Social Standing Affects Our Health and Longevity
. London: Bloomsbury.
Marr, D., 1982,
Vision
. New York: W. H. Freeman and Company.
Masters, John, 1969,
Casanova
. New York: Bernard Geis Associates.
May, R. M., 1973,
Stability and Complexity in Model Ecosystems
. Princeton, N.J.: Princeton University Press.
May, R. S., 1986, “Overconfidence as a Result of Incomplete and Wrong Knowledge.” In R. W.
Scholz, ed.,
Current Issues in West German Decision Research
. Frankfurt am Main, Germany: Lang.
Mayseless, O., and A. W. Kruglanski, 1987, “What Makes You So Sure? Effects of Epistemic Motivations on Judgmental Confidence.
Organizational Behavior and Human Decision Processes
39: 162–183.
McClelland, A. G. R., and F. Bolger, 1994, “The Calibration of Subjective Probabilities: Theories and Models, 1980–1994.” In G. Wright and P. Ayton, eds.,
Subjective Probability
. Chichester, England: Wiley.
McCloskey, Deirdre, 1990,
If You’re So Smart: The Narrative of Economic Expertise
. Chicago: The University of Chicago Press.
———, 1992, “The Art of Forecasting: From Ancient to Modern Times.”
Cato Journal
12(1): 23–43.
McClure, Samuel M., David I. Laibson, George F. Loewenstein, and Jonathan D. Cohen, 2004, “Separate Neural Systems Value Immediate and Delayed Monetary Rewards.”
Science
306(5695): 503–507.
McManus, Chris, 2002,
Right Hand, Left Hand
. London: Orion Books.
McNees, Stephen K., 1978, “Rebuttal of Armstrong.”
Journal of Business
51(4): 573–577.
———, 1995, “An Assessment of the ‘Official’ Economic Forecasts.”
New England Economic Review
(July/August): 13–23.
McNeill, William H., 1976,
Plagues and Peoples
. New York: Anchor Books.
Medawar, Peter, 1996,
The Strange Case of the Spotted Mice and Other Classic Essays on Science
. Oxford: Oxford University Press.
Meehl, Paul E., 1954,
Clinical Versus Statistical Predictions: A Theoretical Analysis and Revision of the Literature
. Minneapolis: University of Minnesota Press.
———, 1973, “Why I Do Not Attend in Case Conferences.” In
Psychodiagnosis: Selected Papers
, 225–302. Minneapolis: University of Minnesota Press.
Mendenhall, Richard R., 1991, “Evidence of Possible Underweighting of Earnings-related Information.”
Journal of Accounting Research
29: 170–178.
Merton, R. K., 1968. “The Matthew Effect in Science.”
Science
159: 56–63.
———, 1973a, “The Matthew Effect in Science.” In N. Storer, ed.,
The Sociology of Science
. Chicago: The University of Chicago Press.
———, 1973b, “The Normative Structure of Science.” In N. Storer, ed.,
The Sociology of Science
. Chicago: The University of Chicago Press.
———, 1988, “The Matthew Effect II: Cumulative Advantage and the Symbolism of Intellectual Property.”
Isis
79: 606–623.
Merton, Robert C., 1972, “An Analytic Derivation of the Efficient Portfolio Frontier.”
Journal of Financial and Quantitative Analysis
7(4): 1851–1872.
———, 1992,
Continuous-Time Finance
, 2nd ed. Cambridge, England: Blackwell.
Merton, Robert K., and Elinor Barber, 2004,
The Travels and Adventures of Serendipity
. Princeton, N.J.: Princeton University Press.
Mihailescu, Calin, 2006,
Lotophysics
. Preprint, University of Western Ontario.
Mikhail, M. B., B. R. Walther, and R. H. Willis, 1999, “Does Forecast Accuracy Matter to Security Analysts?”
The Accounting Review
74(2): 185–200.
Mikhail, Michael B., Beverly R. Walther, and Richard H. Willis, 1997, “Do Security Analysts Improve Their Performance with Experience?”
Journal of Accounting Research
35: 131–157.
Milgram, S., 1967, “The Small World Problem.”
Psychology Today
2: 60–67.
Mill, John Stuart, 1860,
A System of Logic Ratiocinative and Inductive, Being a Connected View of the Principle of Evidence and the Methods of Scientific Investigation
, 3rd ed. London: John W. Parker, West Strand.
Miller, Dale T., and Michael Ross, 1975, “Self-Serving Biases in Attribution of Causality: Fact or Fiction?”
Psychological Bulletin
82(2): 213–225.
Miller, Geoffrey F., 2000,
The Mating Mind: How Sexual Choice Shaped the Evolution of Human Nature
. New York: Doubleday.
Minsky, H., 1982,
Can It Happen Again? Essays on Instability and Finance
. Armonk, N.Y.: M. E. Sharpe.
Mitzenmacher, Michael, 2003, “A Brief History of Generative Models for Power Law and Lognormal Distributions.”
Internet Mathematics
1(2): 226–251.
Mohr, C., T. Landis, H. S. Bracha, and P. Brugger, 2003, “Opposite Turning Behavior in Righthanders and Non-right-handers Suggests a Link Between Handedness and Cerebral Dopamine Asymmetries.”
Behavioral Neuroscience
117(6): 1448–1452.
Mokyr, Joel, 2002,
The Gifts of Athena
. Princeton, N.J.: Princeton University Press.
Montier, James, 2007,
Applied Behavioural Finance
. Chichester, England: Wiley.
Moon, Francis C., 1992,
Chaotic and Fractal Dynamics
. New York: Wiley.
Mossner, E. C., 1970,
The Life of David Hume
. Oxford: Clarendon Press.
Murphy, A. H., and R. Winkler, 1984, “Probability Forecasting in Meteorology.”
Journal of the American Statistical Association
79: 489–500.
Myers, David G., 2002,
Intuition: Its Powers and Perils
. New Haven, Conn.: Yale University Press.
Nader, K., and J. E. LeDoux, 1999, “The Dopaminergic Modulation of Fear: Quinpirole Impairs the Recall of Emotional Memories in Rats.”
Behavioral Neuroscience
113(1): 152–165.
Naya, Emmanuel, and Anne-Pascale Pouey-Mounou, 2005,
Éloge de la médiocrité
. Paris: Éditions Rue d’ulm.
Nelson, Lynn Hankinson, and Jack Nelson, 2000,
On Quine
. Belmont, Calif.: Wadsworth.
Nelson, Robert H., 2001,
Economics as a Religion: From Samuelson to Chicago and Beyond
. University Park, Penn.: The Pennsylvania State University Press.
Newell, A., and H. A. Simon, 1972,
Human Problem Solving
. Englewood Cliffs, N.J.: Prentice-Hall.
Newman, M., 2003, “The Structure and Function of Complex Networks.”
SIAM Review
45: 167–256.
Newman, M. E. J., 2000, “Models of the Small World: A Review.
Journal of Statistical Physics
101: 819–841.
———, 2001, “The Structure of Scientific Collaboration Networks.”
Proceedings of the National Academy of Science
98: 404–409.
———, 2005, “Power Laws, Pareto Distributions, and Zipf’s Law.”
Complexity Digest
2005.02: 1–27.
Newman, M. E. J., C. Moore, and D. J. Watts, 2000, “Mean-field Solution of the Small-World Network Model.”
Physical Review Letters
84: 3201–3204.
Newman, M. E. J., D. J. Watts, and S. H. Strogatz, 2000, “Random Graphs with Arbitrary Degree Distribution and Their Applications.” Preprint cond-mat/0007235 at
http://xxx.lanl.gov
.
Neyman, J., 1977, “Frequentist Probability and Frequentist Statistics.”
Synthese
36: 97–131.
Nietzsche, Friedrich, 1979,
Ecce Homo
. London: Penguin Books.
Nisbett, R. E., D. H. Krantz, D. H. Jepson, and Z. Kunda, 1983, “The Use of Statistical Heuristics in Everyday Inductive Reasoning.”
Psychological Review
90: 339–363.
Nisbett, Richard E., and Timothy D. Wilson, 1977, “Telling More Than We Can Know: Verbal Reports on Mental Processes.”
Psychological Bulletin
84(3): 231–259.
Nussbaum, Martha C., 1986,
The Fragility of Goodness: Luck and Ethics in Greek Tragedy and Philosophy
. Cambridge: Cambridge University Press.
O’Connor, M., and M. Lawrence, 1989, “An Examination of the Accuracy of Judgment Confidence Intervals in Time Series Forecasting.”
International Journal of Forecasting
8: 141–155.
O’Neill, Brian C., and Mausami Desai, 2005, “Accuracy of Past Projections of U.S. Energy Consumption.”
Energy Policy
33: 979–993.
Oberauer K., O. Wilhelm, and R. R. Diaz, 1999, “Bayesian Rationality for the Wason Selection Task? A Test of Optimal Data Selection Theory.”
Thinking and Reasoning
5(2): 115–144.
Odean, Terrance, 1998a, “Are Investors Reluctant to Realize Their Losses?”
Journal of Finance
53(5): 1775–1798.
———, 1998b. “Volume, Volatility, Price and Profit When All Traders Are Above Average.”
Journal of Finance
53(6): 1887–1934.
Officer, R. R., 1972, “The Distribution of Stock Returns.”
Journal of the American Statistical Association
340(67): 807–812.
Olsson, Erik J., 2006,
Knowledge and Inquiry: Essays on the Pragmatism of Isaac Levi
. Cam
bridge Studies in Probability, Induction and Decision Theory Series. Cambridge: Cambridge University Press.
Onkal, D., J. F. Yates, C. Simga-Mugan, and S. Oztin, 2003, “Professional and Amateur Judgment Accuracy: The Case of Foreign Exchange Rates.”
Organizational Behavior and Human Decision Processes
91: 169–185.
Ormerod, Paul, 2005,
Why Most Things Fail
. New York: Pantheon Books.
———, 2006, “Hayek, ‘The Intellectuals and Socialism,’ and Weighted Scale-free Networks.”
Economic Affairs
26: 1–41.
Oskamp, Stuart, 1965, “Overconfidence in Case-Study Judgments.”
Journal of Consulting Psychology
29(3): 261–265.
Paese, P. W., and J. A. Sniezek, 1991, “Influences on the Appropriateness of Confidence in Judgment: Practice, Effort, Information, and Decision Making.”
Organizational Behavior and Human Decision Processes
48: 100–130.
Page, Scott, 2007,
The Difference: How the Power of Diversity Can Create Better Groups, Firms, Schools, and Societies
. Princeton, N.J.: Princeton University Press.
Pais, Abraham, 1982,
Subtle Is the Lord
. New York: Oxford University Press.
Pareto, Vilfredo, 1896,
Cours d’économie politique
. Geneva: Droz.
Park, David, 2005,
The Grand Contraption: The World as Myth, Number, and Chance
. Princeton, N.J.: Princeton University Press.
Paulos, John Allen, 1988,
Innumeracy
. New York: Hill & Wang.
———, 2003,
A Mathematician Plays the Stock Market
. Boston: Basic Books.
Pearl, J., 2000,
Causality: Models, Reasoning, and Inference
. New York: Cambridge University Press.
Peirce, Charles Sanders, 1923, 1998,
Chance, Love and Logic: Philosophical Essays
. Lincoln: University of Nebraska Press.
———, 1955,
Philosophical Writings of Peirce
, edited by J. Buchler. New York: Dover.
Penrose, Roger, 1989,
The Emperor’s New Mind
. New York: Penguin.
Pérez, C. J., A. Corral, A. Diáz-Guilera, K. Christensen, and A. Arenas, 1996, “On Self-organized Criticality and Synchronization in Lattice Models of Coupled Dynamical Systems.”
International Journal of Modern Physics B
10: 1111–1151.
Perilli, Lorenzo, 2004,
Menodoto di Nicomedia: Contributo a una storia galeniana della medicina empirica
. Munich, Leipzig: K. G. Saur.
Perline, R., 2005, “Strong, Weak, and False Inverse Power Laws.”
Statistical Science
20(1): 68–88.
Pfeifer, P. E., 1994, “Are We Overconfident in the Belief That Probability Forecasters Are Overconfident?”
Organizational Behavior and Human Decision Processes
58(2): 203–213.
Phelan, James, 2005, “Who’s Here? Thoughts on Narrative Identity and Narrative Imperialism.”
Narrative
13: 205–211.
Piattelli-Palmarini, Massimo, 1994,
Inevitable Illusions: How Mistakes of Reason Rule Our Minds
. New York: Wiley.
Pieters, Rik, and Hans Baumgartner, 2002. “Who Talks to Whom? Intra- and Interdisciplinary Communication of Economics Journals.”
Journal of Economic Literature
40(2): 483–509.
Pinker, Steven, 1997,
How the Mind Works
. New York: W. W. Norton and Company.
———, 2002,
The Blank Slate: The Modern Denial of Human Nature
. New York: Viking.
Pisarenko, V., and D. Sornette, 2004, “On Statistical Methods of Parameter Estimation for Deterministically Chaotic Time-Series.”
Physical Review E
69: 036122.
Plotkin, Henry, 1998,
Evolution in Mind: An Introduction to Evolutionary Psychology
. London: Penguin.
Plous, S., 1993.
The Psychology of Judgment and Decision Making
. New York: McGraw-Hill.
———, 1995, “A Comparison of Strategies for Reducing Interval Overconfidence in Group Judgments.”
Journal of Applied Psychology
80: 443–454.
Polanyi, Michael, 1958/1974,
Personal Knowledge: Towards a Post-Critical Philosophy
. Chicago: The University of Chicago Press.
Pomata, Gianna, and Nancy G. Siraisi, 2005, Introduction. In Gianna Pomata and Nancy G. Siraisi,
eds.
Historia: Empiricism and Erudition in Early Modern Europe
. (Transformations: Studies in the History of Science and Technology.) Cambridge, Mass.: MIT Press.
Popkin, Richard H., 1951, “David Hume: His Pyrrhonism and His Critique of Pyrrhonism.”
The Philosophical Quarterly
1(5): 385–407.
———, 1955, “The Skeptical Precursors of David Hume.”
Philosophy and Phenomenological Research
16(1): 61–71.
———, 2003,
The History of Scepticism: From Savonarola to Bayle
. Oxford: Oxford University Press.
Popper, Karl R., 1971,
The Open Society and Its Enemies
, 5th ed. Princeton, N.J.: Princeton University Press.
———, 1992,
Conjectures and Refutations: The Growth of Scientific Knowledge
, 5th ed. London: Routledge.
———, 1994,
The Myth of the Framework
. London: Routledge.
———, 2002a,
The Logic of Scientific Discovery
, 15th ed. London: Routledge.
———, 2002b,
The Poverty of Historicism
. London: Routledge.
Posner, Richard A., 2004,
Catastrophe: Risk and Response
. Oxford: Oxford University Press.
Price, Derek J. de Solla, 1965, “Networks of Scientific Papers.”
Science
149: 510–515.
———, 1970, “Citation Measures of Hard Science, Soft Science, Technology, and Non-science.” In C. E. Nelson and D. K. Pollak, eds.,
Communication Among Scientists and Engineers
. Lexington, Mass.: Heat.
———, 1976, “A General Theory of Bibliometric and Other Cumulative Advantage Processes.”
Journal of the American Society of Information Sciences
27: 292–306.
Prigogine, Ilya, 1996,
The End of Certainty: Time, Chaos, and the New Laws of Nature
. New York: The Free Press.
Quammen, David, 2006,
The Reluctant Mr. Darwin
. New York: W. W. Norton and Company.
Quine, W. V., 1951, “Two Dogmas of Empiricism.”
The Philosophical Review
60: 20–43.
———, 1970, “Natural Kinds.” In N. Rescher, ed.,
Essays in Honor of Carl G. Hempel
. Dordrecht: D. Reidel.
Rabin, M., 1998, “Psychology and Economics.”
Journal of Economic Literature
36: 11–46.
Rabin, M., and R. H. Thaler, 2001, “Anomalies: Risk Aversion.”
Journal of Economic Perspectives
15(1): 219–232.
Rabin, Matthew, 2000, “Inference by Believers in the Law of Small Numbers.” Working Paper, Economics Department, University of California, Berkeley,
http://repositories.cdlib.org/iberecon/
.
Ramachandran, V. S., 2003,
The Emerging Mind
. London: Portfolio.
Ramachandran, V. S., and S. Blakeslee, 1998,
Phantoms in the Brain
. New York: Morrow.
Rancière, Jacques, 1997,
Les mots de l’histoire. Essai de poétique du savoir
. Paris: Éditions du Seuil.
Ratey, John J., 2001,
A User’s Guide to the Brain: Perception, Attention and the Four Theaters of the Brain
. New York: Pantheon.
Rawls, John, 1971,
A Theory of Justice
. Cambridge, Mass.: Harvard University Press.
Reboul, Anne, 2006, “Similarities and Differences Between Human and Nonhuman Causal Cognition.” Interdisciplines Conference on Causality,
www.interdisciplines.org
.
Redner, S., 1998, “How Popular Is Your Paper? An Empirical Study of the Citation Distribution.”
European Physical Journal B
4: 131–134.
Rees, Martin, 2004,
Our Final Century: Will Civilization Survive the Twenty-first Century?
London: Arrow Books.
Reichenbach, H., 1938,
Experience and prediction
. Chicago: The University of Chicago Press.
Remus, W., M. Oapos Connor, and K. Griggs, 1997, “Does Feedback Improve the Accuracy of Recurrent Judgmental Forecasts?” Proceedings of the Thirtieth Hawaii International Conference on System Sciences, January 7–10: 5–6.
Rescher, Nicholas, 1995,
Luck: The Brilliant Randomness of Everyday Life
. New York: Farrar, Straus & Giroux.
———, 2001,
Paradoxes: Their Roots, Range, and Resolution
. Chicago: Open Court Books.
Richardson, L. F., 1960,
Statistics of Deadly Quarrels
. Pacific Grove, Calif.: Boxwood Press.
Rips, L., 2001, “Necessity and Natural Categories.”
Psychological Bulletin
127: 827–852.
Roberts, Royston M., 1989,
Serendipity: Accidental Discoveries in Science
. New York: Wiley.
Robins, Richard W., 2005, “Pscyhology: The Nature of Personality: Genes, Culture, and National Character.”
Science
310: 62–63.
Rollet, Laurent, 2005,
Un mathématicien au Panthéon? Autour de la mort de Henri Poincaré
. Laboratoire de Philosophie et d’Histoire des Sciences—Archives Henri-Poincaré, Université Nancy 2.
Ronis, D. L., and J. F. Yates, 1987, “Components of Probability Judgment Accuracy: Individual Consistency and Effects of Subject Matter and Assessment Method.”
Organizational Behavior and Human Decision Processes
40: 193–218.
Rosch, E., 1978, “Principles of Categorization.” In E. Rosch and B. B. Lloyd, eds.,
Cognition and Categorization
. Hillsdale, N.J.: Lawrence Erlbaum.
Rosch, E. H., 1973, “Natural Categories.”
Cognitive Psychology
4: 328–350.
Rose, Steven, 2003,
The Making of Memory: From Molecules to Mind
, revised ed. New York: Vintage.
Rosen, S., 1981, “The Economics of Superstars.”
American Economic Review
71: 845–858.
Rosenzweig, Phil, 2006,
The Halo Effect and Other Business Delusions: Why Experts Are So Often Wrong and What Wise Managers Must Know
. New York: The Free Press.
Ross, Stephen A., 2004,
Neoclassical Finance
. Princeton, N.J.: Princeton University Press.
Rosser, B., 2009, “How complex are the Austrians?,” working paper.
Rounding, Virginia, 2006,
Catherine the Great: Love, Sex and Power
. London: Hutchinson.
Ruelle, David, 1991,
Hasard et chaos
. Paris: Odile Jacob.
Ruffié, Jacques, 1977,
De la biologie à la culture
. Paris: Flammarion.
Russell, Bertrand, 1912,
The Problems of Philosophy
. New York: Oxford University Press.
———, 1993,
My Philosophical Development
. London: Routledge.
———, 1996,
Sceptical Essays
. London: Routledge.
Russo, J. Edward, and Paul J. H. Schoernaker, 1992, “Managing Overconfidence.”
Sloan Management Review
33(2): 7–17.
Ryle, Gilbert, 1949,
The Concept of Mind
. Chicago: The University of Chicago Press.
Salganik, Matthew J., Peter S. Dodds, and Duncan J. Watts, 2006, “Experimental Study of Inequality and Unpredictability in an Artificial Cultural Market.”
Science
311: 854–856.
Saliba, George, 2007,
Islamic Science and the Making of the European Renaissance
(Transformations: Studies in the History of Science and Technology). Cambridge, Mass.: MIT Press.
Samuelson, Paul A., 1983,
Foundations of Economic Analysis
. Cambridge, Mass.: Harvard University Press.
Sapolsky, Robert M., 1998,
Why Zebras Don’t Get Ulcers: An Updated Guide to Stress, Stress-related Diseases, and Coping
. New York: W. H. Freeman and Company.
Sapolsky, Robert, M., and the Department of Neurology and Neurological Sciences, Stanford University School of Medicine, 2003, “Glucocorticoids and Hippocampal Atrophy in Neuropsychiatric Disorders.”
Savage, Leonard J., 1972,
The Foundations of Statistics
. New York: Dover.
Schacter, Daniel L., 2001,
The Seven Sins of Memory: How the Mind Forgets and Remembers
. Boston: Houghton Mifflin.
Schelling, Thomas, 1971, “Dynamic Models of Segregation.”
Journal of Mathematical Sociology
1: 143–186.
———, 1978,
Micromotives and Macrobehavior
. New York: W. W. Norton and Company.
Scheps, Ruth, ed., 1996,
Les sciences de la prévision
. Paris: Éditions du Seuil.
Schroeder, Manfred, 1991,
Fractals, Chaos, Power Laws: Minutes from an Infinite Paradise
. New York: W. H. Freeman and Company.
Schumpeter, Joseph, 1942,
Capitalism, Socialism and Democracy
. New York: Harper.
Seglen, P. O., 1992, “The Skewness of Science.”
Journal of the American Society for Information
Science
43: 628–638.
Sextus Empiricus, 2000,
Outline of Scepticism
, edited by Julia Annas and Jonathan Barnes. New York: Cambridge University Press.
———, 2005,
Against the Logicians
, translated and edited by Richard Bett. New York: Cambridge University Press.
Shackle, G.L.S., 1961,
Decision Order and Time in Human Affairs
. Cambridge: Cambridge University Press
———, 1973,
Epistemics and Economics: A Critique of Economic Doctrines
. Cambridge: Cambridge University Press.
Shanteau, J., 1992, “Competence in Experts: The Role of Task Characteristics.”
Organizational Behavior and Human Decision Processes
53: 252–266.
Sharpe, William F., 1994, “The Sharpe Ratio.”
Journal of Portfolio Management
21(1): 49–58.
———, 1996, “Mutual Fund Performance.”
Journal of Business
39: 119–138.
Shiller, Robert J., 1981, “Do Stock Prices Move Too Much to Be Justified by Subsequent Changes in Dividends?”
American Economic Review
71(3): 421–436.
———, 1989,
Market Volatility
. Cambridge, Mass.: The MIT Press.
———, 1990, “Market Volatility and Investor Behavior.”
American Economic Review
80(2): 58–62.
———, 1995, “Conversation, Information, and Herd Behavior.”
American Economic Review
85(2): 181–185.
———, 2000,
Irrational Exuberance
. Princeton, N.J.: Princeton University Press.
———, 2003,
The New Financial Order: Risk in the 21st Century
. Princeton, N.J.: Princeton University Press.
Shizgal, Peter, 1999, “On the Neural Computation of Utility: Implications from Studies of Brain Simulation Rewards.” In D. Kahneman, E. Diener, and N. Schwarz, eds., 1999.
Sieff, E. M., R. M. Dawes, and G. Loewenstein, 1999, “Anticipated Versus Actual Reaction to HIV Test Results.”
American Journal of Psychology
122: 297–311.
Silverberg, Gerald, and Bart Verspagen, 2004, “The Size Distribution of Innovations Revisited: An Application of Extreme Value Statistics to Citation and Value Measures of Patent Significance,”
www.merit.unimaas.nl/publications/rmpdf/2004/rm2004-021.pdf
.
———, 2005, “Self-organization of R&D Search in Complex Technology Spaces,”
www.merit.unimaas.nl/publications/rmpdf/2005/rm2005-017.pdf
.
Simon, Herbert A., 1955, “On a Class of Skew Distribution Functions.”
Biometrika
42: 425–440.
———, 1987, “Behavioral Economics.” In J. Eatwell, M. Milgate, and P. Newman, eds., 1987.
Simonton, Dean Keith, 1999,
Origins of Genius: Darwinian Perspectives on Creativity
. New York: Oxford University Press.
———, 2004,
Creativity
. New York: Cambridge University Press.
Sloman, S. A., 1993, “Feature Based Induction.”
Cognitive Psychology
25: 231–280.
———, 1994, “When Explanations Compete: The Role of Explanatory Coherence on Judgments of Likelihood.”
Cognition
52: 1–21.
———, 1996, “The Empirical Case for Two Systems of Reasoning.”
Psychological Bulletin
119: 3–22.
———, 1998, “Categorical Inference Is Not a Tree: The Myth of Inheritance Hierarchies.”
Cognitive Psychology
35: 1–33.
———, 2002, “Two Systems of Reasoning.” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Sloman, S. A., B. C. Love, and W. Ahn, 1998, “Feature Centrality and Conceptual Coherence.”
Cognitive Science
22: 189–228.
Sloman, S. A., and B. C. Malt, 2003, “Artifacts Are Not Ascribed Essences, Nor Are They Treated as Belonging to Kinds.”
Language and Cognitive Processes
18: 563–582.
Sloman, S. A., and D. Over, 2003, “Probability Judgment from the Inside and Out.” In D. Over, ed.,
Evolution and the Psychology of Thinking: The Debate
. New York: Psychology Press.
Sloman, S. A., and L. J. Rips, 1998, “Similarity as an Explanatory Construct.”
Cognition
65: 87–101.
Slovic, Paul, M. Finucane, E. Peters, and D. G. MacGregor, 2003a, “Rational Actors or Rational Fools? Implications of the Affect Heuristic for Behavioral Economics.” Working Paper,
www.decisionresearch.com
.
———, 2003b, “Risk as Analysis, Risk as Feelings: Some Thoughts About Affect, Reason, Risk,
and Rationality.” Paper presented at the Annual Meeting of the Society for Risk Analysis, New Orleans, La., December 10, 2002.
Slovic, P., M. Finucane, E. Peters, and D. G. MacGregor, 2002, “The Affect Heuristic.” In T. Gilovich, D. Griffin, and D. Kahneman, eds., 2002.
Slovic, P., B. Fischhoff, and S. Lichtenstein, 1976, “Cognitive Processes and Societal Risk Taking.” In John S. Carroll and John W. Payne, eds.,
Cognition and Social Behavior
. Hillsdale, N.J.: Lawrence Erlbaum.
———, 1977, “Behavioral Decision Theory.”
Annual Review of Psychology
28: 1–39.
Slovic, P., B. Fischhoff, S. Lichtenstein, B. Corrigan, and B. Combs, 1977, “Preference for Insuring Against Probable Small Losses: Implications for the Theory and Practice of Insurance.”
Journal of Risk and Insurance
44: 237–258. Reprinted in P. Slovic, ed.,
The Perception of Risk
. London: Earthscan.
Slovic, Paul, 1987, “Perception of Risk.”
Science
236: 280–285.
———, 2001,
The Perception of Risk
. London: Earthscan.
Sniezek, J. A., and R. A. Henry, 1989, “Accuracy and Confidence in Group Judgement.”
Organizational Behavior and Human Decision Processes
43(11): 1–28.
Sniezek, J. A., and T. Buckley, 1993, “Decision Errors Made by Individuals and Groups.” In N. J. Castellan, ed.,
Individual and Group Decision Making
. Hillsdale, N.J.: Lawrence Erlbaum.
Snyder, A. W., 2001, “Paradox of the Savant Mind.”
Nature
413: 251–252.
Snyder A. W., E. Mulcahy, J. L. Taylor, D. J. Mitchell, P. Sachdev, and S. C. Gandevia, 2003,
“Savant-like Skills Exposed in Normal People by Suppression of the Left Fronto-temporal Lobe.
Journal of Integrative Neuroscience
2: 149–158.
Soll, J. B., 1996, “Determinants of Overconfidence and Miscalibration: The Roles of Random Error and Ecological Structure.”
Organizational Behavior and Human Decision Processes
65: 117–137.
Sornette, D., F. Deschâtres, T. Gilbert, and Y. Ageon, 2004, “Endogenous Versus Exogenous Shocks in Complex Networks: An Empirical Test.”
Physical Review Letters
93: 228701.
Sornette, D., and K. Ide, 2001, “The Kalman-Levy Filter,”
Physica D
151: 142–174.
Sornette, Didier, 2003,
Why Stock Markets Crash: Critical Events in Complex Financial Systems
. Princeton, N.J.: Princeton University Press.
———, 2004,
Critical Phenomena in Natural Sciences: Chaos, Fractals, Self-organization and Disorder: Concepts and Tools
, 2nd ed. Berlin and Heidelberg: Springer.
Sornette, Didier, and Daniel Zajdenweber, 1999, “The Economic Return of Research: The Pareto Law and Its Implications.”
European Physical Journal B
8(4): 653–664.
Soros, George, 1988,
The Alchemy of Finance: Reading the Mind of the Market
. New York: Simon & Schuster.
Spariosu, Mihai I., 2004,
The University of Global Intelligence and Human Development: Towards an Ecology of Global Learning
. Cambridge, Mass.: The MIT Press.
Spasser, Mark A., 1997, “The Enacted Fate of Undiscovered Public Knowledge.”
Journal of the American Society for Information Science
48(8): 707–717.
Spencer, B. A., and G. S. Taylor, 1988, “Effects of Facial Attractiveness and Gender on Causal Attributions of Managerial Performance.”
Sex Roles
19(5/6): 273–285.
Sperber, Dan, 1996a,
La contagion des idées
. Paris: Odile Jacob.
———, 1996b,
Explaining Culture: A Naturalistic Approach
. Oxford: Blackwell.
———, 1997, “Intuitive and Reflective Beliefs.”
Mind and Language
12(1): 67–83.
———, 2001, “An Evolutionary Perspective on Testimony and Argumentation.”
Philosophical Topics
29: 401–413.
Sperber, Dan, and Deirdre Wilson, 1995,
Relevance: Communication and Cognition
, 2nd ed. Oxford: Blackwell.
———, 2004a, “Relevance Theory.” In L. R. Horn, and G. Ward, eds.,
The Handbook of Pragmatics
. Oxford: Blackwell.
———, 2004b, “The Cognitive Foundations of Cultural Stability and Diversity.”
Trends in Cognitive Sciences
8(1): 40–44.
Squire, Larry, and Eric R. Kandel, 2000,
Memory: From Mind to Molecules
. New York: Owl Books.
Stanley, H. E., L. A. N. Amaral, P. Gopikrishnan, and V. Plerou, 2000, “Scale Invariance and Universality of Economic Fluctuations.”
Physica A
283: 31–41.
Stanley, T. J., 2000,
The Millionaire Mind
. Kansas City: Andrews McMeel Publishing.
Stanley, T. J., and W. D. Danko, 1996,
The Millionaire Next Door: The Surprising Secrets of America’s Wealthy
. Atlanta, Ga.: Longstreet Press.
Stanovich, K., and R. West, 2000, “Individual Differences in Reasoning: Implications for the Rationality Debate.”
Behavioral and Brain Sciences
23: 645–665.
Stanovich, K. E., 1986, “Matthew Effects in Reading: Some Consequences of Individual Differences in the acquisition of literacy.”
Reading Research Quarterly
21: 360–407.
Stein, D. L., ed., 1989,
Lectures in the Sciences of Complexity
. Reading, Mass.: Addison-Wesley.
Sterelny, Kim, 2001,
Dawkins vs. Gould: Survival of the Fittest
. Cambridge, England: Totem Books.
Stewart, Ian, 1989,
Does God Play Dice? The New Mathematics of Chaos
. London: Penguin Books.
———, 1993, “Chaos.” In Leo Howe and Alan Wain, eds., 1993.
Stigler, Stephen M., 1986,
The History of Statistics: The Measurement of Uncertainty Before 1900
. Cambridge, Mass.: The Belknap Press of Harvard University.
———, 2002,
Statistics on the Table: The History of Statistical Concepts and Methods
. Cambridge, Mass.: Harvard University Press.
Stiglitz, Joseph, 1994,
Whither Socialism
. Cambridge, Mass.: The MIT Press.
Strawson, Galen, 1994,
Mental Reality
. Cambridge, Mass.: The MIT Press.
———, 2004, “Against Narrativity.”
Ratio
17: 428–452.
Strogatz, S. H., 1994,
Nonlinear Dynamics and Chaos, with Applications to Physics, Biology, Chemistry, and Engineering
. Reading, Mass.: Addison-Wesley.
Strogatz, Steven H., 2001, “Exploring Complex Networks.”
Nature
410: 268–276.
———, 2003,
Sync: How Order Emerges from Chaos in the Universe, Nature, and Daily Life
. New York: Hyperion.
Suantak, L., F. Bolger, and W. R. Ferrell, 1996, “The Hard–easy Effect in Subjective Probability Calibration.”
Organizational Behavior and Human Decision Processes
67: 201–221.
Suddendorf, Thomas, 2006, “Enhanced: Foresight and Evolution of the Human Mind.”
Science
312(5776): 1006–1007.
Sullivan, R., A. Timmermann, and H. White, 1999, “Data-snooping, Technical Trading Rule Performance and the Bootstrap.”
Journal of Finance
54: 1647–1692.
Sunstein, Cass R., 2002,
Risk and Reason: Safety, Law, and the Environment
. Cambridge: Cambridge University Press.
Surowiecki, James, 2004,
The Wisdom of Crowds
. New York: Doubleday.
Sushil, Bikhchandani, David Hirshleifer, and Ivo Welch, 1992, “A Theory of Fads, Fashion, Custom, and Cultural Change as Informational Cascades.”
Journal of Political Economy
100(5): 992–1026.
Sutton, J., 1997, “Gibrat’s Legacy.”
Journal of Economic Literature
35: 40–59.
Swanson, D. R., 1986a, “Fish Oil, Raynaud’s Syndrome and Undiscovered Public Knowledge.”
Perspectives in Biology and Medicine
30(1): 7–18.
———, 1986b, “Undiscovered Public Knowledge.”
Library Quarterly
56: 103–118.
———, 1987, “Two Medical Literatures That Are Logically but Not Bibliographically Connected.”
Journal of the American Society for Information Science
38: 228–233.
Swets, J. A., R. M. Dawes, and J. Monahan, 2000a, “Better Decisions Through Science.”
Scientific American
(October): 82–87.
———, 2000b, “Psychological Science Can Improve Diagnostic Decisions.”
Psychogical Science in the Public Interest
1: 1–26.
Szenberg, Michael, ed., 1992,
Eminent Economists: Their Life Philosophies
. Cambridge: Cambridge University Press.
Tabor, M., 1989,
Chaos and Integrability in Nonlinear Dynamics: An Introduction
. New York: Wiley.
Taine, Hippolyte Adolphe, 1868, 1905.
Les philosophes classiques du XIXe siècle en France
, 9ème éd. Paris: Hachette.
Taleb, N. N., 1997,
Dynamic Hedging: Managing Vanilla and Exotic Options
. New York: Wiley.
———, 2004a (2001, 1st ed.),
Fooled by Randomness: The Hidden Role of Chance in Life and in the Markets
. New York: Random House.
———, 2004b, “These Extreme Exceptions of Commodity Derivatives.” In Helyette Geman,
Commodities and Commodity Derivatives
. New York: Wiley.
———, 2004c, “Bleed or Blowup: What Does Empirical Psychology Tell Us About the Preference for Negative Skewness?”
Journal of Behavioral Finance
5(1): 2–7.
———, 2004d, “The Black Swan: Why Don’t We Learn That We Don’t Learn?” Paper presented at the United States Department of Defense Highland Forum, Summer 2004.
———, 2004e, “Roots of Unfairness.”
Literary Research/Recherche Littéraire
21(41–42): 241–254.
———, 2004f, “On Skewness in Investment Choices.”
Greenwich Roundtable Quarterly
2.
———, 2005, “Fat Tails, Asymmetric Knowledge, and Decision Making: Essay in Honor of Benoît Mandelbrot’s 80th Birthday.” Technical paper series,
Wilmott
(March): 56–59.
———, 2006a, “Homo Ludens and Homo Economicus.” Foreword to Aaron Brown’s
The Poker Face of Wall Street
. New York: Wiley.
———, 2006b, “On Forecasting.” In John Brockman, ed.,
In What We Believe But Cannot Prove: Today’s Leading Thinkers on Science in the Age of Certainty
. New York: Harper Perennial.
———, 2007, “Black Swan and Domains of Statistics,”
The American Statistician
61, (3)3 (Aug. 2007).
———, 2008, “Infinite Variance and the Problems of Practice,”
Complexity
14.
———, 2009, “Errors, Robustness, and the Fourth Quadrant,”
International Journal of Forecasting
25(4).
———, 2010, “Common Errors in the Interpretation of the Ideas of
The Black Swan
and Associated Papers,”
Critical Review
21:4 (withdrawn).
Taleb, N. N., and R. Douady, 2010,
“Undecidability of Probabilistic Measures: On the Inconsistency of Estimating Probabilities from a Sample Without Binding A Priori Assumptions on the Class of Acceptable Probabilities”
(preprint, NYU-Poly).
Taleb, N. N., D. G. Goldstein, and M. Spitznagel, 2009, “The Six Mistakes Executives Make in Risk Management,”
Harvard Business Review
(October 2009).
Taleb, N. N., and D. Goldstein, 2010, “The Telescope Problem” (preprint, NYU-Poly).
Taleb, Nassim Nicholas, and Avital Pilpel, 2004, “I problemi epistemologici del risk management.” In Daniele Pace, a cura di,
Economia del rischio: Antologia di scritti su rischio e decisione economica
. Milano: Giuffrè.
———2007, “Epistemology and Risk Management,”
Risk and Regulation
13 (summer 2007).
———2010, “Beliefs, Decisions, and Probability,” in T. O’Connor and C. Sandis, eds.,
A Companion to the Philosophy of Action
(Wiley-Blackwell).
Taleb, N. N., and C. Tapiero, 2010a, “Too Big to Fail and the Fallacy of Large Institutions” (preprint, NYU-Poly).
———2010b, “The Risk Externalities of Too Big to Fail” (preprint, NYU-Poly).
Tashman, Leonard J., 2000, “Out of Sample Tests of Forecasting Accuracy: An Analysis and Review.”
International Journal of Forecasting
16(4): 437–450.
Teigen, K. H., 1974, “Overestimation of Subjective Probabilities.”
Scandinavian Journal of Psychology
15: 56–62.
Terracciano, A., et al., 2005, “National Character Does Not Reflect Mean Personality Traits.”
Science
310: 96.
Tetlock, Philip E., 1999, “Theory-Driven Reasoning About Plausible Pasts and Probable Futures in World Politics: Are We Prisoners of Our Preconceptions?”
American Journal of Political Science
43(2): 335–366.
———, 2005, “Expert Political Judgment: How Good Is It? How Can We Know?” Princeton, N.J.: Princeton University Press.
Thaler, Richard, 1985, “Mental Accounting and Consumer Choice.”
Marketing Scienc
e 4(3): 199–214.
Thom, René, 1980,
Paraboles et catastrophes
. Paris: Champs Flammarion.
———, 1993,
Prédire n’est pas expliquer
. Paris: Champs Flammarion.
Thorley, 1999, “Investor Overconfidence and Trading Volume.” Working Paper, Santa Clara University.
Tilly, Charles, 2006,
Why? What Happens When People Give Reasons and Why
. Princeton, N.J.: Princeton University Press.
Tinbergen, N., 1963, “On Aims and Methods in Ethology.”
Zeitschrift fur Tierpsychologie
20: 410–433.
———, 1968, “On War and Peace in Animals and Man: An Ethologist’s Approach to the Biology of Aggression.”
Science
160: 1411–1418.
Tobin, James, 1958, “Liquidity Preference as Behavior Towards Risk.”
Review of Economic Studies
67: 65–86.
Triantis, Alexander J., and James E. Hodder, 1990, “Valuing Flexibility as a Complex Option.”
Journal of Finance
45(2): 549–564.
Trivers, Robert, 2002,
Natural Selection and Social Theory: Selected Papers of Robert Trivers
. Oxford: Oxford University Press.
Turner, Mark, 1996,
The Literary Mind
. New York: Oxford University Press.
Tversky, A., and D. Kahneman, 1971, “Belief in the Law of Small Numbers.”
Psychology Bulletin
76(2): 105–110.
———, 1973, “Availability: A Heuristic for Judging Frequency and Probability.”
Cognitive Psychology
5: 207–232.
———, 1974, “Judgement Under Uncertainty: Heuristics and Biases.”
Science
185: 1124–1131.
———, 1982, “Evidential Impact of Base-Rates.” In D. Kahneman, P. Slovic, and A. Tversky, eds.,
Judgment Under Uncertainty: Heuristics and Biases
. Cambridge: Cambridge University Press.
———, 1983, “Extensional Versus Intuitive Reasoning: The Conjunction Fallacy in Probability Judgment.”
Psychological Review
90: 293–315.
———, 1992, “Advances in Prospect Theory: Cumulative Representation of Uncertainty.”
Journal of Risk and Uncertainty
5: 297–323.
Tversky, A., and D. J. Koehler, 1994, “Support Theory: A Nonextensional Representation of Subjective Probability.”
Psychological Review
101: 547–567.
Tyszka, T., and P. Zielonka, 2002, “Expert Judgments: Financial Analysts Versus Weather Forecasters.”
Journal of Psychology and Financial Markets
3(3): 152–160.
Uglow, Jenny, 2003,
The Lunar Men: Five Friends Whose Curiosity Changed the World
. New York: Farrar, Straus & Giroux.
Vale, Nilton Bezerra do, José Delfino, and Lúcio Flávio Bezerra do Vale, 2005, “Serendipity in Medicine and Anesthesiology.”
Revista Brasileira de Anestesiologia
55(2): 224–249.
van Tongeren, Paul, 2002, “Nietzsche’s Greek Measure.”
Journal of Nietzsche Studies
24: 5.
Vandenbroucke, J. P., 1996, “Evidence-Based Medicine and ‘Medicine d’Observation,’”
Journal of Clinical Epidemiology
, 49(12): 1335–1338.
Varela, Francisco J., 1988,
Invitation aux sciences cognitives
. Paris: Champs Flammarion.
Varian, Hal R., 1989, “Differences of Opinion in Financial Markets.” In Courtenay C. Stone, ed.,
Financial Risk: Theory, Evidence and Implications: Proceedings of the Eleventh Annual Economic Policy Conference of the Federal Reserve Bank of St. Louis
. Boston: Kitiwer Academic Publishers.
Véhel, Jacques Lévy, and Christian Walter, 2002,
Les marchés fractals: Efficience, ruptures, et tendances sur les marchés financiers
. Paris: PUF.
Veyne, Paul, 1971,
Comment on écrit l’histoire
. Paris: Éditions du Seuil.
———, 2005,
L’Empire gréco-romain
. Paris: Éditions du Seuil.
Vogelstein, Bert, David Lane, and Arnold J. Levine, 2000, “Surfing the P53 Network.”
Nature
408: 307–310.
Voit, Johannes, 2001,
The Statistical Mechanics of Financial Markets
. Heidelberg: Springer.
von Mises, R., 1928,
Wahrscheinlichkeit, Statistik und Wahrheit
. Berlin: Springer. Translated and reprinted as
Probability, Statistics, and Truth
. New York: Dover, 1957.
von Plato, Jan, 1994,
Creating Modern Probability
. Cambridge: Cambridge University Press.
von Winterfeldt, D., and W. Edwards, 1986,
Decision Analysis and Behavioral Research
. Cambridge: Cambridge University Press.
Wagenaar, Willern, and Gideon B. Keren, 1985, “Calibration of Probability Assessments by Professional Blackjack Dealers, Statistical Experts, and Lay People.”
Organizational Behavior and Human Decision Processes
36: 406–416.
———, 1986, “Does the Expert Know? The Reliability of Predictions and Confidence Ratings of Experts.” In Erik Hollnagel, Giuseppe Mancini, and David D. Woods,
Intelligent Design Support in Process Environments
. Berlin: Springer.
Waller, John, 2002,
Fabulous Science: Fact and Fiction in the History of Scientific Discovery
. Oxford: Oxford University Press.
Wallerstein, Immanuel, 1999, “Braudel and Interscience: A Preacher to Empty Pews?” Paper presented at the 5th Journées Braudeliennes, Binghamton University, Binghamton, N.Y.
Wallsten, T. S., D. V. Budescu, I. Erev, and A. Diederich, 1997, “Evaluating and Combining Subjective Probability Estimates.”
Journal of Behavioral Decision Making
10: 243–268.
Wason, P. C., 1960, “On the Failure to Eliminate Hypotheses in a Conceptual Task.”
Quarterly Journal of Experimental Psychology
12: 129–140.
Watts, D. J., 2003,
Six Degrees: The Science of a Connected Age
. New York: W. W. Norton and Company.
Watts, D. J., and S. H. Strogatz, 1998, “Collective Dynamics of ‘Small-world’ Networks.”
Nature
393: 440–442
Watts, Duncan, 2002, “A Simple Model of Global Cascades on Random Networks.”
Proceedings of the National Academy of Sciences
99(9): 5766–5771.
Wegner, Daniel M., 2002,
The Illusion of Conscious Will
. Cambridge, Mass.: The MIT Press.
Weinberg, Steven, 2001, “Facing Up: Science and Its Cultural Adversaries.” Working Paper, Harvard University.
Weintraub, Roy E., 2002,
How Economics Became a Mathematical Science
, Durham, N.C.: Duke University Press.
Wells, G. L., and Harvey, J. H., 1977, “Do People Use Consensus Information in Making Causal Attributions?”
Journal of Personality and Social Psychology
35: 279–293.
Weron, R., 2001, “Levy-Stable Distributions Revisited: Tail Index > 2 Does Not Exclude the Levy- Stable Regime.”
International Journal of Modern Physics
12(2): 209–223.
Wheatcroft, Andrew, 2003,
Infidels: A History of Conflict Between Christendom and Islam
. New York: Random House.
White, John, 1982,
Rejection
. Reading, Mass.: Addison-Wesley.
Whitehead, Alfred North, 1925,
Science and the Modern World
. New York: The Free Press.
Williams, Mark A., Simon A. Moss, John L. Bradshaw, and Nicole J. Rinehart, 2002, “Brief Report: Random Number Generation in Autism.”
Journal of Autism and Developmental
Disorders
32(1): 43–47.
Williams, Robert J., and Dennis Connolly, 2006, “Does Learning About the Mathematics of Gambling Change Gambling Behavior?”
Psychology of Addictive Behaviors
20(1): 62–68.
Willinger, W., D. Alderson, J. C. Doyle, and L. Li, 2004, “A Pragmatic Approach to Dealing with High Variability Measurements.”
Proceedings of the ACM SIGCOMM Internet Measurement Conference
, Taormina, Sicily, October 25–27, 2004.
Wilson, Edward O., 2000,
Sociobiology: The New Synthesis
. Cambridge, Mass.: Harvard University Press.
———, 2002,
The Future of Life
. New York: Knopf.
Wilson, T. D., J. Meyers, and D. Gilbert, 2001, “Lessons from the Past: Do People Learn from Experience That Emotional Reactions Are Short Lived?”
Personality and Social Psychology Bulletin
29: 1421–1432.
Wilson, T. D., D. T. Gilbert, and D. B. Centerbar, 2003, “Making Sense: The Causes of Emotional Evanescence.” In I. Brocas and J. Carillo, eds., 2003.
Wilson, T. D., D. B. Centerbar, D. A. Kermer, and D. T. Gilbert, 2005, “The Pleasures of Uncertainty: Prolonging Positive Moods in Ways People Do Not Anticipate.”
Journal of Personality and Social Psychology
88(1): 5–21.
Wilson, Timothy D., 2002,
Strangers to Ourselves: Discovering the Adaptive Unconscious
. Cambridge, Mass.: The Belknap Press of Harvard University.
Winston, Robert, 2002,
Human Instinct: How Our Primeval Impulses Shape Our Lives
. London: Bantam Press.
Wolford, George, Michael B. Miller, and Michael Gazzaniga, 2000, “The Left Hemisphere’s Role in Hypothesis Formation.”
Journal of Neuroscience
20: 1–4.
Wood, Michael, 2003,
The Road to Delphi
. New York: Farrar, Straus & Giroux.
Wrangham, R., 1999, “Is Military Incompetence Adaptive?”
Evolution and Human Behavior
20: 3–12.
Yates, J. F., 1990,
Judgment and Decision Making
. Englewood Cliffs, N.J.: Prentice-Hall.
Yates, J. F., J. Lee, and H. Shinotsuka, 1996, “Beliefs About Overconfidence, Including Its Cross- National Variation.”
Organizational Behavior and Human Decision Processes
65: 138–147.
Yates, J. F., J.-W. Lee, H. Shinotsuka, and W. R. Sieck, 1998, “Oppositional Deliberation: Toward Explaining Overconfidence and Its Cross-cultural Variations.” Paper presented at the meeting of the Psychonomics Society, Dallas, Tex.
Yule, G., 1925, “A Mathematical Theory of Evolution, Based on the Conclusions of Dr. J. C. Willis, F. R. S.”
Philosophical Transactions of the Royal Society of London, Series B
213: 21–87.
Yule, G. U., 1944,
Statistical Study of Literary Vocabulary
. Cambridge: Cambridge University Press.
Zacks, R. T., L. Hasher, and H. Sanft, 1982, “Automatic Encoding of Event Frequency: Further Findings.”
Journal of Experimental Psychology: Learning, Memory, and Cognition
8: 106–116.
Zajdenweber, Daniel, 2000,
L’économie des extrèmes
. Paris: Flammarion.
Zajonc, R. B., 1980, “Feeling and Thinking: Preferences Need No Inferences.”
American Psychologist
35: 151–175.
———, 1984, “On the Primacy of Affect.”
American Psychologist
39: 117–123.
Zeki, Semir, 1999,
Inner Vision
. London: Oxford University Press.
Zimmer, A. C., 1983, “Verbal vs. Numerical Processing by Subjective Probabilities.” In R. W. Scholz, ed.,
Decision Making Under Uncertainty
. Amsterdam: North-Holland.
Zipf, George Kingsley, 1932,
Selective Studies and the Principle of Relative Frequency in Language
. Cambridge, Mass.: Harvard University Press.
———, 1949,
Human Behavior and the Principle of Least Effort
. Cambridge, Mass.: Addison- Wesley.
Zitzewitz, Eric, 2001, “Measuring Herding and Exaggeration by Equity Analysts and Other Opinion Sellers.” Working Paper, Stanford University.
Zuckerman, H., 1977,
Scientific Elite
. New York: The Free Press.
———, 1998, “Accumulation of Advantage and Disadvantage: The Theory and Its Intellectual Biography.” In C. Mongardini and S. Tabboni, eds.,
Robert K. Merton and Contemporary Sociology
. New York: Transaction Publishers.
Zweig, Stefan, 1960,
Montaigne
. Paris: Press Universitaires de France.


================================================================================
CHAPTER/SECTION 296 (Item 305)
================================================================================

Fooled by Randomness
is a work of nonfiction, but certain names of nonpublic figures have been changed, and some of the private individuals described are fictionalized or composite portraits.
Copyright © 2004 by Nassim Nicholas Taleb
All rights reserved.
Published in the United States by Random House, an imprint of The Random House Publishing Group, a division of Random House, Inc., New York.
R
ANDOM
H
OUSE
and colophon are registered trademarks of Random House, Inc.
Originally published in the United States in hardcover by TEXERE, part of Thomson Corporation, in 2004,and in trade paperback by Random House Trade Paperbacks, an imprint of The Random House Publishing Group, a division of Random House, Inc., in 2005.
Library of Congress Cataloging-in-Publication Data
Taleb, Nassim.
Fooled by randomness: the hidden role of chance in life and in the markets / Nassim Nicholas Taleb.
p. cm.
Originally published: New York: Thomson/Texere, 2004.
Includes bibliographical references and index.
1. Investments. 2. Chance. 3. Random variables. I. Title.
HG4521.T285 2005
123’.3—dc22                  2005049005
www.atrandom.com
eISBN: 978-1-58836-767-9
v3.0_r4


================================================================================
CHAPTER/SECTION 297 (Item 306)
================================================================================

CONTENTS
Master - Table of Contents
Fooled by Randomness
Title Page
Copyright
Preface
Chapter Summaries
Prologue
PART I: SOLON’S WARNING
Skewness, Asymmetry, Induction
Chapter 1:
IF YOU’RE SO RICH, WHY AREN’T YOU SO SMART?
NERO TULIP
Hit by Lightning
Temporary Sanity
Modus Operandi
No Work Ethics
There Are Always Secrets
JOHN THE HIGH-YIELD TRADER
An Overpaid Hick
THE RED-HOT SUMMER
Serotonin and Randomness
YOUR DENTIST IS RICH, VERY RICH
Chapter 2:
A BIZARRE ACCOUNTING METHOD
ALTERNATIVE HISTORY
Russian Roulette
Possible Worlds
An Even More Vicious Roulette
SMOOTH PEER RELATIONS
Salvation via Aeroflot
Solon Visits Regine’s Nightclub
GEORGE WILL IS NO SOLON: ON COUNTERINTUITIVE TRUTHS
Humiliated in Debates
A Different Kind of Earthquake
Proverbs Galore
Risk Managers
Epiphenomena
Chapter 3:
A MATHEMATICAL MEDITATION ON HISTORY
Europlayboy Mathematics
The Tools
Monte Carlo Mathematics
FUN IN MY ATTIC
Making History
Zorglubs Crowding the Attic
Denigration of History
The Stove Is Hot
Skills in Predicting Past History
My Solon
DISTILLED THINKING ON YOUR PALMPILOT
Breaking News
Shiller Redux
Gerontocracy
PHILOSTRATUS IN MONTE CARLO : ON THE DIFFERENCE BETWEEN NOISE AND INFORMATION
Chapter 4:
RANDOMNESS, NONSENSE, AND THE SCIENTIFIC INTELLECTUAL
RANDOMNESS AND THE VERB
Reverse Turing Test
The Father of All Pseudothinkers
MONTE CARLO POETRY
Chapter 5:
SURVIVAL OF THE LEAST FIT–CAN EVOLUTION BE FOOLED BY RANDOMNESS?
CARLOS THE EMERGING-MARKETS WIZARD
The Good Years
Averaging Down
Lines in the Sand
JOHN THE HIGH-YIELD TRADER
The Quant Who Knew Computers and Equations
The Traits They Shared
A REVIEW OF MARKET FOOLS OF RANDOMNESS CONSTANTS
NAIVE EVOLUTIONARY THEORIES
Can Evolution Be Fooled by Randomness?
Chapter 6:
SKEWNESS AND ASYMMETRY
THE MEDIAN IS NOT THE MESSAGE
BULL AND BEAR ZOOLOGY
An Arrogant Twenty-nine-year-old Son
Rare Events
Symmetry and Science
ALMOST EVERYBODY IS ABOVE AVERAGE
THE RARE-EVENT FALLACY
The Mother of All Deceptions
Why Don’t Statisticians Detect Rare Events?
A Mischievous Child Replaces the Black Balls
Chapter 7:
THE PROBLEM OF INDUCTION
FROM BACON TO HUME
Cygnus Atratus
Niederhoffer
SIR KARL’S PROMOTING AGENT
Location, Location
Popper’s Answer
Open Society
Nobody Is Perfect
Induction and Memory
Pascal’s Wager
THANK YOU, SOLON
PART II: MONKEYS ON TYPEWRITERS
Survivorship and Other Biases
IT DEPENDS ON THE NUMBER OF MONKEYS
VICIOUS REAL LIFE
THIS SECTION
Chapter 8:
TOO MANY MILLIONAIRES NEXT DOOR
HOW TO STOP THE STING OF FAILURE
Somewhat Happy
Too Much Work
You’re a Failure
DOUBLE SURVIVORSHIP BIASES
More Experts
Visibility Winners
It’s a Bull Market
A GURU’S OPINION
Chapter 9:
IT IS EASIER TO BUY AND SELL THAN FRY AN EGG
FOOLED BY NUMBERS
Placebo Investors
Nobody Has to Be Competent
Regression to the Mean
Ergodicity
LIFE IS COINCIDENTAL
The Mysterious Letter
An Interrupted Tennis Game
Reverse Survivors
The Birthday Paradox
It’s a Small World!
Data Mining, Statistics, and Charlatanism
The Best Book I Have Ever Read!
The Backtester
A More Unsettling Extension
The Earnings Season: Fooled by the Results
COMPARATIVE LUCK
Cancer Cures
Professor Pearson Goes to Monte Carlo (Literally): Randomness Does Not Look Random!
The Dog That Did Not Bark: On Biases in Scientific Knowledge
I HAVE NO CONCLUSION
Chapter 10:
LOSER TAKES ALL—ON THE NONLINEARITIES OF LIFE
THE SANDPILE EFFECT
Enter Randomness
Learning to Type
MATHEMATICS INSIDE AND OUTSIDE THE REAL WORLD
The Science of Networks
Our Brain
Buridan’s Donkey or the Good Side of Randomness
WHEN IT RAINS, IT POURS
Chapter 11:
RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND
PARIS OR THE BAHAMAS?
SOME ARCHITECTURAL CONSIDERATIONS
BEWARE THE PHILOSOPHER BUREAUCRAT
Satisficing
FLAWED, NOT JUST IMPERFECT
Kahneman and Tversky
WHERE IS NAPOLEON WHEN WE NEED HIM?
“I’m As Good As My Last Trade” and Other Heuristics
Degree in a Fortune Cookie
Two Systems of Reasoning
WHY WE DON’T MARRY THE FIRST DATE
Our Natural Habitat
Fast and Frugal
Neurobiologists Too
Kafka in a Courtroom
An Absurd World
Examples of Biases in Understanding Probability
We Are Option Blind
PROBABILITIES AND THE MEDIA (MORE JOURNALISTS)
CNBC at Lunchtime
You Should Be Dead by Now
The Bloomberg Explanations
Filtering Methods
We Do Not Understand Confidence Levels
An Admission
PART III: WAX IN MY EARS
Living with Randomitis
I AM NOT SO INTELLIGENT
WITTGENSTEIN’S RULER
THE ODYSSEAN MUTE COMMAND
Chapter 12:
GAMBLERS’ TICKS AND PIGEONS IN A BOX
TAXI-CAB ENGLISH AND CAUSALITY
THE SKINNER PIGEON EXPERIMENT
PHILOSTRATUS REDUX
Chapter 13:
CARNEADES COMES TO ROME: ON PROBABILITY AND SKEPTICISM
CARNEADES COMES TO ROME
Probability, the Child of Skepticism
MONSIEUR DE NORPOIS’ OPINIONS
Path Dependence of Beliefs
COMPUTING INSTEAD OF THINKING
FROM FUNERAL TO FUNERAL
Chapter 14:
BACCHUS ABANDONS ANTONY
NOTES ON JACKIE O.’S FUNERAL
RANDOMNESS AND PERSONAL ELEGANCE
Epilogue:
SOLON TOLD YOU SO
Beware the London Traffic Jams
Postscript:
THREE AFTERTHOUGHTS IN THE SHOWER
FIRST THOUGHT: THE INVERSE SKILLS PROBLEM
SECOND THOUGHT: ON SOME ADDITIONAL BENEFITS OF RANDOMNESS
Uncertainty and Happiness
The Scrambling of Messages
THIRD THOUGHT: STANDING ON ONE LEG
Dedication
Acknowledgments for the First Edition
Acknowledgments for the Updated Second Edition
A Trip to the Library: Notes and Reading Recommendations
Notes
References
Footnotes


================================================================================
CHAPTER/SECTION 298 (Item 307)
================================================================================

PREFACE
TAKING KNOWLEDGE
LESS SERIOUSLY
T
his book is the synthesis of, on one hand, the no-nonsense practitioner of uncertainty who spent his professional life trying to resist being fooled by randomness and trick the emotions associated with probabilistic outcomes and, on the other, the aesthetically obsessed, literature-loving human being willing to be fooled by any form of nonsense that is polished, refined, original, and tasteful. I am not capable of avoiding being the fool of randomness; what I can do is confine it to where it brings some aesthetic gratification.
This comes straight from the gut; it is a personal essay primarily discussing its author’s thoughts, struggles, and observations connected to the practice of risk taking, not exactly a treatise, and certainly, god forbid, not a piece of scientific reporting. It was written for fun and it aims to be read (principally) for, and with, pleasure. Much has been written about our biases (acquired or genetic) in dealing with randomness over the past decade. The rules while writing the first edition of this book had been to avoid discussing (a) anything that I did not either personally witness on the topic or develop independently, and (b) anything that I have not distilled well enough to be able to write on the subject with only the slightest effort. Everything that remotely felt like work was out. I had to purge from the text passages that seemed to come from a visit to the library, including the scientific name dropping. I tried to use no quote that did not naturally spring from my memory and did not come from a writer whom I had intimately frequented over the years (I detest the practice of random use of borrowed wisdom—much on that later).
Aut tace aut loquere meliora silencio
(only when the words outperform silence).
These rules remain intact. But sometimes life requires compromises: Under pressure from friends and readers I have added to the present edition a series of nonintrusive endnotes referring to the related literature. I have also added new material to most chapters, most notably in
Chapter 11
, which altogether has resulted in an expansion of the book by more than a third.
Adding to the Winner
I hope to make this book organic—by, to use traders’ lingo, “adding to the winner”—and let it reflect my personal evolution instead of holding on to these new ideas and putting them into a new book altogether. Strangely, I gave considerably more thought to some sections of this book
after
the publication than I had before, particularly in two separate areas: (a) the mechanisms by which our brain sees the world as less, far less, random that it actually is, and (b) the “fat tails,” that wild brand of uncertainty that causes large deviations (rare events explain more and more of the world we live in, but at the same time remain as counterintuitive to us as they were to our ancestors). The second version of this book reflects this author’s drift into becoming a little less of a student of uncertainty (we can learn so little about randomness) and more of a researcher into how people are fooled by it.
Another phenomenon: the transformation of the author by his own book. As I increasingly started living this book
after
the initial composition, I found luck in the most unexpected of places. It is as if there were two planets: the one in which we actually live and the one, considerably more deterministic, on which people are convinced we live. It is as simple as that: Past events will
always
look less random than they were (it is called the
hindsight bias
). I would listen to someone’s discussion of his own past realizing that much of what he was saying was just backfit explanations concocted ex post by his deluded mind. This became at times unbearable: I could feel myself looking at people in the social sciences (particularly conventional economics) and the investment world as if they were deranged subjects. Living in the real world may be painful particularly if one finds statements more informative about the people making them than the intended message: I picked up
Newsweek
this morning at the dentist’s office and read a journalist’s discussion of a prominent business figure, particularly his ability in “timing moves” and realized how I was making a list of the biases in the journalist’s mind rather than getting the intended information in the article itself, which I could not possibly take seriously. (Why don’t most journalists end up figuring out that they know much less than they think they know? Scientists investigated half a century ago the phenomena of “experts” not learning about their past failings. You can mispredict everything for all your life yet think that you will get it right next time.)
Insecurity and Probability
I believe that the principal asset I need to protect and cultivate is my deep-seated intellectual insecurity. My motto is “
my principal activity is to tease those who take themselves and the quality of their knowledge too seriously.
” Cultivating such insecurity in place of intellectual confidence may be a strange aim—and one that is not easy to implement. To do so we need to purge our minds of the recent tradition of intellectual certainties. A reader turned pen pal made me rediscover the sixteenth-century French essayist and professional introspector Montaigne. I got sucked into the implications of the difference between Montaigne and Descartes—and how we strayed by following the latter’s quest for certitudes. We surely closed our minds by following Descartes’ model of formal thinking rather than Montaigne’s brand of vague and informal (but critical) judgment. Half a millennium later the severely introspecting and insecure Montaigne stands tall as a role model for the modern thinker. In addition, the man had exceptional courage: It certainly takes bravery to remain skeptical; it takes inordinate courage to introspect, to confront oneself, to accept one’s limitations—scientists are seeing more and more evidence that we are specifically designed by mother nature to fool ourselves.
There are many intellectual approaches to probability and risk—“probability” means slightly different things to people in different disciplines. In this book it is tenaciously qualitative and literary as opposed to quantitative and “scientific” (which explains the warnings against economists and finance professors as they tend to firmly believe that they know something, and something useful at that). It is presented as flowing from Hume’s Problem of Induction (or Aristotle’s inference to the general) as opposed to the paradigm of the gambling literature. In this book probability is principally a branch of applied skepticism, not an engineering discipline (in spite of all the self-important mathematical treatment of the subject matter, problems related to the calculus of probability rarely merit to transcend the footnote).
How? Probability is not a mere computation of odds on the dice or more complicated variants; it is the acceptance of the lack of certainty in our knowledge and
the development of methods for dealing with our ignorance.
Outside of textbooks and casinos, probability almost
never
presents itself as a mathematical problem or a brain teaser. Mother nature does not tell you how many holes there are on the roulette table, nor does she deliver problems in a textbook way (in the real world one has to guess the problem more than the solution). In this book, considering that alternative outcomes could have taken place, that the world could have been different, is the core of probabilistic thinking. As a matter of fact, I spent all my career attacking the
quantitative
use of probability. While Chapters
13
and
14
(dealing with skepticism and stoicism) are to me the central ideas of the book, most people focused on the examples of miscomputation of probability in
Chapter 11
(clearly and by far the least original chapter of the book, one in which I compressed all the literature on probability biases). In addition, while we may have some understanding of the probabilities in the hard sciences, particularly in physics, we don’t have much of a clue in the social “sciences” like economics, in spite of the fanfares of experts.
Vindicating (Some) Readers
I have tried to make the minimum out of my occupation of mathematical trader. The fact that I operate in the markets serves only as an inspiration—it does not make this book (as many thought it was) a guide to market randomness any more than the
Iliad
should be interpreted as a military instruction manual. Only three out of fourteen chapters have a financial setting. Markets are a mere special case of randomness traps—but they are by far the most interesting as luck plays a very large role in them (this book would have been considerably shorter if I were a taxidermist or a translator of chocolate labels). Furthermore, the kind of luck in finance is of the kind that nobody understands but most operators
think
they understand, which provides us a magnification of the biases. I have tried to use my market analogies in an illustrative way as I would in a dinner conversation with, say, a cardiologist with intellectual curiosity (I used as a model my second-generation friend Jacques Merab).
I received large quantities of electronic mail on the first version of the book, which can be an essayist’s dream as such dialectic provides ideal conditions for the rewriting of the second version. I expressed my gratitude by answering (once) each one of them. Some of the answers have been inserted back into the text in the different chapters. Being often seen as an iconoclast I was looking forward to getting the angry letters of the type “who are you to judge Warren Buffett” or “you are envious of his success”; instead it was disappointing to see most of the trashing going anonymously to
amazon.com
(there is no such thing as bad publicity: Some people manage to promote your work by insulting it).
The consolation for the lack of attacks was in the form of letters from people who felt vindicated by the book. The most rewarding letters were the ones from people who did not fare well in life, through no fault of their own, who used the book as an argument with their spouse to explain that they were less lucky (not less skilled) than their brother-in-law. The most touching letter came from a man in Virginia who within a period of a few months lost his job, his wife, his fortune, was put under investigation by the redoubtable Securities and Exchange Commission, and progressively felt good for acting stoically. A correspondence with a reader who was hit with a black swan, the unexpected large-impact random event (the loss of a baby) caused me to spend some time dipping into the literature on adaptation after a severe random event (not coincidentally also dominated by Daniel Kahneman, the pioneer of the ideas on irrational behavior under uncertainty). I have to confess that I never felt really particularly directly of service to anyone being a trader (except myself); it felt elevating and
useful
being an essayist.
All or None
A few confusions with the message in this book. Just as our brain does not easily make out probabilistic shades (it goes for the oversimplifying “all-or-none”), it was hard to explain that the idea here was that “it is more random than we think” rather than “it is all random.” I had to face the “Taleb, as a skeptic, thinks everything is random and successful people are just lucky.” The Fooled by Randomness symptom even affected a well-publicized Cambridge Union Debate as my argument “
Most
City Hotshots are Lucky Fools” became “
All
City Hotshots are Lucky Fools” (clearly I lost the debate to the formidable Desmond Fitzgerald in one of the most entertaining discussions in my life—I was even tempted to switch sides!). The same delusion of mistaking irreverence for arrogance (as I noticed with my message) makes people confuse skepticism for nihilism.
Let me make it clear here: Of course chance favors the prepared! Hard work, showing up on time, wearing a clean (preferably white) shirt, using deodorant, and some such conventional things contribute to success—they are certainly necessary but may be insufficient as they do not
cause
success. The same applies to the conventional values of persistence, doggedness and perseverance:
necessary, very necessary.
One needs to go out and buy a lottery ticket in order to win. Does it mean that the work involved in the trip to the store
caused
the winning? Of course skills count, but they do count less in highly random environments than they do in dentistry.
No, I am not saying that what your grandmother told you about the value of work ethics is wrong! Furthermore, as most successes are caused by very few “windows of opportunity,” failing to grab one can be deadly for one’s career. Take your luck!
Notice how our brain sometimes gets the arrow of causality backward. Assume that good qualities
cause
success; based on that assumption, even though it seems intuitively correct to think so, the fact that every intelligent, hardworking, persevering person becomes successful does not imply that every successful person is necessarily an intelligent, hardworking, persevering person (it is remarkable how such a primitive logical fallacy
—affirming the consequent—
can be made by otherwise very intelligent people, a point I discuss in this edition as the “two systems of reasoning” problem).
There is a twist in research on success that has found its way into the bookstores under the banner of advice on: “these are the millionaires’ traits that you need to have if you want to be just like those successful people.” One of the authors of the misguided
The Millionaire Next Door
(that I discuss in
Chapter 8
) wrote another even more foolish book called
The Millionaire Mind.
He observes that in the representative cohort of more than a thousand millionaires whom he studied most did not exhibit high intelligence in their childhood and infers that it is not your endowment that makes you rich—but rather hard work. From this, one can naively infer that chance plays no part in success. My intuition is that if millionaires are close in attributes to the average population, then I would make the more disturbing interpretation that it is because luck played a part. Luck is democratic and hits everyone regardless of original skills. The author notices variations from the general population in a few traits like tenacity and hard work: another confusion of the
necessary
and the causal. That all millionaires were persistent, hardworking people does not make persistent hard workers become millionaires: Plenty of unsuccessful entrepreneurs were persistent, hardworking people. In a textbook case of naive empiricism, the author also looked for traits these millionaires had in common and figured out that they shared a taste for risk taking. Clearly risk taking is necessary for large success—but it is also necessary for failure. Had the author done the same study on bankrupt citizens he would certainly have found a predilection for risk taking.
I was asked to “back up the claims” in the book with the “supply of data,” graphs, charts, diagrams, plots, tables, numbers, recommendations, time series, etc., by some readers (and by
me-too
publishers before I was lucky to find Texere). This text is a series of logical thought experiments, not an economics term paper; logic does not require empirical verification (again there is what I call a “round-trip fallacy”: It is a mistake to use, as journalists and some economists do, statistics without logic, but the reverse does not hold: It is not a mistake to use logic without statistics). If I write that I doubt that my neighbor’s success is devoid of some measure, small or large, of luck, owing to the randomness in his profession, I do not need to “test” it—the Russian roulette thought experiment suffices. All I need is to show that there exists an alternative explanation to the theory that he is a genius. My approach is to manufacture a cohort of intellectually challenged persons and show how a small minority can evolve into successful businessmen—but these are the ones who will be visible. I am not saying that Warren Buffett is not skilled; only that a large population of random investors will
almost necessarily
produce someone with his track records
just by luck.
Missing a Hoax
I was also surprised at the fact that in spite of the book’s aggressive warning against media journalism I was invited to television and radio shows in both North America and Europe (including a hilarious
dialogue de sourds
on a Las Vegas radio station where the interviewer and I were running two parallel conversations). Nobody protected me from myself and I accepted the interviews. Strangely, one needs to use the press to communicate the message that the press is toxic. I felt like a fraud coming up with vapid sound bites, but had fun at it.
It may be that I was invited because the mainstream media interviewers did not read my book or understand the insults (they don’t “have the time” to read books) and the nonprofit ones read it too well and felt vindicated by it. I have a few anecdotes: A famous television show was told that “this guy Taleb believes that stock analysts are just random forecasters” so they seemed eager to have me present my ideas on the program. However, their condition was that I make three stock recommendations to prove my “expertise.” I didn’t attend and missed the opportunity for a great hoax by discussing three stocks selected randomly and fitting a well-sounding explanation to my selection.
On another television show I mentioned that “people think that there is a story when there is none” as I was discussing the random character of the stock market and the backfit logic one always sees in events after the fact. The anchor immediately interjected: “There was a story about Cisco this morning. Can you comment on that?” The best: When invited to an hour-long discussion on a financial radio show (they had not read
Chapter 11
), I was told a few minutes before to refrain from discussing the ideas in this book because I was invited to talk about trading and not about randomness (another hoax opportunity certainly, but I was too unprepared for it and walked out before the show started).
Most journalists do not take things too seriously: After all, this business of journalism is about pure entertainment, not a search for truth, particularly when it comes to radio and television. The trick is to stay away from those who do not seem to know that they are just entertainers (like George Will, who will appear in
Chapter 2
) and actually believe that they are
thinkers.
Another problem was in the interpretation of the message in the media: This guy Nassim thinks that markets are random,
hence they are going lower,
which made me the unwilling bearer of catastrophic messages. Black swans, those rare and unexpected deviations, can be both good and bad events.
However, media journalism is less standardized than it appears; it attracts a significant segment of thoughtful people who manage to extricate themselves from the commercial sound bite–driven system and truly care about the message rather than just catching the public’s attention. One naive observation from my conversations with Kojo Anandi (NPR), Robin Lustig (BBC), Robert Scully (PBS), and Brian Lehrer (WNYC) is that the nonprofit journalist is altogether another intellectual breed. Casually, the quality of the discussion correlates inversely with the luxury of the studios: WNYC, where I felt that Brian Lehrer was making the greatest effort at getting into the arguments, operates out of the shabbiest offices I have seen this side of Kazakhstan.
One final comment on the style. I elected to keep the style of this book as idiosyncratic as it was in the first edition.
Homo sum,
good and bad. I am fallible and see no reason to hide my minor flaws if they are part of my personality no more than I feel the need to wear a wig when I have my picture taken or borrow someone else’s nose when I show my face. Almost all the book editors who read the draft recommended changes at the sentence level (to make my style “better”) and in the structure of the text (in the organization of chapters); I ignored almost all of them and found out that none of the readers thought them necessary—as a matter of fact, I find that injecting the personality of the author (imperfections included) enlivens the text. Does the book industry suffer from the classical “expert problem” with the buildup of rules of thumb that do not have empirical validity? More than half a million readers later I am discovering that books are not written for book editors.


================================================================================
CHAPTER/SECTION 299 (Item 308)
================================================================================

CHAPTER SUMMARIES
ONE: IF YOU’RE SO RICH, WHY AREN’T YOU SO SMART?
An illustration of the effect of randomness on social pecking order and jealousy, through two characters of opposite attitudes. On the concealed rare event. How things in modern life may change rather rapidly, except, perhaps, in dentistry.
TWO: A BIZARRE ACCOUNTING METHOD
On alternative histories, a probabilistic view of the world, intellectual fraud, and the randomness wisdom of a Frenchman with steady bathing habits. How journalists are bred to not understand random series of events. Beware borrowed wisdom: How almost all great ideas concerning random outcomes are against conventional sapience. On the difference between correctness and intelligibility.
THREE: A MATHEMATICAL MEDITATION ON HISTORY
On Monte Carlo simulation as a metaphor for understanding a sequence of random historical events. On randomness and artificial history. Age is beauty, almost always, and the new and the young are generally toxic. Send your history professor to an introductory class on sampling theory.
FOUR: RANDOMNESS, NONSENSE, AND THE SCIENTIFIC INTELLECTUAL
On extending the Monte Carlo generator to produce artificial thinking and compare it with rigorous nonrandom constructs. The science wars enter the business world. Why the aesthete in me loves to be fooled by randomness.
FIVE: SURVIVAL OF THE LEAST FIT—CAN EVOLUTION BE FOOLED BY RANDOMNESS?
A case study on two rare events. On rare events and evolution. How “Darwinism” and evolution are concepts that are misunderstood in the nonbiological world. Life is not continuous. How evolution will be fooled by randomness. A prolegomenon for the problem of induction.
SIX: SKEWNESS AND ASYMMETRY
We introduce the concept of skewness: Why the terms “bull” and “bear” have limited meaning outside of zoology. A vicious child wrecks the structure of randomness. An introduction to the problem of epistemic opacity. The penultimate step before the problem of induction.
SEVEN: THE PROBLEM OF INDUCTION
On the chromodynamics of swans. Taking Solon’s warning into some philosophical territory. How Victor Niederhoffer taught me empiricism; I added deduction. Why it is not scientific to take science seriously. Soros promotes Popper. That bookstore on Eighteenth Street and Fifth Avenue. Pascal’s wager.
EIGHT: TOO MANY MILLIONAIRES NEXT DOOR
Three illustrations of the survivorship bias. Why very few people should live on Park Avenue. The millionaire next door has very flimsy clothes. An overcrowding of experts.
NINE: IT IS EASIER TO BUY AND SELL THAN FRY AN EGG
Some technical extensions of the survivorship bias. On the distribution of “coincidences” in life. It is preferable to be lucky than competent (but you can be caught). The birthday paradox. More charlatans (and more journalists). How the researcher with work ethics can find just about anything in data. On dogs not barking.
TEN: LOSER TAKES ALL—ON THE NONLINEARITIES OF LIFE
The nonlinear viciousness of life. Moving to Bel Air and acquiring the vices of the rich and famous. Why Microsoft’s Bill Gates may not be the best in his business (but please do not inform him of such a fact). Depriving donkeys of food.
ELEVEN: RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND
On the difficulty of thinking of your vacation as a linear combination of Paris and the Bahamas. Nero Tulip may never ski in the Alps again. Do not ask bureaucrats too many questions. A Brain Made in Brooklyn. We need Napoleon. Scientists bowing to the King of Sweden. A little more on journalistic pollution. Why you may be dead by now.
TWELVE: GAMBLERS’ TICKS AND PIGEONS IN A BOX
On gamblers’ ticks crowding up my life. Why bad taxi-cab English can help you make money. How I am the fool of all fools, except that I am aware of it. Dealing with my genetic unfitness. No boxes of chocolate under my trading desk.
THIRTEEN: CARNEADES COMES TO ROME: ON PROBABILITY AND SKEPTICISM
Cato the censor sends Carneades packing. Monsieur de Norpois does not remember his old opinions. Beware the scientist. Marrying ideas. The same Robert Merton putting the author on the map. Science evolves from funeral to funeral.
FOURTEEN: BACCHUS ABANDONS ANTONY
Montherlant’s death. Stoicism is not the stiff upper lip, but the illusion of victory of man against randomness. It is so easy to be heroic. Randomness and personal elegance.


================================================================================
CHAPTER/SECTION 300 (Item 309)
================================================================================

PROLOGUE
MOSQUES IN THE CLOUDS
T
his book is about luck disguised and perceived as nonluck (that is, skills) and, more generally, randomness disguised and perceived as non-randomness (that is, determinism). It manifests itself in the shape of the
lucky fool,
defined as a person who benefited from a disproportionate share of luck but attributes his success to some other, generally very precise, reason. Such confusion crops up in the most unexpected areas, even science, though not in such an accentuated and obvious manner as it does in the world of business. It is endemic in politics, as it can be encountered in the shape of a country’s president discoursing on the jobs that “he” created, “his” recovery, and “his predecessor’s” inflation.
We are still very close to our ancestors who roamed the savannah. The formation of our beliefs is fraught with superstitions—even today (I might say, especially today). Just as one day some primitive tribesman scratched his nose, saw rain falling, and developed an elaborate method of scratching his nose to bring on the much-needed rain, we link economic prosperity to some rate cut by the Federal Reserve Board, or the success of a company with the appointment of the new president “at the helm.” Bookstores are full of biographies of successful men and women presenting their specific explanation on how they made it big in life (we have an expression, “the right time and the right place,” to weaken whatever conclusion can be inferred from them). This confusion strikes people of different persuasions; the literature professor invests a deep meaning into a mere coincidental occurrence of word patterns, while the economist proudly detects “regularities” and “anomalies” in data that are plain random.
At the cost of appearing biased, I have to say that the literary mind can be intentionally prone to the confusion between
noise
and
meaning,
that is, between a randomly constructed arrangement and a precisely intended message. However, this causes little harm; few claim that art is a tool of investigation of the Truth—rather than an attempt to escape it or make it more palatable. Symbolism is the child of our inability and unwillingness to accept randomness; we give meaning to all manner of shapes; we detect human figures in inkblots.
I saw mosques in the clouds
announced Arthur Rimbaud, the nineteenth-century French symbolic poet. This interpretation took him to “poetic”Abyssinia (in East Africa), where he was brutalized by a Christian Lebanese slave dealer, contracted syphilis, and lost a leg to gangrene. He gave up poetry in disgust at the age of nineteen, and died anonymously in a Marseilles hospital ward while still in his thirties. But it was too late. European intellectual life developed what seems to be an irreversible taste for symbolism—we are still paying its price, with psychoanalysis and other fads.
Regrettably, some people play the game too seriously; they are paid to read too much into things. All my life I have suffered the conflict between my love of literature and poetry and my profound allergy to most teachers of literature and “critics.” The French thinker and poet Paul Valery was surprised to listen to a commentary of his poems that found meanings that had until then escaped him (of course, it was pointed out to him that these were intended by his subconscious).
More generally, we underestimate the share of randomness in about everything, a point that may not merit a book—except when it is the specialist who is the fool of all fools. Disturbingly, science has only recently been able to handle randomness (the growth in available information has been exceeded only by the expansion of noise). Probability theory is a young arrival in mathematics; probability applied to practice is almost nonexistent as a discipline. In addition we seem to have evidence that what is called “courage” comes from an underestimation of the share of randomness in things rather than the more noble ability to stick one’s neck out for a given belief. In my experience (and in the scientific literature), economic “risk takers” are rather the victims of delusions (leading to overoptimism and overconfidence with their underestimation of possible adverse outcomes) than the opposite. Their “risk taking” is frequently randomness foolishness.
Consider the left and the right columns of
Table P.1
. The best way to summarize the major thesis of this book is that it addresses situations (many of them tragicomical) where the left column is mistaken for the right one. The subsections also illustrate the key areas of discussion on which this book will be based.
The reader may wonder whether the opposite case might not deserve some attention, that is, the situations where nonrandomness is mistaken for randomness. Shouldn’t we be concerned with situations where patterns and messages may have been ignored? I have two answers. First, I am not overly worried about the existence of undetected patterns. We have been reading lengthy and complex messages in just about any manifestation of nature that presents jaggedness (such as the palm of a hand, the residues at the bottom of Turkish coffee cups, etc.). Armed with home supercomputers and chained processors, and helped by complexity and “chaos” theories, the scientists, semiscientists, and pseudoscientists will be able to find portents. Second, we need to take into account the costs of mistakes; in my opinion, mistaking the right column for the left one is not as costly as an error in the opposite direction. Even popular opinion warns that bad information is worse than no information at all.
However interesting these areas could be, their discussion would be a tall order. There is one world in which I believe the habit of mistaking luck for skill is most prevalent—and most conspicuous—and that is the world of markets. By luck or misfortune, that is the world in which I have operated most of my adult life. It is what I know best. In addition, economic life presents the best (and most entertaining) laboratory for the understanding of these differences. For it is the area of human undertaking where the confusion is greatest and its effects the most pernicious. For instance, we often have the mistaken impression that a strategy is an excellent strategy, or an entrepreneur a person endowed with “vision,” or a trader a talented trader, only to realize that 99.9% of their past performance is attributable to chance, and chance alone. Ask a profitable investor to explain the reasons for his success; he will offer some deep and convincing interpretation of the results. Frequently, these delusions are intentional and deserve to bear the name “charlatanism.”
If there is one cause for this confusion between the left and the right sides of our table, it is our inability to think critically—we may enjoy presenting conjectures as truth. It is our nature. Our mind is not equipped with the adequate machinery to handle probabilities; such infirmity even strikes the expert, sometimes just the expert.
Table P.1 Table of Confusion
Presenting the central distinctions used in the book
The nineteenth-century cartoon character, pot-bellied bourgeois Monsieur Prudhomme, carried around a large sword with a double intent: primarily to defend the Republic against its enemies, and secondarily to attack it should it stray from its course. In the same manner, this book has two purposes: to defend science (as a light beam across the noise of randomness), and to attack the scientist when he strays from his course (most disasters come from the fact that individual scientists do not have an innate understanding of standard error or a clue about critical thinking, and likewise have proved both incapable of dealing with probabilities in the social sciences and incapable of accepting such fact). As a practitioner of uncertainty I have seen more than my share of snake-oil salesmen dressed in the garb of scientists, particularly those operating in economics. The greatest fools of randomness will be found among these.
We are flawed beyond repair, at least for this environment—but it is only bad news for those utopians who believe in an idealized humankind. Current thinking presents the two following polarized visions of man, with little shades in between. On the one hand there is your local college English professor; your great-aunt Irma, who never married and liberally delivers sermons; your how-to-reach-happiness-in-twenty-steps and how-to-become-a-better-person-in-a-week book writer. It is called the Utopian Vision, associated with Rousseau, Godwin, Condorcet, Thomas Paine, and conventional normative economists (of the kind to ask you to make rational choices because that is what is deemed good for you), etc. They believe in reason and rationality—that we should overcome cultural impediments on our way to becoming a better human race—thinking we can control our nature at will and transform it by mere edict in order to attain, among other things, happiness and rationality. Basically this category would include those who think that the cure for obesity is to inform people that they should be healthy.
On the other hand there is the Tragic Vision of humankind that believes in the existence of inherent limitations and flaws in the way we think and act and requires an acknowledgment of this fact as a basis for any individual and collective action. This category of people includes Karl Popper (falsificationism and distrust of intellectual “answers,” actually of anyone who is confident that he knows anything with certainty), Friedrich Hayek and Milton Friedman (suspicion of governments), Adam Smith (intention of man), Herbert Simon (bounded rationality), Amos Tversky and Daniel Kahneman (heuristics and biases), the speculator George Soros, etc. The most neglected one is the misunderstood philosopher Charles Sanders Peirce, who was born a hundred years too early (he coined the term scientific “fallibilism” in opposition to Papal infallibility). Needless to say that the ideas of this book fall squarely into the Tragic category: We are faulty and there is no need to bother trying to correct our flaws. We are so defective and so mismatched to our environment that we can just work around these flaws. I am convinced of that after spending almost all my adult and professional years in a fierce fight between my brain (not
Fooled by Randomness
) and my emotions (completely
Fooled by Randomness
) in which the only success I’ve had is in going around my emotions rather than rationalizing them. Perhaps ridding ourselves of our humanity is not in the works; we need wily tricks, not some grandiose moralizing help. As an empiricist (actually a skeptical empiricist) I despise the moralizers beyond anything on this planet: I still wonder why they blindly believe in ineffectual methods. Delivering advice assumes that our cognitive apparatus rather than our emotional machinery exerts some meaningful control over our actions. We will see how modern behavioral science shows this to be completely untrue.
My colleague Bob Jaeger (he followed the opposite course of mine of moving from philosophy professor to trader) presents a more potent view of the dichotomy: There are those who think that there are easy clear-cut answers and those who don’t think that simplification is possible without severe distortion (his hero: Wittgenstein; his villain: Descartes). I am enamored of the difference as I think that the generator of the
Fooled by Randomness
problem, the false belief in determinism, is also associated with such reduction of the dimensionality of things. As much as you believe in the “keep-it-simple-stupid” it is the
simplification
that is dangerous.
This author hates books that can be easily guessed from the table of contents (not many people read textbooks for pleasure)—but a hint of what comes next seems in order. The book is composed of three parts. The first is an introspection into Solon’s warning, as his outburst on rare events became my lifelong motto. In it we meditate on visible and invisible histories and the elusive property of rare events (black swans). The second presents a collection of probability biases I encountered (and suffered from) in my career in randomness—ones that continue to fool me. The third illustrates my personal jousting with my biology and concludes the book with a presentation of a few practical (wax in my ears) and philosophical (stoicism) aids. Before the “enlightenment” and the age of rationality, there was in the culture a collection of tricks to deal with our fallibility and reversals of fortunes. The elders can still help us with some of their ruses.


================================================================================
CHAPTER/SECTION 301 (Item 310)
================================================================================

Part I
•
SOLON’S
WARNING
Skewness, Asymmetry, Induction
C
roesus, King of Lydia, was considered the richest man of his time. To this day Romance languages use the expression “rich as Croesus” to describe a person of excessive wealth. He was said to be visited by Solon, the Greek legislator known for his dignity, reserve, upright morals, humility, frugality, wisdom, intelligence, and courage. Solon did not display the smallest surprise at the wealth and splendor surrounding his host, nor the tiniest admiration for their owner. Croesus was so irked by the manifest lack of impression on the part of this illustrious visitor that he attempted to extract from him some acknowledgment. He asked him if he had known a happier man than him. Solon cited the life of a man who led a noble existence and died while in battle. Prodded for more, he gave similar examples of heroic but terminated lives, until Croesus, irate, asked him point-blank if he was not to be considered the happiest man of all. Solon answered: “The observation of the numerous misfortunes that attend all conditions forbids us to grow insolent upon our present enjoyments, or to admire a man’s happiness that may yet, in course of time, suffer change. For the uncertain future has yet to come, with all variety of future; and him only to whom the divinity has [guaranteed] continued happiness until the end we may call happy.”
The modern equivalent has been no less eloquently voiced by the baseball coach Yogi Berra, who seems to have translated Solon’s outburst from the pure Attic Greek into no less pure Brooklyn English with “it ain’t over until it’s over,” or, in a less dignified manner, with “it ain’t over until the fat lady sings.” In addition, aside from his use of the vernacular, the Yogi Berra quote presents an advantage of being true, while the meeting between Croesus and Solon was one of those historical facts that benefited from the imagination of the chroniclers, as it was chronologically impossible for the two men to have been in the same location.
Part I is concerned with the degree to which a situation may yet, in the course of time, suffer change. For we can be tricked by situations involving mostly the activities of the goddess Fortuna—Jupiter’s firstborn daughter. Solon was wise enough to get the following point; that which came with the help of luck could be taken away by luck (and often rapidly and unexpectedly at that). The flipside, which deserves to be considered as well (in fact it is even more of our concern), is that things that come with little help from luck are more resistant to randomness. Solon also had the intuition of a problem that has obsessed science for the past three centuries. It is called the problem of induction. I call it in this book the
black swan
or the
rare event.
Solon even understood another linked problem, which I call the
skewness
issue; it does not matter how frequently something succeeds if failure is too costly to bear.
Yet the story of Croesus has another twist. Having lost a battle to the redoubtable Persian king Cyrus, he was about to be burned alive when he called Solon’s name and shouted (something like) “Solon, you were right” (again this is legend). Cyrus asked about the nature of such unusual invocations, and he told him about Solon’s warning. This impressed Cyrus so much that he decided to spare Croesus’ life, as he reflected on the possibilities as far as his own fate was concerned. People were thoughtful at that time.


================================================================================
CHAPTER/SECTION 302 (Item 311)
================================================================================

One
•
IF YOU’RE SO RICH,
WHY AREN’T YOU SO SMART?
An illustration of the effect of randomness on social pecking order and jealousy, through two characters of opposite attitudes. On the concealed rare event. How things in modern life may change rather rapidly, except, perhaps, in dentistry.
NERO TULIP
Hit by Lightning
N
ero Tulip became obsessed with trading after witnessing a strange scene one spring day as he was visiting the Chicago Mercantile Exchange. A red convertible Porsche, driven at several times the city speed limit, abruptly stopped in front of the entrance, its tires emitting the sound of pigs being slaughtered. A visibly demented athletic man in his thirties, his face flushed red, emerged and ran up the steps as if he were chased by a tiger. He left the car double-parked, its engine running, provoking an angry fanfare of horns. After a long minute, a bored young man clad in a yellow jacket (yellow was the color reserved for clerks) came down the steps, visibly untroubled by the traffic commotion. He drove the car into the underground parking garage—perfunctorily, as if it were his daily chore.
That day Nero Tulip was hit with what the French call a
coup de foudre,
a sudden intense (and obsessive) infatuation that strikes like lightning. “This is for me!” he screamed enthusiastically—he could not help comparing the life of a trader to the alternative lives that could present themselves to him. Academia conjured up the image of a silent university office with rude secretaries; business, the image of a quiet office staffed with slow thinkers and semislow thinkers who express themselves in full sentences.
Temporary Sanity
Unlike a
coup de foudre,
the infatuation triggered by the Chicago scene has not left him more than a decade and a half after the incident. For Nero swears that no other lawful profession in our times could be as devoid of boredom as that of the trader. Furthermore, although he has not yet practiced the profession of high-sea piracy, he is now convinced that even that occupation would present more dull moments than that of the trader.
Nero could best be described as someone who randomly (and abruptly) swings between the deportment and speech manners of a church historian and the verbally abusive intensity of a Chicago pit trader. He can commit hundreds of millions of dollars in a transaction without a blink or a shadow of a second thought, yet agonize between two appetizers on the menu, changing his mind back and forth and wearing out the most patient of waiters.
Nero holds an undergraduate degree in ancient literature and mathematics from Cambridge University. He enrolled in a Ph.D. program in statistics at the University of Chicago but, after completing the prerequisite coursework, as well as the bulk of his doctoral research, he switched to the philosophy department. He called the switch “a moment of temporary sanity,” adding to the consternation of his thesis director, who warned him against philosophers and predicted his return back to the fold. He finished writing his thesis in philosophy. But not the Derrida continental style of incomprehensible philosophy (that is,
incomprehensible
to anyone outside of their ranks, like myself). It was quite the opposite; his thesis was on the methodology of statistical inference in its application to the social sciences. In fact, his thesis was indistinguishable from a thesis in mathematical statistics—it was just a bit more thoughtful (and twice as long).
It is often said that philosophy cannot feed its man—but that was not the reason Nero left. He left because philosophy cannot entertain its man. At first, it started looking futile; he recalled his statistics thesis director’s warnings. Then, suddenly, it started to look like work. As he became tired of writing papers on some arcane details of his earlier papers, he gave up the academy. The academic debates bored him to tears, particularly when minute points (invisible to the noninitiated) were at stake. Action was what Nero required. The problem, however, was that he selected the academy in the first place in order to kill what he detected was the flatness and tempered submission of employment life.
After witnessing the scene of the trader chased by a tiger, Nero found a trainee spot on the Chicago Mercantile Exchange, the large exchange where traders transact by shouting and gesticulating frenetically. There he worked for a prestigious (but eccentric)
local,
who trained him in the Chicago style, in return for Nero solving his mathematical equations. The energy in the air proved motivating to Nero. He rapidly graduated to the rank of self-employed trader. Then, when he got tired of standing on his feet in the crowd, and straining his vocal cords, he decided to seek employment “upstairs,” that is, trading from a desk. He moved to the New York area and took a position with an investment house.
Nero specialized in quantitative financial products, in which he had an early moment of glory, became famous and in demand. Many investment houses in New York and London flashed huge guaranteed bonuses at him. Nero spent a couple of years shuttling between the two cities, attending important “meetings” and wearing expensive suits. But soon Nero went into hiding; he rapidly pulled back to anonymity—the Wall Street stardom track did not quite fit his temperament. To stay a “hot trader” requires some organizational ambitions and a power hunger that he feels lucky not to possess. He was only in it for the fun—and his idea of fun does not include administrative and managerial work. He is susceptible to conference room boredom and is incapable of talking to businessmen, particularly the run-of-the-mill variety. Nero is allergic to the vocabulary of business talk, not just on plain aesthetic grounds. Phrases like “game plan,” “bottom line,” “how to get there from here,” “we provide our clients with solutions,” “our mission,” and other hackneyed expressions that dominate meetings lack both the precision and the coloration that he prefers to hear. Whether people populate silence with hollow sentences, or if such meetings present any true merit, he does not know; at any rate he did not want to be part of it. Indeed Nero’s extensive social life includes almost no businesspeople. But unlike me (I can be extremely humiliating when someone rubs me the wrong way with inelegant pompousness), Nero handles himself with gentle aloof-ness in these circumstances.
So, Nero switched careers to what is called proprietary trading. Traders are set up as independent entities, internal funds with their own allocation of capital. They are left alone to do as they please, provided of course that their results satisfy the executives. The name proprietary comes from the fact that they trade the company’s own capital. At the end of the year they receive between 7% and 12% of the profits generated. The proprietary trader has all the benefits of self-employment, and none of the burdens of running the mundane details of his own business. He can work any hours he likes, travel at a whim, and engage in all manner of personal pursuits. It is paradise for an intellectual like Nero who dislikes manual work and values unscheduled meditation. He has been doing that for the past ten years, in the employment of two different trading firms.
Modus Operandi
A word on Nero’s methods. He is as conservative a trader as one can be in such a business. In the past he has had good years and less than good years—but virtually no truly “bad” years. Over these years he has slowly built for himself a stable nest egg, thanks to an income ranging between $300,000 and (at the peak) $2.5 million. On average, he manages to accumulate $500,000 a year in after-tax money (from an average income of about $1 million); this goes straight into his savings account. In 1993, he had a bad year and was made to feel uncomfortable in his company. Other traders made out much better, so the capital at his disposal was severely reduced, and he was made to feel undesirable at the institution. He then went to get an identical job, down to an identically designed workspace, but in a different firm that was friendlier. In the fall of 1994 the traders who had been competing for the great performance award blew up in unison during the worldwide bond market crash that resulted from the random tightening by the Federal Reserve Bank of the United States. They are all currently out of the market, performing a variety of tasks. This business has a high mortality rate.
Why isn’t Nero more affluent? Because of his trading style—or perhaps his personality. His risk aversion is extreme. Nero’s objective is not to maximize his profits, so much as it is to avoid having this entertaining machine called trading taken away from him. Blowing up would mean returning to the tedium of the university or the nontrading life. Every time his risks increase, he conjures up the image of the quiet hallway at the university, the long mornings at his desk spent in revising a paper, kept awake by bad coffee. No, he does not want to have to face the solemn university library where he was bored to tears. “I am shooting for longevity,” he is wont to say.
Nero has seen many traders
blow up,
and does not want to get into that situation.
Blow up
in the lingo has a precise meaning; it does not just mean to lose money; it means to lose more money than one ever expected, to the point of being thrown out of the business (the equivalent of a doctor losing his license to practice or a lawyer being disbarred). Nero rapidly exits trades after a predetermined loss. He never sells “naked options” (a strategy that would leave him exposed to large possible losses). He never puts himself in a situation where he can lose more than, say, $1 million—regardless of the probability of such an event. That amount has always been variable; it depends on his accumulated profits for the year. This risk aversion prevented him from making as much money as the other traders on Wall Street who are often called “Masters of the Universe.” The firms he has worked for generally allocate more money to traders with a different style from Nero, like John, whom we will encounter soon.
Nero’s temperament is such that he does not mind losing small change. “I love taking small losses,”he says. “I just need my winners to be large.” In no circumstances does he want to be exposed to those rare events, like panics and sudden crashes, that wipe a trader out in a flash. To the contrary, he wants to benefit from them. When people ask him why he does not hold on to losers, he invariably answers that he was trained by “the most chicken of them all,” the Chicago trader Stevo who taught him the business. This is not true; the real reason is his training in probability and his innate skepticism.
There is another reason why Nero is not as rich as others in his situation. His skepticism does not allow him to invest any of his own funds outside of treasury bonds. He therefore missed out on the great bull market. The reason he offers is that it could have turned out to be a bear market and a trap. Nero harbors a deep suspicion that the stock market is some form of an investment scam and cannot bring himself to own a stock. The difference with people around him who were enriched by the stock market was that he was cash-flow rich, but his assets did not inflate at all along with the rest of the world (his treasury bonds hardly changed in value). He contrasts himself with one of those start-up technology companies that were massively cash-flow negative, but for which the hordes developed some infatuation. This allowed the owners to become rich from their stock valuation, and thus dependent on the randomness of the market’s election of the winner. The difference with his friends of the investing variety is that he did not depend on the bull market, and, accordingly, does not have to worry about a bear market at all. His net worth is not a function of the investment of his savings—he does not want to depend on his investments, but on his cash earnings, for his enrichment. He takes not an inch of risk with his savings, which he invests in the safest possible vehicles. Treasury bonds are safe; they are issued by the United States government, and governments can hardly go bankrupt since they can freely print their own currency to pay back their obligation.
No Work Ethics
Today, at thirty-nine, after fourteen years in the business, he can consider himself comfortably settled. His personal portfolio contains several million dollars in medium-maturity Treasury bonds, enough to eliminate any worry about the future. What he likes most about proprietary trading is that it requires considerably less time than other high-paying professions; in other words it is perfectly compatible with his non-middle-class work ethic. Trading forces someone to think hard; those who merely work hard generally lose their focus and intellectual energy. In addition, they end up drowning in randomness; work ethics, Nero believes, draw people to focus on noise rather than the signal (the difference we established in
Table P.1
).
This free time has allowed him to carry on a variety of personal interests. As Nero reads voraciously and spends considerable time in the gym and museums, he cannot have a lawyer’s or a doctor’s schedule. Nero found the time to go back to the statistics department where he started his doctoral studies and finished the “harder science” doctorate in statistics, by rewriting his thesis in more concise terms. Nero now teaches, once a year, a half-semester seminar called
History of Probabilistic Thinking
in the mathematics department of New York University, a class of great originality that draws excellent graduate students. He has saved enough to be able to maintain his lifestyle in the future and has contingency plans perhaps to retire into writing popular essays of the scientific-literary variety, with themes revolving around probability and
indeterminism—
but only if some event in the future causes the markets to shut down. Nero believes that risk-conscious hard work and discipline can lead someone to achieve a comfortable life with a very high probability. Beyond that, it is all randomness: either by taking enormous (and unconscious) risks, or by being extraordinarily lucky. Mild success can be explainable by skills and labor. Wild success is attributable to variance.
There Are Always Secrets
Nero’s probabilistic introspection may have been helped out by a dramatic event in his life—one that he kept to himself. A penetrating observer might detect in Nero a measure of suspicious exuberance, an unnatural drive. For his life is not as crystalline as it may seem. Nero harbors a secret, one that will be discussed in time.
JOHN THE HIGH-YIELD TRADER
Through most of the 1990s, across the street from Nero’s house stood John’s—a much larger one. John was a high-yield trader, but he was not a trader in the style of Nero. A brief professional conversation with him would have revealed that he presented the intellectual depth and sharpness of mind of an aerobics instructor (though not the physique). A purblind man could have seen that John had been doing markedly better than Nero (or, at least, felt compelled to show it). He parked two top-of-the-line German cars in his driveway (his and hers), in addition to two convertibles (one of which was a collectible Ferrari), while Nero had been driving the same VW Cabriolet for almost a decade—and still does.
The wives of John and Nero were acquaintances, of the health-club type, but Nero’s wife felt extremely uncomfortable in the company of John’s. She felt that the lady was not merely trying to impress her, but was treating her like someone inferior. While Nero had become inured to the sight of traders getting rich (and trying too hard to become sophisticated by turning into wine collectors and opera lovers), his wife had rarely encountered repressed new wealth—the type of people who have felt the sting of indigence at some point in their lives and want to get even by exhibiting their wares. The only dark side of being a trader, Nero often says, is the sight of money being showered on unprepared people who are suddenly taught that Vivaldi’s
Four Seasons
is “refined” music. But it was hard for his spouse to be exposed almost daily to the neighbor who kept boasting of the new decorator they just hired. John and his wife were not the least uncomfortable with the fact that their “library” came with the leather-bound books (her health club reading was limited to
People
magazine but her shelves included a selection of untouched books by dead American authors). She also kept discussing unpronounceable exotic locations where they would repair during their vacations without so much as knowing the smallest thing about the places—she would have been hard put to explain on which continent the Seychelles Islands are located. Nero’s wife is all too human; although she kept telling herself that she did not want to be in the shoes of John’s wife, she felt as if she had been somewhat swamped in the competition of life. Somehow words and reason became ineffectual in front of an oversized diamond, a monstrous house, and a sports car collection.
An Overpaid Hick
Nero also suffered the same ambiguous feeling toward his neighbors. He was quite contemptuous of John, who represented about everything he is not and does not want to be—but there was the social pressure that was starting to weigh on him. In addition, he too would like to have sampled such excessive wealth. Intellectual contempt does not control personal envy. That house across the street kept getting bigger, with addition after addition—and Nero’s discomfort kept apace. While Nero had succeeded beyond his wildest dreams, both personally and intellectually, he was starting to consider himself as having missed a chance somewhere. In the pecking order of Wall Street, the arrival of such types as John had caused him to be a significant trader no longer—but while he used to not care about this, John and his house and his cars had started to gnaw away at him. All would have been well if Nero had not had that stupid large house across the street judging him with a superficial standard every morning. Was it the animal pecking order at play, with John’s house size making Nero a beta male? Worse even, John was about five years his junior, and, despite a shorter career, was making at least ten times his income.
When they used to run into each other Nero had a clear feeling that John tried to put him down—with barely detectable but no less potent signs of condescension. Some days John ignored him completely. Had John been a remote character, one Nero could only read about in the papers, the situation would have been different. But there John was in flesh and bones and he was his neighbor. The mistake Nero made was to start talking to him, as the rule of pecking order immediately emerged. Nero tried to soothe his discomfort by recalling the behavior of Swann, the character in Proust’s
In Search of Time Lost,
a refined art dealer and man of leisure who was at ease with such men as his personal friend the then Prince of Wales, but acted like he had to prove something in the presence of the middle class. It was much easier for Swann to mix with the aristocratic and well-established set of Guermantes than it was with the social-climbing one of the Verdurins, no doubt because he was far more confident in their presence. Likewise Nero can exact some form of respect from prestigious and prominent people. He regularly takes long meditative walks in Paris and Venice with an erudite Nobel Prize–caliber scientist (the kind of person who no longer has to prove anything) who actively seeks his conversation. A very famous billionaire speculator calls him regularly to ask him his opinion on the valuation of some derivative securities. But there he was obsessively trying to gain the respect of some overpaid hick with a cheap New Jersey “Noo-Joyzy” accent. (Had I been in Nero’s shoes I would have paraded some of my scorn to John with the use of body language, but again, Nero is a nice person.)
Clearly, John was not as well educated, well bred, physically fit, or perceived as being as intelligent as Nero—but that was not all; he was not even as street-smart as him! Nero has met true street-smart people in the pits of Chicago who exhibit a rapidity of thinking that he could not detect in John. Nero was convinced that the man was a confident shallow-thinker who had done well because he never made an allowance for his vulnerability. But Nero could not, at times, repress his envy—he wondered whether it was an objective evaluation of John, or if it was his feelings of being slighted that led him to such an assessment of John. Perhaps it was Nero who was not quite the best trader. Maybe if he had pushed himself harder or had sought the right opportunity—instead of “thinking,” writing articles and reading complicated papers. Perhaps he should have been involved in the high-yield business, where he would have shined among those shallow-thinkers like John.
So Nero tried to soothe his jealousy by investigating the rules of pecking order. Psychologists have shown that most people prefer to make $70,000 when others around them are making $60,000 than to make $80,000 when others around them are making $90,000. Economics, schmeconomics, it is all pecking order, he thought. No such analysis could prevent him from assessing his condition in an absolute rather than a relative way. With John, Nero felt that, for all his intellectual training, he was just another one of those who would prefer to make less money provided others made even less.
Nero thought that there was at least a hint to support the idea of John being merely lucky—in other words Nero, after all, might not need to move away from his neighbor’s starter palazzo. There was hope that John would meet his undoing. For John seemed unaware of one large hidden risk he was taking, the risk of blowup, a risk he could not see because he had too short an experience of the market (but also because he was not thoughtful enough to study history). How could John, with his coarse mind, otherwise be making so much money? This business of junk bonds depends on some knowledge of the “odds,” a calculation of the probability of the rare (or random) events. What do such fools know about odds? These traders use “quantitative tools” that give them the odds—and Nero disagrees with the methods used. This high-yield market resembles a nap on a railway track. One afternoon, the surprise train would run you over. You make money every month for a long time, then lose a multiple of your cumulative performance in a few hours. He has seen it with option sellers in 1987, 1989, 1992, and 1998. One day they are taken off the exchange floors, accompanied by oversized security men, and nobody ever sees them again. The big house is simply a loan; John might end up as a luxury car salesman somewhere in New Jersey, selling to the new newly rich who no doubt would feel comfortable in his presence. Nero cannot blow up. His less oversized abode, with its four thousand books, is his own. No market event can take it away from him. Every one of his losses is limited. His trader’s dignity will never, never be threatened.
John, for his part, thought of Nero as a loser, and a snobbish overeducated loser at that. Nero was involved in a mature business. He believed that he was way over the hill. “These ‘prop’ traders are dying,” he used to say. “They think they are smarter than everybody else, but they are passé.”
THE RED-HOT SUMMER
Finally, in September 1998, Nero was vindicated. One morning while leaving to go to work he saw John in his front yard unusually smoking a cigarette. He was not wearing a business suit. He looked humble; his customary swagger was gone. Nero immediately knew that John had been fired. What he did not suspect was that John also lost almost everything he had. We will see more details of John’s losses in
Chapter 5
.
Nero felt ashamed of his feelings of Schadenfreude, the joy humans can experience upon their rivals’ misfortunes. But he could not repress it. Aside from it being unchivalrous, it was said to bring bad luck (Nero is weakly superstitious). But in this case, Nero’s merriment did not come from the fact that John went back to his place in life, so much as it was from the fact that Nero’s methods, beliefs, and track record had suddenly gained in credibility. Nero would be able to raise public money on his track record precisely because such a thing could not possibly happen to him. A repetition of such an event would pay off massively for him. Part of Nero’s elation also came from the fact that he felt proud of his sticking to his strategy for so long, in spite of the pressure to be the alpha male. It was also because he would no longer question his trading style when others were getting rich because they misunderstood the structure of randomness and market cycles.
Serotonin and Randomness
Can we judge the success of people by their raw performance and their personal wealth? Sometimes—but not always. We will see how, at any point in time, a large section of businessmen with outstanding track records will be no better than randomly thrown darts. More curiously, and owing to a peculiar bias, cases will abound of the least-skilled businessmen being the richest. However, they will fail to make an allowance for the role of luck in their performance.
Lucky fools do not bear the slightest suspicion that they may be lucky fools—by definition, they do not know that they belong to such a category. They will act as if they deserved the money. Their strings of successes will inject them with so much serotonin (or some similar substance) that they will even fool themselves about their ability to outperform markets (our hormonal system does not know whether our successes depend on randomness). One can notice it in their posture; a profitable trader will walk upright, dominant style—and will tend to talk more than a losing trader. Scientists found out that serotonin, a neurotransmitter, seems to command a large share of our human behavior. It sets a positive feedback, the virtuous cycle, but, owing to an external kick from randomness, can start a reverse motion and cause a vicious cycle. It has been shown that monkeys injected with serotonin will rise in the pecking order, which in turn causes an increase of the serotonin level in their blood—until the virtuous cycle breaks and starts a vicious one (during the vicious cycle failure will cause one to slide in the pecking order, causing a behavior that will bring about further drops in the pecking order). Likewise, an increase in personal performance (regardless of whether it is caused deterministically or by the agency of Lady Fortuna) induces a rise of serotonin in the subject, itself causing an increase of what is commonly called “leadership” ability. One is “on a roll.” Some imperceptible changes in deportment, like an ability to express oneself with serenity and confidence, make the subject look credible—as if he truly deserved the shekels. Randomness will be ruled out as a possible factor in the performance, until it rears its head once again and delivers the kick that will induce the downward spiral.
A word on the display of emotions. Almost no one can conceal his emotions. Behavioral scientists believe that one of the main reasons why people become leaders is not from what skills they seem to possess, but rather from what extremely superficial impression they make on others through hardly perceptible physical signals—what we call today “charisma,” for example. The biology of the phenomenon is now well studied under the subject heading “social emotions.” Meanwhile some historian will “explain” the success in terms of, perhaps, tactical skills, the right education, or some other theoretical reason seen in hindsight. In addition, there seems to be curious evidence of a link between leadership and a form of psychopathology (the sociopath) that encourages the non-blinking, self-confident, insensitive person to rally followers.
People have often had the bad taste of asking me in a social setting if my day in trading was profitable. If my father were there, he would usually stop them by saying “never ask a man if he is from Sparta: If he were, he would have let you know such an important fact—and if he were not, you could hurt his feelings.” Likewise, never ask a trader if he is profitable; you can easily see it in his gesture and gait. People in the profession can easily tell if traders are making or losing money; head traders are quick at identifying an employee who is faring poorly. Their face will seldom reveal much, as people consciously attempt to gain control of their facial expressions. But the way they walk, the way they hold the telephone, and the hesitation in their behavior will not fail to reveal their true disposition. On the morning after John had been fired, he certainly lost much of his serotonin—unless it was another substance that researchers will discover in another decade. One cab driver in Chicago explained to me that he could tell if traders he picked up near the Chicago Board of Trade, a futures exchange, were doing well. “They get all puffed up,” he said. I found it interesting (and mysterious) that he could detect it so rapidly. I later got some plausible explanation from evolutionary psychology, which claims that such physical manifestations of one’s performance in life, just like an animal’s dominant condition, can be used for signaling: It makes the winners seem easily visible, which is efficient in mate selection.
YOUR DENTIST IS RICH, VERY RICH
We close this chapter with a hint on the next discussion of resistance to randomness. Recall that Nero can be considered prosperous but not “very rich” by his day’s standards. However, according to some strange accounting measure we will see in the next chapter, he is extremely rich
on the average of lives
he could have led—he takes so little risk in his trading career that there could have been very few disastrous outcomes. The fact that he did not experience John’s success was the reason he did not suffer his downfall. He would be therefore wealthy according to this unusual (and probabilistic) method of accounting for wealth. Recall that Nero protects himself from the rare event. Had Nero had to relive his professional life a few million times, very few sample paths would be marred by bad luck—but, owing to his conservatism, very few as well would be affected by extreme good luck. That is, his life in stability would be similar to that of an ecclesiastic clock repairman. Naturally, we are discussing only his professional life, excluding his (sometimes volatile) private one.
Arguably,
in expectation,
a dentist is considerably richer than the rock musician who is driven in a pink Rolls Royce, the speculator who bids up the price of impressionist paintings, or the entrepreneur who collects private jets. For one cannot consider a profession without taking into account the average of the people who enter it, not the sample of those who have succeeded in it. We will examine the point later from the vantage point of the survivorship bias, but here, in Part I, we will look at it with respect to resistance to randomness.
Consider two neighbors, John Doe A, a janitor who won the New Jersey lottery and moved to a wealthy neighborhood, compared to John Doe B, his next-door neighbor of more modest condition who has been drilling teeth eight hours a day over the past thirty-five years. Clearly one can say that, thanks to the dullness of his career, if John Doe B had to relive his life a few thousand times since graduation from dental school, the range of possible out-comes would be rather narrow (assuming he is properly insured). At the best, he would end up drilling the rich teeth of the New York Park Avenue residents, while the worst would show him drilling those of some semideserted town full of trailers in the Catskills. Furthermore, assuming he graduated from a very prestigious teeth-drilling school, the range of out-comes would be even more compressed. As to John Doe A, if he had to relive his life a million times, almost all of them would see him performing janitorial activities (and spending endless dollars on fruitless lottery tickets), and one in a million would see him winning the New Jersey lottery.
The idea of taking into account both the observed and unobserved possible outcomes sounds like lunacy. For most people, probability is about what may happen in the future, not events in the observed past; an event that has already taken place has 100% probability, i.e., certainty. I have discussed the point with many people who platitudinously accuse me of confusing myth and reality. Myths, particularly well-aged ones, as we saw with Solon’s warning, can be far more potent (and provide us with more experience) than plain reality.


================================================================================
CHAPTER/SECTION 303 (Item 312)
================================================================================

Two
•
A BIZARRE ACCOUNTING METHOD
On alternative histories, a probabilistic view of the world, intellectual fraud, and the randomness wisdom of a Frenchman with steady bathing habits. How journalists are bred to not understand random series of events. Beware borrowed wisdom: How almost all great ideas concerning random outcomes are against conventional sapience. On the difference between correctness and intelligibility.
ALTERNATIVE HISTORY
I
start with the platitude that one cannot judge a performance in any given field (war, politics, medicine, investments) by the results, but by the costs of the alternative (i.e., if history played out in a different way). Such substitute courses of events are called
alternative histories.
Clearly, the quality of a decision cannot be solely judged based on its outcome, but such a point seems to be voiced only by people who fail (those who succeed attribute their success to the quality of their decision). Such opinion—“that I followed the best course”—is what politicians on their way out of office keep telling those members of the press who still listen to them—eliciting the customary commiserating “yes, we know” that makes the sting even worse. And like many platitudes, this one, while being too obvious, is not easy to carry out in practice.
Russian Roulette
One can illustrate the strange concept of alternative histories as follows. Imagine an eccentric (and bored) tycoon offering you $10 million to play Russian roulette, i.e., to put a revolver containing one bullet in the six available chambers to your head and pull the trigger. Each realization would count as one history, for a total of six possible histories of equal probabilities. Five out of these six histories would lead to enrichment; one would lead to a statistic, that is, an obituary with an embarrassing (but certainly original) cause of death. The problem is that only one of the histories is observed in reality; and the winner of $10 million would elicit the admiration and praise of some fatuous journalist (the very same ones who unconditionally admire the Forbes 500 billionaires). Like almost every executive I have encountered during an eighteen-year career on Wall Street (the role of such executives in my view being no more than a judge of results delivered in a random manner), the public observes the external signs of wealth without even having a glimpse at the source (we call such source the
generator
).Consider the possibility that the Russian roulette winner would be used as a role model by his family, friends, and neighbors.
While the remaining five histories are not observable, the wise and thoughtful person could easily make a guess as to their attributes. It requires some thoughtfulness and personal courage. In addition, in time, if the roulette-betting fool keeps playing the game, the bad histories will tend to catch up with him. Thus, if a twenty-five-year-old played Russian roulette, say, once a year, there would be a very slim possibility of his surviving until his fiftieth birthday—but, if there are enough players, say thousands of twenty-five-year-old players, we can expect to see a handful of (extremely rich) survivors (and a very large cemetery). Here I have to admit that the example of Russian roulette is more than intellectual to me. I lost a comrade to this “game” during the Lebanese war, when we were in our teens. But there is more. I discovered that I had more than a shallow interest in literature thanks to the effect of Graham Greene’s account of his flirt with such a game; it bore a stronger effect on me than the actual events I had recently witnessed. Greene claimed that he once tried to soothe the dullness of his childhood by pulling the trigger on a revolver—making me shiver at the thought that I had at least a one in six probability of having been without his novels.
The reader can see my unusual notion of alternative accounting: $10 million earned through Russian roulette does not have the same value as $10 million earned through the diligent and artful practice of dentistry. They are the same, can buy the same goods, except that one’s dependence on randomness is greater than the other. To an accountant, though, they would be identical; to your next-door neighbor too. Yet, deep down, I cannot help but consider them as qualitatively different. The notion of such alternative accounting has interesting intellectual extensions and lends itself to mathematical formulation, as we will see in the next chapter with our introduction of the Monte Carlo engine. Note that such use of mathematics is only illustrative, aiming at getting the intuition of the point, and should not be interpreted as an engineering issue. In other words, one need not actually compute the alternative histories so much as assess their attributes. Mathematics is not just a “numbers game,” it is a way of thinking. We will see that probability is a qualitative subject.
Possible Worlds
Note that these ideas of alternative histories have been covered by separate disciplines in intellectual history, worth presenting quickly because they all seem to converge on the same concept of risk and uncertainty (certainty is something that is likely to take place across the highest number of different alternative histories; uncertainty concerns events that should take place in the lowest number of them).
In philosophy, there has been considerable work on the subject starting with Leibniz’ idea of possible worlds. For Leibniz, God’s mind included an infinity of possible worlds, of which he selected just one. These nonselected worlds are worlds of possibilities, and the one in which I am breathing and writing these lines is just one of them that happened to have been executed. Philosophers also have a branch of logic that specializes in the matter: whether some property holds
across all possible worlds
or if it holds across a single world—with ramifications into the philosophy of language called
possible worlds semantics
with such authors as Saul Kripke.
In physics, there is the many-world interpretation in quantum mechanics (associated with the works of Hugh Everett in 1957) which considers that the universe branches out treelike at each juncture; what we are living now is only one of these many worlds. Taken at a more extreme level, whenever numerous viable possibilities exist, the world splits into many worlds, one world for each different possibility—causing the proliferation of parallel universes. I am an essayist-trader in one of the parallel universes, plain dust in another.
Finally, in economics: Economists studied (perhaps unwittingly) some of the Leibnizian ideas with the possible “states of nature” pioneered by Kenneth Arrow and Gerard Debreu. This analytical approach to the study of economic uncertainty is called the “state space” method—it happens to be the cornerstone of neoclassical economic theory and mathematical finance. A simplified version is called “scenario analysis,” the series of “what-ifs” used in, say, the forecasting of sales for a fertilizer plant under different world conditions and demands for the (smelly) product.
An Even More Vicious Roulette
Reality is far more vicious than Russian roulette. First, it delivers the fatal bullet rather infrequently, like a revolver that would have hundreds, even thousands, of chambers instead of six. After a few dozen tries, one forgets about the existence of a bullet, under a numbing false sense of security. The point is dubbed in this book the
black swan problem,
which we cover in
Chapter 7
, as it is linked to the problem of induction, a problem that has kept a few thinkers awake at night. It is also related to a problem called
denigration of history,
as gamblers, investors, and decision-makers feel that the sorts of things that happen to others would not necessarily happen to them.
Second, unlike a well-defined, precise game like Russian roulette, where the risks are visible to anyone capable of multiplying and dividing by six, one does not observe the barrel of reality. Very rarely is the generator visible to the naked eye. One is thus capable of unwittingly playing Russian roulette—and calling it by some alternative “low risk” name. We see the wealth being generated, never the processor, a matter that makes people lose sight of their risks, and never consider the losers. The game seems terribly easy and we play along carelessly. Even scientists with all their sophistication in calculating probabilities cannot deliver any meaningful answer about the odds, since knowledge of these depends on our witnessing the barrel of reality—of which we generally know nothing.
Finally, there is an ingratitude factor in warning people about something abstract (by definition anything that did not happen is abstract). Say you engage in a business of protecting investors from rare events by constructing packages that shield them from their sting (something I have done on occasion). Say that nothing happens during the period. Some investors will complain about your spending their money; some will even try to make you feel sorry: “You wasted my money on insurance last year; the factory did not burn, it was a stupid expense. You should only insure for events that happen.” One investor came to see me fully expecting me to be apologetic (it did not work). But the world is not that homogeneous: There are some (though very few) who will call you to express their gratitude and thank you for having protected them from the events that did not take place.
SMOOTH PEER RELATIONS
The degree of resistance to randomness in one’s life is an abstract idea, part of its logic counterintuitive, and, to confuse matters, its realizations nonobservable. But I have been increasingly devoted to it—for a collection of personal reasons I will leave for later. Clearly my way of judging matters is probabilistic in nature; it relies on the notion of what could have
probably
happened, and requires a certain mental attitude with respect to one’s observations. I do not recommend engaging an accountant in a discussion about such probabilistic considerations. For an accountant a number is a number. If he were interested in probability he would have gotten involved in more introspective professions—and would be inclined to make a costly mistake on your tax return.
While we do not see the roulette barrel of reality, some people give it a try; it takes a special mindset to do so. Having seen hundreds of people enter and exit my profession (characterized by extreme dependence on randomness), I have to say that those who have had a modicum of scientific training tend to go the extra mile. For many, such thinking is second nature. This might not necessarily come from their scientific training
per se
(beware of causality), but possibly from the fact that people who have decided at some point in their lives to devote themselves to scientific research tend to have an ingrained intellectual curiosity and a natural tendency for such introspection. Particularly thoughtful are those who had to abandon scientific studies because of their inability to keep focused on a narrowly defined problem (or, in Nero’s case, the minute arcane details and petty arguments). Without excessive intellectual curiosity it is almost impossible to complete a Ph.D. thesis these days; but without a desire to narrowly specialize, it is impossible to make a scientific career. (There is a distinction, however, between the mind of a pure mathematician thriving on abstraction and that of a scientist consumed by curiosity. A mathematician is absorbed in what goes into his head while a scientist searches into what is outside of himself.) However, some people’s concern for randomness can be excessive; I have even seen people trained in some fields, like, say, quantum mechanics, push the idea to the other extreme, only seeing alternative histories (in the many-world interpretation) and ignoring the one that actually took place.
Some traders can be unexpectedly introspective about randomness. Not long ago I had dinner at the bar of a Tribeca restaurant with Lauren Rose, a trader who was reading an early draft of this book. We flipped a coin to see who was going to pay for the meal. I lost and paid. He was about to thank me when he abruptly stopped and said that he paid for half of it
probabilistically.
I thus view people distributed across two polar categories: On one extreme, those who never accept the notion of randomness; on the other, those who are tortured by it. When I started on Wall Street in the 1980s, trading rooms were populated with people with a “business orientation,” that is, generally devoid of any introspection, flat as a pancake, and likely to be fooled by randomness. Their failure rate was extremely high, particularly when financial instruments gained in complexity. Somehow, tricky products, like exotic options, were introduced and carried counterintuitive payoffs that were too difficult for someone of such culture to handle. They dropped like flies; I do not think that many of the hundreds of MBAs of my generation I met on Wall Street in the 1980s still engage in such forms of professional and disciplined risk taking.
Salvation via Aeroflot
The 1990s witnessed the arrival of people of richer and more interesting backgrounds, which made the trading rooms far more entertaining. I was saved from the conversation of MBAs. Many scientists, some of them extremely successful in their field, arrived with a desire to make a buck. They, in turn, hired people who resembled them. While most of these people were not Ph.D.s (indeed, the Ph.D. is still a minority), the culture and values suddenly changed, becoming more tolerant of intellectual depth. It caused an increase in the already high demand for scientists on Wall Street, owing to the rapid development of financial instruments. The dominant specialty was physics, but one could find all manner of quantitative backgrounds among them. Russian, French, Chinese, and Indian accents (by order) began dominating in both New York and London. It was said that every plane from Moscow had at least its back row full of Russian mathematical physicists en route to Wall Street (they lacked the street smarts to get good seats). One could hire very cheap labor by going to JFK airport with a (mandatory) translator, randomly interviewing those who fit the stereotype. Indeed, by the late 1990s one could get someone trained by a world-class scientist for almost half the price of an MBA. As they say, marketing is everything; these guys do not know how to sell themselves.
I had a strong bias in favor of Russian scientists; many can be put to active use as chess coaches (I also got a piano teacher out of the process). In addition, they are extremely helpful in the interview process. When MBAs apply for trading positions, they frequently boast “advanced” chess skills on their résumés. I recall the MBA career counselor at Wharton recommending our advertising chess skills “because it sounds intelligent and strategic.” MBAs, typically, can interpret their superficial knowledge of the rules of the game into “expertise.” We used to verify the accuracy of claims of chess expertise (and the character of the applicant) by pulling a chess set out of a drawer and telling the student, now turning pale: “Yuri will have a word with you.”
The failure rate of these scientists, though, was better, but only slightly so than that of MBAs; but it came from another reason, linked to their being on average (but only on average) devoid of the smallest bit of practical intelligence. Some successful scientists had the judgment (and social graces) of a doorknob—but by no means all of them. Many people were capable of the most complex calculations with utmost rigor when it came to equations, but were totally incapable of solving a problem with the smallest connection to reality; it was as if they understood the letter but not the spirit of the math (we will see more on such dual thinking with the two systems of reasoning problem in
Chapter 11
). I am convinced that X, a likeable Russian man of my acquaintance, has two brains: one for math and another, considerably inferior one, for everything else (which included solving problems related to the mathematics of finance). But on occasion a fast-thinking scientific-minded person with street smarts would emerge. Whatever the benefits of such population shift, it improved our chess skills and provided us with quality conversation during lunchtime—it extended the lunch hour considerably. Consider that I had in the 1980s to chat with colleagues who had an MBA or tax accounting background and were capable of the heroic feat of discussing FASB standards. I have to say that their interests were not too contagious. The interesting thing about these physicists did not lie in their ability to discuss fluid dynamics; it is that they were naturally interested in a variety of intellectual subjects and provided pleasant conversation.
Solon Visits Regine’s Nightclub
As the reader may already suspect, my opinions about randomness have not earned me the smoothest of relations with some of my peers during my Wall Street career (many of whom the reader can see indirectly—but only indirectly—portrayed in these chapters). But where I had uneven relations was with some of those who had the misfortune of being my bosses. For I had two bosses in my life of contrasting characteristics in about every trait.
The first, whom I will call Kenny, was the epitome of the suburban family man. He would be of the type to coach soccer on Saturday morning, and invite his brother-in-law for a Sunday afternoon barbecue. He gave the appearance of someone I would trust with my savings—indeed he rose quite rapidly in the institution in spite of his lack of technical competence in financial derivatives (his firm’s claim to fame). But he was too much a no-nonsense person to make out my logic. He once blamed me for not being impressed with the successes of some of his traders who did well during the bull market for European bonds of 1993, whom I openly considered nothing better than random gunslingers. I tried presenting him with the notion of survivorship bias (Part II of this book) in vain. His traders have all exited the business since then “to pursue other interests” (including him). But he gave the appearance of being a calm, measured man, who spoke his mind and knew how to put the other person at ease during a conversation. He was articulate, extremely presentable thanks to his athletic looks, well measured in his speech, and endowed with the extremely rare quality of being an excellent listener. His personal charm allowed him to win the confidence of the chairman—but I could not conceal my disrespect, particularly as he could not make out the nature of my conversation. In spite of his conservative looks he was a perfect time bomb, ticking away.
The second, whom I will call Jean-Patrice, in contrast, was a moody Frenchman with an explosive temper and a hyperaggressive personality. Except for those he truly liked (not that many), he was expert at making his subordinates uncomfortable, putting them in a state of constant anxiety. He greatly contributed to my formation as a risk taker; he is one of the very rare people who have the guts to care only about the generator, entirely oblivious of the results. He presented the wisdom of Solon, but, while one would expect someone with such personal wisdom and such understanding of randomness to lead a dull life, he lived a colorful one. In contrast with Kenny, who wore conservative dark suits and white shirts (his only indulgence was flashy equestrian Hermès ties), Jean-Patrice dressed like a peacock: blue shirts, plaid sports coats stuffed with gaudy silk pocket squares. No family-minded man, he rarely came to work before noon—though I can safely say that he carried his work with him to the most unlikely places. He frequently called me from
Regine’s,
an upscale nightclub in New York, waking me up at three in the morning to discuss some small (and irrelevant) details of my risk exposure. In spite of his slight corpulence, women seemed to find him irresistible; he frequently disappeared at midday and was unreachable for hours. His advantage might have been in his being a New York Frenchman with steady bathing habits. Once he invited me to discuss an urgent business issue with him. Characteristically, I found him mid-afternoon in a strange “club” in Paris that carried no nameplate and where he sat with documents strewn across the table from him. Sipping champagne, he was simultaneously caressed by two scantily dressed young ladies. Strangely, he involved them in the conversation as if they were part of the meeting. He even had one of the ladies pick up his constantly ringing mobile phone as he did not want our conversation to be interrupted.
I am still amazed at this flamboyant man’s obsession with risks, which he constantly played in his head—he literally thought of everything that could possibly happen. He forced me to make an alternative plan should a plane crash into the office building (way before the events of September 2001)—and fumed at my answer that the financial condition of his department would be of small interest to me in such circumstances. He had a horrible reputation as a philanderer, a temperamental boss capable of firing someone at a whim, yet he listened to me and understood every word I had to say, encouraging me to go the extra mile in my study of randomness. He taught me to look for the invisible risks of blowup in any portfolio. Not coincidentally, he has an immense respect for science and an almost fawning deference for scientists; a decade or so after we worked together he showed up unexpectedly during the defense of my doctoral thesis, smiling from the back of the room. While Kenny knew how to climb the ladder of an institution, reaching a high level in the organization before being forced out, Jean-Patrice did not have such a happy career, a matter that taught me to beware of mature financial institutions.
It can be disturbing for many self-styled “bottom line”–oriented people to be questioned about the histories that did not take place rather than the ones that actually happened. Clearly, to a no-nonsense person of the “successful in business” variety, my language (and, I have to reckon, some traits of my personality) appears strange and incomprehensible. To my amusement, the argument appears offensive to many.
The contrast between Kenny and Jean-Patrice is not a mere coincidence that I happened to witness in a protracted career. Beware the spendthrift “businesswise” person; the cemetery of markets is disproportionately well stocked with the self-styled “bottom line” people. In contrast with their customary Masters of the Universe demeanor, they suddenly look pale, humble, and hormone-deprived on the way to the personnel office for the customary discussion of the severance agreement.
GEORGE WILL IS NO SOLON:
ON COUNTERINTUITIVE TRUTHS
Realism can be punishing. Probabilistic skepticism is worse. It is difficult to go about life wearing probabilistic glasses, as one starts seeing fools of randomness all around, in a variety of situations—obdurate in their perceptional illusion. To start, it is impossible to read a historian’s analysis without questioning the inferences: We know that Hannibal and Hitler were mad in their pursuits, as Rome is not today Phoenician-speaking and Times Square in New York currently exhibits no swastikas. But what of all those generals who were equally foolish, but ended up winning the war and consequently the esteem of the historical chronicler? It is hard to think of Alexander the Great or Julius Caesar as men who won only in the visible history, but who could have suffered defeat in others. If we have heard of them, it is simply because they took considerable risks, along with thousands of others, and happened to win. They were intelligent, courageous, noble (at times), had the highest possible obtainable culture in their day—but so did thousands of others who live in the musty footnotes of history. Again I am not contesting that they won their wars—only the claims concerning the quality of their strategies. (My very first impression upon a recent rereading of the
Iliad,
the first in my adulthood, is that the epic poet did not judge his heroes by the result: Heroes won and lost battles in a manner that was totally independent of their own valor; their fate depended upon totally external forces, generally the explicit agency of the scheming gods (not devoid of nepotism). Heroes are heroes because they are heroic in behavior, not because they won or lost. Patrocles does not strike us as a hero because of his accomplishments (he was rapidly killed) but because he preferred to die than see Achilles sulking into inaction. Clearly, the epic poets understood invisible histories. Also later thinkers and poets had more elaborate methods for dealing with randomness, as we will see with stoicism.
Listening to the media, mostly because I am not used to it, can cause me on occasion to jump out of my seat and become emotional in front of the moving image (I grew up with no television and was in my late twenties when I learned to operate a TV set). One illustration of a dangerous refusal to consider alternative histories is provided by the interview that media person George Will, a “commentator” of the extensively commenting variety, conducted with Professor Robert Shiller, a man known to the public for his bestselling book
Irrational Exuberance,
but known to the connoisseur for his remarkable insights about the structure of market randomness and volatility (expressed in the precision of mathematics).
The interview is illustrative of the destructive aspect of the media, in catering to our heavily warped common sense and biases. I was told that George Will was very famous and extremely respected (that is, for a journalist). He might even be someone of the utmost intellectual integrity; his profession, however, is merely to sound smart and intelligent to the hordes. Shiller, on the other hand, understands the ins and outs of randomness; he is trained to deal with rigorous argumentation, but does sound less smart in public because his subject matter is highly counterintuitive. Shiller had been pronouncing the stock market to be overpriced for a long time. George Will indicated to Shiller that had people listened to him in the past they would have lost money, as the market has more than doubled since he started pronouncing it overvalued. To such a journalistic and well-sounding (but senseless) argument, Shiller was unable to respond except to explain that the fact that he was wrong in one single market call should not carry undue significance. Shiller, as a scientist, did not claim to be a prophet or one of the entertainers who comment on the markets on the evening news. Yogi Berra would have had a better time with his confident comment on the fat lady not having sung yet.
I could not understand what Shiller, untrained to compress his ideas into vapid sound bites, was doing on such a TV show. Clearly, it is foolish to think that an irrational market cannot become even more irrational; Shiller’s views on the rationality of the market are not invalidated by the argument that he was wrong in the past. Here I could not help seeing in the person of George Will the representative of so many nightmares in my career; my attempting to prevent someone from playing Russian roulette for $10 million and seeing journalist George Will humiliating me in public by saying that had the person listened to me it would have cost him a considerable fortune. In addition, Will’s comment was not an off-the-cuff remark; he wrote an article on the matter discussing Shiller’s bad “prophecy.” Such tendency to make and unmake prophets based on the fate of the roulette wheel is symptomatic of our ingrained inability to cope with the complex structure of randomness prevailing in the modern world. Mixing forecast and prophecy is symptomatic of randomness-foolishness (prophecy belongs to the right column; forecast is its mere left-column equivalent).
Humiliated in Debates
Clearly, this idea of alternative history does not make intuitive sense, which is where the fun begins. For starters, we are not wired in a way to understand probability, a point that we will examine backward and forward in this book. I will just say at this point that researchers of the brain believe that mathematical truths make little sense to our mind, particularly when it comes to the examination of random outcomes. Most results in probability are entirely counterintuitive; we will see plenty of them. Then why argue with a mere journalist whose paycheck comes from playing on the conventional wisdom of the hordes? I recall that every time I have been humiliated in a public discussion on markets by someone (of the George Will variety) who seemed to present more palatable and easier-to-understand arguments, I turned out (much later) to be right. I do not dispute that arguments should be simplified to their maximum potential; but people often confuse complex ideas that cannot be simplified into a media-friendly statement as symptomatic of a confused mind. MBAs learn the concept of clarity and simplicity—the five-minute-manager take on things. The concept may apply to the business plan for a fertilizer plant, but not to highly probabilistic arguments—which is the reason I have anecdotal evidence in my business that MBAs tend to blow up in financial markets, as they are trained to simplify matters a couple of steps beyond their requirement. (I beg the MBA reader not to take offense; I am myself the unhappy holder of the degree.)
A Different Kind of Earthquake
Try the following experiment. Go to the airport and ask travelers en route to some remote destination how much they would pay for an insurance policy paying, say, a million tugrits (the currency of Mongolia) if they died during the trip (for any reason).Then ask another collection of travelers how much they would pay for insurance that pays the same in the event of death from a terrorist act (and only a terrorist act). Guess which one would command a higher price? Odds are that people would rather pay for the second policy (although the former includes death from terrorism). The psychologists Daniel Kahneman and Amos Tversky figured this out several decades ago. The irony is that one of the sampled populations did not include people on the street, but professional predictors attending some society of forecasters’ annual meeting. In a now famous experiment they found that the majority of people, whether predictors or nonpredictors, will judge a deadly flood (causing thousands of deaths) caused by a California earthquake to be more likely than a fatal flood (causing thousands of deaths) occurring somewhere in North America (which happens to include California). As a derivatives trader I noticed that people do not like to insure against something abstract; the risk that merits their attention is always something vivid.
This brings us to a more dangerous dimension of journalism. We just saw how the scientifically hideous George Will and his colleagues can twist arguments to sound right without being right. But there is a more general impact by information providers in biasing the representation of the world one gets from the delivered information. It is a fact that our brain tends to go for superficial clues when it comes to risk and probability, these clues being largely determined by what emotions they elicit or the ease with which they come to mind. In addition to such problems with the perception of risk, it is also a scientific fact, and a shocking one, that both risk detection and risk avoidance are not mediated in the “thinking” part of the brain but largely in the emotional one (the “risk as feelings” theory). The consequences are not trivial: It means that rational thinking has little, very little, to do with risk avoidance. Much of what rational thinking seems to do is rationalize one’s actions by fitting some logic to them.
In that sense the description coming from journalism is certainly not just an unrealistic representation of the world but rather the one that can fool you the most by grabbing your attention via your emotional apparatus—the
cheapest to deliver
sensation. Take the mad cow “threat” for example: Over a decade of hype, it only killed people (in the highest estimates) in the hundreds as compared to car accidents (several hundred thousands!)—except that the journalistic description of the latter would not be commercially fruitful. (Note that the risk of dying from food poisoning or in a car accident on the way to a restaurant is greater than dying from mad cow disease.) This sensationalism can divert empathy toward wrong causes: cancer and malnutrition being the ones that suffer the most from the lack of such attention. Malnutrition in Africa and Southeast Asia no longer causes the emotional impact—so it literally dropped out of the picture. In that sense the mental probabilistic map in one’s mind is so geared toward the sensational that one would realize informational gains by dispensing with the news. Another example concerns the volatility of markets. In people’s minds lower prices are far more “volatile” than sharply higher moves. In addition, volatility seems to be determined not by the actual moves but by the tone of the media. The market movements in the eighteen months after September 11, 2001, were far smaller than the ones that we faced in the eighteen months prior—but somehow in the mind of investors they were very volatile. The discussions in the media of the “terrorist threats” magnified the effect of these market moves in people’s heads. This is one of the many reasons that journalism may be the greatest plague we face today—as the world becomes more and more complicated and our minds are trained for more and more simplification.
Proverbs Galore
Beware the confusion between correctness and intelligibility. Part of conventional wisdom favors things that can be explained rather instantly and “in a nutshell”—in many circles it is considered law. Having attended a French elementary school, a
lycée primaire,
I was trained to rehash Boileau’s adage:
Ce qui se conçoit bien s’énonce clairement
Et les mots pour le dire viennent aisément
What is easy to conceive is clear to express / Words to say it would come effortlessly.
The reader can imagine my disappointment at realizing, while growing up as a practitioner of randomness, that most poetic sounding adages are plain wrong. Borrowed wisdom can be vicious. I need to make a huge effort not to be swayed by well-sounding remarks. I remind myself of Einstein’s remark that common sense is nothing but a collection of misconceptions acquired by age eighteen. Furthermore,
What sounds intelligent in a conversation or a meeting, or, particularly, in the media, is suspicious.
Any reading of the history of science would show that almost all the smart things that have been proven by science appeared like lunacies at the time they were first discovered. Try to explain to a
Times
(of London) journalist in 1905 that time slows down when one travels (even the Nobel committee never granted Einstein the prize on account of his insight on special relativity). Or to someone with no exposure to physics that there are places in our universe where time does not exist. Try to explain to Kenny that, although his star trader “proved” to be extremely successful, I have enough arguments to convince him that he is a dangerous idiot.
Risk Managers
Corporations and financial institutions have recently created the strange position of risk manager, someone who is supposed to monitor the institution and verify that it is not too deeply involved in the business of playing Russian roulette. Clearly, having been burned a few times, the incentive is there to have someone take a look at the generator, the roulette that produces the profits and losses. Although it is more fun to trade, many extremely smart people among my friends (including Jean-Patrice) felt attracted by such positions. It is an important and attractive fact that the average risk manager earns more than the average trader (particularly when we take into account the number of traders thrown out of the business: While a ten-year survival rate for a trader is in the single digits, that of a risk manager is close to 100%). “Traders come and go; risk managers are here to stay.” I keep thinking of taking such a position both on economic grounds (as it is probabilistically more profitable) and because the job offers more intellectual content than the one consisting in just buying and selling, and allows one to integrate research and execution. Finally, a risk manager’s blood has smaller quantities of the harmful kind of stress hormones. But something has held me back, aside from the irrationality of wanting the pains and entertainment from the emotions of speculation. The risk managers’ job feels strange: As we said, the generator of reality is not observable. They are limited in their power to stop profitable traders from taking risks, given that they would,
ex post,
be accused by the George Wills around of costing the shareholder some precious opportunity shekels. On the other hand, the occurrence of a blowup would cause them to be responsible for it. What to do in such circumstances?
Their focus becomes to play politics, cover themselves by issuing vaguely phrased internal memoranda that warn against risk-taking activities yet stop short of completely condemning it, lest they lose their job. Like a doctor torn between the two types of errors, the false positive (telling the patient he has cancer when in fact he does not) and the false negative (telling the patient he is healthy when in fact he has cancer), they need to balance their existence with the fact that they inherently need some margin of error in their business.
Epiphenomena
From the standpoint of an institution, the existence of a risk manager has less to do with actual risk reduction than it has to do with the
impression
of risk reduction. Philosophers since Hume and modern psychologists have been studying the concept of epiphenomenalism, or when one has the illusion of cause-and-effect. Does the compass move the boat? By “watching” your risks, are you effectively reducing them or are you giving yourself the feeling that you are doing your duty? Are you like a chief executive officer or just an observing press officer? Is such illusion of control harmful?
I conclude the chapter with a presentation of the central paradox of my career in financial randomness. By definition, I go against the grain, so it should come as no surprise that my style and methods are neither popular nor easy to understand. But I have a dilemma: On the one hand, I work with others in the real world, and the real world is not just populated with babbling but ultimately inconsequential journalists. So my wish is for people in general to remain fools of randomness (so I can trade against them), yet for there to remain a minority intelligent enough to value my methods and hire my services. In other words, I need people to remain fools of randomness, but not all of them. I was fortunate to meet Donald Sussman, who corresponds to such an ideal partner; he helped me in the second stage of my career by freeing me from the ills of employment. My greatest risk is to become successful, as it would mean that my business is about to disappear; strange business, ours.


================================================================================
CHAPTER/SECTION 304 (Item 313)
================================================================================

Three
•
A MATHEMATICAL MEDITATION ON HISTORY
On Monte Carlo simulation as a metaphor for understanding a sequence of random historical events. On randomness and artificial history. Age is beauty, almost always, and the new and the young are generally toxic. Send your history professor to an introductory class on sampling theory.
Europlayboy Mathematics
T
he stereotype of a pure mathematician presents an anemic man with a shaggy beard and grimy and uncut fingernails silently laboring on a Spartan but disorganized desk. With thin shoulders and a pot belly, he sits in a grubby office, totally absorbed in his work, oblivious to the grunginess of his surroundings. He grew up in a communist regime and speaks English with an astringent and throaty Eastern European accent. When he eats, crumbs of food accumulate in his beard. With time he becomes more and more absorbed in his subject matter of pure theorems, reaching levels of ever increasing abstraction. The American public was recently exposed to one of these characters with the Unabomber, the bearded and recluse mathematician who lived in a hut and took to murdering people who promoted modern technology. No journalist was capable of even coming close to describing the subject matter of his thesis, “Complex Boundaries,” as it has no intelligible equivalent—a complex number being an entirely abstract and imaginary number that includes the square root of minus one, an object that has no analog outside of the world of mathematics.
The name Monte Carlo conjures up the image of a suntanned urbane man of the Europlayboy variety entering a casino under a whiff of the Mediterranean breeze. He is an apt skier and tennis player, but also can hold his own in chess and bridge. He drives a gray sports car, dresses in a well-ironed Italian handmade suit, and speaks carefully and smoothly about mundane, but real, matters, those a journalist can easily describe to the public in compact sentences. Inside the casino he astutely counts the cards, mastering the odds, and bets in a studied manner, his mind producing precise calculations of his optimal betting size. He could be James Bond’s smarter lost brother.
Now when I think of Monte Carlo mathematics, I think of a happy combination of the two: The Monte Carlo man’s realism without the shallowness, combined with the mathematician’s intuitions without the excessive abstraction. For indeed this branch of mathematics is of immense practical use—it does not present the same dryness commonly associated with mathematics. I became addicted to it the minute I became a trader. It shaped my thinking in most matters related to randomness. Most of the examples used in this book were created with my Monte Carlo generator, which I introduce in this chapter. Yet it is far more a way of thinking than a computational method. Mathematics is principally a tool to meditate, rather than to compute.
The Tools
The notion of alternative histories discussed in the last chapter can be extended considerably and subjected to all manner of technical refinement. This brings us to the tools used in my profession to toy with uncertainty. I will outline them next. Monte Carlo methods, in brief, consist of creating artificial history using the following concepts.
First, consider the sample path. The invisible histories have a scientific name,
alternative sample paths,
a name borrowed from the field of mathematics of probability called stochastic processes. The notion of path, as opposed to outcome, indicates that it is not a mere MBA-style scenario analysis, but the examination of a sequence of scenarios along the course of time. We are not just concerned with where a bird can end up tomorrow night, but rather with all the various places it can possibly visit during the time interval. We are not concerned with what the investor’s worth would be in, say, a year, but rather of the heart-wrenching rides he may experience during that period. The word
sample
stresses that one sees only one realization among a collection of possible ones. Now, a sample path can be either deterministic or random, which brings the next distinction.
A
random sample path,
also called a random run, is the mathematical name for such a succession of virtual historical events, starting at a given date and ending at another, except that they are subjected to some varying level of uncertainty. However, the word
random
should not be mistaken for equiprobable (i.e., having the same probability). Some outcomes will give a higher probability than others. An example of a random sample path can be the body temperature of your explorer cousin during his latest bout with typhoid fever, measured hourly from the beginning to the end of his episode. It can also be a simulation of the price of your favorite technology stock, measured daily at the close of the market, over, say, one year. Starting at $100, in one scenario it can end up at $20 having seen a high of $220; in another it can end up at $145 having seen a low of $10. Another example is the evolution of your wealth during an evening at a casino. You start with $1,000 in your pocket, and measure it every fifteen minutes. In one sample path you have $2,200 at midnight; in another you barely have $20 left for a cab fare.
Stochastic processes refer to the dynamics of events unfolding with the course of time. Stochastic is a fancy Greek name for random. This branch of probability concerns itself with the study of the evolution of successive random events—one could call it the mathematics of history. The key about a process is that it has time in it.
What is a Monte Carlo generator? Imagine that you can replicate a perfect roulette wheel in your attic without having recourse to a carpenter. Computer programs can be written to simulate just about anything. They are even better (and cheaper) than the roulette wheel built by your carpenter, as this physical version may be inclined to favor one number more than others owing to a possible slant in its build or the floor of your attic. These are called the biases.
Monte Carlo simulations are closer to a toy than anything I have seen in my adult life. One can generate thousands, perhaps millions, of random sample paths, and look at the prevalent characteristics of some of their features. The assistance of the computer is instrumental in such studies. The glamorous reference to Monte Carlo indicates the metaphor of simulating the random events in the manner of a virtual casino. One sets conditions believed to resemble the ones that prevail in reality, and launches a collection of simulations around possible events. With no mathematical literacy we can launch a Monte Carlo simulation of an eighteen-year-old Christian Lebanese successively playing Russian roulette for a given sum, and see how many of these attempts result in enrichment, or how long it takes on average before he hits the obituary. We can change the barrel to contain 500 holes, a matter that would decrease the probability of death, and see the results.
Monte Carlo simulation methods were pioneered in martial physics in the Los Alamos laboratory during the A-bomb preparation. They became popular in financial mathematics in the 1980s, particularly in the theories of the random walk of asset prices. Clearly, we have to say that the example of Russian roulette does not need such apparatus, but many problems, particularly those resembling real-life situations, require the potency of a Monte Carlo simulator.
Monte Carlo Mathematics
It is a fact that “true” mathematicians do not like Monte Carlo methods. They believe that they rob us of the finesse and elegance of mathematics. They call it “brute force.” For we can replace a large portion of mathematical knowledge with a Monte Carlo simulator (and other computational tricks). For instance, someone with no formal knowledge of geometry can compute the mysterious, almost mystical Pi. How? By drawing a circle inside of a square, and “shooting” random bullets into the picture (as in an arcade), specifying equal probabilities of hitting any point on the map (something called a uniform distribution). The ratio of bullets inside the circle divided by those inside and outside the circle will deliver a multiple of the mystical Pi, with possibly infinite precision. Clearly, this is not an efficient use of a computer as Pi can be computed analytically, that is, in a mathematical form, but the method can give some users more intuition about the subject matter than lines of equations. Some people’s brains and intuitions are oriented in such a way that they are more capable of getting a point in such a manner (I count myself one of those). The computer might not be natural to our human brain; neither is mathematics.
I am not a “native” mathematician, that is, I am someone who does not speak mathematics as a native language, but someone who speaks it with a trace of a foreign accent. For I am not interested in mathematical properties
per se,
only in the application, while a mathematician would be interested in improving mathematics (via theorems and proofs). I proved incapable of concentrating on deciphering a single equation unless I was motivated by a real problem (with a modicum of greed); thus most of what I know comes from derivatives trading—options pushed me to study the math of probability. Many compulsive gamblers, who otherwise would be of middling intelligence, acquire remarkable card-counting skills thanks to their passionate greed.
Another analogy would be with grammar; mathematics is often tedious and insightless grammar. There are those who are interested in grammar for grammar’s sake, and those interested in avoiding solecisms while writing documents. Those of us in the second category are called “quants”—like physicists, we have more interest in the employment of the mathematical tool than in the tool itself. Mathematicians are born, never made. Physicists and quants too. I do not care about the “elegance” and “quality” of the mathematics I use so long as I can get the point right. I have recourse to Monte Carlo machines whenever I can. They can get the work done. They are also far more pedagogical, and I will use them in this book for the examples.
Indeed, probability is an introspective field of inquiry, as it affects more than one science, particularly the mother of all sciences: that of knowledge. It is impossible to assess the quality of the knowledge we are gathering without allowing a share of randomness in the manner it is obtained and cleaning the argument from the chance coincidence that could have seeped into its construction. In science, probability and information are treated in exactly the same manner. Literally every great thinker has dabbled with it, most of them obsessively. The two greatest minds to me, Einstein and Keynes, both started their intellectual journeys with it. Einstein wrote a major paper in 1905, in which he was almost the first to examine in probabilistic terms the succession of random events, namely the evolution of suspended particles in a stationary liquid. His article on the theory of the Brownian movement can be used as the backbone of the random walk approach used in financial modeling. As for Keynes, to the literate person he is not the political economist that tweed-clad leftists love to quote, but the author of the magisterial, introspective, and potent
Treatise on Probability.
For before his venturing into the murky field of political economy, Keynes was a probabilist. He also had other interesting attributes (he blew up trading his account after experiencing excessive opulence—people’s understanding of probability does not translate into their behavior).
The reader can guess that the next step from such probabilistic introspection is to get drawn into philosophy, particularly the branch of philosophy that concerns itself with knowledge, called epistemology or methodology, or philosophy of science. We will not get into the topic until later in the book.
FUN IN MY ATTIC
Making History
In the early 1990s, like many of my friends in quantitative finance, I became addicted to the various Monte Carlo engines, which I taught myself to build, thrilled to feel that I was generating history, a
Demiurgus.
It can be electrifying to generate virtual histories and watch the dispersion between the various results. Such dispersion is indicative of the degree of resistance to randomness. This is where I am convinced that I have been extremely lucky in my choice of career: One of the attractive aspects of my profession as a quantitative option trader is that I have close to 95% of my day free to think, read, and research (or “reflect” in the gym, on ski slopes, or, more effectively, on a park bench). I also had the privilege of frequently “working” from my well-equipped attic.
The dividend of the computer revolution to us did not come in the flooding of self-perpetuating e-mail messages and access to chat rooms; it was in the sudden availability of fast processors capable of generating a million sample paths per minute. Recall that I never considered myself better than an unenthusiastic equation solver and was rarely capable of prowess in the matter—being better at setting up equations than solving them. Suddenly, my engine allowed me to solve with minimal effort the most intractable of equations. Few solutions became out of reach.
Zorglubs Crowding the Attic
My Monte Carlo engine took me on a few interesting adventures. While my colleagues were immersed in news stories, central bank announcements, earnings reports, economic forecasts, sports results, and, not least, office politics, I started toying with it in fields bordering my home base of financial probability. A natural field of expansion for the amateur is evolutionary biology—the universality of its message and its application to markets are appealing. I started simulating populations of fast-mutating animals called Zorglubs under climatic changes and witnessing the most unexpected of conclusions—some of the results are recycled in
Chapter 5
. My aim, as a pure amateur fleeing the boredom of business life, was merely to develop intuitions for these events—the sort of intuitions that amateurs build away from the overly detailed sophistication of the professional researcher. I also toyed with molecular biology, generating randomly occurring cancer cells and witnessing some surprising aspects of their evolution. Naturally the analog to fabricating populations of Zorglubs was to simulate a population of “idiotic bull,” “impetuous bear,” and “cautious” traders under different market regimes, say booms and busts, and to examine their short-term and long-term survival. Under such a structure, “idiotic bull” traders who get rich from the rally would use the proceeds to buy more assets, driving prices higher, until their ultimate shellacking. Bearish traders, though, rarely made it in the boom to get to the bust. My models showed that ultimately almost nobody really survived; bears dropped out like flies in the rally and bulls ended up being slaughtered, as paper profits vanished when the music stopped. But there was one exception; some of those who traded options (I called them option buyers) had remarkable staying power and I wanted to be one of those. How? Because they could buy the insurance against blowup; they could get anxiety-free sleep at night, thanks to the knowledge that if their careers were threatened, it would not be owing to the outcome of a single day.
If the tone of this book seems steeped in the culture of Darwinism and evolutionary thinking, it does not come from any remotely formal training in the natural sciences, but from the evolutionary way of thinking taught by my Monte Carlo simulators.
I reckon that I outgrew the desire to generate random runs every time I want to explore an idea—but by dint of playing with a Monte Carlo engine for years I can no longer visualize a realized outcome without reference to the nonrealized ones. I call that “summing under histories,” borrowing the expression from the colorful physicist Richard Feynman who applied such methods to examine the dynamics of subatomic particles.
Using my Monte Carlo to make and remake history reminded me of the experimental novels (the so-called new novels) by such writers as Alain Robbe-Grillet, popular in the 1960s and 1970s. There the same chapter would be written and revised, the writer each time changing the plot like a new sample path. Somehow the author was freed from the past situation he helped create and allowed himself the indulgence to change the plot retroactively.
Denigration of History
One more word on history seen from a Monte Carlo perspective. The wisdom of such classical stories as Solon’s prods me to spend even more time in the company of the classical historians, even if the stories, like Solon’s warning, have benefited from the patina of time. However, this goes against the grain: Learning from history does not come naturally to us humans, a fact that is so visible in the endless repetitions of identically configured booms and busts in modern markets. By history I refer to the anecdotes, not the historical theorizing, the grand-scale historicism that aims to interpret events with theories based on uncovering some laws in the evolution of history—the sort of Hegelianism and pseudoscientific historicism leading to such calls as the end of history (it is pseudoscientific because it draws theories from past events without allowing for the fact that such combinations of events might have arisen from randomness; there is no way to verify the claims in a controlled experiment). For me, history is of use merely at the level of my desired sensibility, affecting the way I would wish to think by reference to past events, by being able to better steal the ideas of others and leverage them, correct the mental defect that seems to block my ability to learn from others. It is the respect of the elders that I would like to develop, reinforcing the awe I instinctively feel for people with gray hair, but that has eroded in my life as a trader where age and success are somewhat divorced. Indeed, I have two ways of learning from history: from the past, by reading the elders; and from the future, thanks to my Monte Carlo toy.
The Stove Is Hot
As I mentioned above, it is not natural for us to learn from history. We have enough clues to believe that our human endowment does not favor transfers of experience in a cultural way but through selection of those who bear some favorable traits. It is a platitude that children learn only from their own mistakes; they will cease to touch a burning stove only when they are themselves burned; no possible warning by others can lead to developing the smallest form of cautiousness. Adults, too, suffer from such a condition. This point has been examined by behavioral economics pioneers Daniel Kahneman and Amos Tversky with regard to the choices people make in selecting risky medical treatments—I myself have seen it in my being extremely lax in the area of detection and prevention (i.e., I refuse to derive my risks from the probabilities computed on others, feeling that I am somewhat special) yet extremely aggressive in the treatment of medical conditions (I overreact when I am burned), which is not coherent with rational behavior under uncertainty. This congenital denigration of the experience of others is not limited to children or to people like myself; it affects business decision makers and investors on a grand scale.
If you think that merely reading history books would help you learn “from other’s mistakes,” consider the following nineteenth-century experiment. In a well-known psychology case the Swiss doctor Claparède had an amnesic patient completely crippled with her ailment. Her condition was so bad that he would have to reintroduce himself to her at a frequency of once per fifteen minutes for her to remember who he was. One day he secreted a pin in his hand before shaking hers. The next day she quickly withdrew her hand as he tried to greet her,
but still did not recognize him.
Since then plenty of discussions of amnesic patients show some form of learning on the part of people without their being aware of it and without it being stored in conscious memory. The scientific name of the distinction between the two memories, the conscious and the nonconscious, is declarative and nondeclarative. Much of the risk avoidance that comes from experiences is part of the second. The only way I developed a respect for history is by making myself aware of the fact that I was not programmed to learn from it in a textbook format.
Actually, things can be worse than that: In some respects we do not learn from our own history. Several branches of research have been examining our inability to learn from our own reactions to past events: For example, people fail to learn that their emotional reactions to past experiences (positive or negative) were short-lived—yet they continuously retain the bias of thinking that the purchase of an object will bring long-lasting, possibly permanent, happiness or that a setback will cause severe and prolonged distress (when in the past similar setbacks did not affect them for very long and the joy of the purchase was short-lived).
All of my colleagues who I have known to denigrate history blew up spectacularly—and I have yet to encounter some such person who has not blown up. But the truly interesting point lies in the remarkable similarities in their approaches. The blowup, I will repeat, is different from merely incurring a monetary loss; it is losing money when one does not believe that such fact is possible at all. There is nothing wrong with a risk taker taking a hit provided one declares that one is a risk taker rather than that the risk being taken is small or nonexistent. Characteristically, blown-up traders think that they knew enough about the world to reject the possibility of the adverse event taking place: There was no courage in their taking such risks, just ignorance. I have noticed plenty of analogies between those who blew up in the stock market crash of 1987, those who blew up in the Japan meltdown of 1990, those who blew up in the bond market débâcle of 1994, those who blew up in Russia in 1998, and those who blew up shorting Nasdaq stocks. They all made claims to the effect that “these times are different” or that “their market was different,” and offered seemingly well-constructed, intellectual arguments (of an economic nature) to justify their claims; they were unable to accept that the experience of others was out there, in the open, freely available to all, with books detailing crashes in every bookstore. Aside from these generalized systemic blowups, I have seen hundreds of option traders forced to leave the business after blowing up in a stupid manner, in spite of warnings by the veterans, similar to a child’s touching the stove. This I find to resemble my own personal attitude with respect to the detection and prevention of the variety of ailments I may be subjected to. Every man believes himself to be quite different, a matter that amplifies the “why me?” shock upon a diagnosis.
Skills in Predicting Past History
We can discuss this point from different angles. Experts call one manifestation of such denigration of history
historical determinism.
In a nutshell we think that we would know when history is made; we believe that people who, say, witnessed the stock market crash of 1929 knew then that they lived an acute historical event and that, should these events repeat themselves, they too would know about such facts. Life for us is made to resemble an adventure movie, as we know ahead of time that something big is about to happen. It is hard to imagine that people who witnessed history did not know at the time how important the moment was. Somehow all respect we may have for history does not translate well into our treatment of the present.
Jean-Patrice of the last chapter was abruptly replaced by an interesting civil servant type who had never been involved in the randomness professions. He just went to the right civil servant schools where people learn to write reports and had some senior managerial position in the institution. As is typical with subjectively assessed positions he tried to make his predecessor look bad: Jean-Patrice was deemed sloppy and unprofessional. The civil servant’s first undertaking was to run a formal analysis of our transactions; he found that we traded a little too much, incurring very large back office expenditure. He analyzed a large segment of foreign exchange traders’ transactions, then wrote a report explaining that only close to 1% of these transactions generated significant profits; the rest generated either losses or small profits. He was shocked that the traders did not do more of the winners and less of the losers. It was obvious to him that we needed to comply with these instructions immediately. If we just doubled the winners, the results for the institution would be so great. How come you highly paid traders did not think about it before?
Things are always obvious after the fact. The civil servant was a very intelligent person, and this mistake is much more prevalent than one would think. It has to do with the way our mind handles historical information. When you look at the past, the past will always be deterministic, since only one single observation took place. Our mind will interpret most events not with the preceding ones in mind, but the following ones. Imagine taking a test knowing the answer. While we know that history flows forward, it is difficult to realize that we envision it backward. Why is it so? We will discuss the point in
Chapter 11
but here is a possible explanation: Our minds are not quite designed to understand how the world works, but, rather, to get out of trouble rapidly and have progeny. If they were made for us to understand things, then we would have a machine in it that would run the past history as in a VCR, with a correct chronology, and it would slow us down so much that we would have trouble operating. Psychologists call this overestimation of what one knew at the time of the event due to subsequent information the
hindsight bias,
the “I knew it all along” effect.
Now the civil servant called the trades that ended up as losers “gross mistakes,” just like journalists call decisions that end up costing a candidate his election a “mistake.” I will repeat this point until I get hoarse: A mistake is not something to be determined after the fact, but in the light of the information until that point.
A more vicious effect of such hindsight bias is that those who are very good at
predicting
the past will think of themselves as good at predicting the future, and feel confident about their ability to do so. This is why events like those of September 11, 2001, never teach us that we live in a world where important events are not predictable—even the Twin Towers’ collapse appears to have been predictable
then.
My Solon
I have another reason to be obsessed with Solon’s warning. I hark back to the very same strip of land in the Eastern Mediterranean where the story took place. My ancestors experienced bouts of extreme opulence and embarrassing penury over the course of a single generation, with abrupt regressions that people around me who have the memory of steady and linear betterment do not think feasible (at least not at the time of writing). Those around me either have (so far) had few family setbacks (except for the Great Depression) or, more generally, are not suffused with enough sense of history to reflect backward. For people of my background, Eastern Mediterranean Greek Orthodox and invaded Eastern Roman citizens, it was as if our soul had been wired with the remembrance of that sad spring day circa 500 years ago when Constantinople, under the invading Turks, fell out of history, leaving us the lost subjects of a dead empire, very prosperous minorities in an Islamic world—but with an extremely fragile wealth. Moreover, I vividly remember the image of my own dignified grandfather, a former deputy prime minister and son of a deputy prime minister (whom I never saw without a suit), residing in a nondescript apartment in Athens, his estate having been blown up during the Lebanese civil war. Incidentally, having experienced the ravages of war, I find undignified impoverishment far harsher than physical danger (somehow dying in full dignity appears to me far preferable to living a janitorial life, which is one of the reasons I dislike financial risks far more than physical ones). I am certain that Croesus worried more about the loss of his Kingdom than the perils to his life.
There is an important and nontrivial aspect of historical thinking, perhaps more applicable to the markets than anything else: Unlike many “hard” sciences, history cannot lend itself to experimentation. But somehow, overall, history is potent enough to deliver, on time, in the medium to long run, most of the possible scenarios, and to eventually bury the bad guy. Bad trades catch up with you, it is frequently said in the markets. Mathematicians of probability give that a fancy name:
ergodicity.
It means, roughly, that (under certain conditions) very long sample paths would end up resembling each other. The properties of a very, very long sample path would be similar to the Monte Carlo properties of an average of shorter ones. The janitor in
Chapter 1
who won the lottery, if he lived one thousand years, cannot be expected to win more lotteries. Those who were unlucky in life in spite of their skills would eventually rise. The lucky fool might have benefited from some luck in life; over the longer run he would slowly converge to the state of a less-lucky idiot. Each one would revert to his long-term properties.
DISTILLED THINKING ON YOUR PALMPILOT
Breaking News
The journalist, my
bête noire,
entered this book with George Will dealing with random outcomes. In the next step I will show how my Monte Carlo toy taught me to favor distilled thinking, by which I mean the thinking based on information around us that is stripped of meaningless but diverting clutter. For the difference between noise and information, the topic of this book (noise has more randomness) has an analog: that between journalism and history. To be competent, a journalist should view matters like a historian, and play down the value of the information he is providing, such as by saying: “Today the market went up, but this information is not too relevant as it emanates mostly from noise.” He would certainly lose his job by trivializing the value of the information in his hands. Not only is it difficult for the journalist to think more like a historian, but it is, alas, the historian who is becoming more like the journalist.
For an idea, age is beauty (it is premature to discuss the mathematics of the point).The applicability of Solon’s warning to a life in randomness, in contrast with the exact opposite message delivered by the prevailing media-soaked culture, reinforces my instinct to value distilled thought over newer thinking, regardless of its apparent sophistication—another reason to accumulate the hoary volumes by my bedside (I confess that the only news items I currently read are the far more interesting upscale social gossip stories found in
Tatler, Paris Match,
and
Vanity Fair—
in addition to
The Economist
). Aside from the decorum of ancient thought as opposed to the coarseness of fresh ink, I have spent some time phrasing the idea in the mathematics of evolutionary arguments and conditional probability. For an idea to have survived so long across so many cycles is indicative of its relative fitness. Noise, at least
some
noise, was filtered out. Mathematically, progress means that some new information is better than past information, not that the average of new information will supplant past information, which means that it is optimal for someone, when in doubt, to systematically reject the new idea, information, or method. Clearly and shockingly, always. Why?
The argument in favor of “new things” and even more “new new things” goes as follows: Look at the dramatic changes that have been brought about by the arrival of new technologies, such as the automobile, the airplane, the telephone, and the personal computer. Middlebrow inference (inference stripped of probabilistic thinking) would lead one to believe that all new technologies and inventions would likewise revolutionize our lives. But the answer is not so obvious: Here we only see and count the winners, to the exclusion of the losers (it is like saying that actors and writers are rich, ignoring the fact that actors are largely waiters—and lucky to be ones, for the less comely writers usually serve French fries at McDonald’s). Losers? The Saturday newspaper lists dozens of new patents of such items that can revolutionize our lives. People tend to infer that because
some
inventions have revolutionized our lives that inventions are good to endorse and we should favor the new over the old. I hold the opposite view. The opportunity cost of missing a “new new thing” like the airplane and the automobile is minuscule compared to the toxicity of all the garbage one has to go through to get to these jewels (assuming these have brought some improvement to our lives, which I frequently doubt).
Now the exact same argument applies to information. The problem with information is not that it is diverting and generally useless, but that it is toxic. We will examine the dubious value of the highly frequent news with a more technical discussion of signal filtering and observation frequency farther down. I will say here that such respect for the time-honored provides arguments to rule out any commerce with the babbling modern journalist and implies a minimal exposure to the media as a guiding principle for someone involved in decision making under uncertainty. If there is anything better than noise in the mass of “urgent” news pounding us, it would be like a needle in a haystack. People do not realize that the media is paid to get your attention. For a journalist, silence rarely surpasses any word.
On the rare occasions when I boarded the 6:42 train to New York I observed with amazement the hordes of depressed business commuters (who seemed to prefer to be elsewhere) studiously buried in
The Wall Street Journal,
apprised of the minutiae of companies that, at the time of writing now, are probably out of business. Indeed it is difficult to ascertain whether they seem depressed because they are reading the newspaper, or if depressive people tend to read the newspaper, or if people who are living outside their genetic habitat both read the newspaper and look sleepy and depressed. But while early on in my career such focus on noise would have offended me intellectually, as I would have deemed such information as too statistically insignificant for the derivation of any meaningful conclusion, I currently look at it with delight. I am happy to see such mass-scale idiotic decision making, prone to overreaction in their postperusal investment orders—in other words I currently see in the fact that people read such material an insurance for my continuing in the entertaining business of option trading against the fools of randomness. (It takes a huge investment in introspection to learn that the thirty or more hours spent “studying” the news last month neither had any predictive ability during your activities of that month nor did it impact your current knowledge of the world. This problem is similar to the weaknesses in our ability to correct for past errors: Like a health club membership taken out to satisfy a New Year’s resolution, people often think that it will surely be the next batch of news that will really make a difference to their understanding of things.)
Shiller Redux
Much of the thinking about the negative value of information on society in general was sparked by Robert Shiller. Not just in financial markets; but overall his 1981 paper may be the first mathematically formulated introspection on the manner in which society in general handles information. Shiller made his mark with his 1981 paper on the volatility of markets, where he determined that if a stock price is the estimated value of “something” (say the discounted cash flows from a corporation), then market prices are way too volatile in relation to tangible manifestations of that “something” (he used dividends as proxy). Prices swing more than the fundamentals they are supposed to reflect, they visibly overreact by being too high at times (when their price overshoots the good news or when they go up without any marked reason) or too low at others. The volatility differential between prices and information meant that something about “rational expectation” did not work. (Prices did not rationally reflect the long-term value of securities and were overshooting in either direction.) Markets had to be wrong. Shiller then pronounced markets to be not as efficient as established by financial theory (efficient markets meant, in a nutshell, that prices should adapt to all available information in such a way as to be totally unpredictable to us humans and prevent people from deriving profits). This conclusion set off calls by the religious orders of high finance for the destruction of the infidel who committed such apostasy. Interestingly, and by some strange coincidence, it is that very same Shiller who was trounced by George Will only one chapter ago.
The principal criticism against Shiller came from Robert C. Merton. The attacks were purely on methodological grounds (Shiller’s analysis was extremely rough; for instance, his using dividends in place of earnings was rather weak). Merton was also defending the official financial theory position that markets needed to be efficient and could not possibly deliver opportunities on a silver plate. Yet the same Robert C. Merton later introduced himself as the “founding partner” of a hedge fund that aimed at taking advantage of market inefficiencies. Setting aside the fact that Merton’s hedge fund blew up rather spectacularly from the
black swan problem
(with characteristic denial), his “founding” such a hedge fund requires, by implication, that he agrees with Shiller about the inefficiency of the market. The defender of the dogmas of modern finance and efficient markets started a fund that took advantage of market inefficiencies! It is as if the Pope converted to Islam.
Things are not getting any better these days. At the time of writing, news providers are offering all manner of updates, “breaking news” that can be delivered electronically in a wireless manner. The ratio of undistilled information to distilled is rising, saturating markets. The elder’s messages need not be delivered to you as imminent news.
This does not mean that all journalists are fooled by randomness noise providers: There are hordes of thoughtful journalists in the business (I would suggest London’s Anatole Kaletsky and New York’s Jim Grant and Alan Abelson as the underrated representatives of such a class among financial journalists; Gary Stix among scientific journalists); it is just that prominent media journalism is a thoughtless process of providing the noise that can capture people’s attention and there exists no mechanism for separating the two. As a matter of fact, smart journalists are often penalized. Like the lawyer in
Chapter 11
who does not care about the truth, but about arguments that can sway a jury whose intellectual defects he knows intimately, journalism goes to what can capture our attention, with adequate sound bites. Again, my scholarly friends would wonder why I am getting emotional stating the obvious things about the journalists; the problem with my profession is that we depend on them for what information we need to obtain.
Gerontocracy
A preference for distilled thinking implies favoring old investors and traders, that is, investors who have been exposed to markets the longest, a matter that is counter to the common Wall Street practice of preferring those that have been the most profitable, and preferring the youngest whenever possible. I toyed with Monte Carlo simulations of heterogeneous populations of traders under a variety of regimes (closely resembling historical ones), and found a significant advantage in selecting aged traders, using as a selection criterion their cumulative years of experience rather than their absolute success (conditional on their having survived without blowing up). “Survival of the fittest,” a term so hackneyed in the investment media, does not seem to be properly understood: Under regime switching, as we will see in
Chapter 5
, it will be unclear who is actually the fittest, and those who will survive are not necessarily those who appear to be the fittest. Curiously, it will be the oldest, simply because older people have been exposed longer to the rare event and can be, convincingly, more resistant to it. I was amused to discover a similar evolutionary argument in mate selection that considers that women prefer (on balance) to mate with healthy older men over healthy younger ones, everything else being equal, as the former provide some evidence of better genes. Gray hair signals an enhanced ability to survive—conditional on having reached the gray hair stage, a man is likely to be more resistant to the vagaries of life. Curiously, life insurers in renaissance Italy reached the same conclusion, by charging the same insurance for a man in his twenties as they did for a man in his fifties, a sign that they had the same life expectancy; once a man crossed the forty-year mark, he had shown that very few ailments could harm him. We now proceed to a mathematical rephrasing of these arguments.
PHILOSTRATUS IN MONTE CARLO:
ON THE DIFFERENCE BETWEEN NOISE
AND INFORMATION
The wise man listens to meaning; the fool only gets the noise. The modern Greek poet C. P. Cavafy wrote a piece in 1915 after Philostratus’ adage “For the gods perceive things in the future, ordinary people things in the present, but the wise perceive things about to happen.” Cavafy wrote:
In their intense meditation the hidden sound of things approaching reaches them and they listen reverently while in the street outside the people hear nothing at all.
I thought hard and long on how to explain with as little mathematics as possible the difference between noise and meaning, and how to show why the time scale is important in judging a historical event. The Monte Carlo simulator can provide us with such an intuition. We will start with an example borrowed from the investment world, as it can be explained rather easily, but the concept can be used in any application.
Let us manufacture a happily retired dentist, living in a pleasant, sunny town. We know
a priori
that he is an excellent investor, and that he will be expected to earn a return of 15% in excess of Treasury bills, with a 10% error rate per annum (what we call volatility). It means that out of 100 sample paths, we expect close to 68 of them to fall within a band of plus and minus 10% around the 15% excess return, i.e., between 5% and 25% (to be technical; the bell-shaped normal distribution has 68% of all observations falling between -1 and 1 standard deviations). It also means that 95 sample paths would fall between -5% and 35%.
Clearly, we are dealing with a very optimistic situation. The dentist builds for himself a nice trading desk in his attic, aiming to spend every business day there watching the market, while sipping decaffeinated cappuccino. He has an adventurous temperament, so he finds this activity more attractive than drilling the teeth of reluctant little old Park Avenue ladies.
He subscribes to a Web-based service that supplies him with continuous prices, now to be obtained for a fraction of what he pays for his coffee. He puts his inventory of securities in his spreadsheet and can thus instantaneously monitor the value of his speculative portfolio. We are living in the era of connectivity.
A 15% return with a 10% volatility (or uncertainty) per annum translates into a 93% probability of success in any given year. But seen at a narrow time scale, this translates into a mere 50.02% probability of success over any given second as shown in Table 3.1. Over the very narrow time increment, the observation will reveal close to nothing. Yet the dentist’s heart will not tell him that. Being emotional, he feels a pang with every loss, as it shows in red on his screen. He feels some pleasure when the performance is positive, but not in equivalent amount as the pain experienced when the performance is negative.
Table 3.1 Probability of success at different scales
Scale
Probability
1 year
93%
1 quarter
77%
1 month
67%
1 day
54%
1 hour
51.3%
1 minute
50.17%
1 second
50.02%
At the end of every day the dentist will be emotionally drained. A minute-by-minute examination of his performance means that each day (assuming eight hours per day) he will have 241 pleasurable minutes against 239 unpleasurable ones. These amount to 60,688 and 60,271, respectively, per year. Now realize that if the unpleasurable minute is worse in reverse pleasure than the pleasurable minute is in pleasure terms, then the dentist incurs a large deficit when examining his performance at a high frequency.
Consider the situation where the dentist examines his portfolio only upon receiving the monthly account from the brokerage house. As 67% of his months will be positive, he incurs only four pangs of pain per annum and eight uplifting experiences. This is the same dentist following the same strategy. Now consider the dentist looking at his performance only every year. Over the next 20 years that he is expected to live, he will experience 19 pleasant surprises for every unpleasant one!
This scaling property of randomness is generally misunderstood, even by professionals. I have seen Ph.D.s argue over a performance observed in a narrow time scale (meaningless by any standard). Before additional dumping on the journalist, more observations seem in order.
Viewing it from another angle, if we take the ratio of noise to what we call nonnoise (i.e., left column/right column), which we have the privilege here of examining quantitatively, then we have the following. Over one year we observe roughly 0.7 parts noise for every one part performance. Over one month, we observe roughly 2.32 parts noise for every one part performance. Over one hour, 30 parts noise for every one part performance, and over one second, 1,796 parts noise for every one part performance.
A few conclusions:
1.         Over a short time increment, one observes the variability of the portfolio, not the returns. In other words, one sees the variance, little else. I always remind myself that what one observes is at best a combination of variance and returns, not just returns (but my emotions do not care about what I tell myself).
2.         Our emotions are not designed to understand the point. The dentist did better when he dealt with monthly statements rather than more frequent ones. Perhaps it would be even better for him if he limited himself to yearly statements. (If you think that you can control your emotions, think that some people also believe that they can control their heartbeat or hair growth.)
3.         When I see an investor monitoring his portfolio with live prices on his cellular telephone or his handheld, I smile and smile.
Finally, I reckon that I am not immune to such an emotional defect. But I deal with it by having no access to information, except in rare circumstances. Again, I prefer to read poetry. If an event is important enough, it will find its way to my ears. I will return to this point in time.
The same methodology can explain why the news (the high scale) is full of noise and why history (the low scale) is largely stripped of it (though fraught with interpretation problems). This explains why I prefer not to read the newspaper (outside of the obituary), why I never chitchat about markets, and, when in a trading room, I frequent the mathematicians and the secretaries, not the traders. It explains why it is better to read
The New Yorker
on Mondays than
The Wall Street Journal
every morning (from the standpoint of frequency, aside from the massive gap in intellectual class between the two publications).
Finally, this explains why people who look too closely at randomness burn out, their emotions drained by the series of pangs they experience. Regardless of what people claim, a negative pang is not offset by a positive one (some psychologists estimate the negative effect for an average loss to be up to 2.5 the magnitude of a positive one); it will lead to an emotional deficit.
Now that you know that the high-frequency dentist has more exposure to both stress and positive pangs, and that these do not cancel out, consider that people in lab coats have examined some scary properties of this type of negative pangs on the neural system (the usual expected effect: high blood pressure; the less expected: chronic stress leads to memory loss, lessening of brain plasticity, and brain damage). To my knowledge there are no studies investigating the exact properties of trader’s burnout, but a daily exposure to such high degrees of randomness without much control will have physiological effects on humans (nobody studied the effect of such exposure on the risk of cancer). What economists did not understand for a long time about positive and negative kicks is that both their biology and their intensity are different. Consider that they are mediated in different parts of the brain—and that the degree of rationality in decisions made subsequent to a gain is extremely different from the one after a loss.
Note also that the implication that wealth does not count so much into one’s well-being as the route one uses to get to it.
Some so-called wise and rational persons often blame me for “ignoring” possible valuable information in the daily newspaper and refusing to discount the details of the noise as “short-term events.” Some of my employers have blamed me for living on a different planet.
My problem is that I am not rational and I am extremely prone to drown in randomness and to incur emotional torture. I am aware of my need to ruminate on park benches and in cafés away from information, but I can only do so if I am somewhat deprived of it. My sole advantage in life is that I know some of my weaknesses, mostly that I am incapable of taming my emotions facing news and incapable of seeing a performance with a clear head. Silence is far better. More on that in Part III.


================================================================================
CHAPTER/SECTION 305 (Item 314)
================================================================================

Four
•
RANDOMNESS, NONSENSE, AND THE SCIENTIFIC INTELLECTUAL
On extending the Monte Carlo generator to produce artificial thinking and compare it with rigorous nonrandom constructs. The science wars enter the business world. Why the aesthete in me loves to be fooled by randomness.
RANDOMNESS AND THE VERB
O
ur Monte Carlo engine can take us into more literary territory. Increasingly, a distinction is being made between the scientific intellectual and the literary intellectual—culminating with what is called the “science wars,” plotting factions of literate nonscientists against no less literate scientists. The distinction between the two approaches originated in Vienna in the 1930s, with a collection of physicists who decided that the large gains in science were becoming significant enough to make claims on the field known to belong to the humanities. In their view, literary thinking could conceal plenty of well-sounding non-sense. They wanted to strip thinking from rhetoric (except in literature and poetry where it properly belonged).
The way they introduced rigor into intellectual life is by declaring that a statement could fall only into two categories:
deductive,
like “2 +2 =4,” i.e., incontrovertibly flowing from a precisely defined axiomatic framework (here the rules of arithmetic), or
inductive,
i.e., verifiable in some manner (experience, statistics, etc.), like “it rains in Spain” or “New Yorkers are generally rude.” Anything else was plain unadulterated hogwash (music could be a far better replacement to metaphysics). Needless to say that inductive statements may turn out to be difficult, even impossible, to verify, as we will see with the black swan problem—and empiricism can be worse than any other form of hogwash when it gives someone confidence (it will take me a few chapters to drill the point). However, it was a good start to make intellectuals responsible for providing some form of evidence for their statements. This Vienna Circle was at the origin of the development of the ideas of Popper, Wittgenstein (in his later phase), Carnap, and flocks of others. Whatever merit their original ideas may have, the impact on both philosophy and the practice of science has been significant. Some of their impact on nonphilosophical intellectual life is starting to develop, albeit considerably more slowly.
One conceivable way to discriminate between a scientific intellectual and a literary intellectual is by considering that a scientific intellectual can usually recognize the writing of another but that the literary intellectual would not be able to tell the difference between lines jotted down by a scientist and those by a glib nonscientist. This is even more apparent when the literary intellectual starts using scientific buzzwords, like “uncertainty principle,” “Gödel’s theorem,” “parallel universe,” or “relativity,” either out of context or, as often, in exact opposition to the scientific meaning. I suggest reading the hilarious
Fashionable Nonsense
by Alan Sokal for an illustration of such practice (I was laughing so loudly and so frequently while reading it on a plane that other passengers kept whispering things about me). By dumping the kitchen sink of scientific references in a paper, one can make another literary intellectual believe that one’s material has the stamp of science. Clearly, to a scientist, science lies in the rigor of the inference, not in random references to such grandiose concepts as general relativity or quantum indeterminacy. Such rigor can be spelled out in plain English. Science is method and rigor; it can be identified in the simplest of prose writing. For instance, what struck me while reading Richard Dawkins’
Selfish Gene
is that, although the text does not exhibit a single equation, it seems as if it were translated from the language of mathematics. Yet it is artistic prose.
Reverse Turing Test
Randomness can be of considerable help with the matter. For there is another, far more entertaining way to make the distinction between the babbler and the thinker. You can sometimes replicate something that can be mistaken for a literary discourse with a Monte Carlo generator but it is not possible randomly to construct a scientific one. Rhetoric can be constructed randomly, but not genuine scientific knowledge. This is the application of
Turing’s test
of artificial intelligence, except in reverse. What is the Turing test? The brilliant British mathematician, eccentric, and computer pioneer Alan Turing came up with the following test: A computer can be said to be intelligent if it can (on average) fool a human into mistaking it for another human. The converse should be true. A human can be said to be unintelligent if we can replicate his speech by a computer, which we know is unintelligent, and fool a human into believing that it was written by a human. Can one produce a piece of work that can be largely mistaken for Derrida entirely randomly?
The answer seems to be yes. Aside from the hoax by Alan Sokal (the same of the hilarious book a few lines ago), who managed to produce nonsense and get it published by some prominent journal, there are Monte Carlo generators designed to structure such texts and write entire papers. Fed with “postmodernist” texts, they can randomize phrases under a method called recursive grammar, and produce grammatically sound but entirely meaningless sentences that sound like Jacques Derrida, Camille Paglia, and such a crowd. Owing to the fuzziness of his thought, the literary intellectual can be fooled by randomness.
At the Monash University program in Australia featuring the Dada Engine built by Andrew C. Bulhak, I toyed with the engine and generated a few papers containing the following sentences:
However, the main theme of the works of Rushdie is not theory, as the dialectic paradigm of reality suggests, but pretheory. The premise of the neosemanticist paradigm of discourse implies that sexual identity, ironically, has significance.
Many narratives concerning the role of the writer as observer may be revealed. It could be said that if cultural narrative holds, we have to choose between the dialectic paradigm of narrative and neoconceptual Marxism. Sartre’s analysis of cultural narrative holds that society, paradoxically, has objective value.
Thus, the premise of the neodialectic paradigm of expression implies that consciousness may be used to reinforce hierarchy, but only if reality is distinct from consciousness; if that is not the case, we can assume that language has intrinsic meaning.
Some business speeches belong to this category in their own right, except that they are less elegant and draw on a different type of vocabulary than the literary ones. We can randomly construct a speech imitating that of your chief executive officer to ensure whether what he is saying has value, or if it is merely dressed-up nonsense from someone who was lucky to be put there. How? You select randomly five phrases below, then connect them by adding the minimum required to construct a grammatically sound speech.
We look after our customer’s interests / the road ahead / our assets are our people / creation of shareholder value / our vision / our expertise lies in / we provide interactive solutions / we position ourselves in this market / how to serve our customers better / short-term pain for long-term gain / we will be rewarded in the long run / we play from our strength and improve our weaknesses / courage and determination will prevail / we are committed to innovation and technology / a happy employee is a productive employee / commitment to excellence / strategic plan / our work ethics.
If this bears too close a resemblance to the speech you just heard from the boss of your company, then I suggest looking for a new job.
The Father of All Pseudothinkers
It is hard to resist discussion of artificial history without a comment on the father of all pseudothinkers, Hegel. Hegel writes a jargon that is meaningless outside of a chic Left Bank Parisian café or the humanities department of some university extremely well insulated from the real world. I suggest this passage from the German “philosopher” (this passage was detected, translated, and reviled by Karl Popper):
Sound is the change in the specific condition of segregation of the material parts, and in the negation of this condition; merely an abstract or an ideal ideality, as it were, of that specification. But this change, accordingly, is itself immediately the negation of the material specific subsistence; which is, therefore, real ideality of specific gravity and cohesion, i.e.—heat. The heating up of sounding bodies, just as of beaten and or rubbed ones, is the appearance of heat, originating conceptually together with sound.
Even a Monte Carlo engine could not sound as random as the great philosophical master thinker (it would take plenty of sample runs to get the mixture of “heat” and “sound.” People call that philosophy and frequently finance it with taxpayer subsidies! Now consider that Hegelian thinking is generally linked to a “scientific” approach to history; it has produced such results as Marxist regimes and even a branch called “neo-Hegelian” thinking. These “thinkers” should be given an undergraduate-level class on statistical sampling theory prior to their release into the open world.
MONTE CARLO POETRY
There are instances where I like to be fooled by randomness. My allergy to nonsense and verbiage dissipates when it comes to art and poetry. On the one hand, I try to define myself and behave officially as a no-nonsense hyperrealist ferreting out the role of chance; on the other, I have no qualms indulging in all manner of personal superstitions. Where do I draw the line? The answer is aesthetics. Some aesthetic forms appeal to something in our biology, whether or not they originate in random associations or plain hallucination. Something in our human genes is deeply moved by the fuzziness and ambiguity of language; then why fight it?
The poetry and language lover in me was initially depressed by the account of the “exquisite cadavers” poetic exercise, where interesting and poetic sentences are randomly constructed. By throwing enough words together, some unusual and magical-sounding metaphor is bound to emerge according to the laws of combinatorics. Yet one cannot deny that some of these poems are of ravishing beauty. Who cares about their origin if they manage to please our aesthetic senses?
The story of the “exquisite cadavers” is as follows. In the aftermath of the First World War, a collection of surrealist poets—which included André Breton, their pope, Paul Eluard, and others—got together in cafés and tried the following exercise (modern literary critics attribute the exercise to the depressed mood after the war and the need to escape reality). On a folded piece of paper, in turn, each one of them would write a predetermined part of a sentence, not knowing the others’ choice. The first would pick an adjective, the second a noun, the third a verb, the fourth an adjective, and the fifth a noun. The first publicized exercise of such random (and collective) arrangement produced the following poetic sentence:
The exquisite cadavers shall drink the new wine.
(Les cadavres exquis boiront le vin nouveau.)
Impressive? It sounds even more poetic in the native French. Quite impressive poetry has been produced in such a manner, sometimes with the aid of a computer. But poetry has never been truly taken seriously outside of the beauty of its associations, whether they have been produced by the random ranting of one or more disorganized brains, or the more elaborate constructions of one conscious creator.
Now, regardless of whether the poetry was obtained by a Monte Carlo engine or sung by a blind man in Asia Minor, language is potent in bringing pleasure and solace. Testing its intellectual validity by translating it into simple logical arguments would rob it of a varying degree of its potency, sometimes excessively; nothing can be more bland than translated poetry. A convincing argument of the role of language is the existence of surviving holy languages, uncorrupted by the no-nonsense tests of daily use. Semitic religions, that is Judaism, Islam, and original Christianity understood the point: Keep a language away from the rationalization of daily use and avoid the corruption of the vernacular. Four decades ago, the Catholic church translated the services and liturgies from Latin to the local vernaculars; one may wonder if this caused a drop in religious beliefs. Suddenly religion subjected itself to being judged by intellectual and scientific, without the aesthetic, standards. The Greek Orthodox church made the lucky mistake, upon translating some of its prayers from Church Greek into the Semitic-based vernacular spoken by the Grecosyrians of the Antioch region (southern Turkey and northern Syria), of choosing classical Arabic, an entirely dead language. My folks are thus lucky to pray in a mixture of dead Koiné (Church Greek) and no less dead Koranic Arabic.
What does this point have to do with a book on randomness? Our human nature dictates a need for
péché mignon.
Even the economists, who usually find completely abstruse ways to escape reality, are starting to understand that what makes us tick is not necessarily the calculating accountant in us. We do not need to be rational and scientific when it comes to the details of our daily life—only in those that can harm us and threaten our survival. Modern life seems to invite us to do the exact opposite; become extremely realistic and intellectual when it comes to such matters as religion and personal behavior, yet as irrational as possible when it comes to matters ruled by randomness (say, portfolio or real estate investments). I have encountered colleagues, “rational,” no-nonsense people, who do not understand why I cherish the poetry of Baudelaire and Saint-John Perse or obscure (and often impenetrable) writers like Elias Canetti, J. L. Borges, or Walter Benjamin. Yet they get sucked into listening to the “analyses” of a television “guru,” or into buying the stock of a company they know absolutely nothing about, based on tips by neighbors who drive expensive cars. The Vienna Circle, in their dumping on Hegel-style verbiage-based philosophy, explained that, from a scientific standpoint, it was plain garbage, and, from an artistic point of view, it was inferior to music. I have to say that I find Baudelaire far more pleasant to frequent than CNN newscasters or listening to George Will.
There is a Yiddish saying: “If I am going to be forced to eat pork, it better be of the best kind.” If I am going to be fooled by randomness, it better be of the beautiful (and harmless) kind. This point will be made again in Part III.


================================================================================
CHAPTER/SECTION 306 (Item 315)
================================================================================

Five
•
SURVIVAL OF THE LEAST FIT—CAN
EVOLUTION BE FOOLED
BY RANDOMNESS?
A case study on two rare events. On rare events and evolution. How “Darwinism” and evolution are concepts that are misunderstood in the nonbiological world. Life is not continuous. How evolution will be fooled by randomness. A prolegomenon for the problem of induction.
CARLOS THE EMERGING-MARKETS WIZARD
I
used to meet Carlos at a variety of New York parties, where he would show up impeccably dressed, though a bit shy with the ladies. I used to regularly pounce on him and try to pick his brains about what he did for a living, namely buying or selling emerging-market bonds. A nice gentleman, he complied with my requests, but tensed up; for him speaking English, in spite of his fluency, seemed to require some expenditure of physical effort that made him contract his head and neck muscles (some people are not made to speak foreign languages). What are emerging-market bonds? “Emerging market” is the politically correct euphemism to define a country that is not very developed (as a skeptic, I do not impart to their “emergence”such linguistic certainty).The bonds are financial instruments issued by these foreign governments, mostly Russia, Mexico, Brazil, Argentina, and Turkey. These bonds traded for pennies when these governments were not doing well. Suddenly investors rushed into these markets in the early 1990s and pushed the envelope further and further by acquiring increasingly more exotic securities. All these countries were building hotels where United States cable news channels were available, with health clubs equipped with treadmills and large-screen television sets that made them join the global village. They all had access to the same gurus and financial entertainers. Bankers would come to invest in their bonds and the countries would use the proceeds to build nicer hotels so more investors would visit. At some point these bonds became the vogue and went from pennies to dollars; those who knew the slightest thing about them accumulated vast fortunes.
Carlos supposedly comes from a patrician Latin-American family that was heavily impoverished by the economic troubles of the 1980s, but, again, I have rarely run into anyone from a ravaged country whose family did not at some juncture own an entire province or, say, supply the Russian czar with sets of dominoes. After brilliant undergraduate studies, he went to Harvard to pursue a Ph.D. in economics, as it was the sort of thing Latin-American patricians had gotten into the habit of doing at the time (with a view to saving their economies from the evils of non-Ph.D. hands). He was a good student but could not find a decent thesis topic for his dissertation. Nor did he gain the respect of his thesis advisor, who found him unimaginative. Carlos settled for a master’s degree and a Wall Street career.
The nascent emerging-market desk of a New York bank hired Carlos in 1992. He had the right ingredients for success; he knew where on the map to find the countries that issued “Brady bonds,” dollar-denominated debt instruments issued by Less Developed Countries. He knew what Gross Domestic Product meant. He looked serious, brainy, and well-spoken, in spite of his heavy Spanish accent. He was the kind of person banks felt comfortable putting in front of their customers. What a contrast with the other traders who lacked polish!
Carlos got there right in time to see things happening in that market. When he joined the bank, the market for emerging-market debt instruments was small and traders were located in undesirable parts of trading floors. But the activity rapidly became a large, and growing, part of the bank’s revenues.
He was generic among this community of emerging market traders; they are a collection of cosmopolitan patricians from across the emerging-market world that remind me of the international coffee hour at the Wharton School. I find it odd that rarely does a person specialize in the market of his or her birthplace. Mexicans based in London trade Russian securities, Iranians and Greeks specialize in Brazilian bonds, and Argentines trade Turkish securities. Unlike my experience with real traders, they are generally urbane, dress well, collect art, but are nonintellectual. They seem too conformist to be true traders. They are mostly between thirty and forty, owing to the youth of their market. You can expect many of them to hold season tickets to the Metropolitan Opera. True traders, I believe, dress sloppily, are often ugly, and exhibit the intellectual curiosity of someone who would be more interested in the information-revealing contents of the garbage can than the Cézanne painting on the wall.
Carlos thrived as a trader-economist. He had a large network of friends in the various Latin-American countries and knew exactly what took place there. He bought bonds that he found attractive, either because they paid him a good rate of interest, or because he believed that they would become more in demand in the future, therefore appreciating in price. It would be perhaps erroneous to call him a
trader.
A trader buys and sells (he may sell what he does not own and buy it back later, hopefully making a profit in a decline; this is called “shorting”). Carlos just bought—and he bought in size. He believed that he was paid a good risk premium to hold these bonds because there was economic value in lending to these countries. Shorting, in his opinion, made no economic sense.
Within the bank Carlos was the emerging-markets reference. He could produce the latest economic figures at the drop of a hat. He had frequent lunches with the chairman. In his opinion, trading was economics, little else. It had worked so well for him. He got promotion after promotion, until he became the head trader of the emerging-market desk at the institution. Starting in 1995, Carlos did exponentially well in his new function, getting an expansion of his capital on a steady basis (i.e., the bank allocated a larger portion of its funds to his operation)—so fast that he was incapable of using up the new risk limits.
The Good Years
The reason Carlos had good years was not just because he bought emerging-market bonds and their value went up over the period. It was mostly because he also bought dips. He accumulated when prices experienced a momentary panic. The year 1997 would have been bad had he not added to his position after the dip in October that accompanied the false stock market crash that took place then. Overcoming these small reversals of fortune made him feel invincible. He could do no wrong. He believed that the economic intuition he was endowed with allowed him to make good trading decisions. After a market dip he would verify the fundamentals, and, if they remained sound, he would buy more of the security and lighten up as the market recovered. Looking back at the emerging-market bonds between the time Carlos started his involvement with these markets and his last bonus check in December 1997, one sees an upward sloping line, with occasional blips, such as the Mexican devaluation of 1995, followed by an extended rally. One can also see some occasional dips that turned out to be “excellent buying opportunities.”
It was the summer of 1998 that undid Carlos—that last dip did not translate into a rally. His track record up to that point included just one bad quarter—but bad it was. He had earned for his bank close to $80 million cumulatively in his previous years. He lost $300 million in just one summer. What happened? When the market started dipping in June, his friendly sources informed him that the sell-off was merely the result of a “liquidation” by a New Jersey hedge fund run by a former Wharton professor. That fund specialized in mortgage securities and had just received instructions to wind down the overall inventory. The inventory included some Russian bonds, mostly because
yield hogs,
as these funds are known, engage in the activity of building a “diversified” portfolio of high-yielding securities.
Averaging Down
When the market started falling, he accumulated more Russian bonds, at an average of around $52. That was Carlos’ trait, average down. The problems, he deemed, had nothing to do with Russia, and it was not some New Jersey fund run by some mad scientist that was going to decide the fate of Russia. “Read my lips: It’s a li-qui-dation!” he yelled at those who questioned his buying.
By the end of June, his trading revenues for 1998 had dropped from up $60 million to up $20 million. That made him angry. But he calculated that should the market rise back to the pre–New Jersey sell-off, then he would be up $100 million. That was unavoidable, he asserted. These bonds, he said, would never, ever trade below $48. He was risking so little, to possibly make so much.
Then came July. The market dropped a bit more. The benchmark Russian bond was now at $43. His positions were underwater, but he increased his stakes. By now he was down $30 million for the year. His bosses were starting to become nervous, but he kept telling them that, after all, Russia would not go under. He repeated the cliché that it was too big to fail. He estimated that bailing them out would cost so little and would benefit the world economy so much that it did not make sense to liquidate his inventory now. “This is the time to buy, not to sell,” he said repeatedly. “These bonds are trading very close to their possible default value.” In other words, should Russia go into default, and run out of dollars to pay the interest on its debt, these bonds would hardly budge. Where did he get this idea? From discussions with other traders and emerging-market economists (or trader-economist hybrids). Carlos put about half his net worth, then $5 million, in the Russia Principal Bond. “I will retire on these profits,” he told the stockbroker who executed the trade.
Lines in the Sand
The market kept going through the lines in the sand. By early August, they were trading in the thirties. By the middle of August, they were in the twenties. And he was taking no action. He felt that the price on the screen was quite irrelevant in his business of buying “value.”
Signs of battle fatigue were starting to show in his behavior. Carlos was getting jumpy and losing some of his composure. He yelled at someone in a meeting: “Stop losses are for schmucks! I am not going to buy high and sell low!” During his string of successes he had learned to put down and berate traders of the non-emerging-market variety. “Had we gotten out in October 1997 after our heavy loss we would not have had those excellent 1997 results,” he was also known to repeat. He also told management: “These bonds trade at very depressed levels. Those who can invest now in these markets would realize wonderful returns.” Every morning, Carlos spent an hour discussing the situation with market economists around the globe. They all seemed to present a similar story: This sell-off is overdone.
Carlos’ desk experienced losses in other emerging markets as well. He also lost money in the domestic Russian Ruble Bond market. His losses were mounting, but he kept telling his management rumors about very large losses among other banks—larger than his. He felt justified to show that “he fared well relative to the industry.”This is a symptom of systemic troubles; it shows that there was an entire community of traders who were conducting the exact same activity. Such statements, that other traders had also gotten into trouble, are self-incriminating. A trader’s mental construction should direct him to do precisely
what other people do not do.
Toward the end of August, the bellwether Russia Principal Bonds were trading below $10. Carlos’ net worth was reduced by almost half. He was dismissed. So was his boss, the head of trading. The president of the bank was demoted to a “newly created position.” Board members could not understand why the bank had so much exposure to a government that was not paying its own employees—which, disturbingly, included armed soldiers. This was one of the small points that emerging-market economists around the globe, from talking to each other so much, forgot to take into account. Veteran trader Marty O’Connell calls this the firehouse effect. He had observed that firemen with much downtime who talk to each other for too long come to agree on many things that an outside, impartial observer would find ludicrous (they develop political ideas that are very similar). Psychologists give it a fancier name, but my friend Marty has no training in behavioral sciences.
The nerdy types at the International Monetary Fund had been taken for a ride by the Russian government, which cheated on its account. Let us remember that economists are evaluated on how intelligent they sound, not on a scientific measure of their knowledge of reality. However, the price of the bonds was not fooled. It knew more than the economists, more than the Carloses of the emerging-market departments.
Louie, a veteran trader on the neighboring desk who suffered much humiliation by these rich emerging-market traders, was there, vindicated. Louie was then a fifty-two-year-old Brooklyn-born-and-raised trader who over three decades survived every single conceivable market cycle. He calmly looked at Carlos being escorted by a security guard to the door like a captured soldier taken to the arena. He muttered in his Brooklyn accent: “
Economics Schmeconomics. It is all market dynamics.
”
Carlos is now out of the market. The possibility that history may prove him right (at some point in the future) has nothing to do with the fact that he is a bad trader. He has all of the traits of a thoughtful gentleman, and would be an ideal son-in-law. But he has most of the attributes of the bad trader. And, at any point in time, the richest traders are often the worst traders. This, I will call the
cross-sectional problem:
At a given time in the market, the most successful traders are likely to be those that are best fit to the latest cycle. This does not happen too often with dentists or pianists—because these professions are more immune to randomness.
JOHN THE HIGH-YIELD TRADER
We met John, Nero’s neighbor, in
Chapter 1
. At the age of thirty-five he had been on Wall Street as a corporate high-yield bonds trader for seven years, since his graduation from Pace University’s Lubin School of Business. He rose to head up a team of ten traders in record time—thanks to a jump between two similar Wall Street firms that afforded him a generous profit-sharing contract. The contract allowed him to be paid 20% of his profits, as they stood at the end of each calendar year. In addition, he was allowed to invest his own personal money in his trades—a great privilege.
John is not someone who can be termed as principally intelligent, but he was believed to be endowed with a good measure of business sense. He was said to be “pragmatic” and “professional.” He gave the impression that he was born a businessperson, never saying anything remotely unusual or out of place. He remained calm in most circumstances, rarely betraying any form of emotion. Even his occasional cursing (this is Wall Street!) was so much in context that it sounded, well, professional.
John dressed impeccably. This was in part due to his monthly trips to London where his unit had a satellite supervising European high-yield activities. He wore a Savile Row tailored dark business suit, with a Ferragamo tie—enough to convey the impression that he was the epitome of the successful Wall Street professional. Each time Nero ran into him he came away feeling poorly dressed.
John’s desk engaged principally in an activity called “high-yield” trading, which consisted in acquiring “cheap” bonds that yielded, say, 10%, while the borrowing rate for his institution was 5.5%. It netted a 4.5% revenue, also called
interest rate differential—
which seemed small except that he could leverage himself and multiply such profit by the leverage factor. He did this in various countries, borrowing at the local rate and investing in “risky” assets. It was easy for him to amass over $3 billion dollars in face value of such trade across a variety of continents. He hedged the interest rate exposure by selling U.S., U.K., French, and other government bond futures, thus limiting his bet to the differential between the two instruments. He felt protected by this hedging strategy—cocooned (or so he thought) against those nasty fluctuations in the world’s global interest rates.
The Quant Who Knew Computers and Equations
John was assisted by Henry, a foreign quant whose English was incomprehensible, but who was believed to be at least equally competent in risk-management methods. John knew no math; he relied on Henry. “His brains and my business sense,” he was wont to say. Henry supplied him with risk assessments concerning the overall portfolio. Whenever John felt worried, he would ask Henry for another freshly updated report. Henry was a graduate student in Operations Research when John hired him. His specialty was a field called Computational Finance, which, as its name indicates, seems to focus solely on running computer programs overnight. Henry’s income went from $50,000 to $600,000 in three years.
Most of the profit John generated for the institution was not attributable to the interest rate differential between the instruments described above. It came from the changes in the value of the securities John held, mostly because many other traders were acquiring them to imitate John’s trading strategy (thus causing the price of these assets to rise). The interest rate differential was getting closer to what John believed was “fair value.” John believed that the methods he used to calculate “fair value” were sound. He was backed by an entire department that helped him analyze and determine which bonds were attractive and offered capital appreciation potential. It was normal for him to be earning these large profits over time.
John made steady income for his employers, perhaps even better than steady. Every year the revenues he generated almost doubled as compared to the previous year. During his last year, his income experienced a quantum leap as he saw the capital allocated to his trades swell beyond his wildest expectations. His bonus check was for $10 million (pretax, which would generate close to a $5 million total tax bill). John’s personal net worth reached $1 million at the age of thirty-two. By the age of thirty-five it had exceeded $16 million. Most of it came from the accumulation of bonuses—but a sizeable share came from profits on his personal portfolio. Of the $16 million, about $14 million he insisted in keeping invested in his business. They allowed him, thanks to the leverage (i.e., use of borrowed money), to keep a portfolio of $50 million involved in his trades, with $36 million borrowed from the bank. The effect of the leverage is that a small loss would be compounded and would wipe him out.
It took only a few days for the $14 million to turn into thin air—and for John to lose his job at the same time. As with Carlos, it all happened during the summer of 1998, with the meltdown of high-yield bond values. Markets went into a volatile phase during which nearly everything he had invested in went against him
at the same time.
His hedges no longer worked out. He was mad at Henry for not having figured out that these events could happen. Perhaps there was a bug in the program.
His reaction to the first losses was, characteristically, to ignore the market. “One would go crazy if one were to listen to the mood swings of the market,” he said. What he meant by that statement was that the “noise” was mean reverting, and would likely be offset by “noise” in the opposite direction. That was the translation in plain English of what Henry explained to him. But the “noise” kept adding up in the same direction.
As in a biblical cycle, it took seven years to make John a hero and just seven days to make him a failure. John is now a pariah; he is out of a job and his telephone calls are not returned. Many of his friends were in the same situation. How? With all that information available to him, his perfect track record (and therefore, in his eyes, an above-average intelligence and skill-set), and the benefit of sophisticated mathematics, how could he have failed? Is it perhaps possible that he forgot about the shadowy figure of randomness?
It took a long time for John to figure out what had happened, owing to the rapidity with which the events unfolded and his state of shellshock. The dip in the market was not very large. It was just that his leverage was enormous. What was more shocking for him was that all their calculations gave the event a probability of 1 in 1,000,000,000,000,000,000,000,000 years. Henry called that a “ten sigma” event. The fact that Henry doubled the odds did not seem to matter. It made the probability 2 in 1,000,000,000,000,000,000,000,000 years.
When will John recover from the ordeal? Probably never. The reason is not because John lost money. Losing money is something good traders are accustomed to. It is because he blew up; he lost more than he planned to lose. His personal confidence was wiped out. But there is another reason why John may never recover. The reason is that John was never skilled in the first place. He is one of those people who happened to be there when it all happened. He may have looked the part but there are plenty of people who look the part.
Following the incident, John regarded himself “ruined”; yet his net worth is still close to $1 million, which could be the envy of more than 99.9% of the inhabitants of our planet. Yet there is a difference between a wealth level reached from
above
and a wealth reached from
below.
The road from $16 million to $1 million is not as pleasant as the one from 0 to $1 million. In addition, John is full of shame; he still worries about running into old friends on the street.
His employer should perhaps be most unhappy with the overall outcome. John pulled some money out of the episode, the $1 million he had saved. He should be thankful that the episode did not cost him anything—except the emotional drain. His net worth did not become negative. That was not the case for his last employer. John had earned for the employers, New York investment banks, around $250 million in the course of the seven years. He lost more than $600 million for his last employer in barely a few days.
The Traits They Shared
The reader needs to be warned that not all of the emerging-market and high-yield traders talk and behave like Carlos and John. Only the most successful ones, alas, or perhaps those who were the most successful during the 1992–1998 bull cycle.
At their age, both John and Carlos still have the chance to make a career. It would be wise for them to look outside of their current profession. The odds are that they will not survive the incident. Why? Because by discussing the situation with each of them, one can rapidly see that they share the traits of the
acute successful randomness fool
who, in addition, operates in the most random of environments. What is more worrisome is that their bosses and employers shared the same trait. They, too, are permanently out of the market. We will see throughout this book what characterizes the trait. Again, there may not be a clear definition for it, but you can recognize it when you see it. No matter what John and Carlos do, they will remain fools of randomness.
A REVIEW OF MARKET FOOLS
OF RANDOMNESS CONSTANTS
Most of the traits partake of the same Table P.1 right column–left column confusion; how they are fooled by randomness. Below is a brief outline of them:
An overestimation of the accuracy of their beliefs in some measure, either economic (Carlos) or statistical (John)
. They never considered that the fact that trading on economic variables has worked in the past may have been merely coincidental, or, perhaps even worse, that economic analysis was fit to past events to mask the random element in it. Consider that of all the possible economic theories available, one can find a plausible one that explains the past, or a portion of it. Carlos entered the market at a time when it worked, but he never tested for periods when markets did the opposite of sound economic analysis. There were periods when economics failed traders, and others when it helped them.
The U.S. dollar was overpriced (i.e., the foreign currencies were undervalued) in the early 1980s
. Traders who used their economic intuitions and bought foreign currencies were wiped out. But later those who did so got rich (members of the first crop were bust). It is random! Likewise, those who shorted Japanese stocks in the late 1980s suffered the same fate—few survived to recoup their losses during the collapse of the 1990s. Toward the end of the last century there was a group of operators called “macro” traders who dropped like flies, with, for instance, “legendary”(rather, lucky) investor Julian Robertson closing shop in 2000 after having been a star until then. Our discussion of survivorship bias will enlighten us further, but, clearly, there is nothing less rigorous than their seemingly rigorous use of economic analyses to trade.
A tendency to get married to positions
. There is a saying that bad traders divorce their spouse sooner than abandon their positions. Loyalty to ideas is not a good thing for traders, scientists—or anyone.
The tendency to change their story
. They become investors “for the long haul” when they are losing money, switching back and forth between traders and investors to fit recent reversals of fortune. The difference between a trader and an investor lies in the duration of the bet, and the corresponding size. There is absolutely nothing wrong with investing “for the long haul,” provided one does not mix it with short-term trading—it is just that many people become long-term investors after they lose money, postponing their decision to sell as part of their denial.
No precise game plan ahead of time as to what to do in the event of losses
. They simply were not aware of such a possibility. Both bought more bonds after the market declined sharply, but not in response to a predetermined plan.
Absence of critical thinking expressed in absence of revision of their stance with “stop losses.”
Middlebrow traders do not like selling when it is “even better value.” They did not consider that perhaps their method of determining value is wrong, rather than the market failing to accommodate their measure of value. They may be right, but, perhaps, some allowance for the possibility of their methods being flawed was not made. For all his flaws, we will see that Soros seems rarely to examine an unfavorable outcome without testing his own framework of analysis.
Denial
. When the losses occurred there was no clear acceptance of what had happened. The price on the screen lost its reality in favor of some abstract “value.” In classic denial mode, the usual “this is only the result of liquidation, distress sales” was proffered. They continuously ignored the message from reality.
How could traders who made every single mistake in the book become so successful? Because of a simple principle concerning randomness. This is one manifestation of the survivorship bias. We tend to think that traders were successful
because
they are good. Perhaps we have turned the causality on its head; we consider them good just because they make money. One can make money in the financial markets totally out of randomness.
Both Carlos and John belong to the class of people who benefited from a market cycle. It was not merely because they were involved in the right markets. It was because they had a bent in their style that closely fitted the properties of the rallies experienced in their market during the episode. They were
dip buyers.
That happened, in hindsight, to be the trait that was the most desirable between 1992 and the summer of 1998 in the specific markets in which the two men specialized. Most of those who happened to have that specific trait, over the course of that segment of history, dominated the market. Their score was higher and they replaced people who, perhaps, were better traders.
NAIVE EVOLUTIONARY THEORIES
The stories of Carlos and John illustrate how bad traders have a short- and medium-term survival advantage over good traders. Next we take the argument to a higher level of generality. One must be either blind or foolish to reject the theories of Darwinian self-selection. However, the simplicity of the concept has drawn segments of amateurs (as well as a few professional scientists) into blindly believing in continuous and infallible Darwinism in all fields, which includes economics.
The biologist Jacques Monod bemoaned a couple of decades ago that everyone believes himself an expert on evolution (the same can be said about the financial markets); things have gotten worse. Many amateurs believe that plants and animals reproduce on a one-way route toward perfection. Translating the idea in social terms, they believe that companies and organizations are, thanks to competition (and the discipline of the quarterly report), irreversibly heading toward betterment. The strongest will survive; the weakest will become extinct. As to investors and traders, they believe that by letting them compete, the best will prosper and the worst will go learn a new craft (like pumping gas or, sometimes, dentistry).
Things are not as simple as that. We will ignore the basic misuse of Darwinian ideas in the fact that organizations do not reproduce like living members of nature—Darwinian ideas are about reproductive fitness, not about survival. The problem comes, as everything else in this book, from randomness. Zoologists found that once randomness is injected into a system, the results can be quite surprising: What seems to be an evolution may be merely a diversion, and possibly regression. For instance, Steven Jay Gould (who was accused of being more of a popularizer than a genuine scientist) found ample evidence of what he calls “genetic noise,” or “negative mutations,” thus incurring the wrath of some of his colleagues (he took the idea a little too far). An academic debate ensued, plotting Gould against colleagues like Dawkins who were considered by their peers as better trained in the mathematics of randomness. Negative mutations are traits that survive in spite of being worse, from the reproductive fitness standpoint, than the ones they replaced. However, they cannot be expected to last more than a few generations (under what is called temporal aggregation).
Furthermore, things can get even more surprising when randomness changes in shape, as with regime switches. A regime switch corresponds to situations when all of the attributes of a system change to the point of its becoming unrecognizable to the observer. Darwinian fitness applies to species developing over a very long time, not observed over a short term—time aggregation eliminates much of the effects of randomness; things (I read
noise
) balance out over the long run, as people say.
Owing to the abrupt rare events, we do not live in a world where things “converge” continuously toward betterment. Nor do things in life move
continuously
at all. The belief in continuity was ingrained in our scientific culture until the early twentieth century. It was said that
nature does not make jumps;
people quote this in well-sounding Latin:
Natura non facit saltus.
It is generally attributed to the eighteenth-century botanist Linnaeus who obviously got it all wrong. It was also used by Leibniz as a justification for calculus, as he believed that things are continuous no matter the resolution at which we look at them. Like many well-sounding “make sense” types of statements (such dynamics made perfect intellectual sense), it turned out to be entirely wrong, as it was denied by quantum mechanics. We discovered that, in the very small, particles jump (discretely) between states; they do not slide between them.
Can Evolution Be Fooled by Randomness?
We end this chapter with the following thought. Recall that someone with only casual knowledge about the problems of randomness would believe that an animal is at the maximum fitness for the conditions of its time. This is not what evolution means;
on average,
animals will be fit, but not every single one of them, and not at all times. Just as an animal could have survived because its sample path was lucky, the “best” operators in a given business can come from a subset of operators who survived because of overfitness to a sample path—a sample path that was free of the evolutionary rare event. One vicious attribute is that the longer these animals can go without encountering the rare event, the more vulnerable they will be to it. We said that should one extend time to infinity, then,
by ergodicity,
that event will happen with certainty—the species will be wiped out! For evolution means fitness to one and only one time series, not the average of all the possible environments.
By some viciousness of the structure of randomness, a profitable person like John, someone who is a pure loser in the long run and correspondingly unfit for survival, presents a high degree of eligibility in the short run and has the propensity to multiply his genes. Recall the hormonal effect on posture and its signaling effect to other potential mates. His success (or pseudosuccess owing to its fragility) will show in his features as a beacon. An innocent potential mate will be fooled into thinking (unconditionally) that he has a superior genetic makeup, until the following rare event. Solon seems to have gotten the point; but try to explain the problem to a naive business Darwinist—or your rich neighbor across the street.


================================================================================
CHAPTER/SECTION 307 (Item 316)
================================================================================

Six
•
SKEWNESS AND ASYMMETRY
We introduce the concept of skewness: Why the terms “bull” and “bear” have limited meaning outside of zoology. A vicious child wrecks the structure of randomness. An introduction to the problem of epistemic opacity. The penultimate step before the problem of induction.
THE MEDIAN IS NOT THE MESSAGE
T
he essayist and scientist Steven Jay Gould (who, for a while, was my role model), was once diagnosed when he was in his forties with a deadly form of cancer of the lining of the stomach. The first piece of information he received about his odds of making it was that the
median
survival for the ailment is approximately eight months; information he felt akin to Isaiah’s injunction to King Hezekiah to put his house in order in preparation for death.
Now, a medical diagnosis, particularly one of such severity, can motivate people to do intensive research, particularly those prolific writers like Gould who needed more time with us to complete a few book projects. The further research by Gould uncovered a very different story from the information he had initially been given; mainly that the
expected
(i.e., average) survival was considerably higher than eight months. It came to his notice that
expected
and
median
do not mean the same thing at all. Median means roughly that 50% of the people die before eight months and 50% survive longer than eight months. But those who survive would live considerably longer, generally going about life just like a regular person and fulfilling the average 73.4 or so years predicted by insurance mortality tables.
There is asymmetry. Those who die do so very early in the game, while those who live go on living very long. Whenever there is asymmetry in outcomes, the
average
survival has nothing to do with the
median
survival. This prompted Gould, who thus understood the hard way the concept of skewness, to write his heartfelt piece “The Median Is Not the Message.” His point is that the concept of median used in medical research does not characterize a probability distribution.
I will simplify Gould’s point by introducing the concept of
mean
(also called
average
or
expectation
) as follows, by using a less morbid example, that of gambling. I will give an example of both asymmetric odds and asymmetric outcomes to explain the point. Asymmetric odds means that probabilities are not 50% for each event, but that the probability on one side is higher than the probability on the other. Asymmetric outcomes mean that the payoffs are not equal.
Assume I engage in a gambling strategy that has 999 chances in 1,000 of making $1 (event A) and 1 chance in 1,000 of losing $10,000 (event B), as in Table 6.1. My expectation is a loss of close to $9 (obtained by multiplying the probabilities by the corresponding outcomes). The
frequency
or
probability
of the loss, in and by itself, is totally irrelevant; it needs to be judged in connection with the
magnitude
of the outcome. Here A is far more likely than B. Odds are that we would make money by betting for event A, but it is not a good idea to do so.
Table 6.1
Event
Probability
Outcome
Expectation
A
999/1000
$1
$.999
B
1/1000
-$10,000
-$10
Total
-$9.001
This point is rather common and simple; it is understood by anyone making a simple bet. Yet I had to struggle all my life with people in the financial markets who do not seem to internalize it. I am not talking of novices; I am talking of people with advanced degrees (albeit MBAs) who cannot come to grips with the difference.
How could people miss such a point? Why do they confuse probability and expectation, that is, probability and probability times the payoff? Mainly because much of people’s schooling comes from examples in symmetric environments, like a coin toss, where such a difference does not matter. In fact, the so-called bell curve that seems to have found universal use in society is entirely symmetric. More on that later.
BULL AND BEAR ZOOLOGY
The general press floods us with concepts like
bullish
and
bearish
which refer to the effect of higher (bullish) or lower (bearish) prices in the financial markets. But also we hear people saying “I am
bullish
on Johnny” or “I am
bearish
on that guy Nassim in the back who seems incomprehensible to me,” to denote the belief in the likelihood of someone’s rise in life. I have to say that
bullish
or
bearish
are often hollow words with no application in a world of randomness—particularly if such a world, like ours, presents asymmetric outcomes.
When I was in the employment of the New York office of a large investment house, I was subjected on occasions to the harrying weekly “discussion meeting,” which gathered most professionals of the New York trading room. I do not conceal that I was not fond of such gatherings, and not only because they cut into my gym time. While the meetings included traders, that is, people who are judged on their numerical performance, it was mostly a forum for salespeople (people capable of charming customers), and the category of entertainers called Wall Street “economists” or “strategists,” who make pronouncements on the fate of the markets, but do not engage in any form of risk taking, thus having their success dependent on rhetoric rather than actually testable facts. During the discussion, people were supposed to present their opinions on the state of the world. To me, the meeting was pure intellectual pollution. Everyone had a story, a theory, and insights that they wanted others to share. I resent the person who, without having done much homework in libraries, thinks that he is onto something rather original and insightful on a given subject matter (and I respect people with scientific minds, like my friend Stan Jonas, who feel compelled to spend their nights reading wholesale on a subject matter, trying to figure out what was done on the subject by others before emitting an opinion—would the reader listen to the opinion of a doctor who does not read medical papers?).
I have to confess that my optimal strategy (to soothe my boredom and allergy to confident platitudes) was to speak as much as I could, while totally avoiding listening to other people’s replies by trying to solve equations in my head. Speaking too much would help me clarify my mind, and, with a little bit of luck, I would not be “invited” back (that is, forced to attend) the following week.
I was once asked in one of those meetings to express my views on the stock market. I stated, not without a modicum of pomp, that I believed that the market would go slightly up over the next week with a high probability. How high? “About 70%.” Clearly, that was a very strong opinion. But then someone interjected,“But, Nassim, you just boasted being short a very large quantity of SP500 futures, making a bet that the market would go down. What made you change your mind?” “I did not change my mind! I have a lot of faith in my bet! [Audience laughing.] As a matter of fact I now feel like selling even more!”The other employees in the room seemed utterly confused. “Are you bullish or are you bearish?” I was asked by the strategist. I replied that I could not understand the words
bullish
and
bearish
outside of their purely zoological consideration. Just as with events A and B in the preceding example, my opinion was that the market was more likely to go up (“I would be bullish”), but that it was preferable to short it (“I would be bearish”), because, in the event of its going down, it could go down a lot. Suddenly, the few traders in the room understood my opinion and started voicing similar opinions. And I was not forced to come back to the following discussion.
Let us assume that the reader shared my opinion, that the market over the next week had a 70% probability of going up and 30% probability of going down. However, let us say that it would go up by 1% on average, while it could go down by an average of 10%. What would the reader do? Is the reader
bullish
or
bearish?
Table 6.2
Event
Probability
Outcome
Expectation
Market goes up
70%
Up 1%
0.7
Market goes down
30%
Down 10%
-3.00
Total
-2.3
Accordingly,
bullish
or
bearish
are terms used by people who do not engage in practicing uncertainty, like the television commentators, or those who have no experience in handling risk. Alas, investors and businesses are not paid in probabilities; they are paid in dollars. Accordingly, it is not how likely an event is to happen that matters, it is how much is made when it happens that should be the consideration. How frequent the profit is irrelevant; it is the magnitude of the outcome that counts. It is a pure accounting fact that, aside from the commentators, very few people take home a check linked to how
often
they are right or wrong. What they get is a profit or loss. As to the commentators, their success is linked to how often they are right or wrong. This category includes the “chief strategists” of major investment banks the public can see on TV, who are nothing better than entertainers. They are famous, seem reasoned in their speech, plow you with numbers, but, functionally, they are there to entertain—for their predictions to have any validity they would need a statistical testing framework. Their frame is not the result of some elaborate test but rather the result of their presentation skills.
An Arrogant Twenty-nine-year-old Son
Outside of the need for entertainment in these shallow meetings I have resisted voicing a “market call” as a trader, which caused some personal strain with some of my friends and relatives. One day a friend of my father—of the rich and confident variety—called me during his New York visit (to set the elements of pecking order straight, he hinted right away during the call that he came by Concorde, with some derogatory comment on the comfort of such method of transportation). He wanted to pick my brain on the state of a collection of financial markets. I truly had no opinion, nor had made the effort to formulate any, nor was I remotely interested in markets. The gentleman kept plowing me with questions on the state of economies, on the European central banks; these were precise questions no doubt aiming to compare my opinion to that of some other “expert” handling his account at one of the large New York investment firms. I neither concealed that I had no clue, nor did I seem sorry about it. I was not interested in markets (“yes, I am a trader”) and did not make predictions, period. I went on to explain to him some of my ideas on the structure of randomness and the verifiability of market calls but he wanted a more precise statement of what the European bond markets would do by the Christmas season.
He came away under the impression that I was pulling his leg; it almost damaged the relationship between my father and his rich and confident friend. For the gentleman called him with the following grievance: “When I ask a lawyer a legal question, he answers me with courtesy and precision. When I ask a doctor a medical question, he gives me his opinion. No specialist ever gives me disrespect. Your insolent and conceited twenty-nine-year-old son is playing
prima donna
and refuses to answer me about the direction of the market!”
Rare Events
The best description of my lifelong business in the market is “skewed bets,” that is, I try to benefit from rare events, events that do not tend to repeat themselves frequently, but, accordingly, present a large payoff when they occur. I try to make money infrequently, as infrequently as possible, simply because I believe that rare events are not fairly valued, and that the rarer the event, the more undervalued it will be in price. In addition to my own empiricism, I think that the counterintuitive aspect of the trade (and the fact that our emotional wiring does not accommodate it) gives me some form of advantage.
Why are these events poorly valued? Because of a psychological bias; people who surrounded me in my career were too focused on memorizing section 2 of
The Wall Street Journal
during their train ride to reflect properly on the attributes of random events. Or perhaps they watched too many gurus on television. Or perhaps they spent too much time upgrading their PalmPilot. Even some experienced trading veterans do not seem to get the point that frequencies do not matter. Jim Rogers, a “legendary” investor, made the following statement:
I don’t buy options. Buying options is another way to go to the poorhouse. Someone did a study for the SEC and discovered that 90 percent of all options expire as losses. Well, I figured out that if 90 percent of all long option positions lost money, that meant that 90 percent of all short option positions make money. If I want to use options to be bearish, I sell calls.
Visibly, the statistic that 90% of all option positions lost money is meaningless, (i.e., the
frequency
) if we do not take into account
how much
money is made on average during the remaining 10%. If we make 50 times our bet on average when the option is in the money, then I can safely make the statement that buying options is another way to go to the palazzo rather than the poorhouse. Mr. Jim Rogers seems to have gone very far in life for someone who does not distinguish between probability and expectation (strangely, he was the partner of George Soros, a complex man who thrived on rare events—more on him later).
One such rare event is the stock market crash of 1987, which made me as a trader and allowed me the luxury of becoming involved in all manner of scholarship. Nero of the smaller house in
Chapter 1
aims to get out of harm’s way by avoiding exposure to rare events—a mostly defensive approach. I am far more aggressive than Nero and go one step further; I have organized my career and business in such a way as to be able to benefit from them. In other words, I aim at profiting from the rare event, with my asymmetric bets.
Symmetry and Science
In most disciplines, such asymmetry does not matter. In an academic pass/fail environment, where the cumulative grade does not matter, only frequency matters. Outside of that it is the magnitude that counts. Unfortunately, the techniques used in economics are often imported from other areas—financial economics is still a young discipline (it is certainly not yet a “science”). People in most fields outside of it do not have problems eliminating extreme values from their sample, when the difference in payoff between different outcomes is not significant, which is generally the case in education and medicine. A professor who computes the average of his students’ grades removes the highest and lowest observations, which he would call
outliers,
and takes the average of the remaining ones, without this being an unsound practice. A casual weather forecaster does the same with extreme temperatures—an unusual occurrence might be deemed to skew the overall result (though we will see that this may turn out to be a mistake when it comes to forecasting future properties of the ice cap). So people in finance borrow the technique and ignore infrequent events, not noticing that the effect of a rare event can bankrupt a company.
Many scientists in the physical world are also subject to such foolishness, misreading statistics. One flagrant example is in the global-warming debate. Many scientists failed to notice it in its early stages as they removed from their sample the spikes in temperature, under the belief that these were not likely to recur. It may be a good idea to take out the extremes when computing the average temperatures for vacation scheduling. But it does not work when we study the physical properties of the weather—particularly when one cares about a cumulative effect. These scientists initially ignored the fact that these spikes, although rare, had the effect of adding disproportionately to the cumulative melting of the ice cap. Just as in finance, an event, although rare, that brings large consequences cannot just be ignored.
ALMOST EVERYBODY IS ABOVE AVERAGE
Jim Rogers is not the only person committing such traditional fallacy of mistaking mean and median. In all fairness to him, some people who think for a living, such as the star philosopher Robert Nozik, have committed versions of the same mistake (Nozik, besides, was an admirable and incisive thinker; before his premature death he was perhaps the most respected American philosopher of his generation). In his book
The Nature of Rationality
he gets, as is typical with philosophers, into amateur evolutionary arguments and writes the following: “Since not more than 50 percent of the individuals can be wealthier than average.” Of course, more than 50% of individuals can be wealthier than average. Consider that you have a very small number of very poor people and the rest clustering around the middle class. The mean will be lower than the median. Take a population of 10 people, 9 having a net worth of $30,000 and 1 having a net worth of $1,000. The average net worth is $27,100 and 9 out of 10 people will have above average wealth.
Figure 6.1 shows a series of points starting with an initial level W
0
and ending at the period concerned Wt. It can also be seen as the performance, hypothetical or realized, of your favorite trading strategy, the track record of an investment manager, the price of a foot of average Palazzo real estate in Renaissance Florence, the price series of the Mongolian stock market, or the difference between the U.S. and Mongolian stock markets. It is composed of a given number of sequential observations W
1
, W
2
, etc., ordered in such a way that the one to the right comes
after
the one to the left.
Figure 6.1 A Primer on Time Series
If we were dealing with a deterministic world—that is, a world stripped of randomness (the right-column world in
Table P.1
), and we knew with certainty that it was the case, things would be rather easy. The pattern of the series would reveal considerable and predictive information. You could tell with precision what would happen one day ahead, one year ahead, and perhaps even a decade ahead. We would not even need a statistician; a second-rate engineer would do. He does not even need to be armed with a modern degree; someone with nineteenth-century training under Laplace would be able to solve the equations, called
differential equations,
or, equivalently,
equations of motion—
since we are studying the dynamics of an entity whose position depends on time.
If we were dealing with a world where randomness is charted, things would be easy as well, given that there is an entire field created for that called
Econometrics
or
Time Series Analysis.
You would call a friendly econometrician (my experience of econometricians is that they are usually polite and friendly to practitioners). He would run the data in his software, and provide you with diagnostics that would tell you if it is worth investing in the trader generating such a track record, or if it is worth pursuing the given trading strategy. You can even buy the student version of his software for under $999 and run it yourself during the next rainy weekend.
But we are not sure that the world we live in is well charted. We will see that the judgment derived from the analysis of these past attributes may on occasion be relevant. But it may be meaningless; it could on occasion mislead you and take you in the opposite direction. Sometimes market data becomes a simple trap; it shows you the opposite of its nature, simply to get you to invest in the security or mismanage your risks. Currencies that exhibit the largest historical stability, for example, are the most prone to crashes. This was bitterly discovered in the summer of 1997 by investors who chose the safety of the pegged currencies of Malaysia, Indonesia, and Thailand (they were pegged to the U.S. dollar in a manner to exhibit no volatility, until their sharp, sudden, and brutal devaluations).
We could be either too lax or too stringent in accepting past information as a prediction of the future. As a skeptic, I reject a sole time series of the past as an indication of future performance; I need a lot more than data. My major reason is the
rare event,
but I have plenty of others.
On the surface, my statement here may seem to contradict earlier discussions, where I blame people for not learning enough from history. The problem is that we read too much into shallow recent history, with statements like “this has never happened before,” but not from history in general (things that never happened before in one area tend eventually to happen). In other words, history teaches us that things that never happened before do happen. It can teach us a lot outside of the narrowly defined time series; the broader the look, the better the lesson. In other words, history teaches us to avoid the brand of naive empiricism that consists of learning from casual historical facts.
THE RARE-EVENT FALLACY
The Mother of All Deceptions
The rare event, owing to its dissimulative nature, can take a variety of shapes. It is in Mexico that it was spotted first, where it was called by academics the
peso problem.
Econometricians were puzzled by the behavior of the Mexican economic variables during the 1980s. The money supply, interest rates, or some similar measure of small relevance to the story exhibited some moody behavior, thwarting many of their efforts at modeling them. These indicators erratically switched between periods of stability and brief bursts of turbulence without warning.
By generalization, I started to label a rare event as any behavior where the adage “beware of calm waters” can hold. Popular wisdom often warns of the old neighbor who appears to remain courtly and reserved, the model of an excellent citizen, until you see his picture in the national paper as a deranged killer who went on a rampage. Until then, he was not known to have committed any transgression. There was no way to predict that such pathological behavior could emanate from such a nice person. I associate rare events with any misunderstanding of the risks derived from a narrow interpretation of past time series.
Rare events are always unexpected, otherwise they would not occur. The typical case is as follows. You invest in a hedge fund that enjoys stable returns and no volatility, until one day, you receive a letter starting with “An unforeseen and
unexpected
event, deemed a rare occurrence . . .” (emphasis mine). But rare events exist precisely because they are unexpected. They are generally caused by panics, themselves the results of liquidations (investors rushing to the door simultaneously by dumping anything they can put their hands on as fast as possible). If the fund manager or trader expected it, he and his like-minded peers would not have invested in it, and the rare event would not have taken place.
The rare event is not limited to one security. It can readily affect the performance of a portfolio. For example, many traders engage in the purchase of mortgage securities and hedge them in some manner to offset the risks and eliminate the volatility, hoping to derive some profits in excess of the Treasury bond returns (which is used as the benchmark of the minimum expected returns on an investment). They use computer programs and draw meaningful assistance from Ph.D.s in applied mathematics, astrophysics, particle physics, electrical engineering, fluid dynamics, or sometimes (though rarely) plain Ph.D.s in finance. Such a portfolio shows stable returns for long periods. Then, suddenly, as if by accident (I consider that
no
accident), the portfolio drops by 40% of its value when you expect, at the worst, a 4% drop. You call the manager to express your anger and he tells you that it was not his fault, but somehow the relationship dramatically changed (literally). He will also point out to you that similar funds also experienced the same problems.
Recall that some economists call the rare event a “peso problem.” The designation peso problem does not appear to be undeservedly stereotypical. Things have not gotten better since the early 1980s with the currency of the United States’ southern neighbor. Long periods of stability draw hordes of bank currency traders and hedge fund operators to the calm waters of the Mexican peso; they enjoy owning the currency because of the high interest rate it commands. Then they “unexpectedly” blow up, lose money for investors, lose their jobs, and switch careers. Then a new period of stability sets in. New currency traders come in with no memory of the bad event. They are drawn to the Mexican peso, and the story repeats itself.
It is an oddity that most fixed-income financial instruments present rare events. In the spring of 1998, I spent two hours explaining to a then-important hedge fund operator the notion of the peso problem. I went to great lengths to explain to him that the concept was generalized to every form of investment that was based on a naive interpretation of the volatility of past time series. The reply was:“ You are perfectly right. We do not touch the Mexican peso. We only invest in the Russian ruble.” He blew up a few months later. Until then, the Russian ruble carried attractive interest rates, which invited yield hogs of all types to get involved. He and other holders of investments denominated in rubles lost close to 97% of their investment during the summer of 1998.
We saw in
Chapter 3
that the dentist does not like volatility as it causes a high incidence of negative pangs. The closer he observes his performance, the more pain he will experience owing to the greater variability at a higher resolution. Accordingly investors, merely for emotional reasons, will be drawn into strategies that experience
rare but large
variations. It is called pushing randomness under the rug. Psychologists recently found out that people tend to be sensitive to the presence or absence of a given stimulus rather than its magnitude. This implies that a loss is first perceived as just a loss, with further implications later. The same with profits. The agent would prefer the number of losses to be low and the number of gains to be high, rather than optimizing the total performance.
We can look at other aspects of the problem; think of someone involved in scientific research. Day after day, he will engage in dissecting mice in his laboratory, away from the rest of the world. He could try and try for years and years without anything to show for it. His significant other might lose patience with the
loser
who comes home every night smelling of mice urine. Until bingo, one day he comes up with a result. Someone observing the time series of his occupation would see absolutely no gain, while every day would bring him closer
in probability
to the end result.
The same with publishers; they can publish dog after dog without their business model being the least questionable, if once every decade they hit on a Harry Potter string of super-bestsellers—provided of course that they publish quality work that has a small probability of being of very high appeal. An interesting economist, Art De Vany, manages to apply these ideas to two fields: the movie business and his own health and lifestyle. He figured out the skewed properties of the movies payoffs and brought them to another level: the wild brand on nonmeasurable uncertainty we discuss in
Chapter 10
. What is also interesting is that he discovered that we are designed by mother nature to have an extremely skewed physical workout: Hunter-gatherers had idle moments followed by bursts of intense energy expenditure. At sixty-five, Art is said to have the physique of a man close to half his age.
In the markets, there is a category of traders who have
inverse
rare events, for whom volatility is often a bearer of good news. These traders lose money frequently, but in small amounts, and make money rarely, but in large amounts. I call them crisis hunters. I am happy to be one of them.
Why Don’t Statisticians Detect Rare Events?
Statistics to the layman can appear rather complex, but the concept behind what is used today is so simple that my French mathematician friends call it deprecatorily “cuisine.” It is all based on one simple notion: the more information you have, the more you are confident about the outcome. Now the problem: by how much? Common statistical method is based on the steady augmentation of the confidence level, in nonlinear proportion to the number of observations. That is, for an
n
times increase in the sample size, we increase our knowledge by the square root of
n.
Suppose I am drawing from an urn containing red and black balls. My confidence level about the relative proportion of red and black balls after 20 drawings is not twice the one I have after 10 drawings; it is merely multiplied by the square root of 2 (that is, 1.41).
Where statistics becomes complicated, and fails us, is when we have distributions that are not symmetric, like the urn above. If there is a very small probability of finding a red ball in an urn dominated by black ones, then our knowledge about the
absence
of red balls will increase very slowly—more slowly than at the expected square root of
n
rate. On the other hand, our knowledge of the
presence
of red balls will dramatically improve once one of them is found. This asymmetry in knowledge is not trivial; it is central in this book—it is a central philosophical problem for such people as the ancient skeptics David Hume and Karl Popper (on that, later).
To assess an investor’s performance, we either need more astute, and less intuitive, techniques or we may have to limit our assessments to situations where our judgment is independent of the frequency of these events.
A Mischievous Child Replaces the Black Balls
But there is even worse news. In some cases, if the incidence of red balls is itself randomly distributed, we will never get to know the composition of the urn. This is called “the problem of stationarity.” Think of an urn that is hollow at the bottom. As I am sampling from it, and without my being aware of it, some mischievous child is adding balls of one color or another. My inference thus becomes insignificant. I may infer that the red balls represent 50% of the urn while the mischievous child, hearing me, would swiftly replace all the red balls with black ones. This makes much of our knowledge derived through statistics quite shaky.
The very same effect takes place in the market. We take past history as a single homogeneous sample and believe that we have considerably increased our knowledge of the future from the observation of the sample of the past. What if vicious children were changing the composition of the urn? In other words, what if things have changed?
I have studied and practiced econometrics for more than half my life (since I was nineteen), both in the classroom and in the activity of a quantitative derivatives trader. The “science” of econometrics consists of the application of statistics to samples taken at different periods of time, which we called “time series.” It is based on studying the time series of economic variables, data, and other matters. In the beginning, when I knew close to nothing (that is, even less than today), I wondered whether the time series reflecting the activity of people now dead or retired should matter for predicting the future. Econometricians who knew a lot more than I did about these matters asked no such question; this hinted that it was in all likelihood a stupid inquiry. One prominent econometrician, Hashem Pesaran, answered a similar question by recommending to do “more and better econometrics.” I am now convinced that, perhaps, most of econometrics could be useless—much of what financial statisticians know would not be worth knowing. For a sum of zeros, even repeated a billion times, remains zero; likewise an accumulation of research and gains in complexity will lead to naught if there is no firm ground beneath it. Studying the European markets of the 1990s will certainly be of great help to a historian; but what kind of inference can we make now that the structure of the institutions and the markets has changed so much?
Note that the economist Robert Lucas dealt a blow to econometrics by arguing that if people were rational then their rationality would cause them to figure out predictable patterns from the past and adapt, so that past information would be completely useless for predicting the future (the argument, phrased in a very mathematical form, earned him the Swedish Central Bank Prize in honor of Alfred Nobel). We are human and act according to our knowledge, which integrates past data. I can translate his point with the following analogy. If rational traders detect a pattern of stocks rising on Mondays, then, immediately such a pattern becomes detectable, it would be ironed out by people buying on Friday in anticipation of such an effect. There is no point searching for patterns that are available to everyone with a brokerage account; once detected, they would be self-canceling.
Somehow, what came to be known as the
Lucas critique
was not carried through by the “scientists.” It was confidently believed that the scientific successes of the industrial revolution could be carried through into the social sciences, particularly with such movements as Marxism. Pseudoscience came with a collection of idealistic nerds who tried to create a tailor-made society, the epitome of which is the central planner. Economics was the most likely candidate for such use of science; you can disguise charlatanism under the weight of equations, and nobody can catch you since there is no such thing as a controlled experiment. Now, the spirit of such methods, called scientism by its detractors (like myself), continued past Marxism, into the discipline of finance as a few technicians thought that their mathematical knowledge could lead them to understand markets. The practice of “financial engineering” came along with massive doses of pseudoscience. Practitioners of these methods measure risks, using the tool of past history as an indication of the future. We will just say at this point that the mere possibility of the distributions not being stationary makes the entire concept seem like a costly (perhaps
very costly
) mistake. This leads us to a more fundamental question: The problem of induction, to which we will turn in the next chapter.


================================================================================
CHAPTER/SECTION 308 (Item 317)
================================================================================

Seven
•
THE PROBLEM OF INDUCTION
On the chromodynamics of swans. Taking Solon’s warning into some philosophical territory. How Victor Niederhoffer taught me empiricism; I added deduction. Why it is not scientific to take science seriously. Soros promotes Popper. That bookstore on Eighteenth Street and Fifth Avenue. Pascal’s wager.
FROM BACON TO HUME
N
ow we discuss this problem viewed from the broader standpoint of the philosophy of scientific knowledge. There is a problem in inference well-known as the problem of induction. It is a problem that has been haunting science for a long time, but hard science has not been as harmed by it as the social sciences, particularly economics, even more the branch of financial economics. Why? Because the randomness content compounds its effects. Nowhere is the problem of induction more relevant than in the world of trading—and nowhere has it been as ignored!
Cygnus Atratus
In his
Treatise on Human Nature,
the Scots philosopher David Hume posed the issue in the following way (as rephrased in the now famous black swan problem by John Stuart Mill):
No amount of observations of white swans can allow the inference that all swans are white, but the observation of a single black swan is sufficient to refute that conclusion.
Hume had been irked by the fact that science in his day (the eighteenth century) had experienced a swing from scholasticism, entirely based on deductive reasoning (no emphasis on the observation of the real world) to, owing to Francis Bacon, an overreaction into naive and unstructured empiricism. Bacon had argued against “spinning the cobweb of learning” with little practical result (science resembled theology). Science had shifted, thanks to Bacon, into an emphasis on empirical observation. The problem is that, without a proper method, empirical observations can lead you astray. Hume came to warn us against such knowledge, and to stress the need for some rigor in the gathering and interpretation of knowledge—what is called epistemology (from
episteme,
Greek for learning). Hume is the first modern
epistemologist
(epistemologists operating in the applied sciences are often called methodologists or philosophers of science). What I am writing here is not strictly true, for Hume said things far worse than that; he was an obsessive skeptic and never believed that a link between two items could be truly established as being causal. But we will tone him down a bit for this book.
Niederhoffer
The story of Victor Niederhoffer is both sad and interesting insofar as it shows the difficulty of merging extreme empiricism and logic in one single person—pure empiricism implies necessarily being fooled by randomness. I am bringing up his example because, in a way, similar to Francis Bacon, Victor Niederhoffer stood against the cobweb of learning of the University of Chicago and the efficient-market religion of the 1960s when they were at their worst. In contrast to the scholasticism of financial theorists, his work looked at data in search of anomalies and found some. He also figured out the uselessness of the news, as he showed that reading the newspaper did not confer a predictive advantage to its readers. He derived his knowledge of the world from past data stripped of preconceptions, commentaries, and stories. Since then, an entire industry of such operators, called
statistical arbitrageurs,
flourished; some of the successful ones were initially his trainees. Niederhoffer’s story illustrates how empiricism cannot be inseparable from methodology.
At the center of his
modus
is Niederhoffer’s dogma that any “testable” statement should be tested, as our minds make plenty of empirical mistakes when relying on vague impressions. His advice is obvious, but it is rarely practiced. How many effects we take for granted might not be there? A testable statement is one that can be broken down into quantitative components and subjected to statistical examination. For instance, a conventional-wisdom, empirical style statement like
automobile accidents happen closer to home
can be tested by taking the average distance between the accident and the domicile of the driver (if, say, about 20% of accidents happen within a twelve-mile radius). However, one needs to be careful in the interpretation; a naive reader of the result would tell you that you are more likely to have an accident if you drive in your neighborhood than if you did so in remote places, which is a typical example of naive empiricism. Why? Because accidents may happen closer to home simply because people spend their time driving close to home (if people spend 20% of their time driving in a twelve-mile radius).
*
But there is a more severe aspect of naive empiricism. I can use data to disprove a proposition, never to prove one. I can use history to refute a conjecture, never to affirm it. For instance, the statement
The market never goes down 20% in a given three-month period
can be tested but is completely meaningless if verified. I can quantitatively reject the proposition by finding counterexamples, but it is not possible for me to accept it simply because, in the past, the market never went down 20% in any three-month period (you cannot easily make the logical leap from “has never gone down” to “never goes down”). Samples can be greatly insufficient; markets may change; we may not know much about the market from historical information.
You can more safely use the data to reject than to confirm hypotheses. Why? Consider the following statements:
Statement A:
No swan is black, because I looked at four thousand swans and found none.
Statement B:
Not all swans are white.
I cannot logically make statement A, no matter how many successive white swans I may have observed in my life and may observe in the future (except, of course, if I am given the privilege of observing with certainty all available swans). It is, however, possible to make Statement B merely by finding one single counterexample. Indeed, Statement A was disproved by the discovery of Australia, as it led to the sighting of the
Cygnus atratus,
a swan variety that was jet black! The reader will see a hint of Popper’s ideas, as there is a strong asymmetry between the two statements; and, furthermore, such asymmetry lies in the foundations of knowledge. It is also at the core of my operation as a decision maker under uncertainty.
I said that people rarely test testable statements; this may be better for those who cannot handle the consequence of the inference. The following inductive statement illustrates the problem of interpreting past data literally, without methodology or logic:
I have just completed a thorough statistical examination of the life of President Bush. For fifty-eight years, close to 21,000 observations, he did not die once. I can hence pronounce him as immortal, with a high degree of statistical significance.
Niederhoffer’s publicized hiccup came from his selling naked options based on his testing and assuming that what he saw in the past was an exact generalization about what could happen in the future. He relied on the statement “The market has never done this before,” so he sold puts that made a small income if the statement was true and lost hugely in the event of it turning out to be wrong. When he blew up, close to a couple of decades of performance were overshadowed by a single event that only lasted a few minutes.
Another logical flaw in this type of historical statement is that often when a large event takes place, you hear the “it never happened before,” as if it needed to be absent from the event’s past history for it to be a surprise. So why do we consider the worst case that took place in our own past as the worst possible case? If the past, by bringing surprises, did not resemble the past previous to it (what I call the past’s past), then why should our future resemble our current past?
There is another lesson to his story, perhaps the greatest one: Niederhoffer appears to approach markets as a venue from which to derive pride, status, and wins against “opponents” (such as myself), as he would in a game with defined rules. He was a squash champion with a serious competitive streak; it is just that reality does not have the same closed and symmetric laws and regulations as games. This competitive nature got him into ferocious fighting to “win.” As we saw in the last chapter, markets (and life) are not simple win/lose types of situations, as the cost of the losses can be markedly different from that of the wins. Maximizing the probability of winning does not lead to maximizing the expectation from the game when one’s strategy may include skewness, i.e., a small chance of large loss and a large chance of a small win. If you engaged in a Russian roulette–type strategy with a low probability of large loss, one that bankrupts you every several years, you are likely to show up as the winner in almost all samples—except in the year when you are dead.
I remind myself never to fail to acknowledge the insights of the 1960s empiricist and his early contributions. Sadly, I learned quite a bit from Niederhoffer, mostly by contrast, and particularly from the last example: not to approach anything as a
game to win,
except, of course, if it is a game. Even then, I do not like the asphyxiating structure of competitive games and the diminishing aspect of deriving pride from a numerical performance. I also learned to stay away from people of a competitive nature, as they have a tendency to commoditize and reduce the world to categories, like how many papers they publish in a given year, or how they rank in the league tables. There is something nonphilosophical about investing one’s pride and ego into a “my house/library/car is bigger than that of others in my category”—it is downright foolish to claim to be first in one’s category all the while sitting on a time bomb.
To conclude, extreme empiricism, competitiveness, and an absence of logical structure to one’s inference can be a quite explosive combination.
SIR KARL’S PROMOTING AGENT
Next I will discuss how I discovered Karl Popper via another trader, perhaps the only one I have ever truly respected. I do not know if it applies to other people, but, in spite of my being a voracious reader, I have rarely been truly affected in my behavior (in any durable manner) by anything I have read. A book can make a strong impression, but such an impression tends to wane after some newer impression replaces it in my brain (a new book). I have to discover things by myself (recall the “Stove Is Hot” section in
Chapter 3
). These self-discoveries last.
One exception of ideas that stuck with me are those of Sir Karl, whom I discovered (or perhaps rediscovered) through the writings of the trader and self-styled philosopher George Soros, who seemed to have organized his life by becoming a promoter of the ideas of Karl Popper. What I learned from George Soros was not quite in the way he perhaps intended us to learn from him. I disagreed with his statements when it came to economics and philosophy. First, although I admire him greatly, I agree with professional thinkers that Soros’
forte
is not in philosophical speculation. Yet he considers himself a philosopher—which makes him endearing in more than one way. Take his first book,
The Alchemy of Finance.
On the one hand, he seems to discuss ideas of scientific explanation by throwing in big names like “deductive-nomological,” something always suspicious as it is reminiscent of postmodern writers who play philosophers and scientists by using complicated references. On the other hand, he does not show much grasp of the concepts. For instance, he conducts what he calls a “trading experiment,” and uses the success of the trade to imply that the theory behind it is valid. This is ludicrous: I could roll the dice to prove my religious beliefs and show the favorable outcome as evidence that my ideas are right. The fact that Soros’ speculative portfolio turned a profit proves very little of anything. One cannot infer much from a single experiment in a random environment—an experiment needs a repeatability showing some causal component. Second, Soros indicts wholesale the science of economics, which may be very justified but he did not do his homework. For instance, he writes that the category of people he lumps as “economists” believe that things converge to equilibrium, when that only applies to
some
cases of neoclassical economics. There are plenty of economic theories that believe that departure from a price level can cause further divergence and cause cascading feedback loops. There has been considerable research to that effect in, say, game theory (the works of Harsanyi and Nash) or information economics (the works of Stiglitz, Akerlof, and Spence). Lumping all economics in one basket shows a bit of unfairness and lack of rigor.
But in spite of some of the nonsense in his writing, probably aimed at convincing himself that he was not just a trader, or because of it, I succumbed to the charm of this Hungarian man who like me is ashamed of being a trader and prefers his trading to be a minor extension of his intellectual life even if there is not much scholarship in his essays. Having never been impressed by people with money (and I have met plenty of those throughout my life), I did not look at any of them as remotely a role model for me. Perhaps the opposite effect holds, as I am generally repelled by the wealthy, generally because of the attitude of epic heroism that usually accompanies rapid enrichment. Soros was the only one who seemed to share my values. He wanted to be taken seriously as a Middle European professor who happened to have gotten rich owing to the validity of his ideas (it was only by failing to gain acceptance by other intellectuals that he would try to gain alpha status through his money, sort of like a seducer who, after trying hard, would end up using such an appendage as the red Ferrari to seduce the girl). In addition, although Soros did not deliver anything meaningful in his writings, he knew how to handle randomness, by keeping a critical open mind and changing his opinions with minimal shame (which carries the side effect of making him treat people like napkins). He walked around calling himself fallible, but was so potent because he knew it while others had loftier ideas about themselves. He understood Popper. Do not judge him by his writings: He lived a Popperian life.
As an aside, Popper was not new to me. I had briefly heard of Karl Popper when I was in my teens and early twenties, as part of a motivated education in Europe and the United States. But I did not understand his ideas as presented then, nor did I think it would be important (like metaphysics) for anything in life. I was at the age when one felt like one needed to read everything, which prevented one from making contemplative stops. Such hurry made it hard to detect that there was something important in Popper. It was either my conditioning by the intellectual-chic culture at the time (too much Plato, too many Marxists, too much Hegel, too many pseudoscientific intellectuals), the educational system (too many conjectures propounded as truth), or the fact that I was too young and was reading too much then to make a bridge to reality.
Popper
*
then slipped out of my mind without hanging on a single brain cell—there was nothing in the baggage of a boy without experience to let it stick. Besides, having started trading, I entered an anti-intellectual phase; I needed to make a nonrandom buck to secure my newly lost future and wealth that had just evaporated with the Lebanese war (until then I was living with the desire to become a comfortable man of leisure like almost everyone in my family over the past two centuries). I suddenly felt financially insecure and feared becoming an employee of some firm that would turn me into a corporate slave with “work ethics” (whenever I hear
work ethics
I interpret
inefficient mediocrity
). I needed the backing of my bank account so I could buy time to think and enjoy life. The last thing I needed was immediate philosophizing and work at the local McDonald’s. Philosophy, to me, became something rhetorical people did when they had plenty of time on their hands; it was an activity reserved for those who were not well versed in quantitative methods and other productive things. It was a pastime that should be limited to late hours, in bars around the campuses, when one had a few drinks and a light schedule—provided one forgot the garrulous episode as early as the next day. Too much of it can get a man in trouble, perhaps turn one into a Marxist ideologue. Popper was not to reemerge until I secured my career as a trader.
Location, Location
It is said that people generally remember the time and geographic condition where they were swept with a governing idea. The religious poet and diplomat Paul Claudel remembers the exact spot of his conversion (or reconversion) to Catholicism in the Cathedral Notre-Dame of Paris, near a precise column. Thus I remember exactly the spot at Barnes and Noble on Eighteenth Street and Fifth Avenue where in 1987, inspired by Soros, I read fifty pages of
The Open Society
and feverishly bought all the Popper titles I could get my hands on lest they run out of stock. It was in a sparsely lit side-room that had a distinctive smell of mildew. I remember vividly the thoughts that rushed through my head like a revelation.
Popper turned out to be exactly the opposite of what I initially thought about “philosophers”; he was the epitome of no nonsense. By then I had been an option trader for a couple of years and I felt angry that I was being taken for a total ride by the academic researchers in finance, particularly since I was deriving my income from the failure of their models. I had already started talking to finance academics as part of my involvement with derivatives and I had trouble getting through to them some basic points about financial markets (they believed in their models a little too much). There was all along lurking in my mind the idea that these researchers had missed a point, but I did not quite know what it was. It was not what they knew, it was how they knew it, that was the subject of my annoyance.
Popper’s Answer
Popper came up with a major answer to the problem of induction (to me he came up with
the
answer). No man has influenced the way scientists do science more than Sir Karl—in spite of the fact that many of his fellow professional philosophers find him quite naive (to his credit, in my opinion). Popper’s idea is that science is not to be taken as seriously as it sounds (Popper when meeting Einstein did not take him as the demigod he thought he was). There are only two types of theories:
1. Theories that are known to be wrong, as they were tested and adequately rejected (he calls them falsified).
2. Theories that have not yet been known to be wrong, not falsified yet, but are exposed to be proved wrong.
Why is a theory never
right
? Because we will never know if all the swans are white (Popper borrowed the Kantian idea of the flaws in our mechanisms of perception). The testing mechanism may be faulty. However, the statement that there is a black swan is possible to make. A theory cannot be
verified.
To paraphrase baseball coach Yogi Berra again,
past data has a lot of good in it, but it is the bad side that is bad.
It can only be provisionally accepted. A theory that falls outside of these two categories is not a theory. A theory that does not present a set of conditions under which it would be considered wrong would be termed charlatanism—it-would be impossible to reject otherwise. Why? Because the astrologist can always find a reason to fit the past event, by saying that
Mars was probably in line but not too much so
(likewise to me a trader who does not have a point that would make him change his mind is not a trader). Indeed the difference between Newtonian physics, which was falsified by Einstein’s relativity, and astrology lies in the following irony. Newtonian physics is scientific because it allowed us to falsify it, as we know that it is wrong, while astrology is not because it does not offer conditions under which we could reject it. Astrology cannot be disproved, owing to the auxiliary hypotheses that come into play. Such point lies at the basis of the demarcation between science and nonsense (called “the problem of demarcation”).
More practically to me, Popper had many problems with statistics and statisticians. He refused to blindly accept the notion that knowledge can always increase with incremental information—which is the foundation of statistical inference. It may in some instances, but we do not know which ones. Many insightful people, such as John Maynard Keynes, independently reached the same conclusions. Sir Karl’s detractors believe that favorably repeating the same experiment again and again should lead to an increased comfort with the notion that “it works.” I came to understand Popper’s position better once I saw the first rare event ravaging a trading room. Sir Karl feared that some type of knowledge did not increase with information—but which type we could not ascertain. The reason I feel that he is important for us traders is because to him the matter of knowledge and discovery is not so much in dealing with what we know as in dealing with what we do not know. His famous quote:
These are men with bold ideas, but highly critical of their own ideas; they try to find whether their ideas are right by trying first to find whether they are not perhaps wrong. They work with bold conjectures and severe attempts at refuting their own conjectures.
“These” are scientists. But they could be anything.
Putting the master in context, Popper was rebelling against the growth of science. Popper intellectually came to the world with the dramatic shifts in philosophy as attempts were made to shift it from the verbal and rhetorical to the scientific and rigorous, as we saw with the presentation of the Vienna Circle in
Chapter 4
. These people were sometimes called the logical positivists, after the movement called
positivism
pioneered in France in the nineteenth century by Auguste Comte, where positivism meant scientification of things (literally everything under the sun). It was the equivalent of bringing the industrial revolution into the soft sciences. Without dwelling on positivism, I have to note that Popper is the antidote to positivism. To him, verification is not possible. Verificationism is more dangerous than anything else. Taken to the extreme, Popper’s ideas appear naive and primitive—but they work. Note that his detractors call him a
naive falsificationist.
I am an exceedingly naive falsificationist. Why? Because I can survive being one. My extreme and obsessive Popperism is carried out as follows. I speculate in all of my activities on theories that represent some vision of the world, but with the following stipulation: No rare event should harm me. In fact, I would like all conceivable rare events to help me. My idea of science diverges with that of the people around me walking around calling themselves scientists. Science is mere speculation, mere formulation of conjecture.
Open Society
Popper’s falsificationism is intimately connected to the notion of an open society. An open society is one in which no permanent truth is held to exist; this would allow counter-ideas to emerge. Karl Popper shared ideas with his friend, the low-key economist von Hayek, who endorsed capitalism as a state in which prices can disseminate information that bureaucratic socialism would choke. Both notions of falsificationism and open society are, counterintuitively, connected to those of a rigorous method for handling randomness in my day job as a trader. Clearly, an open mind is a necessity when dealing with randomness. Popper believed that any idea of Utopia is necessarily closed owing to the fact that it chokes its own refutations. The simple notion of a good model for society that cannot be left open for falsification is totalitarian. I learned from Popper, in addition to the difference between an open and a closed society, that between an open and a closed mind.
Nobody Is Perfect
I have some sobering information about Popper the man. Witnesses of his private life find him rather un-Popperian. The philosopher and Oxford don Bryan Magee who befriended him for close to three decades depicts him as unworldly (except in his youth) and narrowly focused on his work. He spent the last fifty years of his long career (Popper lived ninety-two years) closed to the outside world, insulated from outside distractions and stimulation. Popper also engaged in giving people “firm sounding advice about their career or their private life, though he had little understanding of either. All this, of course, was in direct contravention of his professed (and indeed genuine) beliefs, and practices, in philosophy.”
He was not much better in his youth. Members of the Vienna Circle tried to avoid him, not because of his divergent ideas but because he was a social problem. “He was brilliant, but self-focused, both insecure and arrogant, irascible and self-righteous. He was a terrible listener and bent on winning arguments at all costs. He had no understanding of group dynamics and no ability to negotiate them.”
I will refrain from commonplace discourse about the divorce between those who have ideas and those who carry them in practice, except to bring out the interesting behavioral problem; we like to emit logical and rational ideas but we do not necessarily
enjoy
this execution. Strange as it sounds, this point has only been discovered very recently (we will see that we are not genetically fit to be rational and act rationally; we are merely fit for the maximum probability of transmitting our genes in some given unsophisticated environment). Also, strange as it sounds, George Soros, obsessively self-critical, seems to be more Popperian than Popper in his professional behavior.
Induction and Memory
Memory in humans is a large machine to make inductive inferences. Think of memories: What is easier to remember, a collection of random facts glued together, or a story, something that offers a series of logical links? Causality is easier to commit to memory. Our brain would have less work to do in order to retain the information. The
size
is smaller. What is induction exactly? Induction is going from plenty of particulars to the general. It is very handy, as the general takes much less room in one’s memory than a collection of particulars. The effect of such compression is the reduction in the degree of detected randomness.
Pascal’s Wager
I conclude with the exposition of my own method of dealing with the problem of induction. The philosopher Pascal proclaimed that the optimal strategy for humans is to believe in the existence of God. For if God exists, then the believer would be rewarded. If he does not exist, the believer would have nothing to lose. Accordingly, we need to accept the asymmetry in knowledge; there are situations in which using statistics and econometrics can be useful. But I do not want my life to depend on it.
Like Pascal, I will therefore state the following argument. If the science of statistics can benefit me in anything, I will use it. If it poses a threat, then I will not. I want to take the best of what the past can give me without its dangers. Accordingly, I will use statistics and inductive methods to make aggressive bets, but I will not use them to manage my risks and exposure. Surprisingly, all the surviving traders I know seem to have done the same. They trade on ideas based on some observation (that includes past history) but, like the Popperian scientists, they make sure that the costs of being wrong are limited (and their probability is not derived from past data). Unlike Carlos and John, they know before getting involved in the trading strategy which events would prove their conjecture wrong and allow for it (recall that Carlos and John used past history both to make their bets and to measure their risk). They would then terminate their trade. This is called a
stop loss,
a predetermined exit point, a protection from the black swan. I find it rarely practiced.
THANK YOU, SOLON
Finally, I have to confess that upon finishing my writing of Part I, that writing about the genius of Solon’s insight has carried an extreme effect on both my thinking and my private life. The composition of Part I made me even more confident in my withdrawal from the media and my distancing myself from other members of the business community, mostly other investors and traders for whom I am developing more and more contempt. I believe that I cannot have power over myself as I have an ingrained desire to integrate among people and cultures and would end up resembling them; by withdrawing myself entirely I can have a better control of my fate. I am currently enjoying a thrill of the classics I have not felt since childhood. I am now thinking of the next step: to recreate a low-information, more deterministic ancient time, say in the nineteenth century, all the while benefiting from some of the technical gains (such as the Monte Carlo engine), all of the medical breakthroughs, and all the gains of social justice of our age. I would then have the best of everything. This is called evolution.


================================================================================
CHAPTER/SECTION 309 (Item 318)
================================================================================

Part II
•
MONKEYS ON
TYPEWRITERS
Survivorship and Other Biases
I
f one puts an infinite number of monkeys in front of (strongly built) typewriters, and lets them clap away, there is a certainty that one of them would come out with an exact version of the
Iliad.
Upon examination, this may be less interesting a concept than it appears at first: Such probability is ridiculously low. But let us carry the reasoning one step beyond. Now that we have found that hero among monkeys, would any reader invest his life’s savings on a bet that the monkey would write the
Odyssey
next?
In this thought experiment, it is the second step that is interesting. How much can past performance (here the typing of the
Iliad
) be relevant in forecasting future performance? The same applies to any decision based on past performance, merely relying on the attributes of the past time series. Think about the monkey showing up at your door with his impressive past performance. Hey, he wrote the
Iliad.
The major problem with inference in general is that those whose profession is to derive conclusions from data often fall into the trap faster and more confidently than others. The more data we have, the more likely we are to drown in it. For common wisdom among people with a budding knowledge of probability laws is to base their decision making on the following principle: It is very unlikely for someone to perform considerably well in a consistent fashion without his doing something right. Track records therefore become preeminent. They call on the rule of the likelihood of such a successful run and tell themselves that if someone performed better than the rest in the past then there is a great chance of his performing better than the crowd in the future—and a very great one at that. But, as usual, beware the middlebrow: A small knowledge of probability can lead to worse results than no knowledge at all.
IT DEPENDS ON THE NUMBER OF MONKEYS
I do not deny that if someone performed better than the crowd in the past, there is a presumption of his ability to do better in the future. But the presumption might be weak, very weak, to the point of being useless in decision making. Why? Because it all depends on two factors: The randomness content of his profession and the number of monkeys in operation.
The initial sample size matters greatly. If there are five monkeys in the game, I would be rather impressed with the
Iliad
writer, to the point of suspecting him to be a reincarnation of the ancient poet. If there are a billion to the power one billion monkeys I would be less impressed—as a matter of fact I would be surprised if one of them did not get some well-known (but unspecified) piece of work, just by luck (perhaps Casanova’s
Memoirs of My Life
). One monkey would even be expected to provide us with former vice president Al Gore’s
Earth in the Balance,
perhaps stripped of the platitudes.
This problem enters the business world more viciously than other walks of life, owing to the high dependence on randomness (we have already belabored the contrast between randomness-dependent business with dentistry). The greater the number of businessmen, the greater the likelihood of one of them performing in a stellar manner just by luck. I have rarely seen anyone count the monkeys. In the same vein, few count the investors in the market in order to calculate, instead of the probability of success, the conditional probability of successful runs given the number of investors in operation over a given market history.
VICIOUS REAL LIFE
There are other aspects to the monkeys problem; in real life the other monkeys are not countable, let alone visible. They are hidden away, as one sees only the winners—it is natural for those who failed to vanish completely. Accordingly, one sees the survivors, and only the survivors, which imparts such a mistaken perception of the odds. We do not respond to probability, but to society’s assessment of it. As we saw with Nero Tulip, even people with training in probability respond unintelligently to social pressure.
THIS SECTION
Part I described situations where people do not understand the rare event, and do not seem to accept either the possibility of its occurrence or the dire consequences of such occurrence. It also set out my own ideas, those that do not seem to have been explored in the literature. But a book on randomness is not complete without a presentation of what possible biases one might have aside from the deformations caused by the rare event. The business of Part II is more pedestrian; I will rapidly provide a synthesis of the biases of randomness as discussed in the now abundant literature on the subject.
These biases can be outlined as follows: (a) The survivorship biases (a.k.a. monkeys on a typewriter) arising from the fact that we see only winners and get a distorted view of the odds (Chapters
8
and
9
, “Too Many Millionaires” and “Fry an Egg”), (b) the fact that luck is most frequently the reason for extreme success (
Chapter 10
, “Loser Takes All”), and (c) the biological handicap of our inability to understand probability (
Chapter 11
, “Randomness and Our Brain”).


================================================================================
CHAPTER/SECTION 310 (Item 319)
================================================================================

Eight
•
TOO MANY MILLIONAIRES NEXT DOOR
Three illustrations of the survivorship bias. Why very few people should live on Park Avenue. The millionaire next door has very flimsy clothes. An overcrowding of experts.
HOW TO STOP THE STING OF FAILURE
Somewhat Happy
M
arc lives on Park Avenue in New York City with his wife, Janet, and their three children. He makes $500,000 a year, give or take a boom or a recession—he does not believe that the recent spurt in prosperity is here to last and has not mentally adjusted yet to his recent abrupt rise in income. A rotund man in his late forties, with spongy features that make him look ten years older than his age, he leads the seemingly comfortable (but heckled) life of a New York City lawyer. But he is on the quiet side of Manhattan residents. Marc is clearly not the man one would expect to go bar-hopping or attend late-night Tribeca and SoHo parties. He and his wife have a country house and a rose garden and tend to be concerned, like many people of their age, mentality, and condition, with (in the following order) material comfort, health, and status. Weekdays, he does not come home until at least 9:30 p.m. and, at times, he can be found in the office at close to midnight. By the end of the week, Marc is so fatigued that he falls asleep during their three-hour drive to “the house”; and Marc spends most of Saturday lying in bed recovering and healing.
Marc grew up in a small town in the Midwest, the son of a quiet tax accountant who worked with sharp yellow pencils. His obsession with sharpness was so strong that he carried a sharpener in his pocket at all times. Marc exhibited very early signs of intelligence. He did extremely well in high school. He attended Harvard College, then Yale Law School. Not bad, one would say. Later his career took him to corporate law, where he started working on large cases for a prestigious New York law firm, with barely enough hours left for him to brush his teeth. This is not too much an exaggeration, for he ate almost all of his dinners in the office, accumulating body fat and Brownie points toward his partnership. He later became a partner within the usual seven years, but not without the usual human costs. His first wife (whom he met in college) left him, as she was tired of an absentee lawyer husband and weary of the deterioration in his conversation—but, ironically, she ended up moving in with and later marrying another New York lawyer, probably with a no-less-flat conversation, but who made her happier.
Too Much Work
Marc’s body became progressively flabbier, and his bespoke suits needed periodic visits to the tailor, in spite of his occasional crash diets. After he got over the depression of the abandonment, he started dating Janet, his paralegal, and promptly married her. They had three children in quick succession, bought the Park Avenue apartment, and the country house.
Janet’s immediate acquaintance is composed of the other parents of the Manhattan private school attended by their children, and their neighbors at the co-operative apartment building where they live. From a materialistic standpoint, they come at the low end of such a set, perhaps even at the exact bottom. They would be the poorest of these circles, as their co-op is inhabited by extremely successful corporate executives, Wall Street traders, and high-flying entrepreneurs. Their children’s private school harbors the second set of children of corporate raiders, from their trophy wives—perhaps even the third set, if one takes into account the age discrepancy and the model-like features of the other mothers. By comparison, Marc’s wife, Janet, like him, presents a homely country-home-with-a-rose-garden type of appearance.
You’re a Failure
Marc’s strategy of staying in Manhattan may be rational, as his demanding work hours would make it impossible for him to commute. But the costs on his wife, Janet, are monstrous. Why? Because of their relative nonsuccess—as geographically defined by their Park Avenue neighborhood. Every month or so, Janet has a crisis, giving in to the strains and humiliations of being snubbed by some other mother at the school where she picks up the children, or another woman with larger diamonds by the elevator of the co-op where they live in the smallest type of apartments (the G line). Why isn’t her husband so successful? Isn’t he smart and hardworking? Didn’t he get close to 1600 on the SAT? Why is this Ronald Something, whose wife never even nods to Janet, worth hundreds of millions, when her husband went to Harvard and Yale and has such a high IQ and has hardly any substantial savings?
We will not get too involved in the Chekhovian dilemmas in the private lives of Marc and Janet, but their case provides a very common illustration of the emotional effect of
survivorship bias.
Janet feels that her husband is a failure, by comparison, but she is miscomputing the probabilities in a gross manner—she is using the wrong distribution to derive a rank. As compared to the general U.S. population, Marc has done very well, better than 99.5% of his compatriots. As compared to his high school friends, he did extremely well, a fact that he could have verified had he had time to attend the periodic reunions, and he would come at the top. As compared to the other people at Harvard, he did better than 90% of them (financially, of course). As compared to his law school comrades at Yale, he did better than 60% of them. But as compared to his co-op neighbors, he is at the bottom! Why? Because he chose to live among the people who have been successful, in an area that excludes failure. In other words, those who have failed do not show up in the sample, thus making him look as if he were not doing well at all. By living on Park Avenue, one does not have exposure to the losers, one only sees the winners. As we are cut to live in very small communities, it is difficult to assess our situation outside of the narrowly defined geographic confines of our habitat. In the case of Marc and Janet, this leads to considerable emotional distress; here we have a woman who married an extremely successful man but all she can see is comparative failure, for she cannot emotionally compare him to a sample that would do him justice.
Aside from the misperception of one’s performance, there is a social treadmill effect: You get rich, move to rich neighborhoods, then become poor again. To that add the psychological treadmill effect; you get used to wealth and revert to a set point of satisfaction. This problem of some people never really getting to feel satisfied by wealth (beyond a given point) has been the subject of technical discussions on happiness.
Someone would rationally say to Janet: “Go read this book
Fooled by Randomness
by one mathematical trader on the deformations of chance in life; it would give you a statistical sense of perspective and would accordingly make you feel better.” As an author, I would like to offer a panacea for $14.95, but I would rather say that in my best hopes it may provide an hour or so of solace. Janet may need something more drastic for relief. I have repeated that becoming more rational, or not feeling emotions of social slights, is not part of the human race, at least not with our current biology. There is no solace to be found from reasoning—as a trader I have learned something about these unfruitful efforts to reason against the grain. I would advise Janet to move out, and go live in some blue-collar neighborhood where they would feel less humiliated by their neighbors and rise in the pecking order beyond their probability of success. They could use the deformation in the opposite direction. If Janet cares about status, then I would even recommend some of these large housing blocks.
DOUBLE SURVIVORSHIP BIASES
More Experts
I recently read a bestseller called
The Millionaire Next Door,
an extremely misleading (but almost enjoyable) book by two “experts,” in which the authors try to infer some attributes that are common to rich people. They examined a collection of currently wealthy people and found out that these are unlikely to lead lavish lives. They call such people the accumulators; persons ready to postpone consumption in order to amass funds. Most of the appeal of the book comes from the simple but counterintuitive fact that these are less likely to look like very rich people—it clearly costs money to look and behave rich, not to count the time demands of spending money. Leading prosperous lives is time-consuming—shopping for trendy clothes, becoming conversant in Bordeaux wines, getting to know the expensive restaurants. All these activities can put high demands on one’s time and divert the subject from what should be the real preoccupation, namely the accumulation of nominal (and paper) wealth. The moral of the book is that the wealthiest are to be found among those less suspected to be wealthy. On the other hand, those who act and look wealthy subject their net worth to such a drain that they inflict considerable and irreversible damage to their brokerage account.
I will set aside the point that I see no special
heroism
in accumulating money, particularly if, in addition, the person is foolish enough to not even try to derive any tangible benefit from the wealth (aside from the pleasure of regularly counting the beans). I have no large desire to sacrifice much of my personal habits, intellectual pleasures, and personal standards in order to become a billionaire like Warren Buffett, and I certainly do not see the point of becoming one if I were to adopt Spartan (even miserly) habits and live in my starter house. Something about the praise lavished upon him for living in austerity while being so rich escapes me; if austerity is the end, he should become a monk or a social worker—we should remember that becoming rich is a purely selfish act, not a social one. The virtue of capitalism is that society can take advantage of people’s greed rather than their benevolence, but there is no need to, in addition, extol such greed as a moral (or intellectual) accomplishment (the reader can easily see that, aside from very few exceptions like George Soros, I am not impressed by people with money). Becoming rich is not directly a moral achievement, but that is not where the severe flaw in the book lies.
As we saw, the heroes of
The Millionaire Next Door
are the accumulators, people who defer spending in order to invest. It is undeniable that such strategy might work; money spent bears no fruit (except the enjoyment of the spender). But the benefits promised in the book seem grossly overstated. A finer read of their thesis reveals that their sample includes a double dose of survivorship bias. In other words, it has two compounding flaws.
Visibility Winners
The first bias comes from the fact that the rich people selected for their sample are among the lucky monkeys on typewriters. The authors made no attempt to correct their statistics with the fact that they saw only the winners. They make no mention of the “accumulators” who have accumulated the wrong things (members of my family are experts on that; those who accumulated managed to accumulate currencies about to be devalued and stocks of companies that later went bust). Nowhere do we see a mention of the fact that some people were lucky enough to have invested in the winners; these people no doubt would make their way into the book. There is a way to take care of the bias: Lower the wealth of your average millionaire by, say, 50%, on the grounds that the bias causes the average net worth of the observed millionaire to be higher by such amount (it consists in adding the effect of the losers into the pot). It would certainly modify the conclusion.
It’s a Bull Market
As to the second, more serious flaw, I have already discussed the problem of induction. The story focuses on an unusual episode in history; buying its thesis implies accepting that the current returns in asset values are permanent (the sort of belief that prevailed before the great crash that started in 1929). Remember that asset prices have (still at the time of writing) witnessed the greatest bull market in history and that values did compound astronomically during the past two decades. A dollar invested in the average stock would have grown almost twenty-fold since 1982—and that is the average stock. The sample might include people who invested in stocks performing better than average. Virtually all of the subjects became rich from asset price inflation, in other words from the recent inflation in financial paper and assets that started in 1982. An investor who engaged in the same strategy during less august days for the market would certainly have a different story to tell. Imagine the book being written in 1982, after the prolonged erosion of the inflation-adjusted value of the stocks, or in 1935, after the loss of interest in the stock market.
Or consider that the United States stock market is not the only investment vehicle. Consider the fate of those who, in place of spending their money buying expensive toys and paying for ski trips, bought Lebanese lira denominated Treasury bills (as my grandfather did), or junk bonds from Michael Milken (as many of my colleagues in the 1980s did). Go back in history and imagine the accumulator buying Russian Imperial bonds bearing the signature of Czar Nicholas II and trying to accumulate further by cashing them from the Soviet government, or Argentine real estate in the 1930s (as my great-grandfather did).
The mistake of ignoring the survivorship bias is chronic, even (or perhaps especially) among professionals. How? Because we are trained to take advantage of the information that is lying in front of our eyes, ignoring the information that we do not see. At the time of writing, pension funds and insurance companies in the United States and in Europe somehow bought the argument that “in the long term equities
always
pay off 9%” and back it up with statistics. The statistics are right, but they are past history. My argument is that I can find you a security somewhere among the 40,000 available that went up twice that amount every year without fail. Should we put the social security money into it?
A brief summing up at this point: I showed how we tend to mistake one realization among all possible random histories as the most representative one, forgetting that there may be others. In a nutshell, the survivorship bias implies that
the highest performing realization will be the most visible.
Why? Because the losers do not show up.
A GURU’S OPINION
The fund management industry is populated with gurus. Clearly, the field is randomness-laden and the guru is going to fall into a trap, particularly if he has no proper training in inference. At the time of writing, there is one such guru who developed the very unfortunate habit of writing books on the subject. Along with one of his peers, he computed the success of a “Robin Hood” policy of investing with the least successful manager in a given population of managers. It consists in switching down by taking money away from the winner and allocating it to the loser. This goes against the prevailing wisdom of investing with a winning manager and taking away money from a losing one. Doing so, their “paper strategy” (i.e., as in a Monopoly game, not executed in real life) derived considerably higher returns than if they stuck to the winning manager. Their hypothetical example seemed to them to prove that one should not stay with the best manager, as we would be inclined to do, but rather switch to the worst manager, or at least such seems to be the point they were attempting to convey.
Their analysis presents one severe hitch that any graduate student should be able to pinpoint at the first reading. Their sample only had
survivors.
They simply forgot to take into account the managers who went out of business. Such a sample includes managers that were operating during the simulation, and
are still operating today.
True, their sample included managers who did poorly, but only those managers who did poorly and recovered, without getting out of business. So it would be obvious that investing with those who fared poorly at some point but recovered (with the benefit of hindsight) would yield a positive return! Had they continued to fare poorly, they would be out of business and would not be included in the sample.
How should one conduct the proper simulation? By taking a population of managers in existence, say, five years ago and running the simulation up to today. Clearly, the attributes of those who leave the population are biased toward failure; few successful people in such a lucrative business call it quits because of extreme success. Before we turn to a more technical presentation of these issues, one mention of the much idealized buzzword of optimism. Optimism, it is said, is predictive of success. Predictive? It can also be predictive of failure. Optimistic people certainly take more risks as they are overconfident about the odds; those who win show up among the rich and famous, others fail and disappear from the analyses. Sadly.


================================================================================
CHAPTER/SECTION 311 (Item 320)
================================================================================

Nine
•
IT IS EASIER TO BUY AND SELL THAN FRY AN EGG
Some technical extensions of the survivorship bias. On the distribution of “coincidences” in life. It is preferable to be lucky than competent (but you can be caught). The birthday paradox. More charlatans (and more journalists). How the researcher with work ethics can find just about anything in data. On dogs not barking.
T
his afternoon I have an appointment with my dentist (it will mostly consist in the dentist picking my brain on Brazilian bonds). I can state with a certain level of comfort that he knows something about teeth, particularly if I enter his office with a toothache and exit it with some form of relief. It will be difficult for someone who knows literally nothing about teeth to provide me with such relief, except if he is particularly lucky on that day—or has been very lucky in his life to become a dentist while not knowing anything about teeth. Looking at his diploma on the wall, I determine that the odds that he repeatedly gave correct answers to the exam questions and performed satisfactorily on a few thousand cavities before his graduation—out of plain randomness—are remarkably small.
Later in the evening, I go to Carnegie Hall. I can say little about the pianist; I even forgot her unfamiliar foreign-sounding name. All I know is that she studied in some Muscovite conservatory. But I can expect to get some music out of the piano. It will be rare to have someone who performed brilliantly enough in the past to get to Carnegie Hall and now turns out to have benefited from luck alone. The expectation of having a fraud who will bang on the piano, producing only cacophonous sounds, is indeed low enough for me to rule it out completely.
I was in London last Saturday. Saturdays in London are magical; bustling but without the mechanical industry of a weekday or the sad resignation of a Sunday. Without a wristwatch or a plan I found myself in front of my favorite carvings by Canova at the Victoria and Albert Museum. My professional bent immediately made me question whether randomness played a large role in the carving of these marble statues. The bodies were realistic reproductions of human figures, except that they were more harmonious and finely balanced than anything I have seen mother nature produce on its own (Ovid’s
materiam superabat opus
comes to mind). Could such finesse be a product of luck?
I can practically make the same statement about anyone operating in the physical world, or in a business in which the degree of randomness is low. But there is a problem in anything related to the business world. I am bothered because tomorrow, unfortunately, I have an appointment with a fund manager seeking my help, and that of my friends, in finding investors. He has what he claims is a
good track record.
All I can infer is that he has learned to buy and sell. And it is harder to fry an egg than buy and sell. Well . . . the fact that he made money in the past may have some relevance, but not terribly so. This is not to say that it is always the case; there are some instances in which one can trust a track record, but, alas, there are not too many of these. As the reader now knows, the fund manager can expect to be heckled by me during the presentation, particularly if he does not exhibit the minimum of humility and self-doubt that I would expect from someone practicing randomness. I will probably bombard him with questions that he may not be prepared to answer, blinded by his past results. I will probably lecture him that Machiavelli ascribed to luck at least a 50% role in life (the rest was cunning and bravura), and that was before the creation of modern markets.
In this chapter, I discuss some well-known counterintuitive properties of performance records and historical time series. The concept presented here is well-known for some of its variations under the names
survivorship bias, data mining, data snooping, over-fitting, regression to the mean,
etc., basically situations where the performance is exaggerated by the observer, owing to a misperception of the importance of randomness. Clearly, this concept has rather unsettling implications. It extends to more general situations where randomness may play a share, such as the choice of a medical treatment or the interpretation of coincidental events.
When I am tempted to suggest a possible future contribution of financial research to science in general, I adduce the analysis of data mining and the study of survivorship biases. These have been refined in finance but can extend to all areas of scientific investigation. Why is finance so rich a field? Because it is one of the rare areas of investigation where we have plenty of information (in the form of abundant price series), but no ability to conduct experiments as in, say, physics. This dependence on past data brings about its salient defects.
FOOLED BY NUMBERS
Placebo Investors
I have often been faced with questions of the sort: “Who do you think you are to tell me that I might have been plain lucky in my life?” Well, nobody really believes that he or she was lucky. My approach is that, with our Monte Carlo engine, we can manufacture purely random situations. We can do the exact opposite of conventional methods; in place of analyzing real people hunting for attributes we can create artificial ones with precisely known attributes. Thus we can manufacture situations that depend on pure, unadulterated luck, without the shadow of skills or whatever we have called nonluck in Table P.1. In other words, we can man-make pure nobodies to laugh at; they will be
by design
stripped of any shadow of ability (exactly like a placebo drug).
We saw in
Chapter 5
how people may survive owing to traits that momentarily fit the given structure of randomness. Here we take a far simpler situation where
we know the structure of randomness;
the first such exercise is a finessing of the old popular saying that
even a broken clock is right twice a day.
We will take it a bit further to show that statistics is a knife that cuts on both sides. Let us use the Monte Carlo generator introduced earlier and construct a population of 10,000 fictional investment managers (the generator is not terribly necessary since we can use a coin, or even do plain algebra, but it is considerably more illustrative—and fun). Assume that they each have a perfectly fair game; each one has a 50% probability of making $10,000 at the end of the year, and a 50% probability of losing $10,000. Let us introduce an additional restriction; once a manager has a single bad year, he is thrown out of the sample, good-bye and have a nice life. Thus we will operate like the legendary speculator George Soros who was said to tell his managers gathered in a room: “Half of you guys will be out by next year” (with an Eastern European accent). Like Soros, we have extremely high standards; we are looking only for managers with an unblemished record. We have no patience for low performers.
The Monte Carlo generator will toss a coin;
heads
and the manager will make $10,000 over the year,
tails
and he will lose $10,000. We run it for the first year. At the end of the year, we expect 5,000 managers to be up $10,000 each, and 5,000 to be down $10,000. Now we run the game a second year. Again, we can expect 2,500 managers to be up two years in a row; another year, 1,250; a fourth one, 625; a fifth, 313. We have now, simply in a fair game, 313 managers who made money for five years in a row. Out of pure luck.
Meanwhile if we throw one of these successful traders into the real world we would get very interesting and helpful comments on his remarkable style, his incisive mind, and the influences that helped him achieve such success. Some analysts may attribute his achievement to precise elements among his childhood experiences. His biographer will dwell on the wonderful role models provided by his parents; we would be supplied with black-and-white pictures in the middle of the book of a great mind in the making. And the following year, should he stop outperforming (recall that his odds of having a good year have stayed at 50%) they would start laying blame, finding fault with the relaxation in his work ethics, or his dissipated lifestyle. They will find something he did before when he was successful that he has subsequently stopped doing, and attribute his failure to that. The truth will be, however, that he simply ran out of luck.
Nobody Has to Be Competent
Let’s push the argument further to make it more interesting. We create a cohort that is composed exclusively of incompetent managers. We will define an incompetent manager as someone who has a negative
expected return,
the equivalent of the odds being stacked against him. We instruct the Monte Carlo generator now to draw from an urn. The urn has 100 balls, 45 black and 55 red. By drawing with replacement, the ratio of red to black balls will remain the same. If we draw a black ball, the manager will earn $10,000. If we draw a red ball, he will lose $10,000. The manager is thus expected to earn $10,000 with 45% probability, and lose $10,000 with 55%. On average, the manager will lose $1,000 each round—but only
on average.
At the end of the first year, we still expect to have 4,500 managers turning a profit (45% of them), the second, 45% of that number, 2,025. The third, 911; the fourth, 410; the fifth, 184. Let us give the surviving managers names and dress them in business suits. True, they represent less than 2% of the original cohort. But they will get attention. Nobody will mention the other 98%.What can we conclude?
The first counterintuitive point is that a population entirely composed of bad managers will produce a small amount of great track records. As a matter of fact, assuming the manager shows up unsolicited at your door, it will be practically impossible to figure out whether he is good or bad. The results would not markedly change even if the population were composed entirely of managers who are expected in the long run to lose money. Why? Because owing to volatility, some of them will make money. We can see here that volatility actually helps bad investment decisions.
The second counterintuitive point is that the
expectation of the maximum
of track records, with which we are concerned, depends more on the size of the initial sample than on the individual odds per manager. In other words, the number of managers with great track records in a given market depends far more on the number of people who started in the investment business (in place of going to dental school), rather than on their ability to produce profits. It also depends on the volatility. Why do I use the notion of expectation of the maximum? Because I am not concerned at all with the average track record. I will get to see only the
best
of the managers, not all of the managers. This means that we would see more “excellent managers” in 2006 than in 1998, provided the cohort of beginners was greater in 2001 than it was in 1993—I can safely say that it was.
Regression to the Mean
The “hot hand in basketball” is another example of misperception of random sequences: It is very likely in a large sample of players for one of them to have an inordinately lengthy lucky streak. As a matter of fact it is very unlikely that an unspecified player somewhere does not have an inordinately lengthy lucky streak. This is a manifestation of the mechanism called regression to the mean. I can explain it as follows:
Generate a long series of coin flips producing heads and tails with 50% odds each and fill up sheets of paper. If the series is long enough you may get eight heads or eight tails in a row, perhaps even ten of each. Yet you know that in spite of these wins the conditional odds of getting a head or a tail is still 50%. Imagine these heads and tails as monetary bets filling up the coffers of an individual. The deviation from the norm as seen in excess heads or excess tails is here entirely attributable to luck, in other words, to variance, not to the skills of the hypothetical player (since there is an even probability of getting either).
A result is that in real life, the larger the deviation from the norm, the larger the probability of it coming from luck rather than skills: Consider that even if one has 55% probability of heads, the odds of ten wins is still very small. This can be easily verified in stories of very prominent people in trading rapidly reverting to obscurity, like the heroes I used to watch in trading rooms. This applies to height of individuals or the size of dogs. In the latter case, consider that two average-sized parents produce a large litter. The largest dogs, if they diverge too much from the average, will tend to produce offspring of smaller size than themselves, and vice versa. This “reversion” for the large outliers is what has been observed in history and explained as regression to the mean. Note that the larger the deviation, the more important its effect.
Again, one word of warning: All deviations do not come from this effect, but a disproportionately large proportion of them do.
Ergodicity
To get more technical, I have to say that people believe that they can figure out the properties of the distribution from the sample they are witnessing. When it comes to matters that depend on the maximum, it is altogether another distribution that is being inferred, that of the best performers. We call the difference between the average of such distribution and the unconditional distribution of winners and losers the survivorship bias—here the fact that about 3% of the initial cohort discussed earlier will make money five years in a row. In addition, this example illustrates the properties of ergodicity, namely, that time will eliminate the annoying effects of randomness. Looking forward, in spite of the fact that these managers were profitable in the past five years, we expect them to break even in any future time period. They will fare no better than those of the initial cohort who failed earlier in the exercise. Ah, the long term.
A few years ago, when I told one A., a then Master-of-the-Universe type, that track records were less relevant than he thought, he found the remark so offensive that he violently flung his cigarette lighter in my direction. The episode taught me a lot. Remember that nobody accepts randomness in his own success, only his failure. His ego was pumped up as he was heading up a department of “great traders” who were then temporarily making a fortune in the markets and attributing the idea to the soundness of their business, their insights, or their intelligence. They subsequently blew up during the harsh New York winter of 1994 (it was the bond market crash that followed the surprise interest rate hike by Alan Greenspan). The interesting part is that several years later I can hardly find any of them still trading (ergodicity).
Recall that the survivorship bias depends on the size of the initial population. The information that a person derived some profits in the past, just by itself, is neither meaningful nor relevant. We need to know the size of the population from which he came. In other words, without knowing how many managers out there have tried and failed, we will not be able to assess the validity of the track record. If the initial population includes ten managers, then I would give the performer half my savings without a blink. If the initial population is composed of 10,000 managers, I would ignore the results. The latter situation is generally the case; these days so many people have been drawn to the financial markets. Many college graduates are trading as a first career, failing, then going to dental school.
If, as in a fairy tale, these fictional managers materialized into real human beings, one of these could be the person I am meeting tomorrow at 11:45 a.m. Why did I select 11:45 a.m.? Because I will question him about his trading style. I need to know how he trades. I will then be able to claim that I have to rush to a lunch appointment if the manager puts too much emphasis on his track record.
LIFE IS COINCIDENTAL
Next, we look at the extensions to real life of our bias in the understanding of the distribution of coincidences.
The Mysterious Letter
You get an anonymous letter on January 2 informing you that the market will go up during the month. It proves to be true, but you disregard it owing to the well-known January effect (stocks have gone up historically during January). Then you receive another one on February 1 telling you that the market will go down. Again, it proves to be true. Then you get another letter on March 1—same story. By July you are intrigued by the prescience of the anonymous person and you are asked to invest in a special offshore fund. You pour all your savings into it. Two months later, your money is gone. You go spill your tears on your neighbor’s shoulder and he tells you that he remembers that he received two such mysterious letters. But the mailings stopped at the second letter. He recalls that the first one was correct in its prediction, the other incorrect.
What happened? The trick is as follows. The con operator pulls 10,000 names out of a phone book. He mails a bullish letter to one half of the sample, and a bearish one to the other half. The following month he selects the names of the persons to whom he mailed the letter whose prediction turned out to be right, that is, 5,000 names. The next month he does the same with the remaining 2,500 names, until the list narrows down to 500 people. Of these there will be 200 victims. An investment in a few thousand dollars’ worth of postage stamps will turn into several million.
An Interrupted Tennis Game
It is not uncommon for someone watching a tennis game on television to be bombarded by advertisements for funds that did (until that minute) outperform others by some percentage over some period. But, again, why would anybody advertise if he didn’t happen to outperform the market? There is a high probability of the investment coming to you if its success is caused entirely by randomness. This phenomenon is what economists and insurance people call adverse selection. Judging an investment that comes to you requires more stringent standards than judging an investment you seek, owing to such selection bias. For example, by going to a cohort composed of 10,000 managers, I have 2/100 chances of finding a spurious survivor. By staying home and answering my doorbell, the chance of the soliciting party being a spurious survivor is closer to 100%.
Reverse Survivors
We have so far discussed the spurious survivor—the same logic applies to the skilled person who has the odds markedly stacked in her favor, but who still ends up going to the cemetery. This effect is the exact opposite of the survivorship bias. Consider that all one needs is two bad years in the investment industry to terminate a risk-taking career and that, even with great odds in one’s favor, such an outcome is very possible. What do people do to survive? They maximize their odds of staying in the game by taking black-swan risks (like John and Carlos)—those that fare well most of the time, but incur a risk of blowing up.
The Birthday Paradox
The most intuitive way to describe the data mining problem to a nonstatistician is through what is called the birthday paradox, though it is not really a paradox, simply a perceptional oddity. If you meet someone randomly, there is a one in 365.25 chance of your sharing their birthday, and a considerably smaller one of having the exact birthday of the same year. So, sharing the same birthday would be a coincidental event that you would discuss at the dinner table. Now let us look at a situation where there are 23 people in a room. What is the chance of there being 2 people with the same birthday? About 50%. For we are not specifying which people need to share a birthday; any pair works.
It’s a Small World!
A similar misconception of probabilities arises from the random encounters one may have with relatives or friends in highly unexpected places. “It’s a small world!” is often uttered with surprise. But these are not improbable occurrences—the world is much larger than we think. It is just that we are not truly testing for the odds of having an encounter with one specific person, in a specific location at a specific time. Rather, we are simply testing for any encounter, with any person we have ever met in the past, and in any place we will visit during the period concerned. The probability of the latter is considerably higher, perhaps several thousand times the magnitude of the former.
When the statistician looks at the data
to test a given relationship,
say, to ferret out the correlation between the occurrence of a given event, like a political announcement, and stock market volatility, odds are that the results can be taken seriously. But when one throws the computer at data, looking for just about
any
relationship, it is certain that a spurious connection will emerge, such as the fate of the stock market being linked to the length of women’s skirts. And just like the birthday coincidences, it will amaze people.
Data Mining, Statistics, and Charlatanism
What is your probability of winning the New Jersey lottery twice? One in 17 trillion. Yet it happened to Evelyn Adams, whom the reader might guess should feel particularly chosen by destiny. Using the method we developed above, researchers Percy Diaconis and Frederick Mosteller estimated at 30 to 1 the probability that someone, somewhere, in a totally unspecified way, gets so lucky!
Some people carry their data mining activities into theology—after all, ancient Mediterraneans used to read potent messages in the entrails of birds. An interesting extension of data mining into biblical exegesis is provided in
The Bible Code
by Michael Drosnin. Drosnin, a former journalist (seemingly innocent of any training in statistics), aided by the works of a “mathematician,” helped “predict” the former Israeli Prime Minister Yitzhak Rabin’s assassination by deciphering a bible code. He informed Rabin, who obviously did not take it too seriously.
The Bible Code
finds statistical irregularities in the Bible; these help predict some such events. Needless to say that the book sold well enough to warrant a sequel predicting with hindsight even more such events.
The same mechanism is behind the formation of conspiracy theories. Like
The Bible Code
they can seem perfect in their logic and can cause otherwise intelligent people to fall for them. I can create a conspiracy theory by downloading hundreds of paintings from an artist or group of artists and finding a constant among all those paintings (among the hundreds of thousand of traits). I would then concoct a conspiratorial theory around a secret message shared by these paintings. This is seemingly what the author of the bestselling
The Da Vinci Code
did.
The Best Book I Have Ever Read!
My favorite time is spent in bookstores, where I aimlessly move from book to book in an attempt to make a decision as to whether to invest the time in reading it. My buying is frequently made on impulse, based on superficial but suggestive clues. Frequently, I have nothing but a book jacket as appendage to my decision making. Jackets often contain praise by someone, famous or not, or excerpts from a book review. Good praise by a famous and respected person or a well-known magazine would sway me into buying the book.
What is the problem? I tend to confuse a book review, which is supposed to be an assessment of the quality of the book, with the
best
book reviews, marred with the same survivorship biases. I mistake the distribution of the maximum of a variable with that of the variable itself. The publisher will never put on the jacket of the book anything but the best praise. Some authors go even a step beyond, taking a tepid or even unfavorable book review and selecting words in it that appear to praise the book. One such example came from one Paul Wilmott (an English financial mathematician of rare brilliance and irreverence) who managed to announce that I gave him his “first bad review,” yet used excerpts from it as praise on the book jacket (we later became friends, which allowed me to extract an endorsement from him for this book).
The first time I was fooled by this bias was upon buying, when I was sixteen,
Manhattan Transfer,
a book by John Dos Passos, the American writer, based on praise on the jacket by the French writer and “philosopher” Jean-Paul Sartre, who claimed something to the effect that Dos Passos was the greatest writer of our time. This simple remark, possibly blurted out in a state of intoxication or extreme enthusiasm, caused Dos Passos to become required reading in European intellectual circles, as Sartre’s remark was mistaken for a consensus estimate of the quality of Dos Passos rather than what it was, the best remark. (In spite of such interest in his work, Dos Passos has reverted to obscurity.)
The Backtester
A programmer helped me build a
backtester.
It is a software program connected to a database of historical prices, which allows me to check the hypothetical past performance of any trading rule of average complexity. I can just apply a mechanical trading rule, like buy NASDAQ stocks if they close more than 1.83% above their average of the previous week, and immediately get an idea of its past performance. The screen will flash my hypothetical track record associated with the trading rule. If I do not like the results, I can change the percentage to, say, 1.2%. I can also make the rule more complex. I will keep trying until I find something that works well.
What am I doing? The exact same task of looking for the survivor within the set of rules that can possibly work. I am
fitting
the rule on the data. This activity is called
data snooping.
The more I try, the more I am likely, by mere luck, to find a rule that worked on past data. A random series will always present some detectable pattern. I am convinced that there exists a tradable security in the Western world that would be 100% correlated with the changes in temperature in Ulan Bator, Mongolia.
To get technical, there are even worse extensions. An outstanding recent paper by Sullivan, Timmerman, and White goes further and considers that the rules that may be in use successfully today may be the result of a survivorship bias.
Suppose that, over time, investors have experimented with technical trading rules drawn from a very wide universe—in principle thousands of parameterizations of a variety of types of rules. As time progresses, the rules that happen to perform well historically receive more attention and are considered “serious contenders” by the investment community, while unsuccessful trading rules are more likely to be forgotten. . . . If enough trading rules are considered over time, some rules are bound by pure luck, even in a very large sample, to produce superior performance even if they do not genuinely possess predictive power over asset returns. Of course, inference based solely on the subset of surviving trading rules may be misleading in this context since it does not account for the full set of initial trading rules, most of which are unlikely to have underperformed.
I have to decry some excesses in backtesting that I have closely witnessed in my private career. There is an excellent product designed just for that, called Omega TradeStation, that is currently on the market, in use by tens of thousands of traders. It even offers its own computer language. Beset with insomnia, the computderized day traders become night testers plowing the data for some of its properties. By dint of throwing their monkeys on typewriters, without specifying what book they want their monkey to write, they will hit upon hypothetical gold somewhere. Many of them blindly believe in it.
One of my colleagues, a man with prestigious degrees, grew to believe in such a virtual world to the point of losing all sense of reality. Whether the modicum of common sense left in him might have rapidly vanished under the mounds of simulations, or whether he might have had none to engage in such pursuit, I cannot tell. By closely watching him I learned that what natural skepticism he may have had vanished under the weight of data—for he was extremely skeptical, but in the wrong area. Ah, Hume!
A More Unsettling Extension
Historically, medicine has operated by trial and error—in other words, statistically. We know by now that there can be entirely fortuitous connections between symptoms and treatment, and that some medications succeed in medical trials for mere random reasons. I cannot claim expertise in medicine, but have been a steady reader of a segment of the medical literature over the past half decade, long enough to be concerned with the standards, as we will see in the next chapter. Medical researchers are rarely statisticians; statisticians are rarely medical researchers. Many medical researchers are not even remotely aware of this data mining bias. True, it may only play a small role, but it is certainly present. One recent medical study links cigarette smoking to a
reduction
in breast cancer, thus conflicting with all previous studies. Logic would indicate that the result may be suspicious, the result of mere coincidence.
The Earnings Season: Fooled by the Results
Wall Street analysts, in general, are trained to find the accounting tricks that companies use to hide their earnings. They tend to (occasionally) beat the companies at that game. But they are neither trained to reflect nor to deal with randomness (nor to understand the limitations of their methods by introspecting—stock analysts have both a worse record and higher idea of their past performance than weather forecasters). When a company shows an increase in earnings once, it draws no immediate attention. Twice, and the name starts showing up on computer screens. Three times, and the company will merit some buy recommendation.
Just as with the track record problem, consider a cohort of 10,000 companies that are assumed on average to barely return the risk-free rate (i.e., Treasury bonds). They engage in all forms of volatile business. At the end of the first year, we will have 5,000 “star” companies showing an increase in profits (assuming no inflation), and 5,000 “dogs.” After three years, we will have 1,250 “stars.” The stock review committee at the investment house will give your broker their names as “strong buys.” He will leave a voice message that he has a hot recommendation that necessitates immediate action. You will be e-mailed a long list of names. You will buy one or two of them. Meanwhile, the manager in charge of your 401(k) retirement plan will be acquiring the entire list.
We can apply the reasoning to the selection of investment categories—as if they were the managers in the example above. Assume you are standing in 1900 with hundreds of investments to look at. There are the stock markets of Argentina, Imperial Russia, the United Kingdom, Unified Germany, and plenty of others to consider. A rational person would have bought not just the emerging country of the United States, but those of Russia and Argentina as well. The rest of the story is well-known; while many of the stock markets like those of the United Kingdom and the United States fared extremely well, the investor in Imperial Russia would have no better than medium-quality wallpaper in his hands. The countries that fared well are not a large segment of the initial cohort; randomness would be expected to allow a few investment classes to fare extremely well. I wonder if those “experts” who make foolish (and self-serving) statements like “markets will always go up in any twenty-year period” are aware of this problem.
COMPARATIVE LUCK
A far more acute problem relates to the outperformance, or the comparison, between two or more persons or entities. While we are certainly fooled by randomness when it comes to a single times series, the foolishness is compounded when it comes to the comparison between, say, two people, or a person and a benchmark. Why? Because
both
are random. Let us do the following simple thought experiment. Take two individuals, say, a person and his brother-in-law, launched through life. Assume equal odds for each of good and bad luck. Outcomes: lucky-lucky (no difference between them), unlucky-unlucky (again, no difference), lucky-unlucky (a large difference between them), unlucky-lucky (again, a large difference).
I recently attended for the first time a conference of investment managers where I sat listening to a very dull presenter comparing traders. His profession is to select fund managers and package them together for investors, something called “funds of funds” and I was listening to him as he was pouring out numbers on the screen. The first revelation was that I suddenly recognized the speaker, a former colleague biologically transformed by the passage of time. He used to be crisp, energetic, and nice; he became dull, portly, and inordinately comfortable with success. (He was not rich when I knew him—can people react to money in different ways? Do some take themselves seriously while others do not?) The second revelation was that while I suspected that he was fooled by randomness, the extent had to be far greater than one could imagine, particularly with the survivorship bias. A back of the envelope calculation showed that at least 97% of what he was discussing was just noise. The fact that he was
comparing
performances made the matter far worse.
Cancer Cures
When I return home from an Asian or European trip, my jet lag often causes me to rise at a very early hour. Occasionally, though very rarely, I switch on the TV set searching for market information. What strikes me in these morning explorations is the abundance of claims by the alternative medicine vendors of the curing power of their products. These no doubt are caused by the lower advertising rates at that time. To prove their claim, they present the convincing testimonial of someone who was cured thanks to their methods. For instance, I once saw a former throat cancer patient explaining how he was saved by a combination of vitamins for sale for the exceptionally low price of $14.95—in all likelihood he was sincere (although of course compensated for his account, perhaps with a lifetime supply of such medicine). In spite of our advances, people still believe in the existence of links between disease and cure based on such information, and there is no scientific evidence that can convince them more potently than a sincere and emotional testimonial. Such testimonial does not always come from the regular guy; statements by Nobel Prize winners (in the wrong discipline) could easily suffice. Linus Pauling, a Nobel Prize winner in chemistry, was said to believe in vitamin C’s medicinal properties, himself ingesting massive daily doses. With his bully pulpit, he contributed to the common belief in vitamin C’s curative properties. Many medical studies, unable to replicate Pauling’s claims, fell on deaf ears as it was difficult to undo the testimonial by a “Nobel Prize winner,” even if he was not qualified to discuss matters related to medicine.
Many of these claims have been harmless outside of the financial profits for these charlatans—but many cancer patients may have replaced the more scientifically investigated therapies, in favor of these methods, and died as a result of their neglecting more orthodox cures (again, the nonscientific methods are gathered under what is called “alternative medicine,” that is, unproven therapies, and the medical community has difficulties convincing the press that there is only one medicine and that alternative medicine is not medicine). The reader might wonder about my claims that the user of these products could be sincere, without it meaning that he was cured by the illusory treatment. The reason is something called “spontaneous remission,” in which a very small minority of cancer patients, for reasons that remain entirely speculative, wipe out cancer cells and recover “miraculously.” Some switch causes the patient’s immune system to eradicate all cancer cells from the body. These people would have been equally cured by drinking a glass of Vermont spring water or chewing on dried beef as they were by taking these beautifully wrapped pills. Finally, these spontaneous remissions might not be so spontaneous; they might, at the bottom, have a cause that we are not yet sophisticated enough to detect.
The late astronomer Carl Sagan, a devoted promoter of scientific thinking and an obsessive enemy of nonscience, examined the cures from cancer that resulted from a visit to Lourdes in France, where people were healed by simple contact with the holy waters, and found out the interesting fact that, of the total cancer patients who visited the place, the cure rate was, if anything, lower than the statistical one for spontaneous remissions. It was lower than the average for those who did not go to Lourdes! Should a statistician infer here that cancer patients’ odds of surviving deteriorates after a visit to Lourdes?
Professor Pearson Goes to Monte Carlo (Literally):
Randomness Does Not Look Random!
At the beginning of the twentieth century, as we were starting to develop techniques to deal with the notion of random outcomes, several methods were designed to detect anomalies. Professor Karl Pearson (father of Egon Pearson of Neyman-Pearson fame, familiar to every person who sat in a statistics 101 class) devised the first test of nonrandomness (it was in reality a test of deviation from normality, which, for all intents and purposes, was the same thing). He examined millions of runs of what was called a Monte Carlo (the old name for a roulette wheel) during the month of July 1902. He discovered that, with a high degree of statistical significance (with an error of less than one to a billion), the runs were not purely random. What! The roulette wheel was not random! Professor Pearson was greatly surprised at the discovery. But this result in itself tells us nothing; we know that there is no such thing as a pure random draw, for the outcome of the draw depends on the quality of the equipment. With enough minutiae one would be able to uncover the nonrandomness somewhere (e.g., the wheel itself may not have been perfectly balanced or perhaps the spinning ball was not completely spherical). Philosophers of statistics call this the
reference case problem
to explain that there is no true attainable randomness in practice, only in theory. Besides, a manager would question whether such nonrandomness can lead to any meaningful, profitable rules. If I need to gamble $1 on 10,000 runs and expect to make $1 for my efforts, then I would do much better in the part-time employment of a janitorial agency.
But the result bears another suspicious element. Of more practical relevance here is the following severe problem about nonrandomness. Even the fathers of statistical science forgot that a random series of runs need not exhibit a pattern to look random; as a matter of fact, data that is perfectly patternless would be extremely suspicious and appear to be man-made. A single random run is bound to exhibit some pattern—if one looks hard enough. Note that Professor Pearson was among the first scholars who were interested in creating artificial random data generators, tables one could use as inputs for various scientific and engineering simulations (the precursors of our Monte Carlo simulator). The problem is that they did not want these tables to exhibit any form of regularity. Yet real randomness does not look random!
I would further illustrate the point with the study of a phenomenon well-known as cancer clusters. Consider a square with 16 random darts hitting it with equal probability of being at any place in the square. If we divide the square into 16 smaller squares, it is expected that each smaller square will contain one dart on average—but only on average. There is a very small probability of having exactly 16 darts in 16 different squares. The average grid will have more than one dart in a few squares, and no dart at all in many squares. It will be an exceptionally rare incident that no (cancer) cluster would show on the grid. Now, transpose our grid with the darts in it to overlay a map of any region. Some newspaper will declare that one of the areas (the one with more than the average of darts) harbors radiation that causes cancer, prompting lawyers to start soliciting the patients.
The Dog That Did Not Bark: On Biases
in Scientific Knowledge
By the same argument, science is marred by a pernicious survivorship bias, affecting the way research gets published. In a way that is similar to journalism, research that yields no result does not make it to print. That may seem sensible, as newspapers do not have to have a screaming headline saying that nothing new is taking place (though the Bible was smart enough to declare
ein chadash tachat hashemesh—
“nothing new under the sun,” providing the information that things just do recur). The problem is that a finding of absence and an absence of findings get mixed together. There may be great information in the fact that
nothing took place.
As Sherlock Holmes noted in the
Silver Blaze
case—the curious thing was that the dog did not bark. More problematic, there are plenty of scientific results that are left out of publications because they are not statistically significant, but nevertheless provide information.
I HAVE NO CONCLUSION
I am frequently asked the question “When is it truly not luck?” There are professions in randomness for which performance is low in luck, like casinos, which manage to tame randomness. In finance? Perhaps. All traders are not speculative traders: There exists a segment called market makers whose job is to derive, like bookmakers, or even like store owners, an income against a transaction. If they speculate, their dependence on the risks of such speculation remains too small compared to their overall volume. They buy at a price and sell to the public at a more favorable one, performing large numbers of transactions. Such income provides them some insulation from randomness. Such category includes floor traders on the exchanges, bank traders who “trade against order flow,” money changers in the souks of the Levant. The skills involved are sometimes rare to find: Fast thinking, alertness, a high level of energy, an ability to guess from the voice of the seller her level of nervousness; those who have them make a long career (that is, perhaps a decade).They never make it big, as their income is constrained by the number of customers, but they do well probabilistically. They are, in a way, the dentists of the profession.
Outside of this very specialized bookmaker-style profession, to be honest, I am unable to answer the question of who’s lucky or unlucky. I can tell that person A seems less lucky than person B, but the confidence in such knowledge can be so weak as to be meaningless. I prefer to remain a skeptic. People frequently misinterpret my opinion. I never said that every rich man is an idiot and every unsuccessful person unlucky, only that in absence of much additional information it is preferable to reserve one’s judgment. It is safer.


================================================================================
CHAPTER/SECTION 312 (Item 321)
================================================================================

Ten
•
LOSER TAKES ALL—ON THE NONLINEARITIES OF LIFE
The nonlinear viciousness of life. Moving to Bel Air and acquiring the vices of the rich and famous. Why Microsoft’s Bill Gates may not be the best in his business (but please do not inform him of such a fact). Depriving donkeys of food.
N
ext I put the platitude
life is unfair
under some examination, but from a new angle. The twist: Life is unfair in a
nonlinear
way. This chapter is about how a small advantage in life can translate into a highly disproportionate payoff, or, more viciously, how no advantage at all, but a very, very small help from randomness, can lead to a bonanza.
THE SANDPILE EFFECT
First we define
nonlinearity.
There are many ways to present it, but one of the most popular ones in science is what is called the sand-pile effect, which I can illustrate as follows. I am currently sitting on a beach in Copacabana, in Rio de Janeiro, attempting to do nothing strenuous, away from anything to read and write (unsuccessfully, of course, as I am mentally writing these lines). I am playing with plastic beach toys borrowed from a child, trying to build an edifice—modestly but doggedly attempting to emulate the Tower of Babel. I continuously add sand to the top, slowly raising the entire structure. My Babylonian relatives thought they could thus reach the heavens. I have more humble designs—to test how high I can go before it topples. I keep adding sand, testing to see how the structure will ultimately collapse. Unused to seeing adults build sandcastles, a child looks at me with amazement.
In time—and much to the onlooking child’s delight—my castle inevitably topples to rejoin the rest of the sand on the beach. It could be said that the last grain of sand is responsible for the destruction of the entire structure. What we are witnessing here is a nonlinear effect resulting from a linear force exerted on an object. A very small additional input, here the grain of sand, caused a disproportionate result, namely the destruction of my starter Tower of Babel. Popular wisdom has integrated many such phenomena, as witnessed by such expressions as “the straw that broke the camel’s back” or “the drop that caused the water to spill.”
These nonlinear dynamics have a bookstore name, “chaos theory,” which is a misnomer because it has nothing to do with chaos. Chaos theory concerns itself primarily with functions in which a small input can lead to a disproportionate response. Population models, for instance, can lead to a path of explosive growth, or extinction of a species, depending on a very small difference in the population at a starting point in time. Another popular scientific analogy is the weather, where it has been shown that a simple butterfly fluttering its wings in India can cause a hurricane in New York. But the classics have their share to offer as well: Pascal (he of the wager in
Chapter 7
) said that if Cleopatra’s nose had been slightly shorter, the world’s fate would have changed. Cleopatra had comely features dominated by a thin and elongated nose that made Julius Caesar and his successor, Marc Antony, fall for her (here the intellectual snob in me cannot resist dissenting against conventional wisdom; Plutarch claimed that it was Cleopatra’s skills in conversation, rather than her good looks, that caused the maddening infatuation of the shakers and movers of her day; I truly believe it).
Enter Randomness
Things can become more interesting when randomness enters the game. Imagine a waiting room full of actors queuing for an audition. The number of actors who will win is clearly small, and they are the ones generally observed by the public as representative of the profession, as we saw in our discussion on survivorship bias. The winners would move into Bel Air, feel pressure to acquire some basic training in the consumption of luxury goods, and, perhaps owing to the dissolute and unrhythmic lifestyle, flirt with substance abuse. As to the others (the great majority), we can imagine their fate; a lifetime of serving foamed
caffe latte
at the neighboring Starbucks, fighting the biological clock between auditions.
One may argue that the actor who lands the lead role that catapults him into fame and expensive swimming pools has some skills others lack, some charm, or a specific physical trait that is a perfect match for such a career path. I beg to differ. The winner may have some acting skills, but so do all of the others, otherwise they would not be in the waiting room.
It is an interesting attribute of fame that it has its own dynamics. An actor becomes known by some parts of the public because he is known by other parts of the public. The dynamics of such fame follow a rotating helix, which may have started at the audition, as the selection could have been caused by some silly detail that fitted the mood of the examiner on that day. Had the examiner not fallen in love the previous day with a person with a similar-sounding last name, then our selected actor from that particular sample
history
would be serving
caffe latte
in the intervening sample
history.
Learning to Type
Researchers frequently use the example of QWERTY to describe the vicious dynamics of winning and losing in an economy, and to illustrate how the final outcome is more than frequently the undeserved one. The arrangement of the letters on a typewriter is an example of the success of the least deserving method. For our typewriters have the order of the letters on their keyboard arranged in a nonoptimal manner, as a matter of fact in such a nonoptimal manner as to slow down the typing rather than make the job easy, in order to avoid jamming the ribbons as they were designed for less electronic days. Therefore, as we started building better typewriters and computerized word processors, several attempts were made to rationalize the computer keyboard, to no avail. People were trained on a QWERTY keyboard and their habits were too sticky for change. Just like the helical propulsion of an actor into stardom, people patronize what other people like to do. Forcing rational dynamics on the process would be superfluous, nay, impossible. This is called a
path dependent outcome,
and has thwarted many mathematical attempts at modeling behavior.
It is obvious that the information age, by homogenizing our tastes, is causing the unfairness to be even more acute—those who win capture almost all the customers. The example that strikes many as the most spectacular lucky success is that of the software maker Microsoft and its moody founder Bill Gates. While it is hard to deny that Gates is a man of high personal standards, work ethics, and above-average intelligence, is he the best? Does he
deserve
it? Clearly not. Most people are equipped with his software (like myself ) because other people are equipped with his software, a purely circular effect (economists call that “network externalities”). Nobody ever claimed that it was the best software product. Most of Gates’ rivals have an obsessive jealousy of his success. They are maddened by the fact that he managed to win so big while many of them are struggling to make their companies survive.
Such ideas go against classical economic models, in which results either come from a precise reason (there is no account for uncertainty) or the good guy wins (the good guy is the one who is more skilled and has some technical superiority). Economists discovered path-dependent effects late in their game, then tried to publish wholesale on the topic that otherwise would be bland and obvious. For instance, Brian Arthur, an economist concerned with nonlinearities at the Santa Fe Institute, wrote that chance events coupled with positive feedback rather than technological superiority will determine economic superiority—not some abstrusely defined edge in a given area of expertise. While early economic models excluded randomness, Arthur explained how “unexpected orders, chance meetings with lawyers, managerial whims . . . would help determine which ones achieved early sales and, over time, which firms dominated.”
MATHEMATICS INSIDE AND OUTSIDE THE REAL WORLD
A mathematical approach to the problem is in order. While in conventional models (such as the well-known Brownian random walk used in finance) the probability of success does not change with every incremental step, only the accumulated wealth, Arthur suggests models such as the Polya process, which is mathematically very difficult to work with, but can be easily understood with the aid of a Monte Carlo simulator. The Polya process can be presented as follows: Assume an urn initially containing equal quantities of black and red balls. You are to guess each time which color you will pull out before you make the draw. Here the game is rigged. Unlike a conventional urn, the probability of guessing correctly depends on past success, as you get better or worse at guessing depending on past performance. Thus, the probability of winning increases after past wins, that of losing increases after past losses. Simulating such a process, one can see a huge variance of outcomes, with astonishing successes and a large number of failures (what we called skewness).
Compare such a process with those that are more commonly modeled, that is, an urn from which the player makes guesses with replacement. Say you played roulette and won. Would this increase your chances of winning again? No. In a Polya process case, it does. Why is this so mathematically hard to work with? Because the notion of independence (i.e., when the next draw does not depend on past outcomes) is violated. Independence is a requirement for working with the (known) math of probability.
What has gone wrong with the development of economics as a science? Answer: There was a bunch of intelligent people who felt compelled to use mathematics just to tell themselves that they were rigorous in their thinking, that theirs was a science. Someone in a great rush decided to introduce mathematical modeling techniques (culprits: Leon Walras, Gerard Debreu, Paul Samuelson) without considering the fact that either the class of mathematics they were using was too restrictive for the class of problems they were dealing with, or that perhaps they should be aware that the precision of the language of mathematics could lead people to believe that they had solutions when in fact they had none (recall Popper and the costs of taking science too seriously). Indeed the mathematics they dealt with did not work in the real world, possibly because we needed richer classes of processes—and they refused to accept the fact that no mathematics at all was probably better.
The so-called
complexity theorists
came to the rescue. Much excitement was generated by the works of scientists who specialized in nonlinear quantitative methods—the mecca of those being the Santa Fe Institute near Santa Fe, New Mexico. Clearly these scientists are trying hard, and providing us with wonderful solutions in the physical sciences and better models in the social siblings (though nothing satisfactory there yet). And if they ultimately do not succeed, it will simply be because mathematics may be of only secondary help in our real world. Note another advantage of Monte Carlo simulations is that we can get results where mathematics fails us and can be of no help. In freeing us from equations it frees us from the traps of inferior mathematics. As I said in
Chapter 3
, mathematics is merely a way of thinking and meditating, little more, in our world of randomness.
The Science of Networks
Studies of the dynamics of networks have mushroomed recently. They became popular with Malcolm Gladwell’s book
The Tipping Point,
in which he shows how some of the behaviors of variables such as epidemics spread extremely fast beyond some unspecified critical level. (Like, say, the use of sneakers by inner-city kids or the diffusion of religious ideas. Book sales witness a similar effect, exploding once they cross a significant level of word-of-mouth.) Why do some ideologies or religions spread like wildfire while others become rapidly extinct? How do fads catch fire? How do idea viruses proliferate? Once one exits the conventional models of randomness (the bell curve family of charted randomness), something acute can happen. Why does the Internet hub Google get so many hits as compared to that of the National Association of Retired Veteran Chemical Engineers? The more connected a network, the higher the probability of someone hitting it and the more connected it will be, especially if there is no meaningful limitation on such capacity. Note that it is sometimes foolish to look for precise “critical points” as they may be unstable and impossible to know except, like many things, after the fact. Are these “critical points” not quite points but progressions (the so-called Pareto power laws)? While it is clear that the world produces clusters it is also sad that these may be too difficult to predict (outside of physics) for us to take their models seriously. Once again the important fact is knowing the existence of these nonlinearities, not trying to model them. The value of the great Benoit Mandelbrot’s work lies more in telling us that there is a “wild” type of randomness of which we will never know much (owing to their unstable properties).
Our Brain
Our brain is not cut out for nonlinearities. People think that if, say, two variables are causally linked, then a steady input in one variable should
always
yield a result in the other one. Our emotional apparatus is designed for linear causality. For instance, you study every day and learn something in proportion to your studies. If you do not feel that you are going anywhere, your emotions will cause you to become demoralized. But reality rarely gives us the privilege of a satisfying linear positive progression: You may study for a year and learn nothing, then, unless you are disheartened by the empty results and give up, something will come to you in a flash. My partner Mark Spitznagel summarizes it as follows: Imagine yourself practicing the piano every day for a long time, barely being able to perform “Chopsticks,” then suddenly finding yourself capable of playing Rachmaninov. Owing to this nonlinearity, people cannot comprehend the nature of the rare event. This summarizes why there are routes to success that are nonrandom, but few, very few, people have the mental stamina to follow them. Those who go the extra mile are rewarded. In my profession one may own a security that benefits from lower market prices, but may not react at all until some critical point. Most people give up before the rewards.
Buridan’s Donkey or the Good Side of Randomness
Nonlinearity in random outcomes is sometimes used as a tool to break stalemates. Consider the problem of the nonlinear nudge. Imagine a donkey equally hungry and thirsty placed at exactly equal distance from sources of food and water. In such a framework, he would die of both thirst and hunger as he would be unable to decide which one to get to first. Now inject some randomness in the picture, by randomly nudging the donkey, causing him to get closer to one source, no matter which, and accordingly away from the other. The impasse would be instantly broken and our happy donkey will be either in turn well fed then well hydrated, or well hydrated then well fed.
The reader no doubt has played a version of Buridan’s donkey, by “flipping a coin” to break some of the minor stalemates in life where one lets randomness help with the decision process. Let Lady Fortuna make the decision and gladly submit. I often use Buridan’s donkey (under its mathematical name) when my computer goes into a freeze between two possibilities (to be technical, these “randomizations” are frequently done during optimization problems, when one needs to perturbate a function).
Note that Buridan’s donkey was named after the fourteenth-century philosopher Jean Buridan. Buridan had an interesting death (he was thrown in the Seine tied in a bag and died drowning). This tale was considered an example of sophistry by his contemporaries who missed the import of randomization—Buridan was clearly ahead of his time.
WHEN IT RAINS, IT POURS
As I am writing these lines, I am suddenly realizing that the world’s bipolarity is hitting me very hard. Either one succeeds wildly, by attracting all the cash, or fails to draw a single penny. Likewise with books. Either everyone wants to publish it, or nobody is interested in returning telephone calls (in the latter case my discipline is to delete the name from my address book). I am also realizing the nonlinear effect behind success in anything: It is better to have a handful of enthusiastic advocates than hordes of people who appreciate your work—better to be loved by a dozen than liked by the hundreds. This applies to the sales of books, the spread of ideas, and success in general and runs counter to conventional logic. The information age is worsening this effect. This is making me, with my profound and antiquated Mediterranean sense of
metron
(measure), extremely uncomfortable, even queasy. Too much success is the enemy (think of the punishment meted out on the rich and famous); too much failure is demoralizing. I would like the option of having neither.


================================================================================
CHAPTER/SECTION 313 (Item 322)
================================================================================

Eleven
•
RANDOMNESS AND OUR MIND: WE ARE PROBABILITY BLIND
On the difficulty of thinking of your vacation as a linear combination of Paris and the Bahamas. Nero Tulip may never ski in the Alps again. Do not ask bureaucrats too many questions. A Brain Made in Brooklyn. We need Napoleon. Scientists bowing to the King of Sweden. A little more on journalistic pollution. Why you may be dead by now.
PARIS OR THE BAHAMAS?
Y
ou have two options for your next brief vacation in March. The first is to fly to Paris; the second is to go to the Caribbean. You expressed indifference between the two options; your spouse will tip the decision one way or the other. Two distinct and separate images come to you when you think of the possibilities. In the first one, you see yourself standing at the Musée d’Orsay in front of some Pissaro painting depicting a cloudy sky—the gray Parisian wintry sky. You are carrying an umbrella under your arm. In the second image, you are lying on a towel with a stack of books by your favorite authors next to you (Tom Clancy and Ammianus Marcellinus), and an obsequious waiter serving you a banana daiquiri. You know that the two states are mutually exclusive (you can only be in one place at one time), but exhaustive (there is a 100% probability that you will be in one of them). They are equiprobable, with, in your opinion, 50% probability assigned to each.
You derive great pleasure thinking about your vacation; it motivates you and makes your daily commute more bearable. But the adequate way to visualize yourself, according to rational behavior under uncertainty, is 50% in one of the vacation spots and 50% in the other—what is mathematically called a
linear combination
of the two states. Can your brain handle that? How desirable would it be to have your feet in the Caribbean waters and your head exposed to the Parisian rain? Our brain can properly handle one and only one state at once—unless you have personality troubles of a deeply pathological nature. Now try to imagine an 85%/15% combination. Any luck?
Consider a bet you make with a colleague for the amount of $1,000, which, in your opinion, is exactly fair. Tomorrow night you will have zero or $2,000 in your pocket, each with a 50% probability. In purely mathematical terms, the fair value of a bet is the linear combination of the states, here called the
mathematical expectation,
i.e., the probabilities of each payoff multiplied by the dollar values at stake (50% multiplied by 0 and 50% multiplied by $2,000 =$1,000). Can you
imagine
(that is visualize, not compute mathematically) the value being $1,000? We can conjure up one
and only one
state at a given time, i.e., either 0 or $2,000. Left to our own devices, we are likely to bet in an irrational way, as one of the states would dominate the picture—the fear of ending with nothing or the excitement of an extra $1,000.
SOME ARCHITECTURAL CONSIDERATIONS
Time to reveal Nero’s secret. It was a black swan. He was then thirty-five. Although prewar buildings in New York can have a pleasant front, their architecture seen from the back offers a stark contrast by being completely bland. The doctor’s examination room had a window overlooking the backyard of one such Upper East Side street, and Nero will always remember how bland that backyard was in comparison with the front, even if he were to live another half century. He will always remember the view of the ugly pink backyard from the leaden window panes, and the medical diploma on the wall that he read a dozen times as he was waiting for the doctor to come into the room (half an eternity, for Nero suspected that something was wrong). The news was then delivered (grave voice), “I have some . . . I got the pathology report . . . It’s . . . It is not as bad as it sounds . . . It’s . . . It’s cancer.” The declaration caused his body to be hit by an electric discharge, running through his back down to his knees. Nero tried to yell “What?” but no sound came out of his mouth. What scared him was not so much the news as the sight of the doctor. Somehow the news reached his body before his mind. There was too much fear in the doctor’s eyes and Nero immediately suspected that the news was even worse than what he was being told (it was).
The night of the diagnosis, at the medical library where he sat, drenched wet from walking for hours in the rain without noticing it and making a puddle of water around him (he was yelled at by an attendant but could not concentrate on what she was saying so she shrugged her shoulders and walked away); later he read the sentence “72% 5-year actuarially adjusted survival rate.” It meant that 72 people out of 100 make it. It takes between three and five years for the body without clinical manifestations of the disease for the patient to be pronounced cured (closer to three at his age). He then felt in his guts quite certain that he was going to make it.
Now the reader might wonder about the mathematical difference between a 28% chance of death and a 72% chance of survival over the next five years. Clearly, there is none, but we are not made for mathematics. In Nero’s mind a 28% chance of death meant the image of himself dead, and thoughts of the cumbersome details of his funeral. A 72% chance of survival put him in a cheerful mood; his mind was planning the result of a cured Nero skiing in the Alps. At no point during his ordeal did Nero think of himself as 72% alive and 28% dead.
Just as Nero cannot “think” in complicated shades, consumers consider a 75% fat-free hamburger to be different from a 25% fat one. Likewise with statistical significance. Even specialists tend to infer too fast from data in accepting or rejecting things. Recall the dentist whose emotional well-being depends on the recent performance of his portfolio. Why? Because as we will see, rule-determined behavior does not require nuances. Either you kill your neighbor or you don’t. Intermediate sentiments (leading, say, to only half his killing) are either useless or downright dangerous when you do things. The emotional apparatus that jolts us into action does not understand such nuances—it is not efficient to understand things. The rest of this chapter will rapidly illustrate some manifestations of such blindness, with a cursory exposition of the research in that area (only what connects to the topics in this book).
BEWARE THE PHILOSOPHER BUREAUCRAT
For a long time we had the wrong product specifications when we thought of ourselves. We humans have been under the belief that we were endowed with a beautiful machine for thinking and understanding things. However, among the factory specifications for us is the lack of awareness of the true factory specifications (why complicate things?). The problem with thinking is that it causes you to develop illusions. And thinking may be such a waste of energy! Who needs it!
Consider that you are standing in front of a government clerk in a heavily socialist country where being a bureaucrat is held to be what respectable people do for a living. You are there to get your papers stamped by him so you can export some of their lovely chocolate candies to the New Jersey area, where you think the local population would have a great taste for them. What do you think his function is? Do you think for a minute that he cares about the general economic theory behind the transaction? His job is just to verify that you have the twelve or so signatures from the right departments, true/false; then stamp your papers and let you go. General considerations of economic growth or balance of trade are none of his interests. In fact you are lucky that he doesn’t spend any time meditating about these things: Consider how long the procedure would take if he had to solve balance of trade equations. He just has a rulebook and, over a career spanning forty to forty-five years, he will just stamp documents, be mildly rude, and go home to drink nonpasteurized beer and watch soccer games. If you gave him Paul Krugman’s book on international economics he would either sell it in the black market or give it to his nephew.
Accordingly, rules have their value. We just follow them not because they are the best but because they are useful and they save time and effort. Consider that those who started theorizing upon seeing a tiger on whether the tiger was of this or that taxonomic variety, and the degree of danger it represented, ended up being eaten by it. Others who just ran away at the smallest presumption and were not slowed down by the smallest amount of thinking ended up either outchasing the tiger or outchasing their cousin who ended up being eaten by it.
Satisficing
It is a fact that our brains would not be able to operate without such shortcuts. The first thinker who figured it out was Herbert Simon, an interesting fellow in intellectual history. He started out as a political scientist (but he was a formal thinker, not the literary variety of political scientists who write about Afghanistan in
Foreign Affairs
); he was an artificial-intelligence pioneer, taught computer science and psychology, did research in cognitive science, philosophy, and applied mathematics, and received the Bank of Sweden Prize for Economics in honor of Alfred Nobel. His idea is that if we were to optimize at every step in life, then it would cost us an infinite amount of time and energy. Accordingly, there has to be in us an approximation process that stops somewhere. Clearly he got his intuitions from computer science—he spent his entire career at Carnegie-Mellon University in Pittsburgh, which has a reputation as a computer science center. “Satisficing” was his idea (the melding together of
satisfy
and
suffice
): You stop when you get a near-satisfactory solution. Otherwise it may take you an eternity to reach the smallest conclusion or perform the smallest act. We are therefore rational, but in a limited way: “boundedly rational.” He believed that our brains were a large optimizing machine that had built-in rules to stop somewhere.
Not quite so, perhaps. It may not be just a rough approximation. For two (initially) Israeli researchers on human nature, how we behave seemed to be a completely different process from the optimizing machine presented by Simon. The two sat down introspecting in Jerusalem looking at aspects of their own thinking, compared it to rational models, and noticed
qualitative
differences. Whenever they both seemed to make the same mistake of reasoning they ran empirical tests on subjects, mostly students, and discovered very surprising results on the relation between thinking and rationality. It is to their discovery that we turn next.
FLAWED, NOT JUST IMPERFECT
Kahneman and Tversky
Who has exerted the most influence on economic thinking over the past two centuries? No, it is not John Maynard Keynes, not Alfred Marshall, not Paul Samuelson, and certainly not Milton Friedman. The answer is two noneconomists: Daniel Kahneman and Amos Tversky, the two Israeli introspectors, and their specialty was to uncover areas where human beings are not endowed with rational probabilistic thinking and optimal behavior under uncertainty. Strangely, economists studied uncertainty for a long time and did not figure out much—if anything, they thought they knew something and were fooled by it. Aside from some penetrating minds like Keynes, Knight, and Shackle, economists did not even figure out that they had no clue about uncertainty—the discussions on risk by their idols show that
they did not know how much they did not know.
Psychologists, on the other hand, looked at the problem and came out with solid results. Note that, unlike economists, they conducted experiments, true controlled experiments of a repeatable nature, that can be done in Ulan Bator, Mongolia, tomorrow if necessary. Conventional economists do not have this luxury as they observe the past and make lengthy and mathematical comments, then bicker with each other about them.
Kahneman and Tversky went in a completely different direction than Simon and started figuring out rules in humans that did not make them rational—but things went beyond the shortcut. For them, these rules, which are called
heuristics,
were not merely a simplification of rational models, but were different in methodology and category. They called them “quick and dirty” heuristics. There is a dirty part: These shortcuts came with side effects, these effects being the biases, most of which I discussed previously throughout the text (such as the inability to accept anything abstract as risk). This started an empirical research tradition called the “heuristics and biases” tradition that attempted to catalogue them—it is impressive because of its empiricism and the experimental aspect of the methods used.
Since the Kahneman and Tversky results, an entire discipline called behavioral finance and economics has flourished. It is in open contradiction with the orthodox so-called neoclassical economics taught in business schools and economics departments under the normative names of efficient markets, rational expectations, and other such concepts. It is worth stopping, at this juncture, and discussing the distinction between normative and positive sciences. A normative science (clearly a self-contradictory concept) offers prescriptive teachings; it studies how things
should
be. Some economists, for example those of the efficient-market religion, believe that our studies should be based on the hypothesis that humans are rational and act rationally because it is the best thing for them to do (it is mathematically “optimal”). The opposite is a positive science, which is based on how people actually are observed to behave. In spite of economists’ envy of physicists, physics is an inherently positive science while economics, particularly microeconomics and financial economics, is predominantly a normative one. Normative economics is like religion without the aesthetics.
Note that the experimental aspect of the research implies that Daniel Kahneman and the experimental ponytailed economist Vernon Smith were the first true scientists ever to bow in front of the Swedish king for the economics prize, something that should give credibility to the Nobel academy, particularly if, like many, one takes Daniel Kahneman far more seriously than a collection of serious-looking (and very human, hence fallible) Swedes. There is another hint of the scientific firmness of this research: It is extremely readable for someone outside of psychology, unlike papers in conventional economics and finance that even people in the field have difficulty reading (as the discussions are jargon-laden and heavily mathematical to give the illusion of science). A motivated reader can get concentrated in four volumes the collection of the major heuristics and biases papers.
Economists were not at the time very interested in hearing these stories of irrationality:
Homo economicus
as we said is a normative concept. While they could easily buy the “Simon” argument that we are not perfectly rational and that life implies approximations, particularly when the stakes are not large enough, they were not willing to accept that people were flawed rather than imperfect. But they are. Kahneman and Tversky showed that these biases do not disappear when there are incentives, which means that they are not necessarily cost saving. They were a different form of reasoning, and one where the probabilistic reasoning was weak.
WHERE IS NAPOLEON WHEN WE NEED HIM?
If your mind operates by series of different disconnected rules, these may not be necessarily consistent with each other, and if they may still do the job
locally,
they will not necessarily do so
globally.
Consider them stored as a rulebook of sorts. Your reaction will depend on which page of the book you open to at any point in time. I will illustrate it with another socialist example.
After the collapse of the Soviet Union, Western businesspeople involved in what became Russia discovered an annoying (or entertaining) fact about the legal system: It had conflicting and contradictory laws. It just depended on which chapter you looked up. I don’t know whether the Russians wanted it as a prank (after all, they lived long, humorless years of oppression) but the confusion led to situations where someone had to violate a law to comply with another. I have to say that lawyers are quite dull people to talk to; talking to a dull lawyer who speaks broken English with a strong accent and vodka breath can be quite straining—so you give up. This spaghetti legal system came from the piecewise development of the rules: You add a law here and there and the situation is too complicated as there is no central system that is consulted every time to ensure compatibility of all the parts together. Napoleon faced a similar situation in France and remedied it by setting up a top-down code of law that aimed to dictate a full logical consistency. The problem with us humans is not so much that no Napoleon has showed up so far to dynamite the old structure then reengineer our minds like a big central program; it is that our minds are far more complicated than just a system of laws, and the requirement for efficiency is far greater.
Consider that your brain reacts differently to the same situation depending on which chapter you open to. The absence of a central processing system makes us engage in decisions that can be in conflict with each other. You may prefer apples to oranges, oranges to pears, but pears to apples—it depends on how the choices are presented to you. The fact that your mind cannot retain and use everything you know at once is the cause of such biases. One central aspect of a heuristic is that it is blind to reasoning.
“I’m As Good As My Last Trade” and Other Heuristics
There exist plenty of different catalogues of these heuristics in the literature (many of them overlapping); the object of this discussion is to provide the intuition behind their formation rather than list them. For a long time we traders were totally ignorant of the behavioral research and saw situations where there was with strange regularity a wedge between the simple probabilistic reasoning and people’s perception of things. We gave them names such as the “I’m as good as my last trade” effect, the “sound-bite effect,” the “Monday morning quarterback” heuristic, and the “It was obvious after the fact” effect. It was both vindicating for traders’ pride and disappointing to discover that they existed in the heuristics literature as the “anchoring,” the “affect heuristic,” and the “hindsight bias” (it makes us feel that trading is true, experimental scientific research). The correspondence between the two worlds is shown in Table 11.1.
I start with the “I’m as good as my last trade” heuristic (or the “loss of perspective” bias)—the fact that the counter is reset at zero and you start a new day or month from scratch, whether it is your accountant who does it or your own mind. This is the most significant distortion and the one that carries the most consequences. In order to be able to put things in general context, you do not have everything you know in your mind at all times, so you retrieve the knowledge that you require at any given time in a piecemeal fashion, which puts these retrieved knowledge chunks in their local context. This means that you have an arbitrary reference point and react to differences from that point, forgetting that you are only looking at the differences from that particular perspective of the local context, not the absolutes.
Table 11.1 Trader and Scientific Approach
There is the well-known trader maxim “life is incremental.” Consider that as an investor you examine your performance like the dentist in
Chapter 3
, at some set interval. What do you look at: your monthly, your daily, your life-to-date, or your hourly performance? You can have a good month and a bad day. Which period should dominate?
When you take a gamble, do you say: “My net worth will end up at $99,000 or $101,500 after the gamble” or do you say “I lose $1,000 or make $1,500?” Your attitude toward the risks and rewards of the gamble will vary according to whether you look at your net worth or changes in it. But in fact in real life you will be put in situations where you will only look at your
changes.
The fact that the losses hurt more than the gains, and
differently,
makes your accumulated performance, that is, your total wealth, less relevant than the last change in it.
This dependence on the local rather than the global status (coupled with the effect of the losses hitting harder than the gains) has an impact on your perception of well-being. Say you get a windfall profit of $1 million. The next month you lose $300,000. You adjust to a given wealth (unless of course you are very poor) so the following loss would hurt you emotionally, something that would not have taken place if you received the net amount of $700,000 in one block, or, better, two sums of $350,000 each. In addition, it is easier for your brain to detect differences rather than absolutes, hence rich or poor will be (above the minimum level) in relation to something else (remember Marc and Janet). Now, when something is
in relation
to something else, that something else can be manipulated. Psychologists call this effect of comparing to a given reference
anchoring.
If we take it to its logical limit we would realize that, because of this resetting, wealth itself does not really make one happy (above, of course, some subsistence level); but positive changes in wealth may, especially if they come as “steady” increases. More on that later with my discussion of option blindness.
Other aspects of anchoring. Given that you may use two different anchors in the same situation, the way you act depends on so little. When people are asked to estimate a number, they will position it with respect to a number they have in mind or one they just heard, so “big” or “small” will be comparative. Kahneman and Tversky asked subjects to estimate the proportion of African countries in the United Nations after making them consciously pull a random number between 0 and 100 (they knew it was a random number). People guessed in relation to that number, which they used as anchor: Those who randomized a high number guessed higher than those who randomized a low one. This morning I did my bit of anecdotal empiricism and asked the hotel concierge how long it takes to go to the airport. “40 minutes?” I asked. “About 35,” he answered. Then I asked the lady at the reception if the journey was 20 minutes. “No, about 25,” she answered. I timed the trip: 31 minutes.
This anchoring to a number is the reason people do not react to their total accumulated wealth, but to differences of wealth from whatever number they are currently anchored to. This is the major conflict with economic theory, as according to economists, someone with $1 million in the bank would be more satisfied than if he had half a million. But we saw John reaching $1 million having had a total of $10 million; he was happier when he only had half a million (starting at nothing) than where we left him in
Chapter 1
. Also recall the dentist whose emotions depended on how frequently he checked his portfolio.
Degree in a Fortune Cookie
I used to attend a health club in the middle of the day and chat with an interesting Eastern European fellow with two Ph.D. degrees, one in physics (statistical no less), the other in finance. He worked for a trading house and was obsessed with the anecdotal aspects of the markets. He once asked me doggedly what I thought the stock market would do that day. Clearly I gave him a social answer of the kind “I don’t know, perhaps lower”—quite possibly the opposite answer to what I would have given him had he asked me an hour earlier. The next day he showed great alarm upon seeing me. He went on and on discussing my credibility and wondering how I could be so wrong in my “predictions,” since the market went up subsequently. The man was able to derive conclusions about my ability to predict and my “credibility” with a single observation. Now, if I went to the phone and called him and disguised my voice and said, “Hello, this is Doktorr Talebski from the Academy of Lodz and I have an interrresting prrroblem,” then presented the issue as a statistical puzzle, he would laugh at me. “Doktorr Talevski, did you get your degree in a fortune cookie?” Why is it so?
Clearly there are two problems. First, the quant did not use his statistical brain when making the inference, but a different one. Second, he made the mistake of overstating the importance of small samples (in this case just one single observation, the worst possible inferential mistake a person can make). Mathematicians tend to make egregious mathematical mistakes outside of their theoretical habitat. When Tversky and Kahneman sampled mathematical psychologists, some of whom were authors of statistical textbooks, they were puzzled by their errors. “Respondents put too much confidence in the result of small samples and their statistical judgment showed little sensitivity to sample size.”The puzzling aspect is that not only
should
they have known better, “they
did
know better.” And yet . . .
I will next list a few more heuristics. (1) The
availability
heuristic, which we saw in
Chapter 3
with the earthquake in California deemed more likely than catastrophe in the entire country, or death from terrorism being more “likely” than death from all possible sources (including terrorism). It corresponds to the practice of estimating the frequency of an event according to the ease with which instances of the event can be recalled. (2) The
representativeness
heuristic: gauging the probability that a person belongs to a particular social group by assessing how similar the person’s characteristics are to the “typical” group member’s. A feminist-style philosophy student is deemed more likely to be a feminist bank teller than to be just a bank teller. This problem is known as the “Linda problem” (the feminist’s name was Linda) and has caused plenty of academic ink to flow (some of the people engaged in the “rationality debate” believe that Kahneman and Tversky are putting highly normative demands on us humans). (3) The
simulation
heuristic: the ease of mentally undoing an event—playing the alternative scenario. It corresponds to counterfactual thinking: Imagine what might have happened had you not missed your train (or how rich you’d be today had you liquidated your portfolio at the height of the NASDAQ bubble). (4) We discussed in
Chapter 3
the
affect
heuristic: What emotions are elicited by events determine their probability in your mind.
Two Systems of Reasoning
Later research refines the problem as follows: There are two possible ways for us to reason, the heuristics being part of one—rationality being part of the other. Recall the colleague who used a different brain in the classroom than the one in real life in
Chapter 2
. Didn’t you wonder why the person you think knows physics so well cannot apply the basic laws of physics by driving well? Researchers divide the activities of our mind into the following two polarized parts, called System 1 and System 2.
System 1
is effortless, automatic, associative, rapid, parallel process, opaque (i.e., we are not aware of using it), emotional, concrete, specific, social, and personalized.
System 2
is effortful, controlled, deductive, slow, serial, self-aware, neutral, abstract, sets, asocial, and depersonalized.
I have always believed that professional option traders and market makers by dint of practicing their probabilistic game build an innate probabilistic machine that is far more developed than the rest of the population—even that of probabilists. I found a confirmation of that as researchers in the heuristics and biases tradition believe that System 1 can be impacted by experience and integrate elements from System 2. For instance, when you learn to play chess, you use System 2. After a while things become intuitive and you are able to gauge the relative strength of an opponent by glancing at the board.
Next I introduce the evolutionary psychology point of view.
WHY WE DON’T MARRY THE FIRST DATE
Another branch of research, called evolutionary psychology, developed a completely different approach to the same problem. It operates in parallel, creating some bitter but not too worrisome academic debates. These evolutionary psychologists agree with the Kahneman-Tversky school that people have difficulties with standard probabilistic reasoning. However, they believe that the reason lies in the way things are presented to us in the current environment. To them, we are optimized for a set of probabilistic reasoning, but in a different environment than the one prevailing today. The statement “Our brains are made for fitness not for truth” by the scientific intellectual Steven Pinker, the public spokesmen of that school, summarizes it all. They agree that our brains are not made for understanding things but think that they are not biased, or only biased because we do not use them in their real habitat.
Strangely, the Kahneman-Tversky school of researchers did not incur any credible resistance from the opinions of the economists of the time (the general credibility of conventional economists has always been so low that almost nobody in science or in the real world ever pays attention to them). No, instead the challenge came from the sociobiologists—and the center of the disagreement lies in their belief in using evolutionary theory as a backbone for our understanding of human nature. While this caused a fierce scientific dispute, I will have to say that they agree on the significant part as far as this book is concerned: (1) We do not
think
when making choices but use heuristics; (2) We make serious probabilistic mistakes in today’s world
—whatever the true reason.
Note that the split even covers the new economics: Just as we have a scientific branch of economics coming out of the Kahneman and Tversky tradition (behavioral economics), there is another scientific branch of economics coming out of evolutionary psychology, with the caveman economics approach followed by such researchers as the economist-biologist Terry Burnham, coauthor of the very readable
Mean Genes.
Our Natural Habitat
I will not delve too deeply into amateur evolutionary theory to probe at the reasons (besides, in spite of having spent some time in libraries I feel that I am truly an amateur in the subject matter). Clearly, the environment for which we have built our endowment is not the one that prevails today. I have not told too many of my colleagues that their decision making contains some lingering habits of cavemen—but when markets experience an abrupt move, I experience the same rush of adrenaline as if a leopard were seen prowling near my trading desk. Some of my colleagues who break telephone handles upon losing money might be even closer in their psychological makeup to our common origin.
This might be a platitude to those who frequent the Greek and Latin classics, but we never fail to be surprised when noticing that people a couple of dozen centuries removed from us can exhibit similar sensibility and feelings. What used to strike me as a child upon visiting museums is that ancient Greek statues exhibit men with traits indistinguishable from ours (only more harmonious and aristocratic). I was so wrong to believe that 2,200 years was a long time. Proust wrote frequently about the surprise people have when coming across emotions in Homeric heroes that are similar to those we experience today. By genetic standards, these Homeric heroes of thirty centuries ago in all likelihood have the exact identical makeup as the pudgy middle-aged man you see schlepping groceries in the parking lot. More than that. In fact, we are truly identical to the man who perhaps eighty centuries ago started being called “civilized,” in that strip of land stretching from southeastern Syria to southwestern Mesopotamia.
What is our natural habitat? By natural habitat, I mean the environment in which we reproduced the most, the one in which we spent the highest number of generations. The consensus among anthropologists is that we have been around as a separate species for 130,000 years, most of which were spent in the African savannah. But we do not have to go back that far in history to get the point. Imagine life in an early urban settlement, in Middle-Town, Fertile Crescent, only about 3,000 years ago—surely modern times from a genetic standpoint. Information is limited by the physical means of its transmission; one cannot travel fast, hence information will come from faraway places in concise batches. Traveling is a nuisance fraught with all manner of physical danger; you will settle within a narrow radius of where you were born unless famine or some invading uncivilized tribe dislodges you and your relatives from your happy settlement. The number of people you would get to know in a lifetime will be small. Should a crime be committed, it will be easy to gauge the evidence of guilt within the small number of possible suspects. If you are unjustly convicted of a crime, you will argue in simple terms, propounding simple evidence like “I was not there as I was praying in the temple of Baal and was seen at dusk by the high priest” and add that Obedshemesh, son of Sahar, was more likely to be guilty because he had more to gain from the crime. Your life would be simple, hence your space of
probabilities
would be narrow.
The real problem is, as I have mentioned, that such a natural habitat does not include much information. An efficient computation of the odds was never necessary until very recently. This also explains why we had to wait until the emergence of the gambling literature to see the growth of the mathematics of probability. Popular belief holds that the religious backdrop of the first and second millennia blocked the growth of tools that hint at absence of determinism, and caused the delays in probability research. The idea is extremely dubious; we simply did not compute probabilities because we did not
dare
to? Surely the reason is rather because we did not
need
to. Much of our problem comes from the fact that we have evolved out of such a habitat faster, much faster, than our genes. Even worse, our genes have not changed at all.
Fast and Frugal
Evolutionary theorists agree that brainwork depends on how the subject is presented and the frame offered—and they can be contradictory in their results. We detect cheaters with a different part of our brain than the one we draw on to solve logical problems. People can make incoherent choices because the brain works in the form of small partial jobs. Those heuristics that we said were “quick and dirty” to the psychologists are “fast and frugal” to the evolutionary psychologists. Not only that, but some thinkers, like the cognitive scientist Gerd Gigerenzer, seem to have obsessively taken the other side of the trade from Kahneman and Tversky; his work and that of his associates at the ABC Group (Adaptive Behavior and Cognition) intend to show that we are rational and that evolution produces a form of rationality he calls “ecological rationality.” They believe that not only are we hard-wired for
optimizing probabilistic
behavior in situations like mate selection (how many people of the opposite sex do you need to meet before pulling the trigger?), or choosing a meal, but we are also so wired for stock selection and that we do it appropriately if the stocks are presented to us in the correct manner.
In fact, Gigerenzer agrees that we do not understand probability (too abstract), but we react rather well to frequencies (less abstract): According to him, some problems that normally would cause us to make a mistake disappear when phrased in terms of percentages.
According to these researchers, while we may like to think of our brain as a central processing system, with top-down features, an analogy to the Swiss Army knife (with its small specific tools) seems to be in order. How? The psychologists’ framework is built around the distinction between the domain-specific and domain-general adaptations. A domain-specific adaptation is something that is meant to solve a very precise task (as opposed to domain-general ones that are meant to solve global ones). While these are easy to understand and accept for physiological adaptations (i.e., a giraffe’s neck helps in reaching food or an animal’s colors in providing camouflage), people have had difficulties accepting why these apply to our mind in the same manner.
Our brain functions by “modules.” An interesting aspect of modularity is that we may use different modules for different instances of the
same
problem, depending on the framework in which it is presented—as discussed in the notes to this section. One of the attributes of a module is its “encapsulation,” i.e., we cannot interfere with its functioning, as we are not aware of using it. The most striking module is used when we try to find a cheater. Expressed in purely logical form (though with extreme clarity), a given quiz is only solved by 15% of the people to whom it is given. Now, the same quiz expressed in a manner that aims at uncovering a cheater, almost everyone gets it.
Neurobiologists Too
Neurobiologists also have their side of the story. They believe (roughly) that we have three brains: The very old one, the reptilian brain that dictates heartbeat and that we share with all animals; the limbic brain center of emotions that we share with mammals; and the neocortex, or cognitive brain, that distinguishes primates and humans (note that even institutional investors seem to have a neocortex). While that theory of the Triune brain shows some over-simplification (particularly when handled by journalists), it seems to provide a framework for the analysis of brain functions.
Although it is very difficult to figure out which part of the brain does what exactly, neuroscientists have been doing some environment mapping in the brain by, say, taking a patient whose brain is damaged in one single spot (say, by a tumor or an injury deemed to be local) and deducing by elimination the function performed by such part of the anatomy. Other methods include brain imaging and electric simulations to specific areas. Many researchers outside of neurobiology, like the philosopher and cognitive scientist Jerry Fodor (who pioneered the notion of modularity) remain skeptical about the quality of the knowledge that we can uncover by examining the physical properties of the brain, be it only on account of the complicated interactions of the single parts (with corresponding nonlinearities). The mathematician and cognitive scientist David Marr, who pioneered the field of object recognition, made the apt remark that one does not learn how birds fly by studying feathers but rather by studying aerodynamics. I will present the theses of two watershed works presented in readable books, Damasio’s
Descartes’ Error
and LeDoux’s
Emotional Brain.
Descartes’ Error
presents a very simple thesis: You perform a surgical ablation on a piece of someone’s brain (say, to remove a tumor and tissue around it) with the sole resulting effect of an inability to register emotions, nothing else (the IQ and every other faculty remain the same). What you have done is a controlled experiment to separate someone’s intelligence from his emotions. Now you have a purely rational human being unencumbered with feelings and emotions. Let’s watch: Damasio reported that the purely unemotional man was incapable of making the simplest decision. He could not get out of bed in the morning, and frittered away his days fruitlessly weighing decisions. Shock! This flies in the face of everything one would have expected: One cannot make a decision without emotion. Now, mathematics gives the same answer: If one were to perform an optimizing operation across a large collection of variables, even with a brain as large as ours, it would take a very long time to decide on the simplest of tasks. So we need a shortcut; emotions are there to prevent us from temporizing. Does it remind you of Herbert Simon’s idea? It seems that the emotions are the ones doing the job. Psychologists call them “lubricants of reason.”
Joseph LeDoux’s theory about the role of emotions in behavior is even more potent: Emotions affect one’s thinking. He figured out that much of the connections from the emotional systems to the cognitive systems are stronger than connections from the cognitive systems to the emotional systems. The implication is that we feel emotions (limbic brain) then find an explanation (neocortex). As we saw with Claparède’s discovery, much of the opinions and assessments that we have concerning risks may be the simple result of emotions.
Kafka in a Courtroom
The O. J. Simpson trial provides an example of how our modern society is ruled by probability (because of the explosion in information), while important decisions are made without the smallest regard for its basic laws. We are capable of sending a spacecraft to Mars, but we are incapable of having criminal trials managed by the basic laws of probability—yet evidence is clearly a probabilistic notion. I remember buying a book on probability at a Borders Books chain bookstore only a short distance from the Los Angeles courthouse where the “trial of the century” was taking place—another book that crystallized the highly sophisticated quantitative knowledge in the field. How could such a leap in knowledge elude lawyers and jurors only a few miles away?
People who are as close to being criminal as probability laws can allow us to infer (that is, with a confidence that exceeds the
shadow of a doubt
) are walking free because of our misunderstanding of basic concepts of the odds. Equally, you could be convicted for a crime you never committed, again owing to a poor reading of probability—for we still cannot have a court of law properly compute the joint probability of events (the probability of two events taking place at the same time). I was in a dealing room with a TV set turned on when I saw one of the lawyers arguing that there were at least four people in Los Angeles capable of carrying O. J. Simpson’s DNA characteristics (thus ignoring the joint set of events—we will see how in the next paragraph). I then switched off the television set in disgust, causing an uproar among the traders. I was under the impression until then that sophistry had been eliminated from legal cases thanks to the high standards of republican Rome. Worse, one Harvard lawyer used the specious argument that only 10% of men who brutalize their wives go on to murder them, which is a probability unconditional on the murder (whether the statement was made out of a warped notion of advocacy, pure malice, or ignorance is immaterial). Isn’t the law devoted to the truth? The correct way to look at it is to determine the percentage of murder cases where women were killed by their husbands
and
had previously been battered by them (that is, 50%)—for we are dealing with what is called
conditional
probabilities; the probability that O. J. killed his wife
conditional
on the information of her having been killed, rather than the
unconditional
probability of O. J. killing his wife. How can we expect the untrained person to understand randomness when a Harvard professor who deals and teaches the concept of probabilistic evidence can make such an incorrect statement?
More particularly, where jurors (and lawyers) tend to make mistakes, along with the rest of us, is in the notion of joint probability. They do not realize that evidence compounds. The probability of my being diagnosed with respiratory tract cancer and being run over by a pink Cadillac in the same year, assuming each one of them is 1/100,000, becomes 1/10,000,000,000—by multiplying the two (obviously independent) events. Arguing that O. J. Simpson had 1/500,000 chance of not being the killer from the blood standpoint (remember the lawyers used the sophistry that there were four people with such blood types walking around Los Angeles) and adding to it the fact that he was the husband of the person and that there was additional evidence, then (owing to the compounding effect) the odds against him rise to several trillion trillion.
“Sophisticated” people make worse mistakes. I can surprise people by saying that the probability of the joint event is lower than either. Recall the availability heuristic: with the Linda problem rational and educated people finding the likelihood of an event greater than that of a larger one that encompasses it. I am glad to be a trader taking advantage of people’s biases but I am scared of living in such a society.
An Absurd World
Kafka’s prophetic book,
The Trial,
about the plight of a man, Joseph K., who is arrested for a mysterious and unexplained reason, hit a spot as it was written before we heard of the methods of the “scientific” totalitarian regimes. It projected a scary future of mankind wrapped in absurd self-feeding bureaucracies, with spontaneously emerging rules subjected to the internal logic of the bureaucracy. It spawned an entire “literature of the absurd”; the world may be too incongruous for us. I am terrified of certain lawyers. After listening to statements during the O. J. trial (and their effect) I was scared, truly scared, of the possible outcome—my being arrested for some reason that made no sense probabilistically, and having to fight some glib lawyer in front of a randomness illiterate jury.
We said that mere judgment would probably suffice in a primitive society. It is easy for a society to live without mathematics—or traders to trade without quantitative methods—when the space of possible outcomes is one-dimensional. One-dimensional means that we are looking at one sole variable, not a collection of separate events. The price of one security is one-dimensional, whereas the collection of the prices of several securities is multi-dimensional and requires mathematical modeling—we cannot easily see the collection of possible outcomes of the portfolio with a naked eye, and cannot even represent it on a graph as our physical world has been limited to visual representation in three dimensions only. We will argue later why we run the risk of having bad models (admittedly, we have) or making the error of condoning ignorance—swinging between the Carybde of the lawyer who knows no math to the Scylla of the mathematician who misuses his math because he does not have the judgment to select the right model. In other words, we will have to swing between the mistake of listening to the glib nonsense of a lawyer who refuses science and that of applying the flawed theories of some economist who takes his science too seriously. The beauty of science is that it makes an allowance for both error types. Luckily, there is a middle road—but sadly, it is rarely traveled.
Examples of Biases in Understanding Probability
I found in the behavioral literature at least forty damning examples of such acute biases, systematic departures from rational behavior widespread across professions and fields. Below is the account of a well-known test, and an embarrassing one for the medical profession. The following famous quiz was given to medical doctors (which I borrowed from the excellent Deborah Bennett’s
Randomness
).
A test of a disease presents a rate of 5% false positives. The disease strikes 1/1,000 of the population. People are tested at random, regardless of whether they are suspected of having the disease. A patient’s test is positive. What is the probability of the patient being stricken with the disease?
Most doctors answered 95%, simply taking into account the fact that the test has a 95% accuracy rate. The answer is the conditional probability that the patient is sick and the test shows it—close to 2%. Less than one in five professionals got it right.
I will simplify the answer (using the frequency approach). Assume no false negatives. Consider that out of 1,000 patients who are administered the test, one will be expected to be afflicted with the disease. Out of a population of the remaining 999 healthy patients, the test will identify about 50 with the disease (it is 95% accurate).The correct answer should be that the probability of being afflicted with the disease for someone selected at random who presented a positive test is the following ratio:
Number of afflicted persons
________________________
Number of true and false positives
here 1 in 51.
Think of the number of times you will be given a medication that carries damaging side effects for a given disease you were told you had, when you may only have a 2% probability of being afflicted with it!
We Are Option Blind
As an option trader, I have noticed that people tend to undervalue options as they are usually unable to correctly mentally evaluate instruments that deliver an
uncertain
payoff, even when they are fully conscious of the mathematics. Even regulators reinforce such ignorance by explaining to people that options are a
decaying
or
wasting
asset. Options that are out of the money are deemed to
decay,
by losing their premium between two dates.
I will clarify next with a simplified (but sufficient) explanation of what an option means. Say a stock trades at $100 and that someone gives me the right (but not the obligation) to buy it at $110 one month ahead of today. This is dubbed a
call
option. It makes sense for me to
exercise
it, by asking the seller of the option to deliver me the stock at $110, only if it trades at a higher price than $110 in one month’s time. If the stock goes to $120, my option will be worth $10, for I will be able to buy the stock at $110 from the option writer and sell it to the market at $120, pocketing the difference. But this does not have a very high probability. It is called
out-of-the-money,
for I have no gain from exercising it right away.
Consider that I buy the option for $1. What do I expect the value of the option to be one month from now? Most people think 0. That is not true. The option has a high probability, say 90%, of being worth 0 at expiration, but perhaps 10% probability to be worth an average of $10. Thus, selling the option to me for $1 does not provide the seller with free money. If the seller had instead bought the stock himself at $100 and waited the month, he could have sold it for $120. Making $1 now was hardly, therefore, free money. Likewise, buying it is not a wasting asset. Even professionals can be fooled. How? They confuse the expected value and the most likely scenario (here the expected value is $1 and the most likely scenario is for the option to be worth 0). They mentally overweigh the state that is the most likely, namely, that the market does not move at all. The option is simply the weighted average of the possible states the asset can take.
There is another type of satisfaction provided by the option seller. It is the steady return and the steady feeling of reward—what psychologists call
flow.
It is very pleasant to go to work in the morning with the expectation of being up some small money. It requires some strength of character to accept the expectation of bleeding a little, losing pennies on a steady basis even if the strategy is bound to be profitable over longer periods. I noticed that very few option traders can maintain what I call a “long volatility” position, namely a position that will most likely lose a small quantity of money at expiration, but is expected to make money in the long run because of occasional spurts. I discovered very few people who accepted losing $1 for most expirations and making $10 once in a while, even if the game were fair (i.e., they made the $10 more than 9.1% of the time).
I divide the community of option traders into two categories:
premium sellers
and
premium buyers.
Premium sellers (also called option sellers) sell options, and generally make steady money, like John in Chapters
1
and
5
. Premium buyers do the reverse. Option sellers, it is said, eat like chickens and go to the bathroom like elephants. Alas, most option traders I encountered in my career are
premium sellers—
when they blow up it is generally other people’s money.
How could professionals seemingly aware of the (simple) mathematics be put in such a position? As previously discussed, our actions are not quite guided by the parts of our brain that dictate rationality. We think with our emotions and there is no way around it. For the same reason, people who are otherwise rational engage in smoking or in fights that get them no immediate benefits; likewise people sell options even when they know that it is not a good thing to do. But things can get worse. There is a category of people, generally finance academics, who, instead of fitting their actions to their brains, fit their brains to their actions. These people go back and unwittingly cheat with the statistics to justify their actions. In my business, they fool themselves with statistical arguments to justify their option selling.
What is less unpleasant: to lose 100 times $1 or lose once $100? Clearly the second: Our sensitivity to losses decreases. So a trading policy that makes $1 a day for a long time then loses them all is actually pleasant from a hedonic standpoint, although it does not make sense economically. So there is an incentive to invent a story about the likelihood of the events and carry on such strategy.
In addition, there is the risk ignorance factor. Scientists have subjected people to tests—what I mentioned in the prologue as risk taking out of underestimating the risks rather than courage. The subjects were asked to predict a range for security prices in the future, an upper bound and a lower bound, in such a way that they would be comfortable with 98% of the security ending inside such range. Of course violations to such bound were very large, up to 30%.
Such violations arise from a far more severe problem: People overvalue their knowledge and underestimate the probability of their being wrong.
One example to illustrate further option blindness. What has more value? (a) a contract that pays you $1 million if the stock market goes down 10% on any given day in the next year; (b) a contract that pays you $1 million if the stock market goes down 10% on any given day in the next year due to a terrorist act. I expect most people to select (b).
PROBABILITIES AND THE MEDIA (MORE JOURNALISTS)
A journalist is trained in methods to express himself rather than to plumb the depth of things—the selection process favors the most communicative, not necessarily the most knowledgeable. My medical doctor friends claim that many medical journalists do not understand anything about medicine and biology, often making mistakes of a very basic nature. I cannot confirm such statements, being myself a mere amateur (though at times a voracious reader) in medical research, but I have noticed that they almost always misunderstand the probabilities used in medical research announcements. The most common one concerns the interpretation of evidence. They most commonly get mixed up between
absence of evidence
and
evidence of absence,
a similar problem to the one we saw in
Chapter 9
. How? Say I test some chemotherapy, for instance Fluorouracil, for upper respiratory tract cancer, and find that it is better than a placebo, but only marginally so; that (in addition to other modalities) it improves survival from 21 per 100 to 24 per 100. Given my sample size, I may not be confident that the additional 3% survival points come from the medicine; it could be merely attributable to randomness. I would write a paper outlining my results and saying that there is no evidence of improved survival (as yet) from such medicine, and that further research would be needed. A medical journalist would pick it up and claim that one Professor N. N. Taleb found evidence that Fluorouracil
does not help,
which is entirely opposite to my intentions. Some naive doctor in Smalltown, even more uncomfortable with probabilities than the most untrained journalist, would pick it up and build a mental block against the medication, even when some researcher finally finds fresh evidence that such medicine confers a clear survival advantage.
CNBC at Lunchtime
The advent of the financial television channel CNBC presented plenty of benefits to the financial community but it also allowed a collection of extrovert practitioners long on theories to voice them in a few minutes of television time. One often sees respectable people making ludicrous (but smart-sounding) statements about properties of the stock market. Among these are statements that blatantly violate the laws of probability. One summer during which I was assiduous at the health club, I often heard statements such as “the real market is only 10% off the highs while the average stock is close to 40% off its highs,” which is intended to be indicative of deep troubles or anomalies—some harbinger of bear markets.
There is no incompatibility between the fact that the average stock is down 40% from the highs while the average of all stocks (that is, the market) is down 10% from its own highs. One must consider that the stocks did not all reach their highs
at the same time.
Given that stocks are not 100% correlated, stock A might reach its maximum in January, stock B might reach its maximum in April, but the average of the two stocks A and B might reach its maximum at some time in February. Furthermore, in the event of negatively correlated stocks, if stock A is at its maximum when stock B is at its minimum, then they could both be down 40% from their maximum when the stock market is at its highs! By a law of probability called distribution of the maximum of random variables, the maximum of an average is necessarily less volatile than the average maximum.
You Should Be Dead by Now
This brings to mind another common violation of probability by prime-time TV financial experts, who may be selected for their looks, their charisma, and their presentation skills, but certainly not for their incisive minds. For instance, a fallacy that I saw commonly made by a prominent TV financial guru goes as follows: “The average American is expected to live seventy-three years. Therefore if you are sixty-eight you can expect to live five more years, and should plan accordingly.” She went into precise prescriptions of how the person should invest for a five-more-years horizon. Now what if you are eighty? Is your life expectancy
minus
seven years? What these journalists confuse is the unconditional and conditional life expectancy. At birth, your unconditional life expectancy may be seventy-three years. But as you advance in age and do not die, your life expectancy increases along with your life. Why? Because other people, by dying, have taken your spot in the statistics, for expectation means average. So if you are seventy-three and are in good health, you may still have, say, nine years
in expectation.
But the expectation would change, and at eighty-two, you will have another five years, provided of course you are still alive. Even someone one hundred years old still has a positive conditional life expectation. Such a statement, when one thinks about it, is not too different from the one that says: Our operation has a mortality rate of 1%. So far we have operated on ninety-nine patients with great success; you are our one hundreth, hence you have a 100% probability of dying on the table.
TV financial planners may confuse a few people. This is quite harmless. What is far more worrying is the supply of information by nonprofessionals to professionals; it is to the journalists that we turn next.
The Bloomberg Explanations
I have, on my desk, a machine eponymously called a
Bloomberg
(after the legendary founder Michael Bloomberg). It acts as a safe e-mail service, a news service, a historical-data retrieving tool, a charting system, an invaluable analytical aid, and, not least, a screen where I can see the price of securities and currencies. I have gotten so addicted to it that I cannot operate without it, as I would otherwise feel cut off from the rest of the world. I use it to get in contact with my friends, confirm appointments, and solve some of those entertaining quarrels that put some sharpness into life. Somehow, traders who do not have a Bloomberg address do not exist for us (they have to have recourse to the more plebeian Internet). But there is one aspect of Bloomberg I would dispense with: the journalist’s commentary. Why? Because they engage in explaining things and perpetuate the right-column, left-column confusion in a serious manner. Bloomberg is not the sole perpetrator; it is just that I have not been exposed to newspapers’ business sections over the past decade, preferring to read real prose instead.
As I am writing these lines I see the following headlines on my Bloomberg:
→
Dow is up 1.03 on lower interest rates.
→
Dollar down 0.12 yen on higher Japanese surplus.
and so on for an entire page. If I translate it well, the journalist claims to provide an explanation for something that amounts to
perfect noise.
A move of 1.03 with the Dow at 11,000 constitutes less than a 0.01% move. Such a move does not warrant an explanation. There is nothing there that an honest person can try to explain; there are no reasons to adduce. But like apprentice professors of comparative literature, journalists being paid to provide explanations will gladly and readily provide them. The only solution is for Michael Bloomberg to stop paying his journalists for providing commentary.
Significance:
How did I decide that it was perfect noise? Take a simple analogy. If you engage in a mountain bicycle race with a friend across Siberia and, a month later, beat him by one single second, you clearly cannot quite boast that you are faster than him. You might have been helped by something, or it can be just plain randomness, nothing else. That second is not in itself significant enough for someone to draw conclusions. I would not write in my pre-bedtime diary:
Cyclist A is better than cyclist B because he is fed with spinach whereas cyclist B has a diet rich in tofu. The reason I am making this inference is because he beat him by 1.3 seconds in a 3,000 mile race.
Should the difference be one week, then I could start analyzing whether tofu is the reason, or if there are other factors.
Causality:
There is another problem; even assuming statistical significance, one has to accept a cause and effect, meaning that the event in the market can be linked to the cause proffered.
Post hoc ergo propter hoc
(it is the consequence because it came after). Say hospital A delivered 52% boys and hospital B delivered the same year only 48%; would you try to give the explanation that you had a boy because it was delivered in hospital A?
Causality can be very complex. It is very difficult to isolate a single cause when there are plenty around. This is called multivariate analysis. For instance, if the stock market can react to U.S. domestic interest rates, the dollar against the yen, the dollar against the European currencies, the European stock markets, the United States balance of payments, United States inflation, and another dozen prime factors, then the journalists need to look at all of these factors, look at their historical effect both in isolation and jointly, look at the stability of such influence, then, after consulting the test statistic, isolate the factor if it is possible to do so. Finally, a proper confidence level needs to be given to the factor itself; if it is less than 90% the story would be dead. I can understand why Hume was extremely obsessed with causality and could not accept such inference anywhere.
I have a trick to know if something
real
in the world is taking place. I have set up my Bloomberg monitor to display the price and percentage change of all relevant prices in the world: currencies, stocks, interest rates, and commodities. By dint of looking at the same setup for years, as I keep the currencies in the upper left corner and the various stock markets on the right, I managed to build an instinctive way of knowing if something serious is going on. The trick is to look only at the large percentage changes. Unless something moves by more than its usual daily percentage change, the event is deemed to be noise. Percentage moves are the size of the headlines. In addition, the interpretation is not linear; a 2% move is not twice as significant an event as 1%, it is rather like four to ten times. A 7% move can be several billion times more relevant than a 1% move! The headline of the Dow moving by 1.3 points on my screen today has less than one billionth of the significance of the serious 7% drop of October 1997. People might ask me: Why do I want everybody to learn some statistics? The answer is that too many people read explanations. We cannot instinctively understand the nonlinear aspect of probability.
Filtering Methods
Engineers use methods to clean up the noise from the signal in the data. Did it ever occur to you while talking to your cousin in Australia or the South Pole that the static on the telephone line could be distinguished from the voice of your correspondent? The method is to consider that when a change in amplitude is small, it is more likely to result from noise—with its likelihood of being a signal increasing exponentially as its magnitude increases. The method is called a smoothing kernel, which has been applied in Figures 11.1 and 11.2. But our auditory system is incapable of performing such a function by itself. Likewise our brain cannot see the difference between a significant price change and mere noise, particularly when it is pounded with unsmoothed journalistic noise.
We Do Not Understand Confidence Levels
Figure 11.1 Unfiltered Data Containing Signal and Noise
Figure 11.2 Same Data with Its Noise Removed
Professionals forget the following reality. It is not the estimate or the forecast that matters so much as the degree of confidence with the opinion. Consider that you are going on a trip one fall morning and need to formulate an idea about the weather conditions prior to packing your luggage. If you expect the temperature to be 60 degrees, plus or minus 10 degrees (say in Arizona), then you would take no snow clothes and no portable electric fan. Now, what if you were going to Chicago, where you are told that the weather, while being 60 degrees, will nevertheless vary by about 30 degrees? You would have to pack winter and summer clothes. Here the expectation of the temperature carries little importance concerning the choice of clothing; it is the variance that matters. Your decision to pack is markedly different now that you are told that the variability would be around 30 degrees. Now let us push the point further; what if you were going to a planet where the expectation is also going to be around 60 degrees, but plus or minus 500 degrees? What would you pack?
We can see that my activity in the market (and other random variables) depends far less on where I think the market or the random variable is going so much as it does on the degree of error I allow around such a confidence level.
An Admission
We close this chapter with the following information: I consider myself as prone to foolishness as anyone I know, in spite of my profession and the time spent building my expertise on the subject. But here is the exception; I know that I am very, very weak on that score. My humanity will try to foil me; I have to stay on my guard. I was born to be fooled by randomness. That will be explored in Part III.


================================================================================
CHAPTER/SECTION 314 (Item 323)
================================================================================

Part III
•
WAX IN MY EARS
Living with Randomitis
O
dysseus, the Homerian hero, had the reputation of using guile to overcome stronger opponents. I find the most spectacular use of such guile was against no other opponent than himself.
In Book 12 of the
Odyssey,
the hero encounters the sirens, on an island not far from the rocks of Charybdis and Scylla. Their songs are known to charm the sailors into madness, causing them irresistibly to cast themselves into the sea off the sirens’ coast, and perish. The indescribable beauty of the sirens’ songs is contrasted with the moldering corpses of sailors who strayed into the area around them. Odysseus, forewarned by Circe, contrives the following ruse. He fills the ears of all his men with wax, to the point of total deafness, and has himself tied to the mast. The sailors are under strict instructions not to release him. As they approach the sirens’ island, the sea is calm and over the water comes the sound of a music so ravishing that Odysseus struggles to get loose, expending an inordinate amount of energy to unrestrain himself. His men tie him even further, until they are safely past the poisoned sounds.
The first lesson I took from the story is not to even attempt to be Odysseus. He is a mythological character and I am not. He can be tied to the mast; I can merely reach the rank of a sailor who needs to have his ears filled with wax.
I AM NOT SO INTELLIGENT
The epiphany I had in my career in randomness came when I understood that I was not intelligent enough, nor strong enough, to even try to fight my emotions. Besides, I believe that I need my emotions to formulate my ideas and get the energy to execute them.
I am just intelligent enough to understand that I have a predisposition to be fooled by randomness—and to accept the fact that I am rather emotional. I am dominated by my emotions—but as an aesthete, I am happy about that fact. I am just like every single character whom I ridiculed in this book. Not only that, but I may be even worse than them because there may be a negative correlation between beliefs and behavior (recall Popper the man). The difference between me and those I ridicule is that I try to be aware of it. No matter how long I study and try to understand probability, my emotions will respond to a different set of calculations, those that my unintelligent genes want me to handle. If my brain can tell the difference between noise and signal, my heart cannot.
Such unintelligent behavior does not just cover probability and randomness. I do not think I am reasonable enough to avoid getting angry when a discourteous driver blows his horn at me for being one nanosecond late after a traffic light turns green. I am fully aware that such anger is self-destructive and offers no benefit, and that if I were to develop anger for every idiot around me doing something of the sort, I would be long dead. These small daily emotions are not rational. But we need them to function properly. We are designed to respond to hostility with hostility. I have enough enemies to add some spice to my life, but I sometimes wish I had a few more (I rarely go to the movies and need the entertainment). Life would be unbearably bland if we had no enemies on whom to waste efforts and energy.
The good news is that there are tricks. One such trick is to avoid eye contact (through the rearview mirror) with other persons in such traffic encounters. Why? Because when you gaze into someone’s eyes, a different part of your brain, the more emotional one, is activated and engaged as the result of the interaction. I try to imagine that the other person is a Martian, rather than a human being. It works sometimes—but it works best when the person presents the appearance of being from a different species. How? I am an avid road cyclist. Recently, as I was riding along with other cyclists, slowing down traffic in a rural area, a small woman in a giant sports utility vehicle opened her window and heaped curses at us. Not only did it not upset me but I did not even interrupt my thoughts to pay attention. When I am on my bicycle, people in large trucks become a variety of dangerous animals, capable of threatening me but incapable of making me angry.
I have, like anyone with strong opinions, a collection of critics among finance academics and economists, annoyed by my attacks on their misuse of probability and unhappy about my branding them as pseudoscientists. I am incapable of taming my emotions when reading their comments. The best I can do is just not read them. Likewise with journalists. Not reading their discussions of markets spares me plenty of emotional expenditure. I will do the same with unsolicited comments on this book. Wax in my ears.
WITTGENSTEIN’S RULER
What is the mechanism that should convince authors to avoid reading comments on their work, except for those they solicit from specified persons for whom they have intellectual respect? The mechanism is a probabilistic method called conditional information: Unless the source of the statement has extremely high qualifications, the statement will be more revealing of the author than the information intended by him. This applies, of course, to matters of judgment. A book review, good or bad, can be far more descriptive of the reviewer than informational about the book itself. This mechanism I also call Wittgenstein’s ruler:
Unless you have confidence in the ruler’s reliability, if you use a ruler to measure a table you may also be using the table to measure the ruler.
The less you trust the ruler‘s reliability (in probability called the
prior
),the more information you are getting about the ruler and the less about the table. The point extends way beyond information and probability. This conditionality of information is central in epistemology, probability, even in studies of consciousness. We will see later extensions with “ten sigma” problems.
The point carries practical implications: The information from an anonymous reader on
Amazon.com
is all about the person, while that of a qualified person, is going to be all about the book. This plays equally in court: Take the O. J. Simpson trial once again. One of the jurors said, “There was not enough blood,” meaning to assess the statistical evidence of what was offered: Such statement reveals very little about the statistical evidence as compared with what it shows about the author of the statement’s ability to make a valid inference. Had the juror been a forensic expert, the ratio of information would have tilted the other way.
The problem is that while such reasoning is central to my thinking, my brain knows it though not my heart: My emotional system does not understand Wittgenstein’s ruler. I can offer the following evidence: A compliment is always pleasant, regardless of its authorship—something manipulators know rather well. Likewise with book reviews or comments on my risk-management strategy.
THE ODYSSEAN MUTE COMMAND
Recall that the accomplishment from which I derive the most pride is my weaning myself from television and the news media. I am currently so weaned that it actually costs me more energy to watch television than to perform any other activity, like, say, writing this book. But this did not come without tricks. Without tricks I would not escape the toxicity of the information age. In the trading room of my company, I have the television set turned on all day with the financial news channel CNBC staging commentator after commentator and CEO after CEO murdering rigor all day long. What is the trick? I have the volume turned completely off. Why? Because when the television set is silent, the babbling person looks ridiculous, exactly the opposite effect as when the sound is on. One sees a person with moving lips and contortions in his facial muscles, taking themselves seriously—but no sound comes out. We are visually but not auditorily intimidated, which causes a dissonance. The speaker’s face expresses some excitement, but since no sound comes out, the exact opposite is conveyed. This is the sort of contrast the philosopher Henri Bergson had in mind in his
Treatise on Laughter,
with his famous description of the gap between the seriousness of a gentleman about to walk on a banana skin and the comical aspect of the situation. Television pundits lose their intimidating effect;they even look ridiculous. They seem to be excited about something terribly unimportant. Suddenly pundits become clowns, which is a reason the writer Graham Greene refused to go on television.
I had this idea of stripping people of language while, on a trip, I listened (while brutally jet-lagged) to a speech in Cantonese, a language I do not understand, without the benefit of translation. Since I had no possible clue about his subject, the animated orator lost a large share of his dignity. The idea came to me that perhaps I could use a built-in bias, here prejudice, to offset another built-in bias, our predisposition to take information seriously. It seems to work.
This part, the conclusion of this book, presents the human aspect of dealing with uncertainty. I have personally failed in achieving a general insulation from randomness, but I have managed a few tricks.


================================================================================
CHAPTER/SECTION 315 (Item 324)
================================================================================

Twelve
•
GAMBLERS’ TICKS AND PIGEONS IN A BOX
On gamblers’ ticks crowding up my life. Why bad taxi-cab English can help you make money. How I am the fool of all fools, except that I am aware of it. Dealing with my genetic unfitness. No boxes of chocolate under my trading desk.
TAXI-CAB ENGLISH AND CAUSALITY
F
irst, a flashback in time to my early days as a trader in New York. Early in my career, I worked at Credit Suisse First Boston, then located in the middle of the block between Fifty-second and Fifty-third streets, between Madison and Park Avenue. It was called a Wall Street firm, in spite of its Midtown location—I used to claim to work “on Wall Street” in spite of having been lucky enough to set foot only twice on the physical Wall Street, one of the most repulsive areas I have visited east of Newark, New Jersey.
Then, in my twenties, I lived in a book-choked (but otherwise rather bare) apartment on Manhattan’s Upper East Side. The bareness was not ideological; it was simply because I never managed to enter a furniture store, as I would eventually stop at a bookstore along the way and haul bags of books instead. As can be expected, the kitchen was devoid of any form of food and utensils, save for a defective espresso machine, as I learned to cook only very recently (even then . . .).
I went to work every morning in a yellow cab, which dropped me off at the corner of Park Avenue and Fifty-third Street. Cab drivers in New York City are known to be rather untamed and universally unfamiliar with the geography of the place, but, on occasion, one can find a cab driver who is both unacquainted with the city and skeptical of the universality of the laws of arithmetic. One day I had the misfortune (or perhaps the fortune, as we will see) to ride with a driver who did not seem capable of handling any language known to me, which includes taxi-cab English. I tried to help him navigate south between Seventy-fourth Street and Fifty-third Street, but he stubbornly continued the journey an additional block south, forcing me to use the Fifty-second Street entrance. That day, my trading portfolio made considerable profits, owing to considerable turmoil in currencies; it was then the best day of my young career.
The next day, as usual, I hailed a cab from the corner of Seventy-fourth Street and Third Avenue. The previous driver was nowhere in sight, perhaps deported back to the old country. Too bad; I was gripped with the unexplainable desire to pay him back for the favor he had done me and surprise him with a gigantic tip. Then I caught myself instructing the new cab driver to take me to the northeast corner of Fifty-second Street and Park Avenue, exactly where I was dropped off the day before. I was taken aback by my own words . . . but it was too late.
When I looked at my reflection in the elevator’s mirror, it dawned on me that I wore the exact same tie as the day before—with the coffee stains from the previous day’s fracas (my only addiction is to coffee). There was someone in me who visibly believed in a strong causal link between my use of the entrance, my choice of tie, and the previous day’s market behavior. I was disturbed for acting like a fake, like an actor playing some role that was not his. I felt that I was an impostor. On the one hand, I talked like someone with strong scientific standards, a probabilist focused on his craft. On the other, I had closed superstitions just like one of these blue-collar pit traders. Would I have to go buy a horoscope next?
A little brooding revealed that my life until then had been governed by mild superstitions, me the expert in options, the dispassionate calculator of probabilities, a rational trader! It was not the first time that I had acted on mild superstitions of a harmless nature, which I believed were instilled in me by my Eastern Mediterranean roots: One does not grab the salt shaker from the hand of another person risking a falling out; one is to knock on wood upon receiving a compliment; plus many other Levantine beliefs passed on for a few dozen centuries. But like many things that brew and spread around the ancient pond, these beliefs I had taken with a fluctuating mixture of solemnity and mistrust. We consider them more like rituals than truly important actions meant to stave off undesirable turns of the goddess Fortuna—superstitions can instill some poetry in daily life.
The worrying part was that it was the first time that I noticed superstitions creeping into my professional life. My profession is to act like an insurance company, stringently computing the odds based on well-defined methods, taking advantage of other people when they are less rigorous, get blinded by some “analysis,” or act with the belief that they are chosen by destiny. But there was too much randomness flooding my occupation.
I detected the rapid accumulation of what are called “gamblers’ ticks” surreptitiously developing in my behavior—though minute and barely detectable. Until then these small ticks had escaped me. My mind seemed to be constantly trying to detect a statistical connection between some of my facial expressions and the outcome of events. For example, my income started to increase after I discovered my slight nearsightedness and started wearing glasses. Although glasses were not quite necessary, nor even useful, except for night driving, I kept them on my nose as I unconsciously acted as if I believed in the association between performance and glasses. To my brain such statistical association was as spurious as it can get, owing to the reduced sample size (here a single instance), yet this native statistical instinct did not seem to benefit from my expertise in hypothesis testing.
Gamblers are known to develop some behavioral distortions as a result of some pathological association between a betting outcome and some physical move. “Gambler” is about the most derogatory term that could be used in my derivatives profession. As an aside, gambling to me is best defined as an activity where the agent gets a thrill when confronting a random outcome, regardless of whether he has the odds stacked in his favor or against him. Even when the odds are clearly stacked against the gambler, he sometimes transcends the odds by believing that destiny selected him in some manner. This shows in the very sophisticated people one meets in casinos where they normally should not be found. I even ran into world-class probability experts who had a gambling habit on the side, throwing all of their knowledge to the wind. For example, a former colleague of mine, one of the most intelligent people I have ever met, frequently went to Las Vegas, and seemed to be such a turkey that the casino provided him with complimentary luxury suites and transportation. He even consulted a fortune teller prior to taking large trading positions and tried to get reimbursed by our employer.
THE SKINNER PIGEON EXPERIMENT
At twenty-five, I was totally ignorant of the behavioral sciences. I had been fooled by my education and culture into believing that my superstitions were cultural, and that, consequently, they could be shed through the exercise of so-called reason. Taken at the general level of society, modern life would eliminate them as science and logic would enter. But in my case, I was over time getting more sophisticated intellectually, but the floodgates of randomness were bursting and I was becoming more superstitious.
These superstitions needed to be biological—but I was brought up in an era when the dogma was that it was nurture, rarely nature, that was the culprit. Clearly, there was nothing cultural about my link between my wearing glasses and a random market outcome. There was nothing cultural in my link between my use of entrance and my performance as a trader. There was nothing cultural in my wearing the same tie as the day before. Something in us has not developed properly over the past thousand years and I was dealing with the remnant of our old brain.
To probe the point further, we need to look at such formations of causal associations in the lower forms of life. The famous Harvard psychologist B. F. Skinner constructed a box for rats and pigeons, equipped with a switch that the pigeon can operate by pecking. In addition, an electrical mechanism delivers food into the box. Skinner designed the box in order to study more general properties of the behavior of a collection of nonhumans, but it was in 1948 that he had the brilliant idea of ignoring the lever and focusing on the food delivery. He programmed it to deliver food at random to the famished birds.
He saw quite astonishing behavior on the part of the birds; they developed an extremely sophisticated rain-dance type of behavior in response to their ingrained statistical machinery. One bird swung its head rhythmically against a specific corner of the box, others spun their heads counterclockwise; literally all of the birds developed a specific ritual that progressively became hardwired into their mind as linked to their feeding.
This problem has a more worrying extension; we are not made to view things as independent from each other. When viewing two events A and B, it is hard not to assume that A causes B, B causes A, or both cause each other. Our bias is immediately to establish a causal link. While to a budding trader this results in hardly any worse costs than a few pennies in cab fare, it can draw the scientist into spurious inference. For it is harder to act as if one were ignorant than as if one were smart; scientists know that it is emotionally harder to reject a hypothesis than to accept it (what are called type I and type II errors)—quite a difficult matter when we have such sayings as
felix qui po¨tuit cognoscere causas
(happy is he who understands what is behind things). It is very hard for us to just shut up. We are not cut out for it. Popper or not, we take things too seriously.
PHILOSTRATUS REDUX
I offered no solution to the problem of statistical inference at a low resolution. I discussed in
Chapter 3
the technical difference between noise and meaning—but it is time to discuss the execution. The Greek philosopher Pyrrho, who advocated a life of equanimity and indifference, was criticized for failing to keep his composure during a critical circumstance (he was chased by an ox). His answer was that he found it sometimes difficult to rid himself of his humanity. If Pyrrho cannot stop being human, I do not see why the rest of us should resemble the rational man who acts perfectly under uncertainty as propounded by economic theory. I discovered that much of the rationally obtained results using my computations of the various probabilities do not register deeply enough to impact my own conduct. In other words, I acted like the doctor in
Chapter 11
who knew of the 2% probability of the disease, but somehow unwittingly treated the patient as if the ailment had a 95% probability of being there. My brain and my instinct were not acting in concert.
The details are as follows. As a rational trader (all traders boast so) I believe, as I discussed before, that there is a difference between noise and signal, and that noise needs to be ignored while a signal needs to be taken seriously. I use elementary (but robust) methods that allow me to calculate the expected noise and signal composition of any fluctuation in my trading performance. For example, after registering a profit of $100,000 on a given strategy, I may assign a 2% probability to the hypothesis of the strategy being profitable and 98% probability to the hypothesis that the performance may be the result of mere noise. A gain of $1 million on the other hand, certifies that the strategy is a profitable one, with a 99% probability. A rational person would act accordingly in the selection of strategies, and set his emotions in accordance with his results. Yet I have experienced leaps of joy over results that I knew were mere noise, and bouts of unhappiness over results that did not carry the slightest degree of statistical significance. I cannot help it, but I am emotional and derive most of my energy from my emotions. So the solution does not reside in taming my heart.
Since my heart does not seem to agree with my brain, I need to take serious action to avoid making irrational trading decisions, namely, by denying myself access to my performance report unless it hits a predetermined threshold. This is no different from the divorce between my brain and my appetite when it comes to the consumption of chocolate. I generally deal with it by ascertaining that there are no chocolate boxes under my trading desk.
One of the most irritating conversations I’ve had is with people who lecture me on
how I should
behave. Most of us know pretty much
how we should
behave. It is the execution that is the problem, not the absence of knowledge. I am tired of the moralizing slow-thinkers who pound me with platitudes like I should floss daily, eat my regular apple, and visit the gym outside of the New Year’s resolution. In the markets the recommendation would be to ignore the noise component in the performance. We need tricks to get us there but before that we need to accept the fact that we are mere animals in need of lower forms of tricks, not lectures.
Finally, I consider myself lucky for not having a cigarette addiction. For the best way to understand how we could be rational in our perception of the risks and probabilities and, at the same time, be foolish while acting on them would be to have a conversation with a cigarette smoker. For few cigarette smokers remain unaware of the lung cancer rates in their population. If you remain unconvinced, take a look at the huddling smoking crowd outside the service entrance of the Memorial Sloan-Kettering Cancer Center in New York City’s Upper East Side. You will see dozens of cancer nurses (and, perhaps, doctors) standing outside the entrance with a cigarette in hand as hopeless patients are wheeled in for their treatments.


================================================================================
CHAPTER/SECTION 316 (Item 325)
================================================================================

Thirteen
•
CARNEADES COMES TO ROME: ON PROBABILITY AND SKEPTICISM
Cato the censor sends Carneades packing. Monsieur de Norpois does not remember his old opinions. Beware the scientist. Marrying ideas. The same Robert Merton putting the author on the map. Science evolves from funeral to funeral.
A
sk your local mathematician to define probability; he would most probably show you how to compute it. As we saw in
Chapter 3
on probabilistic introspection, probability is not about the odds, but about the belief in the existence of an alternative outcome, cause, or motive. Recall that mathematics is a tool to meditate, not compute. Again, let us go back to the elders for more guidance—for probabilities were always considered by them as nothing beyond a subjective, and fluid, measure of beliefs.
CARNEADES COMES TO ROME
Around 155
B.C.
, the Greek postclassical philosopher Carneades of Cyrene came to Rome as one of the three Athenian ambassadors who came to beg the Roman Senate for a political favor. A fine had been levied against the citizens of their city, and they wanted to convince Rome that it was unfair. Carneades represented the Academy, the same argumentative open-air institution where three centuries before, Socrates drove his interlocutors to murder him just to get some respite from his arguments. It was now called the New Academy, was no less argumentative, and had the reputation of being the hotbed of skepticism in the ancient world.
On the much anticipated day of his oration, he stood up and delivered a brilliantly argued harangue in praise of justice and how devolving it should be at the top of our motives. The Roman audience was spellbound. It was not just his charisma; the audience was swayed by the strength of the arguments, the eloquence of the thought, the purity of the language, and the energy of the speaker. But that was not the point he wanted to drill.
The next day, Carneades came back, stood up, and established the doctrine of uncertainty of knowledge in the most possibly convincing way. How? By proceeding to contradict and refute with no less swaying arguments what he had established so convincingly the day before. He managed to persuade the very same audience and in the same spot that justice should be way down on the list of motivations for human undertakings.
Now the bad news. Cato the elder (the “censor”) was among the audience, already quite old, and no more tolerant than he had been during his office of censor. Enraged, he persuaded the Senate to send the three ambassadors packing lest their argumentative spirit muddle the spirit of the youth of the Republic and weaken the military culture. (Cato had banned during his office of censorship all Greek rhetoricians from establishing residence in Rome. He was too much a no-nonsense type of person to accept their introspective expansions.)
Carneades was not the first skeptic in classical times, nor was he the first to teach us the true notion of probability. But this incident remains the most spectacular in its impact on generations of rhetoricians and thinkers. Carneades was not merely a skeptic; he was a dialectician, someone who never committed himself to any of the premises from which he argued, or to any of the conclusions he drew from them. He stood all his life against arrogant dogma and belief in one sole truth. Few credible thinkers rival Carneades in their rigorous skepticism (a class that would include the medieval Arab philosopher al-Ghaz
al
i, Hume, and Kant—but only Popper came to elevate his skepticism to an all-encompassing scientific methodology). As the skeptics’ main teaching was that nothing could be accepted with certainty, conclusions of various degrees of probability could be formed, and these supplied a guide to conduct.
Stepping further back in time and searching for the first known uses of probabilistic thinking in history, we find it harks back to sixth-century (
B.C.
) Greek Sicily. There, the notion of probability was used in a legal framework by the very first rhetoricians who, when arguing a case, needed to show the existence of a doubt concerning the certainty of the accusation. The first known rhetorician was a Syracusean named Korax, who engaged in teaching people how to argue from probability. At the core of his method was the notion of the
most probable.
For example, the ownership of a piece of land, in the absence of further information and physical evidence, should go to the person after whose name it is best known. One of his indirect students, Gorgias, took this method of argumentation to Athens, where it flourished. It is the establishment of such
most probable
notions that taught us to view the possible contingencies as distinct and separable events with probabilities attached to each one of them.
Probability, the Child of Skepticism
Until the Mediterranean basin was dominated with monotheism, which led to the belief in some form of uniqueness of the truth (to be superceded later by episodes of communism), skepticism had gained currency among many major thinkers—and certainly permeated the world. The Romans did not have a religion
per se;
they were too tolerant to accept a given truth. Theirs was a collection of a variety of flexible and syncretic superstitions. I will not get too theological, except to say that we had to wait for a dozen centuries in the Western world to espouse critical thinking again. Indeed, for some strange reason during the Middle Ages, Arabs were critical thinkers (through their postclassical philosophical tradition) when Christian thought was dogmatic; then, after the Renaissance, the roles mysteriously reversed.
One author from antiquity who provides us evidence of such thinking is the garrulous Cicero. He preferred to be guided by probability than allege with certainty—very handy, some said, because it allowed him to contradict himself. This may be a reason for us, who have learned from Popper how to remain self-critical, to respect him more, as he did not hew stubbornly to an opinion for the mere fact that he had voiced it in the past. Indeed your average literature professor would fault him for his contradictions and his change of mind.
It was not until modern times that such desire to be free from our own past statements emerged. Nowhere was it made more eloquently than in rioting student graffiti in Paris. The student movement that took place in France in 1968, with the youth no doubt choking under the weight of years of having to sound intelligent and coherent, produced, among other jewels, the following demand:
We demand the right to contradict ourselves!
MONSIEUR DE NORPOIS’ OPINIONS
Modern times provide us with a depressing story. Self-contradiction is made culturally to be shameful, a matter that can prove disastrous in science. Marcel Proust’s novel
In Search of Time Lost
features a semiretired diplomat, Marquis de Norpois, who, like all diplomats before the advent of the fax machine, was a socialite who spent considerable time in salons. The narrator of the novel sees Monsieur de Norpois openly contradicting himself on some issue (some prewar rapprochement between France and Germany). When reminded of his previous position, Monsieur de Norpois did not seem to recall it. Proust reviles him:
Monsieur de Norpois was not lying. He had just forgotten. One forgets rather quickly what one has not thought about with depth, what has been dictated to you by imitation, by the passions surrounding you. These change, and with them so do your memories. Even more than diplomats, politicians do not remember opinions they had at some point in their lives and their fibbings are more attributable to an excess of ambition than a lack of memory.
Monsieur de Norpois is made to be ashamed of the fact that he expressed a different opinion. Proust did not consider that the diplomat might have changed his mind. We are supposed to be faithful to our opinions. One becomes a traitor otherwise.
Now I hold that Monsieur de Norpois should be a trader. One of the best traders I have ever encountered in my life, Nigel Babbage, has the remarkable attribute of being completely free of any path dependence in his beliefs. He exhibits absolutely no embarrassment buying a given currency on a pure impulse, when only hours ago he might have voiced a strong opinion as to its future weakness. What changed his mind? He does not feel obligated to explain it.
The public person most visibly endowed with such a trait is George Soros. One of his strengths is that he revises his opinion rather rapidly, without the slightest embarrassment. The following anecdote illustrates Soros’ ability to reverse his opinion in a flash. The French playboy trader Jean-Manuel Rozan discusses the following episode in his autobiography (disguised as a novel in order to avoid legal bills).The protagonist (Rozan) used to play tennis in the Hamptons on Long Island with Georgi Saulos, an “older man with a funny accent,” and sometimes engage in discussions about the market, not initially knowing how important and influential Saulos truly was. One weekend, Saulos exhibited in his discussion a large amount of bearishness, with a complicated series of arguments that the narrator could not follow. He was obviously short the market. A few days later, the market rallied violently, making record highs. The protagonist worried about Saulos, and asked him at their subsequent tennis encounter if he was hurt. “We made a killing,” Saulos said. “I changed my mind. We covered and went very long.”
It was this very trait that, a few years later, affected Rozan negatively and almost cost him a career. Soros gave Rozan in the late 1980s $20 million to speculate with (a sizeable amount at the time), which allowed him to start a trading company (I was almost dragged into it). A few days later, as Soros was visiting Paris, they discussed markets over lunch. Rozan saw Soros becoming distant. He then completely pulled the money, offering no explanation. What characterizes real speculators like Soros from the rest is that their activities are devoid of path dependence. They are totally free from their past actions. Every day is a clean slate.
Path Dependence of Beliefs
There is a simple test to define path dependence of beliefs (economists have a manifestation of it called the endowment effect).
Say you own a painting you bought for $20,000, and owing to rosy conditions in the art market, it is now worth $40,000. If you owned no painting, would you still acquire it at the current price? If you would not, then you are said to be married to your position. There is no rational reason to keep a painting you would not buy at its current market rate—only an emotional investment. Many people get married to their ideas all the way to the grave. Beliefs are said to be path dependent if the sequence of ideas is such that the first one dominates.
There are reasons to believe that, for evolutionary purposes, we may be programmed to build a loyalty to ideas in which we have invested time. Think about the consequences of being a good trader outside of the market activity, and deciding every morning at 8 a.m. whether to keep the spouse or part with him or her for a better emotional investment elsewhere. Or think of a politician who is so rational that, during a campaign, he changes his mind on a given matter because of fresh evidence and abruptly switches political parties. That would make rational investors who evaluate trades in a proper way a genetic oddity—perhaps a rare mutation. Researchers found that purely rational behavior on the part of humans can come from a defect in the amygdala that blocks the emotions of attachment, meaning that the subject is, literally, a psychopath. Could Soros have a genetic flaw that makes him rational as a decision maker?
Such trait of absence of marriage to ideas is indeed rare among humans. Just as we do with children, we support those in whom we have a heavy investment of food and time until they are able to propagate our genes, so we do with ideas. An academic who became famous for espousing an opinion is not going to voice anything that can possibly devalue his own past work and kill years of investment. People who switch parties become traitors, renegades, or, worst of all, apostates (those who abandoned their religion were punishable by death).
COMPUTING INSTEAD OF THINKING
There is another story of probability other than the one I introduced with Carneades and Cicero. Probability entered mathematics with gambling theory, and stayed there as a mere computational device. Recently, an entire industry of “risk measurers” emerged, specializing in the application of these probability methods to assess risks in the social sciences. Certainly, the odds in games where the rules are clearly and explicitly defined are computable and the risks consequently measured. But not in the real world. For mother nature did not endow us with clear rules. The game is not a deck of cards (we do not even know how many colors there are). But somehow people “measure” risks, particularly if they are paid for it. I have already discussed Hume’s problem of induction and the occurrence of black swans. Here I introduce the scientific perpetrators.
Recall that I have waged a war against the charlatanism of some prominent financial economists for a long time. The points are as follows. One Harry Markowitz received something called the Nobel Memorial Prize in Economics (which in fact is not even a Nobel Prize, as it is granted by the Swedish Central Bank in honor of Alfred Nobel—it was never in the will of the famous man). What is his achievement? Creating an elaborate method of computing
future
risk if one knows
future
uncertainty; in other words, if the world had clearly defined rules one picks up in a rulebook of the kind one finds in a Monopoly package. Now, I explained the point to a cab driver who laughed at the fact that someone ever thought that there was any scientific method to understanding markets and predicting their attributes. Somehow when one gets involved in financial economics, owing to the culture of the field, one becomes likely to forget these basic facts (pressure to publish to keep one’s standing among the other academics).
An immediate result of Dr. Markowitz’s theory was the near collapse of the financial system in the summer of 1998 (as we saw in Chapters
1
and
5
) by Long Term Capital Management (“LTCM”), a Greenwich, Connecticut, fund that had for principals two of Dr. Markowitz’s colleagues,“Nobels”as well. They are Drs. Robert Merton (the one in
Chapter 3
trouncing Shiller) and Myron Scholes. Somehow they thought they could scientifically “measure” their risks. They made absolutely no allowance in the LTCM episode for the possibility of their not understanding markets and their methods being wrong. That was not a hypothesis to be considered. I happen to specialize in black swans. Suddenly I started getting some irritating fawning respect. Drs. Merton and Scholes helped put your humble author on the map and caused interest in his ideas. The fact that these “scientists” pronounced the catastrophic losses a “ten sigma” event reveals a Wittgenstein’s ruler problem: Someone saying this is a ten sigma either (a) knows what he is talking about with near perfection (the prior assumption is that it has one possibility of being unqualified in several billion billions), knows his probabilities, and it is an event that happens once every several times the history of the universe; or (b) just does not know what he is talking about when he talks about probability (with a high degree of certainty), and it is an event that has a probability higher than once every several times the history of the universe. I will let the reader pick from these two mutually exclusive interpretations which one is more plausible.
Note that the conclusions also reflect on the Nobel committee who sanctified the ideas of the gentlemen involved: Conditional on these events, did they make a mistake or were these events unusual? Is the Nobel committee composed of infallible judges? Where is Charles Sanders Peirce to talk to us about papal infallibilism? Where is Karl Popper to warn us against taking science—and scientific institutions—seriously? In a few decades will we look upon the Nobel economics committee with the same smirk as when we look at the respected “scientific” establishments of the Middle Ages that promoted (against all observational evidence) the idea that the heart was a center of heat? We have been getting things wrong in the past and we laugh at our past institutions; it is time to figure out that we should avoid enshrining the present ones.
One would think that when scientists make a mistake, they develop a new science that incorporates what has been learned from it. When academics blow up trading, one would expect them to integrate such information in their theories and make some heroic statement to the effect that they were wrong, but that now they have learned something about the real world. Nothing of the sort. Instead they complain about the behavior of their counterparts in the market who pounced on them like vultures, thus exacerbating their downfall. Accepting what has happened, clearly the courageous thing to do, would invalidate the ideas they have built throughout an entire academic career. All of the principals who engaged in a discussion of the LTCM events partook of a masquerade of science by adducing
ad hoc
explanations and putting the blame on a rare event (problem of induction: How did they know it was a rare event?). They spent their energy defending themselves rather than trying to make a buck with what they learned. Again, compare them with Soros, who walks around telling whoever has the patience to listen to him that he is fallible. My lesson from Soros is to start every meeting at my boutique by convincing everyone that we are a bunch of idiots who know nothing and are mistake-prone, but happen to be endowed with the rare privilege of knowing it.
The scientist’s behavior while facing the refutation of his ideas has been studied in depth as part of the so-called attribution bias. You attribute your successes to skills, but your failures to randomness. This explains why these scientists attributed their failures to the “ten sigma” rare event, indicative of the thought that they were right but that luck played against them. Why? It is a human heuristic that makes us actually believe so in order not to kill our self-esteem and keep us going against adversity.
We have known about this wedge between performance and self-assessment since 1954, with Meehl’s study of experts comparing their perceived abilities to their statistical ones. It shows a substantial discrepancy between the objective record of people’s success in prediction tasks and the sincere beliefs of these people about the quality of their performance. The attribution bias has another effect: It gives people the illusion of being better at what they do, which explains the findings that 80 to 90% of people think that they are above the average (and the median) in many things.
FROM FUNERAL TO FUNERAL
I conclude with the following saddening remark about scientists in the soft sciences. People confuse science and scientists. Science is great, but individual scientists are dangerous. They are human; they are marred by the biases humans have. Perhaps even more. For most scientists are hard-headed, otherwise they would not derive the patience and energy to perform the Herculean tasks asked of them, like spending eighteen hours a day perfecting their doctoral thesis.
A scientist may be forced to act like a cheap defense lawyer rather than a pure seeker of the truth. A doctoral thesis is “defended” by the applicant; it would be a rare situation to see the student change his mind upon being supplied with a convincing argument. But science is better than scientists. It was said that science evolves from funeral to funeral. After the LTCM collapse, a new financial economist will emerge, who will integrate such knowledge into his science. He will be resisted by the older ones, but, again, they will be much closer to their funeral date than he.


================================================================================
CHAPTER/SECTION 317 (Item 326)
================================================================================

Fourteen
•
BACCHUS ABANDONS ANTONY
Montherlant’s death. Stoicism is not the stiff upper lip, but the illusion of victory of man against randomness. It is so easy to be heroic. Randomness and personal elegance.
W
hen the classicist aristocratic French writer Henry de Montherlant was told that he was about to lose his eyesight to a degenerative disease, he found it most appropriate to take his own life. Such is the end that becomes a classicist. Why? Because the stoic’s prescription was precisely to elect what one can do to control one’s destiny in front of a random outcome. At the end, one is allowed to choose between no life at all and what one is given by destiny; we always have an option against uncertainty. But such an attitude is not limited to stoics; both competing sects in the ancient world, stoicism and Epicureanism, recommended such control (the difference between the two resides in minor technicalities—neither philosophies meant then what is commonly accepted today in middlebrow culture).
Being a hero does not necessarily mean such an extreme act as getting killed in battle or taking one’s life—the latter is only recommended in a narrow set of circumstances and considered cowardly otherwise. Having control over randomness can be expressed in the manner in which one acts in the small and the large. Recall that epic heroes were judged by their actions, not by the results. No matter how sophisticated our choices, how good we are at dominating the odds, randomness will have the last word. We are left only with dignity as a solution—dignity defined as the execution of a protocol of behavior that does not depend on the immediate circumstance. It may not be the optimal one, but it certainly is the one that makes us feel best.
Grace under pressure,
for example. Or in deciding not to toady up to someone, whatever the reward. Or in fighting a duel to save face. Or in signaling to a prospective mate during courtship: “Listen, I have a crush on you; I am obsessed with you, but I will not do a thing to compromise my dignity. Accordingly, the slightest snub and you will never see me again.”
This last chapter will discuss randomness from a totally new angle; philosophical but not the
hard
philosophy of science and epistemology as we saw in Part I with the
black swan problem.
It is a more archaic,
softer
type of philosophy, the various guidelines that the ancients had concerning the manner in which a man of virtue and dignity deals with randomness—there was no real
religion
at the time (in the modern sense). It is worthy of note that before the spread of what can be best called Mediterranean monotheism, the ancients did not believe enough in their prayers to influence the course of destiny. Their world was dangerous, fraught with invasions and reversals of fortune. They needed substantial prescriptions in dealing with randomness. It is such beliefs that we will outline next.
NOTES ON JACKIE O.’S FUNERAL
If a stoic were to visit us, he would feel represented by the following poem. To many (sophisticated) lovers of poetry, one of the greatest poets who ever breathed is C. P. Cavafy. Cavafy was an Alexandrian Greek civil servant with a Turkish or Arabic last name who wrote almost a century ago in a combination of classical and modern Greek a lean poetry that seems to have eluded the last fifteen centuries of Western literature. Greeks treasure him like their national monument. Most of his poems take place in Syria (his Grecosyrian poems initially drew me to him), Asia Minor, and Alexandria. Many people believe it worth learning formal semi-classical Greek just to savor his poems. Somehow their acute aestheticism stripped of sentimentality provides a relief from centuries of mawkishness in poetry and drama. He provides a classical relief for those of us who were subjected to the middle-class-valued melodrama as represented by Dickens’s novels, romantic poetry, and Verdi’s operas.
I was surprised to hear that Maurice Tempelsman, last consort of Jackie Kennedy Onassis, read Cavafy’s valedictory “Apoleipein o Theos Antonion” (“The God Abandons Antony”) at her funeral. The poem addresses Marc Antony, who has just lost the battle against Octavius and was forsaken by Bacchus, the god who until then had protected him. It is one of the most elevating poems I have ever read, beautiful because it was the epitome of such dignified aestheticism—and because of the gentle but edifying tone of the voice of the narrator advising a man who had just received a crushing reversal of fortune.
The poem addresses Antony, now defeated and betrayed (according to legend, even his horse deserted him to go to his enemy Octavius). It asks him to just bid her farewell, Alexandria the city that is leaving him. It tells him not to mourn his luck, not to enter denial, not to believe that his ears and eyes are deceiving him. Antony, do not degrade yourself with empty hopes. Antony,
Just listen while shaken by emotion but not with the coward’s imploration and complaints.
While shaken with emotion. No stiff upper lip. There is nothing wrong and undignified with emotions—we are cut to have them. What is wrong is not following the heroic or, at least, the dignified path. That is what
stoicism
truly means. It is the attempt by man to get even with probability. I need not be nasty at all and break the spell of the poem and its message, but I cannot resist some cynicism. A couple of decades later, Cavafy, while dying of throat cancer, did not quite follow the prescription. Deprived of his voice by the surgeons, he used to randomly enter undignified spells of crying and cling to his visitors, preventing them from leaving his death room.
Some history. I said that stoicism has rather little to do with the stiff-upper-lip notion that we believe it means. Started as an intellectual movement in antiquity by a Phoenician Cypriot, Zeno of Kition, it developed by Roman time into a life based on a system of virtues—in the ancient sense when virtue meant
virtu,
the sort of belief in which virtue is its own reward. There developed a social model for a stoic person, like the gentlemen in Victorian England. Its tenets can be summarized as follows: The stoic is a person who combines the qualities of wisdom, upright dealing, and courage. The stoic will thus be immune from life’s gyrations as he will be superior to the wounds from some of life’s dirty tricks. But things can be carried to the extreme; the stern Cato found it beneath him to have human feelings. A more human version can be read in Seneca’s
Letters from a Stoic,
a soothing and surprisingly readable book that I distribute to my trader friends (Seneca also took his own life when cornered by destiny).
RANDOMNESS AND PERSONAL ELEGANCE
The reader knows my opinion on unsolicited advice and sermons on how to behave in life. Recall that ideas do not truly sink in when emotions come into play; we do not use our rational brain outside of classrooms. Self-help books (even when they are not written by charlatans) are largely ineffectual. Good, enlightened (and “friendly”) advice and eloquent sermons do not register for more than a few moments when they go against our wiring. The interesting thing about stoicism is that it plays on dignity and personal aesthetics, which are part of our genes. Start stressing personal elegance at your next misfortune. Exhibit
sapere vivere
(“know how to live”) in all circumstances.
Dress at your best on your execution day (shave carefully); try to leave a good impression on the death squad by standing erect and proud. Try not to play victim when diagnosed with cancer (hide it from others and only share the information with the doctor—it will avert the platitudes and nobody will treat you like a victim worthy of their pity; in addition, the dignified attitude will make both defeat and victory feel equally heroic). Be extremely courteous to your assistant when you lose money (instead of taking it out on him as many of the traders whom I scorn routinely do). Try not to blame others for your fate, even if they deserve blame. Never exhibit any self-pity, even if your significant other bolts with the handsome ski instructor or the younger aspiring model. Do not complain. If you suffer from a benign version of the “attitude problem,” like one of my childhood friends, do not start playing nice guy if your business dries up (he sent a heroic e-mail to his colleagues informing them “less business, but same attitude”). The only article Lady Fortuna has no control over is your behavior. Good luck.


================================================================================
CHAPTER/SECTION 318 (Item 327)
================================================================================

Epilogue
•
SOLON TOLD YOU SO
Beware the London Traffic Jams
A
couple of years after we left him looking at John smoking a cigarette with a modicum of
schadenfreude,
Nero’s skepticism ended up paying off. Simultaneously as he beat the 28% odds, up to the point of complete cure, he made a series of exhilarating personal and professional victories. Not only did he end up sampling the next level of wealth but he got the riches right when other Wall Street hotshots got poor, which could have allowed him to buy the goods they owned at very large discounts, if he wanted to. But he acquired very little, and certainly none of the goods Wall Streeters usually buy. But Nero did engage in occasional excess.
Friday afternoon traffic in London can be dreadful. Nero started spending more time there. He developed an obsession with traffic jams. One day he spent five hours moving west from his office in the city of London toward a cottage in the Cotswolds, where he stayed most weekends. The frustration prompted Nero to get a helicopter-flying license, through a crash course in Cambridgeshire. He realized that the train was probably an easier solution to get out of town for the weekend, but he felt the urge for a pet extravagance. The other result of his frustration was his no less dangerous commuting on a bicycle between his flat in Kensington and his office in the city.
Nero’s excessive probability-consciousness in his profession somehow did not register fully into his treatment of physical risk. For Nero’s helicopter crashed as he was landing it near Battersea Park on a windy day. He was alone in it. In the end the black swan got its man.


================================================================================
CHAPTER/SECTION 319 (Item 328)
================================================================================

Postscript
•
THREE AFTERTHOUGHTS IN THE SHOWER
O
wing to the subject’s tentacles and its author’s ruminating nature, this book keeps growing like a living object. I will add in this section a few post-thoughts I’ve had in the shower and in the few boring philosophy lectures I’ve attended (without wanting to offend my new colleagues in the thinking business, I discovered that listening to a speaker reciting
verbatim
his lecture notes makes me invariably daydream).
FIRST THOUGHT:
THE INVERSE SKILLS PROBLEM
The higher up the corporate ladder, the higher the compensation to the individual. This might be justified, as it makes plenty of sense to pay individuals according to their contributions. However, and in general (provided we exclude risk-bearing entrepreneurs), the higher up the corporate ladder, the
lower
the evidence of such contribution. I call this the
inverse rule.
I will be deriving the point by mere logical arguments.
Chapter 2
made the distinction between those skills that are visible (like the abilities of a dentist) and those that present more difficulty in nailing down, especially when the subject belongs to a randomness-laden profession (say, one that includes the occasional practice of Russian roulette). The degree of randomness in such an activity and our ability to isolate the contribution of the individual determine the visibility of the skills content. Accordingly, the cook at the company headquarters or the factory worker will exhibit their direct abilities with minimal uncertainty. These contributions may be modest but they are clearly definable. A patently incompetent professional cook who cannot distinguish salt from sugar or who tends to systematically overcook the meat would be easily caught, provided the diners have functioning taste buds. And if he gets it right by luck once, it also will be hard for him to get it right by sheer chance a second, third, and a thousandth time.
Repetitiveness is key for the revelation of skills because of what I called
ergodicity
in
Chapter 8
—the detection of long-term properties, particularly when these exist. If you bang one million dollars at your next visit to Las Vegas at the roulette table in one single shot, you will not be able to ascertain from this single outcome whether the house has the advantage or if you were particularly out of the gods’ favor. If you slice your gamble into a series of one million bets of one dollar each, the amount you recover will systematically show the casino’s advantage. This is the core of sampling theory, traditionally called the
law of large numbers.
To view it in another way, consider the difference between judging
on process
and judging
on results.
Lower-ranking persons in the enterprise are judged on both process and results—in fact, owing to the repetitive aspect of their efforts, their process converges rapidly to results. But top management is only paid on result—no matter the process. There seems to be no such thing as a foolish decision if it results in profits. “Money talks,” we are often told. The rest is supposed to be philosophy.
Now take a peek inside the chief executive suite. Clearly, the decisions there are not repeatable. CEOs take a small number of large decisions, more like the person walking into the casino with a single million-dollar bet. External factors, such as the environment, play a considerably larger role than with the cook. The link between the skill of the CEO and the results of the company are tenuous. By some argument, the boss of the company may be unskilled labor but one who presents the necessary attributes of charisma and the package that makes for good MBA talk. In other words, he may be subjected to the monkey-on-the-typewriter problem. There are so many companies doing all kinds of things that some of them are bound to make “the right decision.”
It is a very old problem. It is just that, with the acceleration of the power law–style winner-takes-all effects in our environment, such differences in outcomes are more accentuated, more visible, and more offensive to people’s sense of fairness. In the old days, the CEO was getting ten to twenty times what the janitor earned. Today, he can get several thousand times that.
I am excluding entrepreneurs from this discussion for the obvious reason: These are people who stuck their necks out for some idea, and risked belonging to the vast cemetery of those who did not make it. But CEOs are not entrepreneurs. As a matter a fact, they are often
empty suits.
In the “quant” world, the designation
empty suit
applies to the category of persons who are good at looking the part but nothing more. More appropriately, what they have is skill in getting promoted within a company rather than pure skills in making optimal decisions—we call that “corporate political skill.” These are people mostly trained at using PowerPoint presentations.
There is an asymmetry, as these executives have almost nothing to lose. Assume that two equally charismatic, empty-suit-style twin brothers manage to climb the corporate ladder to get two different jobs in two different corporations. Assume that they own good-looking suits, that they have MBAs, and that they are tall (the only truly visible predictor of corporate success is to be taller than average). They flip coins in secret and randomly take completely opposite actions, leading to great failure for one and great success for the other. We end up with a mildly wealthy, but fired, executive and his extremely wealthy, and still operating, twin brother. The shareholder bore the risk; the executives got the reward.
The problem is as old as leadership. Our attribution of heroism to those who took crazy decisions but were lucky enough to win shows the aberration—we continue to worship those who won battles and despise those who lost, no matter the reason. I wonder how many historians use luck in their interpretation of success—or how many are conscious of the difference between process and result.
I insist that it is not society’s problem but that of the investors. If shareholders are foolish enough to pay someone $200 million to just wear a good-looking suit and ring a bell, as they did with the New York Stock Exchange’s Richard Grasso in 2003, it is their own money they part with, not yours and mine. It is a corporate governance issue.
The situation is not much better in a bureaucratic economy. Outside the capitalistic system, presumed talent flows to the governmental positions, where the currency is prestige, power, and social rank. There, too, it is distributed disproportionately. The contributions of civil servants might be even more difficult to judge than those of the executives of a corporation—and the scrutiny is smaller. The central banker lowers interest rates, a recovery ensues, but we do not know whether he caused it or if he slowed it down. We can’t even know that he didn’t destabilize the economy by increasing the risk of future inflation. He can always fit a theoretical explanation, but economics is a narrative discipline, and explanations are easy to fit retrospectively.
The problem may not be incurable. It is just that we need to drill into the heads of those who measure the contribution of executives that what they see is not necessarily what is there. Shareholders, in the end, are the ones who are fooled by randomness.
SECOND THOUGHT: ON SOME ADDITIONAL
BENEFITS OF RANDOMNESS
Uncertainty and Happiness
Have you ever had a weeknight dinner in New York City with a suburban commuter? Odds are that the shadow of the schedule will be imprinted in his consciousness. He will be tightly aware of the clock, pacing his meal in such a way that he does not miss the 7:08 because after that one, there are no more express trains and he would be reduced to taking the 7:42 local, something that appears to be very undesirable. He will cut the conversation short around 6:58, offer a quick handshake, then zoom out of the restaurant to catch his train with maximal efficiency. You will also be stuck with the bill. Since the meal is not finished, and the bill is not ready, your manners will force you to tell him that it’s on you. You will also finish the cup of decaffeinated skim cappuccino all alone while staring at his empty seat and wondering why people get trapped by choice into such a life.
Now deprive him of his schedule—or randomize the time of departures of the trains so they no longer obey a fixed and known timetable. Given that what is random and what you do not know are functionally the same, you do not have to ask the New York area Metropolitan Transit Authority to randomize their trains for the purpose of the experiment: Just assume that he is deprived of knowledge of the various departure times. All he would know is that they operate about every, say, thirty-five minutes. What would he do under such a scenario? Although you might still end up paying for dinner, he would let the meal follow its natural course, then leisurely walk to the nearby station, where he would have to wait for the next train to show up. The time difference between the two situations will be a little more than a quarter of an hour. Another way to see the contrast between a known and an unknown schedule is to compare his condition to that of another diner who has to use the subway to go home, for an equivalent distance, but without a known and fixed schedule. Subway riders are freer of their schedule, and not just because of the higher frequency of trains. Uncertainty protects them from themselves.
Chapter 10
showed, with the illustration of Buridan’s donkey, that randomness is not always unwelcome. This discussion aims to show how some degree of unpredictability (or lack of knowledge) can be beneficial to our defective species. A slightly random schedule prevents us from optimizing and being exceedingly efficient, particularly in the wrong things. This little bit of uncertainty might make the diner relax and forget the time pressures. He would be forced to act as a
satisficer
instead of a
maximizer
(
Chapter 11
discussed Simon’s satisficing as a blend of satisfying and maximizing)—research on happiness shows that those who live under a self-imposed pressure to be optimal in their enjoyment of things suffer a measure of distress.
The difference between satisficers and optimizers raises a few questions. We know that people of a happy disposition tend to be of the satisficing kind, with a set idea of what they want in life and an ability to stop upon gaining satisfaction. Their goals and desires do not move along with the experiences. They do not tend to experience the internal treadmill effects of constantly trying to improve on their consumption of goods by seeking higher and higher levels of sophistication. In other words, they are neither avaricious nor insatiable. An optimizer, by comparison, is the kind of person who will uproot himself and change his official residence just to reduce his tax bill by a few percentage points. (You would think that the entire point of a higher income is to be free to choose where to live; in fact it seems, for these people, wealth causes them to increase their dependence!) Getting rich results in his seeing flaws in the goods and services he buys. The coffee is not warm enough. The cook no longer deserves the three stars given to him by the Michelin guide (he will write to the editors).The table is too far from the window. People who get promoted to important positions usually suffer from tightness of schedules: Everything has an allotted time. When they travel, everything is “organized” with optimizing intent, including lunch at 12:45 with the president of the company (a table not too far from the window), the Stairmaster at 4:40, and opera at 8:00.
Causality is not clear: The question remains whether optimizers are unhappy because they are constantly seeking a better deal or if unhappy people tend to optimize out of their misery. In any case, randomness seems to operate either as a cure or as Novocain!
I am convinced that we are not made for clear-cut, well-delineated schedules. We are made to live like firemen, with downtime for lounging and meditating between calls, under the protection of protective uncertainty. Regrettably, some people might be involuntarily turned into optimizers, like a suburban child having his weekend minutes squeezed between karate, guitar lessons, and religious education. As I am writing these lines I am on a slow train in the Alps, comfortably shielded from traveling businesspersons. People around me are either students or retired persons, or those who do not have “important appointments,” hence not afraid of what they call wasted time. To go from Munich to Milan, I picked the seven-and-a-half-hour train instead of the plane, which no self-respecting businessperson would do on a weekday, and am enjoying an air unpolluted by persons squeezed by life.
I came to this conclusion when, about a decade ago, I stopped using an alarm clock. I still woke up around the same time, but I followed my own personal clock. A dozen minutes of fuzziness and variability in my schedule made a considerable difference. True, there are some activities that require such dependability that an alarm clock is necessary, but I am free to choose a profession where I am not a slave to external pressure. Living like this, one can also go to bed early and not optimize one’s schedule by squeezing every minute out of one’s evening. At the limit, you can decide whether to be (relatively) poor, but free of your time, or rich but as dependent as a slave.
It took me a while to figure out that we are not designed for schedules. The realization came when I recognized the difference between writing a paper and writing a book. Books are fun to write, papers are painful. I tend to find the activity of writing greatly entertaining, given that I do it without any external constraint. You write, and may interrupt your activity, even in mid-sentence, the second it stops being attractive. After the success of this book, I was asked to write papers by the editors of a variety of professional and scientific journals. Then they asked me how long the piece should be. What? How long? For the first time in my life, I experienced a loss of pleasure in writing! Then I figured out a personal rule: For writing to be agreeable to me,
the length of the piece needs to remain unpredictable.
If I see the end of it, or if I am subjected to the shadow of an outline, I give up. I repeat that our ancestors were not subjected to outlines, schedules, and administrative deadlines.
Another way to see the beastly aspect of schedules and rigid projections is to think in limit situations. Would you like to know with great precision the date of your death? Would you like to know who committed the crime before the beginning of the movie? Actually, wouldn’t it be better if the length of movies were kept a secret?
The Scrambling of Messages
Besides its effect on well-being, uncertainty presents tangible informational benefits, particularly with the scrambling of potentially damaging, and self-fulfilling, messages. Consider a currency pegged by a central bank to a fixed rate. The bank’s official policy is to use its reserves to support it by buying and selling its currency in the open market, a procedure called
intervention.
But should the currency rate drop a tiny bit, people will immediately get the message that the intervention failed to support the currency and that the devaluation is coming. A pegged currency is not supposed to fluctuate; the slightest downward fluctuation is meant to be a harbinger of bad news! The rush to sell would cause a self-feeding frenzy leading to certain devaluation.
Now consider an environment where the central bank allows some noise around the official band. It does not promise a fixed rate, but one that can fluctuate a bit before the bank starts intervening. A small drop would not be considered to bear much information. The existence of noise leads us to avoid reading too much into variations.
Fluctuat nec mergitur
(it fluctuates but does not sink).
This point has applications in evolutionary biology, evolutionary game theory, and conflict situations. A mild degree of unpredictability in your behavior can help you to protect yourself in situations of conflict. Say you always have the same threshold of reactions. You take a set level of abuse, say seventeen insulting remarks per week, before getting into a rage and punching the eighteenth offender in the nose. Such predictability will allow people to take advantage of you up to that well-known trigger point and stop there. But if you randomize your trigger point, sometimes overreacting at the slightest joke, people will not know in advance how far they can push you. The same applies to governments in conflicts: They need to convince their adversaries that they are crazy enough to sometimes overreact to a small peccadillo. Even the magnitude of their reaction should be hard to foretell. Unpredictability is a strong deterrent.
THIRD THOUGHT: STANDING ON ONE LEG
I have been periodically challenged to compress all this business of randomness into a few sentences, so even an MBA can understand it (surprisingly, MBAs, in spite of the insults, represent a significant portion of my readership, simply because they think that my ideas apply to other MBAs and not to them).
This brings to mind Rabbi Hillel’s story, when he was asked by someone particularly lazy if Hillel could teach him the Torah while the student was standing on one leg. Rabbi Hillel’s genius is that he did not
summarize;
instead, he provided the core generator of the idea, the axiomatic framework, which I paraphrase as follows:
Don’t do to others what you don’t want them to do to you; the rest is just commentary.
It took me an entire lifetime to find out what my generator is. It is:
We favor the visible, the embedded, the personal, the narrated, and the tangible; we scorn the abstract.
Everything good (aesthetics, ethics) and wrong (Fooled by Randomness) with us seems to flow from it.


================================================================================
CHAPTER/SECTION 320 (Item 329)
================================================================================

To my mother,
Minerva Ghosn Taleb


================================================================================
CHAPTER/SECTION 321 (Item 330)
================================================================================

ACKNOWLEDGMENTS FOR THE FIRST EDITION
First, I would like to thank friends who can be considered rightful coauthors. I am grateful to New York intellectual and expert in randomness Stan Jonas (I do not know any other designation that would do him justice) for half a lifetime of conversations into all subjects bordering on probability with the animation and the zeal of the neophyte. I thank my probabilist friend Don Geman (husband of Helyette Geman, my thesis director) for his enthusiastic support for my book; he also made me realize that probabilists are born, not made—many mathematicians are capable of computing, but not understanding, probability (they are no better than the general population in exerting probabilistic judgments). The real book started with an all-night conversation with my erudite friend Jamil Baz during the summer of 1987, as he discussed the formation of “new” and “old” money among families. I was then a budding trader and he scorned the arrogant Salomon Brothers traders who surrounded him (he was proved right). He instilled in me the voracious introspection about my performance in life and really gave me the idea for this book. Both of us ended up getting doctorates later in life, on an almost identical subject matter. I have also dragged many people on (very long) walks in New York, London, or Paris, discussing some parts of this book, such as the late Jimmy Powers, who helped nurture my trading early on, and who kept repeating “anyone can buy and sell,” or my encyclopedic friend David Pastel, equally at ease with literature, mathematics, and Semitic languages. I have also engaged my lucid Popperian colleague Jonathan Waxman in numerous conversations on the integration of Karl Popper’s ideas into our life as traders.
Second, I have been lucky to meet Myles Thompson and David Wilson, when they both were at J. Wiley & Sons. Myles understood that books need not be written to satisfy a predefined labeled audience, but that a book will find its own unique set of readers—thus giving more credit to the reader than the off-the-rack publisher. As to David, he believed enough in the book to push me to take it into its natural course, free of all labels and taxonomies. David saw me the way I view myself: someone who has a passion for probability and randomness, who is obsessed with literature but happens to be a trader, rather than a generic “expert.” He also saved my idiosyncratic style from the dulling of the editing process (for all its faults, the style is mine). Finally, Mina Samuels proved to be the greatest conceivable editor: immensely intuitive, cultured, aesthetically concerned, yet nonintrusive.
Many friends have fed me with ideas during conversations, ideas that found their way into the text. I can mention the usual suspects, all of them prime conversationalists: Cynthia Shelton Taleb, Helyette Geman, Marie-Christine Riachi, Paul Wilmott, Shaiy Pilpel, David DeRosa, Eric Briys, Sid Kahn, Jim Gatheral, Bernard Oppetit, Cyrus Pirasteh, Martin Mayer, Bruno Dupire, Raphael Douady, Marco Avellaneda, Didier Javice, Neil Chriss, and Philippe Asseily.
Some of these chapters were composed and discussed as part of the “Odeon Circle,” as my friends and I met with a varying degree of regularity (on Wednesdays at 10 p.m. after my Courant class) at the bar of the restaurant Odeon in Tribeca. Genius loci (“the spirit of the place”) and outstanding Odeon staff member Tarek Khelifi made sure that we were well taken care of and enforced our assiduity by making me feel guilty on no-shows, thus helping greatly with the elaboration of the book. We owe him a lot.
I must also acknowledge the people who read the MS, diligently helped with the errors, or contributed to the elaboration of the book with useful comments: Inge Ivchenko, Danny Tosto, Manos Vourkoutiotis, Stan Metelits, Jack Rabinowitz, Silverio Foresi, Achilles Venetoulias, and Nicholas Stephanou. Erik Stettler was invaluable in his role as a shadow copy editor. All mistakes are mine.
Finally, many versions of this book sat on the Web, yielding sporadic (and random) bursts of letters of encouragement, corrections, and valuable questions, which made me weave answers into the text. Many chapters of this book came in response to readers’ questions. Francesco Corielli from Bocconi alerted me on the biases in the dissemination of scientific results.
This book was written and finished after I founded Empirica, my intellectual home, “Camp Empirica,” in the woods in the back country of Greenwich, Connecticut, which I designed to fit my taste and feel like a hobby: a combination of an applied probability research laboratory, athletic summer camp, and, not least, a trading operation (I had experienced one of my best professional years while writing these lines). I thank all the like-minded people who helped fuel the stimulating atmosphere there: Pallop Angsupun, Danny Tosto, Peter Halle, Mark Spitznagel, Yuzhao Zhang, and Cyril de Lambilly as well as the members of Paloma Partners such as Tom Witz, who challenged our wisdom on a daily basis, and Donald Sussman, who supplied me with his penetrating judgment.


================================================================================
CHAPTER/SECTION 322 (Item 331)
================================================================================

ACKNOWLEDGMENTS
FOR THE UPDATED SECOND EDITION
Out of the Library
T
he book helped me break out of my intellectual isolation (not being a full-time academic offers plenty of benefits, such as independence and the avoidance of the dull parts of the process, but it comes at the cost of seclusion). I made many interesting dinner companions and pen pals among lucid thinkers through the first edition, and, thanks to them, I was able to make a second pass on some of the topics. In addition, I have gotten closer to my dream life thanks to the stimulation of discussion with people who share my interests; I feel that I need to pay the book back for that. There seems to be some evidence that conversations and correspondence with intelligent people is a better engine for personal edification than plain library-ratting (human warmth: Something in our nature may help us grow ideas while dealing and socializing with other people). Somehow there was the
pre-
and
post-Fooled
life. While the acknowledgments for the first edition hold more than ever, I would like to add here my newly incurred debt.
Shrinking the World
I first met Robert Shiller in person as we were seated next to each other at a breakfast panel discussion. I found myself inadvertently eating all the fruits on his plate and drinking his coffee and water, leaving him with the muffins and other unfashionable food (and nothing to drink). He did not complain (he may have not noticed). I did not know Shiller when I featured him in the first edition and was surprised by his accessibility, his humility, and his charm (by some heuristic one does not expect people who have vision to be also personable). He later drove me to a bookstore in New Haven, showed me
Flatland,
a scientific parable dealing with physics that he read when he was in high school, and told me to keep this book as it was in the first edition: short, personal, as close to a novel as possible, something I kept in mind throughout the exercise of this reworking (he tried to convince me to not do this second edition, I begged him to do a second one of his own
Irrational Exuberance,
be it only for my own consumption; I think that I won both points). Books have bubble dynamics of the type discussed in
Chapter 10
, a matter that makes an extra edition of an existing book far more likely to break through the critical point than a new one (network externalities make religions and fads fare incrementally better in their second editions than brand-new ones). The physicist and crash theorist Didier Sornette provided me with convincing arguments for the effectiveness of a second version; we are surprised that book publishers who thrive on informational cascades are not conscious of the point.
During much of the rewriting of this book I was under the energizing influence of two intense dinner conversations in Italy with Daniel Kahneman, which had the effect of “pushing” me to the next critical point of intellectual drive, after I saw that his work went so much deeper than mere rational choice under uncertainty. I am certain that his influence on economics (including the Nobel medal) focused people away from the breadth and depth and the general applicability of his discoveries. Economics is boring stuff, but
His work matters
I kept telling myself, not just because he is an empiricist, not just because of the contrast of the relevance of his work (and personality) with those of the other recent Nobel economists, but because of its far-reaching implications on far worthier questions: (a) He and Amos Tversky helped stand on its head the notion of man that we owe to the dogmatic rationalism of the Hellenistic age and which held for twenty-three centuries, with all the damaging consequences that we know of now; (b) Kahneman’s important work is on utility theory (in its different stages) with consequences on such significant things as happiness. Now understanding happiness is a
real
pursuit.
I had lengthy discussions with Terry Burnham, the biologist and evolutionary economist and co-author of
Mean Genes,
that unpretentious introduction to evolutionary psychology, who coincidentally turned out to be best friends with Jamil Baz, the childhood friend who was my sounding board with my early introspections on randomness two decades ago. Peter McBurney got me involved with the Artificial Intelligence community, which seems to fuse together the fields of philosophy, cognitive neuroscience, mathematics, economics, and logic. He and I started a voluminous correspondence on the various theories of rationality. Michael Schrage, one of my reviewers, is the epitome of the modern (hence scientific) intellectual—he has a knack of reading everything that seems to matter. He offers the conversation of a true intellectual, shielded from the straitjacket of academic pressures. Ramaswami Ambarish and Lester Siegel showed me (with their suspiciously unnoticed work) that if we are fooled by randomness with respect to plain performance, then performance differential is even harder to pin down. The writer Malcolm Gladwell sent me into some interesting parts of the literature on intuition and self-knowledge. Art De Vany, the insightful and brilliantly colorful economist who specializes in nonlinearities and rare events, started his introductory letter to me with the shibboleth “I despise textbooks.” It is encouraging to see someone with such depth in his thinking who can also have fun in life. The economist William Easterly showed me that randomness contributed to illusionary causes in economic development. He liked the link between being a skeptical empiricist and disliking monopolies on knowledge by institutions like governments and universities. I am grateful to Hollywood agent Jeff Berg, an enthusiastic reader, for his insights on the wild type of uncertainty that prevails in the media business. I have to thank the book for allowing me to have insightful dinner discussions with Jack Schwager, who seems to have thought of some of the problems longer than anybody alive.
Thank You, Google
The following people have provided me with help on this text. I was very fortunate to have Andreea Munteanu as an incisive reader and valuable sounding board; she spent hours away from her impressive derivatives job checking the integrity of the references on Google. Amanda Gharghour also helped with the search. I was also lucky to have Gianluca Monaco as the Italian translator; he found mistakes in the text that it would have taken me a century to detect (a cognitive scientist and book-translator-turned-student-of-mathematical-finance, he called up the publisher and appointed himself the translator). My collaborator, the philosopher of science Avital Pilpel, provided me with invaluable help with technical probability discussions. Elie Ayache, another Levantine-tradder-mathematician-physicist-turned-philosopher-of-science-probability-markets (though without the neurobiology), made me spend numerous hours at Borders Books in both the philosophy section and the science section. Flavia Cymbalista, Sole Marittimi (now Riley), Paul Wilmott, Mark Spitznagel, Gur Huberman, Tony Glickman, Winn Martin, Alexander Reisz, Ted Zink, Andrei Pokrovsky, Shep Davis, Guy Riviere, Eric Schoenberg, and Marco Di Martino provided comments on the text. George Martin was, as usual, an invaluable sounding board. The readers Carine Chichereau, Bruce Bellner, and Illias Katsounis, gracefully e-mailed me extensive errata. I thank Cindy, Sarah, and Alexander for support and the reminder that there are other things than probability and uncertainty.
I also have to thank my second home, the Courant Institute of Mathematical Sciences, for providing me with the right atmosphere to pursue my interests and teach and coach students while retaining my intellectual independence, particularly Jim Gatheral, who took the habit of heckling me while co-teaching the class. I am indebted to Paloma’s Donald Sussman and Tom Witz for their unusual insights; I am truly impressed by their heroic ability to understand the “black swan.” I also thank the Empirica members (we ban the use of the word
employees
) for fostering a climate of fierce and ruthless, truly cut-throat intellectual debate in the office. My coworkers make sure that not a single comment on my part can go without some sort of challenge.
I insist once again that without David Wilson and Myles Thompson this book would have never been initially published. But without Will Murphy, Daniel Menaker, and Ed Klagsbrun, who revived this book, it would have been dead. I thank Janet Wygal for her thoroughness (and patience) and Fleetwood Robbins for his assistance. Given their zeal, I doubt that many mistakes are left; however, those that remain are mine.


================================================================================
CHAPTER/SECTION 323 (Item 332)
================================================================================

A TRIP TO THE LIBRARY
Notes and Reading Recommendations
NOTES
I confess that, as a practitioner of randomness, I focused primarily on the defects of my
own
thinking (and that of a few people I’ve observed or tracked through time). I also intended the book to be playful, which is not very compatible with referencing every idea to some scientific paper to give it a degree of respectability. I take the liberty in this section to finesse a few points and to provide select references (of the “further reading” variety)—but references linked to matters that I directly experienced. I repeat that this is a personal essay, not a treatise.
On completion of this compilation I discovered the predominance of matters relating to human nature (mostly empirical psychology) over things mathematical. Sign of the times: I am convinced that the next edition, hopefully two years from now, will have plenty of references and notes in neurobiology and neuroeconomics.
PREFACE
Hindsight bias:
a.k.a Monday morning quarterback. See Fischhoff (1982).
Clinical knowledge:
The problem of clinicians not knowing what they do not know, and not quite figuring it out. See Meehl (1954) for the seminal introduction. “It is clear that the dogmatic, complacent assertion sometimes heard from clinicians that ‘naturally’ clinical prediction, being based on ‘real understanding’ is superior, is simply not justified by the facts to date.” In his testing, in all but one case, predictions made by actuarial means were equal to or better than clinical methods. Even worse: In a later paper, he changed his mind about that one exception. Since Meehl’s work there has been a long tradition of examination of expert opinions, confirming the same results. This problem applies to about every profession—particularly journalists and economists. We will discuss in further notes the associated problem of self-knowledge.
Montaigne vs Descartes:
I thank the artificial intelligence researcher and omnivorous reader Peter McBurney for bringing to my attention the discussion in Toulmin (1990). On that I have to make the sad remark that Descartes was originally a skeptic (as attested by his demon thought experiment) but the so-called Cartesian mind corresponds to someone with an appetite for certainties. Descartes’ idea in its original form is that there are very few certainties outside of narrowly defined deductive statements, not that everything we think about needs to be deductive.
Affirming the consequent:
The logical fallacy is generally presented as follows.
If p then q
q
Therefore, p
(All people in the Smith family are tall; he is tall therefore he belongs to the Smith family).
The track record of the general population in correctly making such inference is exceedingly poor. Although it is not customary to quote textbooks, I refer the reader to the excellent Eysenck and Keane (2000) for a list of the research papers on the different difficulties—up to 70% of the population can make such a mistake!
The millionaire mind:
Stanley (2000). He also figured out (correctly) that the rich were “risk takers” and inferred (incorrectly) that risk taking made one rich. Had he examined the population of failed entrepreneurs he would have also inferred (correctly) that the failed entrepreneurs too were “risk takers.”
Journalists are “practical”:
I heard at least four times the word
practical
on the part of journalists trying to justify their simplification. The television show that wanted me to present three stock recommendations wanted something “practical,” not theories.
PROLOGUE
Mathematics conflicts with probability:
One is about certainties, the other about the exact opposite. This explains the disrespect held by pure mathematicians for the subject of probability for a long time—and the difficulty in integrating the two. It is not until recently that it was termed “the logic of science”—the title of the posthumous Jaynes (2003). Interestingly, this book is also perhaps the most complete account of the mathematics of the subject—he manages to use probability as an expansion of conventional logic.
The prominent mathematician David Mumford, a Fields medalist, repents for his former scorn for probability. He writes in
The Dawning of the Age of Stochasticity
(Mumford, 1999): “For over two millennia, Aristotle’s logic has ruled over the thinking of Western intellectuals. All precise theories, all scientific models, even models of the process of thinking itself, have in principle conformed to the straight-jacket of logic. But from its shady beginnings devising gambling strategies and counting corpses in medieval London, probability theory and statistical inference now emerge as better foundations for scientific models, especially those of the process of thinking and as essential ingredients of theoretical mathematics, even the foundations of mathematics itself. We propose that this sea change in our perspective will affect virtually all of mathematics in the next century.”
Courage or foolishness:
For an examination of that notion of “courage” and “guts,” see Kahneman and Lovallo (1993). See also a discussion in Hilton (2003). I drew the idea from Daniel Kahneman’s presentation in Rome in April 2003 (Kahneman, 2003).
Cognitive errors in forecasting:
Tversky and Kahneman (1971), Tversky and Kahneman (1982), and Lichtenstein, Fischhoff and Phillips (1977).
Utopian/tragic:
The essayist and prominent (scientific) intellectual Steven Pinker popularized the distinction (originally attributable to the political scholar Thomas Sowell). See Sowell (1987), Pinker (2002). Actually, the distinction is not so clear. Some people actually believe, for instance, that Milton Friedman is a utopist in the sense that all ills come from governments and that getting rid of government would be a great panacea.
Fallibility and infallibilism:
Peirce (in a prospectus for a never written book), writes, “Nothing can be more completely contrary to a philosophy, the fruit of a scientific life, than infallibilism, whether arrayed in the old ecclesiastical trappings, or under its recent ‘scientific’ disguise.” (Brent, 1993). For a brief and very readable acquaintance to the works of Peirce, Menand (2001). It draws on his sole biography, Brent (1993).
CHAPTER 1
Relative compared to absolute position:
See Kahneman, Knetsch and Thaler (1986). Robert Frank is an interesting researcher who spent part of his career thinking about the problem of status, rank, and relative income: See Frank (1985), and the very readable Frank (1999). The latter includes discussions on the interesting proposer/responder problem where people forego windfall profits in order to deprive others of a larger share. One person proposes to the other a share of, say, $100. She can accept or refuse. If she refuses, both get nothing.
Even more vicious results have been shown by researchers who studied how much people would
pay
to lower other people’s income: See Zizzo and Oswald (2001). On that also, see Burnham (2003) (he ran an experiment measuring the testosterone levels in economic exchange).
Serotonin and pecking order:
Frank (1999) includes a discussion.
On the social role of the psychopath:
See Horrobin (2002). While it may have some extreme views on the point, the book reviews discussions of the theories around the success realized by the psychopaths. Also, see Carter (1999) for a presentation of the advantage some people have in being separated from the feeling of empathy and compassion.
Social emotions:
Damasio (2003): “One of the many reasons why people become leaders and others followers, why so many command respect, has little to do with knowledge or skills and a lot to do with how some physical traits and the manner of a given individual promote certain emotional responses in others.”
Literature on emotions:
For a review of the current scientific ideas, see the excellent compact Evans (2002). Evans belongs to the new breed of the philosopher/essayist contemplating large themes with a scientific mind. Elster (1998) goes into the broad social implications of emotions. The bestselling Goleman (1995) offers a surprisingly complete account (the fact that it is a bestseller is surprising: We are aware of our irrationality but it does not seem to help).
CHAPTER 2
Possible worlds:
Kripke (1980).
Many worlds:
See the excellently written Deutsch (1997). I also suggest a visit to the author’s rich website. The earlier primary work can be found in DeWitt and Graham (1973), which contains Hugh Everett’s original paper.
Economics of uncertainty and possible states of nature:
See Debreu (1959). For a presentation of lattice state-space methods in mathematical finance, see Ingersoll (1987) (well structured though dry and very, very boring, like the personality of its author), and the more jargon-laden Huang and Litzenberger (1988). For an economics-oriented presentation, see Hirshleifer and Riley (1992).
For the works of Shiller:
See Shiller (2000). The more technical work is in the (originally) controversial Shiller (1981). See also Shiller (1990). For a compilation: Shiller (1989). See also Kurz (1997) for a discussion of endogenous uncertainty.
Risk and emotions:
Given the growing recent interest in the emotional role in behavior, there has been a growing literature on the role of emotions in both risk bearing and risk avoidance: The “risk as feeling” theory: See Loewenstein, Weber, Hsee and Welch (2001), and Slovic, Finucane, Peters and MacGregor (2003a). For a survey, see Slovic, Finucane, Peters and MacGregor (2003b). See also Slovic (1987).
For a discussion of the affect heuristic:
See Finucane, Alhakami, Slovic and Johnson (2000).
Emotions and cognition:
For the effect of emotions on cognition, see LeDoux (2002).
Availability heuristic (how easily things come to mind):
Tversky and Kahneman (1973).
Real incidence of catastrophes:
For an insightful discussion, see Albouy (2002).
On sayings and proverbs:
Psychologists have long examined the gullibility of people in social settings facing well-sounding proverbs. For instance, experiments since the 1960s have been made where people are asked whether they believed that a proverb is right, while another cohort is presented the opposite meaning. For a presentation of the hilarious results, see Myers (2002).
Epiphenomena:
See the beautiful Wegner (2002).
CHAPTER 3
Keynes:
Keynes’
Treatise on Probability
(Keynes, 1989, 1920) remains in many people’s opinion the most important single work on the subject—particularly considering Keynes’ youth at the time of composition (it was published years after he finished it). In it he develops the critical notion of subjective probability.
Les gommes:
Robbe-Grillet (1985).
Pseudoscientific historicism:
For an example, I suggest Fukuyama (1992).
Fears built into our genes:
This is not strictly true—genetic traits need to be culturally activated. We are wired for some fears, such as fears of snakes, but monkeys who have never seen a snake do not have it. They need the sight of the fear in the facial features of another monkey to start getting scared (LeDoux, 1998).
Amnesia and risk avoidance:
Damasio (2000) presents the case of David the amnesic patient who knew to avoid those who abused him. See also Lewis, Amini and Lannon (2000). Their book presents a pedagogic discussion of “camouflaged learning,” in the form of implicit memory, as opposed to explicit memory (neocortical). The book portrays memory as a correlation in neuron connectivity rather than some CD-style recording—which explains the revisions of memory by people after events.
Why don’t we learn from our past history?:
Two strains of literature. (1) The recent “stranger to ourselves” line of research in psychology (Wilson 2002). (2) The literature on “immune neglect,” Wilson, Meyers and Gilbert (2001) and Wilson, Gilbert and Centerbar (2003). Literally, people don’t learn from their past reactions to good and bad things.
Literature on bubbles:
There is a long tradition, see Kindleberger (2001), MacKay (2002), Galbraith (1991), Chancellor (1999), and of course Shiller (2000). Shiller with a little work may be convinced to do a second edition.
Long-term capital management:
See Lowenstein (2000).
Stress and randomness:
Sapolsky (1998) is a popular, sometimes hilarious presentation. The author specializes among other things on the effect of glucocorticoids released at times of stress on the atrophy of the hycocampus, hampering the formation of new memory and brain plasticity. More technical, Sapolsky (2003).
Brain asymmetries with gains/losses:
See Gehring and Willoughby (2002). See the works of Davidson on the anterior brain asymmetry (a clear summary and popular presentation in Goleman 2003). See also Shizgal (1999).
The dentist and prospect theory:
Kahneman and Tversky (1979). In this seminal discussion they present agents as interested in differences and resetting their pain/pleasure level at zero as “anchor.” The gist of it is that “wealth” does not matter, almost only differences in wealth, since the resetting cancels the effect of the accumulation. Think of John hitting wealth of $1 million from below or above and the impact on his well-being. The difference between utility of wealth and utility of changes in wealth is not trivial: It leads to dependence on the observation period. In fact the notion, taken to its limit, leads to the complete revision of economic theory: Neoclassical economics will no longer be useful beyond mathematical exercises. There have been vigorous such discussions in the hedonistic literature as well: See Kahneman, Diener and Schwarz (1999).
CHAPTER 4
Public and scientific intellectual:
Brockman (1995) offers presentations by the “who’s who” in the new scientific intellectual tradition. See also his website,
www.edge.org
. For a physicist’s position on the culture wars, Weinberg (2001). For a presentation of a public intellectual, see Posner (2002). Note that Florida Atlantic University offers a Ph.D. to become a public intellectual—literary, since scientists need no such artifice.
The hoax:
Sokal (1996).
The Selfish Gene:
Dawkins (1989, 1976). Hegel: In Popper (1994).
Exquisite cadavers:
Nadeau (1970).
The generator:
www.monash.edu.au
.
Language and probability:
There is a very large connection between language and probability; it has been studied by thinkers and scientists via the sister methods of entropy and information theory—one can reduce the dimensionality of a message by eliminating redundancy, for instance; what is left is measured as information content (think of zipping a file) and is linked to the notion of “entropy,” which is the degree of disorder, the unpredictable that is left. Entropy is a very invasive notion as it relates to aesthetics and thermodynamics. See Campbell (1982) for a literary presentation, and Cover and Thomas (1991) for a scientific one, particularly the discussion on the “entropy of English.” For a classic discussion of entropy and art, Arnheim (1971), though the connection between entropy and probability was not yet clear at the time. See Georgescu-Roegen (1971) for a (perhaps) pioneering discussion of entropy in economics.
CHAPTER 5
The firehouse effect and the convergence of opinions:
There are plenty of discussions in the psychology literature of such convergence of opinions, particularly in the area of mate selection or what Keynes calls “the beauty contest,” as people tend to choose what other people choose, causing positive-feedback loops.
An interesting manifestation is the autokinetic effect. When people gaze at a stationary light in a room they see it moving after a while and can estimate the amount of movement, not knowing that it is an optical illusion. When isolated the subjects give wildly varying speeds of movement; when tested in a group they converge to a common speed of movement: See Plotkin (1998). Sornette (2003) gives an interesting account of the feedback loops that result from herding written in light, but with extremely intuitive mathematics.
Biology of imitation:
See Dugatkin (2001).
Evolution and small probabilities:
Evolution is principally a probabilistic concept. Can it be fooled by randomness? Can the least skilled survive? There is a prevalent strain of Darwinism, called naive Darwinism, that believes that any species or member of a species that dominates at any point has been selected by evolution because they have an advantage over others. This results from a common misunderstanding of local and global optima, mixed with an inability to get rid of the belief in the law of small numbers (overinference from small data sets). Just put two people in a random environment, say a gambling casino, for a weekend. One of them will fare better than the other. To a naive observer the one who fares better will have a survival advantage over the other. If he is taller or has some trait that distinguishes him from the other, such trait will be identified by the naive observer as the explanation of the difference in fitness. Some people do it with traders—make them compete in a formal competition. Consider also the naive evolutionary thinking positing the “optimality” of selection—the founder of sociobiology does not agree with such optimality when it comes to rare events: E. O. Wilson (2002) writes: “The human brain evidently evolved to commit itself emotionally only to a small piece of geography, a limited band of kinsmen, and two or three generations into the future. To look neither far ahead nor far afield is elemental in a Darwinian sense.
We are innately inclined to ignore any distant possibility not yet requiring examination. It is, people say, just good common sense.
Why do they think in this shortsighted way? “The reason is simple: It is a hardwired part of our Paleolithic heritage. For hundreds of millennia, those who worked for short-term gain within a small circle of relatives and friends lived longer and left more offspring—even when their collective striving caused their chiefdoms and empires to crumble around them. The long view that might have saved their distant descendants required a vision and extended altruism instinctively difficult to marshal.”
See also Miller (2000): “Evolution has no foresight. It lacks the long-term vision of drug company management. A species can’t raise venture capital to pay its bills while its research team . . . Each species has to stay biologically profitable every generation, or else it goes extinct. Species always have cashflow problems that prohibit speculative investments in their future. More to the point, every gene underlying every potential innovation has to yield higher evolutionary payoffs than competing genes, or it will disappear before the innovation evolves any further. This makes it hard to explain innovations.”
CHAPTER 6
Fooled by negative skewness:
The first hint of an explanation for the popularity of negatively skewed payoffs comes from the early literature on behavior under uncertainty, with the “small number problem.” Tversky and Kahneman (1971) write: “We submit that people view a sample randomly drawn from a population as highly representative, that is, similar to a population in all essential characteristics.” The consequence is the inductive fallacy: overconfidence in the ability to infer general properties from observed facts, “undue confidence in early trends,” the stability of observed patterns and deriving conclusions with more confidence attached to them than can be warranted by the data. Worst, the agent finds causal explanations or perhaps distributional attributes that confirm his undue generalization. It is easy to see that the “small numbers” get exacerbated with skewness since most of the time the observed mean will be different from the true mean and most of the time the observed variance will be lower than the true one. Now consider that it is a fact that in life, unlike a laboratory or a casino, we do not observe the probability distribution from which random variables are drawn: We only see the realizations of these random processes. It would be nice if we could, but it remains that we do not measure probabilities as we would measure the temperature or the height of a person. This means that when we compute probabilities from past data we are making assumptions about the skewness of the generator of the random series—all data is conditional upon a generator. In short, with skewed packages, the camouflage of the properties comes into play
and
we tend to believe what we see. Taleb (2004).
Philosopher sometimes playing scientist:
Nozik (1993).
Hollywood economics:
De Vany (2003).
People are sensitive to sign rather than magnitude:
Hsee and Rottenstreich (2004).
Lucas critique:
Lucas (1978).
CHAPTER 7
Niederhoffer’s book:
Niederhoffer (1997).
Goodman’s riddle of induction:
One can take the issue of induction into a more difficult territory with the following riddle. Say the market went up every day for a month. For many people of inductive taste it could confirm the theory that it is going up every day. But consider: It may confirm the theory that it goes up every day then crashes—what we are witnessing is not an ascending market but one that
ascends then crashes.
When one observes a blue object it is possible to say that one is observing something blue until time
t,
beyond which it is green—that such object is not blue but “grue.” Accordingly, by such logic, the fact that the market went up all this time may confirm that it will crash tomorrow! It confirms that we are observing a rising-crashing market. See Goodman (1954).
Writings by Soros:
Soros (1988).
Hayek:
See Hayek (1945) and the prophetic Hayek (1994), first published in 1945.
Popper’s personality:
Magee (1997), and Hacohen (2001). Also an entertaining account in Edmonds and Eidinow (2001).
CHAPTER 8
The millionaire next door: Stanley (1996).
Equity premium puzzle:
There is an active academic discussion of the “equity premium” puzzle, taking the “premium” here to be the outperformance of stocks in relation to bonds and looking for possible explanations. Very little consideration was given to the possibility that the premium may have been an optical illusion owing to the survivorship bias—or that the process may include the occurrence of black swans. The discussion seems to have calmed a bit after the declines in the equity markets after the events of 2000–2002.
CHAPTER 9
Hot-hand effect:
Gilovich, Vallone and Tversky (1985).
Stock analysts fooled by themselves:
For a comparison between analysts and weather forecasters, see Taszka and Zielonka (2002).
Differences between returns:
See Ambarish and Siegel (1996). The dull presenter was actually comparing “Sharpe ratios,” i.e., returns scaled by their standard deviations (both annualized), named after the financial economist William Sharpe, but the concept has been commonly used in statistics and called “coefficient of variation.” (Sharpe introduced the concept in the context of the normative theory of asset pricing to compute the expected portfolio returns given some risk profile, not as a statistical device.) Not counting the survivorship bias, over a given twelve-month period, assuming (very generously) the Gaussian distribution, the “Sharpe ratio” differences for two uncorrelated managers would exceed 1.8 with close to 50% probability. The speaker was discussing “Sharpe ratio” differences of around .15! Even assuming a five-year observation window, something very rare with hedge fund managers, things do not get much better.
Value of the seat:
Even then, by some attribution bias, traders tend to believe that their income is due to their skills, not the “seat,” or the “franchise” (i.e., the value of the order flow).The seat has a value as the New York Stock Exchange specialist “book” is worth quite large sums: See Hilton (2003). See also Taleb (1997) for a discussion of the time and place advantage.
Data mining:
Sullivan, Timmermann and White (1999).
Dogs not barking:
I thank my correspondent Francesco Corielli from Bocconi for his remark on meta-analysis.
CHAPTER 10
Networks:
Arthur (1994). See Barabasi (2002), Watts (2003).
Nonlinear dynamics:
For an introduction to nonlinear dynamics in finance, see Brock and De Lima (1995), and Brock, Hsieh and LeBaron (1991). See also the recent, and certainly the most complete, Sornette (2003). Sornette goes beyond just characterizing the process as fat-tailed and saying that the probability distribution is different from the one we learned in Finance 101. He studies the transition points: Say a book’s sales become close to a critical point from which they will really take off. Their dynamics, conditional on past growth, become predictable.
The Tipping Point:
Gladwell (2000). In the article that preceded the book (Gladwell,1996) he writes:“The reason this seems surprising is that human beings prefer to think in linear terms . . . . I can remember struggling with these same theoretical questions as a child, when I tried to pour ketchup on my dinner. Like all children encountering this problem for the first time, I assumed that the solution was linear: That steadily increasing hits on the base of the bottle would yield steadily increasing amounts of ketchup out the other end. Not so, my father said, and he recited a ditty that, for me, remains the most concise statement of the fundamental nonlinearity of everyday life: ‘Tomato ketchup in a bottle—None will come and then the lot’ll.’ ”
Pareto:
Before we had a generalized use of the bell curve, we took the ideas of Pareto with his distribution more seriously—its mark is the contribution of large deviations to the overall properties. Later elaborations led to the so-called Pareto-Levy or Levy-Stable distributions with (outside of special cases) some quite vicious properties (no known error rate). The reasons economists never liked to use it is that it does not offer tractable properties—economists like to write papers in which they offer the illusion of solutions, particularly in the form of mathematical answers. A Pareto-Levy distribution does not provide them with such luxury. For economic discussions on the ideas of Pareto, see Zajdenweber (2000), Bouvier (1999). For a presentation of the mathematics of Pareto-Levy distributions, see Voit (2001), and Mandelbrot (1997). There is a recent rediscovery of power law dynamics. Intuitively a power law distribution has the following property: If the power exponent were 2, then there would be 4 times more people with an income higher than $1 million than people with $2 million. The effect is that there is a very small probability of having an event of an extremely large deviation. More generally given a deviation
x,
the incidence of a deviation of a multiple of
x
will be that multiple to a given power exponent. The higher the exponent the lower the probability of a large deviation.
Spitznagel’s remark:
In Gladwell (2002).
Don’t take “correlation” and those who use the word seriously:
The same “A.” of the lighterthrowing variety taught me a bit about the fallacy of the notion of correlation. “You do not seem to be correlated to anything” is the most common blame I’ve received when carrying my strategy of shooting for rare events. The following example might illustrate it. A nonlinear trading instrument, such as a put, will be positively correlated to the underlying security over many sample paths (say the put expires worthless in a bear market as the market did not drop enough), except of course upon becoming in the money and crossing the strike, in which case the correlation reverses with a vengeance. The reader should do himself a favor by not taking the notion of correlation seriously except in very narrow matters where linearity is justified.
CHAPTER 11
Probability “blindness”:
I borrow the expression from Piattelli-Palmarini (1994).
Discussion of “rationality”:
The concept is not so easy to handle. As the concept has been investigated in plenty of fields, it has been developed the most by economists as a normative theory of choice. Why did the economists develop such an interest in it? The basis of economic analysis is a concept of human nature and rationality embodied in the notion of
homo economicus.
The characteristics and behavior of such
homo economicus
are built into the postulates of consumer choice and include nonsatiation (more is
always
preferred to less) and transitivity (global consistency in choice). For instance, Arrow (1987) writes, “It is note-worthy that the everyday usage of the term ‘rationality’ does not correspond to the economist’s definition as transitivity and completeness, that is maximization of something. The common understanding is instead the complete exploitation of information, sound reasoning, and so forth.”
Perhaps the best way to see it for an economist is the maximization leading to a unique solution.
Even then, it is not easy. Who is maximizing what? To begin, there is a conflict between collective and individual rationality (“tragedy of the commons” seen by Keynes in his parable of the stadium where one’s optimal strategy is to stand up, but collectively the optimal strategy is for everyone to remain seated). Another problem is seen in Arrow’s voter’s impossibility theorem. Consider also the following voter problem: People vote but the probability adjusted gains from voting can be less than the effort expended in going to the polling place. See Luce and Raiffa (1957) for a discussion of these paradoxes.
Note that the literature on rational choice under uncertainty is very extensive, cutting across fields, from evolutionary game theory to political science. But as John Harsanyi put it bluntly,
It is normative, and meant to be so.
This is a heroic statement: Saying that economics has abandoned its scientific pretensions and accepted that it does not describe how people
do
act but rather how they
should
act. It means that it has entered the realm of something else: philosophy (though not quite ethics). As such, an individual can accept it fully and should aim to act like the neoclassical man. If he can.
Ultimate/proximate as a solution to some rationality problems:
Evolutionary theorists distinguish between proximate and ultimate cause.
Proximate cause: I eat
because
I am hungry.
Ultimate cause: If I didn’t have an incentive to eat I would have gracefully exited the gene pool.
Now, if one invokes ultimate causes, plenty of behavior deemed locally irrational (like the voter problem above) can be interpreted as rational. It explains altruism: Why would you take a small risk to help a stranger from drowning? Visibly this impetus to help put us where we are today.
See Dawkins (1989, 1976) and Pinker (2002) for additional insights on the difference.
Rationality and scientism:
Under the suggestion of my correspondent Peter McBurney I discovered the novel
We
by Yevgeny Zamyatin, a satire on Leninist Russia written in the 1920s and set in the far distant future, at a time when Taylorist and rationalist ideas had succeeded, apparently, in eliminating all uncertainty and irrationality from life.
Bounded rationality:
Simon (1956), Simon (1957), Simon (1987a), and Simon (1987b).
Birth of the neurobiology of rationality:
Berridge (2003) introduces a neurobiological dimension to rationality using two of Daniel Kahneman’s four utilities (the experienced, remembered, predicted, and decision utilities) and setting irrationality if the decision utility exceeds the predicted one. There is a neural dimension to such irrationality: dopamine activity in the mesolimbic brain.
Compilation of the heuristics and biases papers in four volumes:
Kahneman, Slovic and Tversky (1982), Kahneman and Tversky (2000), Gilovich, Griffin and Kahneman (2002), and Kahneman, Diener and Schwarz (1999).
Two systems of reasoning:
See Sloman (1996), and Sloman (2002). See the summary in Kahneman and Frederick (2002). For the affect heuristic, see Zajonc (1980), and Zajonc (1984).
Evolutionary psychology/sociobiology:
The most readable is Burnham and Phelan (2000). See Kreps and Davies (1993) for the general framework of ecology as optimization. See also Wilson (E. O., 2000), Winston (2002), the cartoons of Evans and Zarate (1999), Pinker (1997), and Burnham (1997).
Modularity:
For the seminal work, see Fodor (1983) in philosophy and cognitive science, Cosmides and Tooby (1992) in evolutionary psychology.
The Wason selection task (written about in nearly every book on evolutionary psychology) is as follows. Consider the following two tests:
Problem 1: Suppose that I have a pack of cards, each of which has a letter written on one side and a number written on the other side. Suppose in addition that I claim that the following rule is true:
If a card has a vowel on one side, then it has an even number on the other side.
Imagine that I now show you four cards from the pack: E 6 K 9. Which card or cards should you turn over in order to decide whether the rule is true or false?
Problem 2: You are a bartender in a town where the legal age for drinking is twenty-one and feel responsible for the violations of the rules. You are confronted with the following situations and would have to ask the patron to show you either his age or what he is drinking. Which of the four patrons would you have to question?
1, drinking beer; 2, over twenty-one; 3, drinking Coke; 4, under 21.
While the two problems are identical (it is clear that you need to check only the first and last of the four cases) the majority of the population gets the first one wrong and the second one right. Evolutionary psychologists believe that the defects in solving the first problem and ease in the second show evidence of a cheater detection module—just consider that we adapted to the enforcement of cooperative tasks and are quick at identifying free riders.
Criteria of modularity:
I borrow from the linguist Elisabeth Bates’ presentation (Bates, 1994) of Fodor’s nine criteria of modularity (ironically Bates is a skeptic on the subject). The information-processing criteria are: encapsulation (we cannot interfere with the functioning of a module), unconsciousness, speed (that’s the point of the module), shallow outputs (we have no idea of the intermediate steps), and obligatory firing (a module generates predetermined outputs for predetermined inputs). The biological criteria that distinguish them from learned habits are: ontogenetic universals (they develop in characteristic sequence), localization (they use dedicated neural systems), and pathological universals (modules have characteristic pathologies across populations). Finally, modularity’s most important property is its domain specificity.
Books on the physical brain:
For the hierarchy reptilian/limbic/neocortical, see causal descriptions in Ratey (2001), Ramachandran and Blakeslee (1998), Carter (1999), Carter (2002), Conlan (1999), Lewis, Amini, and Lannon (2000), and Goleman (1995).
Emotional Brain:
Damasio (1994) and LeDoux (1998). Bechara, Damasio, Damasion, and Tranel (1994) show the degradation of the risk-avoidance behavior of patients with damage in their ventromedial frontal cortex, a part of the brain that links us to our emotions. Emotions seem to play a critical role both ways. For the new field of neuroeconomics, see discussions in Glimcher (2002) and Camerer, Loewenstein and Prelec (2003).
Sensitivity to losses:
Note that losses matter more than gains, but you become rapidly desensitized to them (a loss of $10,000 is better than ten losses of $1,000). Gains matter less than losses, and large gains even less (ten gains of $1,000 are better than one gain of $10,000).
Hedonic treadmill:
My late friend Jimmy Powers used to go out of his way to show me very wealthy investment bankers acting miserably after a bad day. How good is all this wealth for them if they adjust to it to such a point that a single bad day can annihilate the effect of all these past successes? If things do not accumulate well then it follows that humans should follow a different set of strategies. This “resetting”shows the link to prospect theory.
Debate:
Gigerenzer (1996), Kahneman and Tversky (1996), and Stanovich and West (2000). The evolutionary theorists are deemed to hold a Panglossian view: Evolution solves everything. Strangely, the debate is bitter not because of large divergences of opinions but because of small ones.
Simple Heuristics That Make Us Smart
is the title of a compilation of articles by Gigerenzer and his peers (Gigerenzer, 2000). See also Gigerenzer, Czerlinski and Martignon (2002).
Medical example:
Bennett (1998). It is also discussed in Gigerenzer, Czerlinski and Martignon (2002).The heuristics and biases catalogue it as the base rate fallacy. The evolutionary theorists split into domain general (unconditional probability) as opposed to domain specific (conditional).
Behavioral finance:
See Schleifer (2000) and Shefrin (2000) for a review. See also Thaler (1994b) and the original Thaler (1994a).
Domain-specific adaptations:
Our lungs are a domain-specific adaptation meant to extract oxygen from the air and deposit it into our blood; they are not meant to circulate blood. For evolutionary psychologists the same applies to psychological adaptations.
Opaque process:
For psychologists in the heuristics and biases tradition, System 1 is opaque, that is, not self-aware. This resembles the encapsulation and unconsciousness of modules discussed earlier.
Flow:
See Csikszentmihalyi (1993) and Csikszentmihalyi (1998). I am quoting both to be safe but I don’t know if there are differences between the books: The author seems to rewrite the same global idea in different ways.
Underestimation of possible outcomes:
Hilton (2003).
The neurobiology of eye contact:
Ramachandran and Blakeslee (1998) on the visual centers that project to the amygdala: “Scientists recording cell responses in the amygdala found that, in addition to responding to facial expressions and emotions, the cells also respond to the direction of eye gaze. For instance, one cell may fire if another person is looking directly at you, whereas a neighboring cell will fire only if that person’s gaze is averted by a fraction of an inch. Still other cells fire when the gaze is way off to the left or the right. This phenomenon is not surprising given the important role that gaze direction plays in primate social communications—the averted gaze of guilt, shame or embarrassment; the intense, direct gaze of a lover, or the threatening stare of an enemy.”
CHAPTER 12
Pigeons in a box:
Skinner (1948).
Illusion of knowledge:
Barber and Odean (2001) presents a discussion of the literature on the tendency to make a stronger inference than warranted by the data, which they call “Illusion of Knowledge.”
CHAPTER 13
Arabic skeptics:
al-Ghaz
l
(1989).
Rozan’s book:
Rozan (1999).
Mental accounting:
Thaler (1980) and Kahneman, Knetch and Thaler (1991).
Portfolio theory (alas):
Markowitz (1959).
The conventional probability paradigm:
Most of the conventional discussions on probabilistic thought, especially in the philosophical literature, present minor variants of the same paradigm with the succession of the following historical contributions: Chevalier de Méré, Pascal, Cardano, De Moivre, Gauss, Bernouilli, Laplace, Bayes, von Mises, Carnap, Kolmogorov, Borel, De Finetti, Ramsey, etc. However, these concern the problems of
calculus
of probability, perhaps fraught with technical problems, but ones that are hair-splitting and, to be derogatory,
academic.
They are not of much concern in this book—because, inspite of my specialty, they do not seem to provide any remote usefulness for practical matters. For a review of these, I refer the reader to Gillies (2000),Von Plato (1994),Hacking (1990),or the more popular and immensely readable
Against the Gods
(Bernstein, 1996), itself drawing heavily on Florence Nightingale David (David, 1962). I recommend Bernstein’s
Against the Gods
as a readable presentation of the history of probabilistic thought in engineering and the applied hard sciences but completely disagree with its message on the measurability of risks in the social sciences.
I repeat the point: To philosophers operating in probability
per se,
the problem seems one of calculus. In this book the problem of probability is largely a matter of knowledge, not one of computation. I consider these computations a mere footnote to the subject. The real problem is: Where do we get the probability from? How do we change our beliefs? I have been working on the “gambling with the wrong dice” problem: It is far more important to figure out what dice we are using when gambling than to develop sophisticated computations of outcomes and run the risk of having, say, dice with nothing but 6s. In economics, for instance, we have very large models of risk calculations sitting on very rickety assumptions (actually, not rickety but plain wrong). They smoke us with math, but everything else is wrong. Getting the right assumptions may matter more than having a sophisticated model.
An interesting problem is the “value at risk” issue where people imagine that they have a way to understand the risk using “complicated mathematics” and running predictions on rare events—thinking that they were able from past data to observe the probability distributions. The most interesting behavioral aspect is that those who advocate it do not seem to have tested their past predicting record, another Meehl type of problem.
Thinkers and philosophers of probability:
Perhaps the most insightful book ever written on the subject remains the great John Maynard Keynes’
Treatise on Probability
(Keynes, 1989, 1920), which surprisingly has not collected dust—somehow everything we seem to discover appears to have been said in it (though, characteristic of Keynes, in a convoluted way). In the usual supplied lists of thinkers of probability, Shackle, who refined subjective probability, is often undeservedly absent (Shackle, 1973). Most authors also omit the relevant contributions of Isaac Levi on subjective probability and its links to belief (Levi, 1970), which should be required reading in that area (it is impenetrable but is worth the exercise). It is a shame because Isaac Levi is a probability
thinker
(as opposed to probability
calculator
). The epistemologist of probability Henry Kyburg (Kyburg, 1983) is also absent (too difficult to read).
One observation about philosophers as compared to scientists is that they do seem to work in a very heterogeneous and compartmented manner: Probability in philosophy is dealt with in different branches: logic, epistemology, rational choice, philosophy of mathematics, philosophy of science. It is surprising to see Nicholas Rescher delivering an insightful presidential address of the American Philosophical Association on the topic of luck (later published as a book called
Luck,
see Rescher, 1995) without discussing much of the problems in the philosophical and cognitive literature on probability.
Problems with my message:
Note that many readers in the technical professions, say engineering, exhibited some difficulty seeing the connection between probability and belief and the importance of skepticism in risk management.
CHAPTER 14
Stoicism:
Modern discussions in Becker (1998) and Banateanu (2001).
POSTSCRIPT
Uncertainty and pleasure:
See Wilson, et. al. (2005) for the effect of randomness on the prolongation of positive hedonic states.
Looks and success:
See (Shahami, et. al., 1993; Hosoda et. al., 1999). My friend Peter Bevelin wrote to me: “When I’m thinking about misjudgment of personalities I am always reminded of Sherlock Holmes in Arthur Conan Doyle’s
The Sign of Four.
“It is of the first importance not to allow your judgment to be biased by personal qualities. I assure you that the most winning woman I ever knew was hanged for poisoning three little children for their insurance-money, and the most repellent man of my acquaintance is a philanthropist who has spent nearly a quarter of a million upon the London poor.”
Maximizing:
Psychology literature has focused on maximizing in terms of choice, not so much in these terms of actual optimization. I go beyond by looking at the activity of optimization in daily life. For a synthesis and review of the hedonic impact of maximizing and why “less is more,” see Schwartz (2003). See also Schwartz, et. al. (2002). For the causal link between unhappiness and the pursuit of material benefits, see Kasser (2002).
Date of your death:
I owe this last point to Gerd Gigerenzer.
Unpredictable behavior:
See Miller (2000) for the discussion of the point in biology. See also Lucas’s (1978) applications to a random monetary policy that thwarts expectations.


================================================================================
CHAPTER/SECTION 324 (Item 333)
================================================================================

REFERENCES
Albouy, François-Xavier, 2002,
Le temps des catastrophes.
Paris: Descartes & Cie.
al-Ghaz
l
, 1989, “Mikhtarat Min Ahthar Al-Ghazali.” In Saliba, Jamil,
Tarikh Al Falsafa Al Arabiah.
Beirut: Al Sharikah Al Ahlamiah Lilkitab.
Ambarish, R., and L. Siegel, 1996, “Time Is the Essence.”
RISK,
9, 8, 41–42.
Arnheim, Rudolf, 1971,
Entropy and Art: An Essay on Disorder and Order.
Berkeley: University of California Press.
Arrow, Kenneth, 1987, “Economic Theory and the Postulate of Rationality.” In Eatwell, J., Milgate, M., and Newman, P., eds., 1987.
The New Palgrave: A Dictionary of Economics,
vol.2,69–74,London: Macmillan.
Arthur, Brian W., 1994,
Increasing Returns and Path Dependence in the Economy.
Ann Arbor: University of Michigan Press.
Banateanu, Anne, 2002,
La théorie stoïcienne de l’amitié: essai de reconstruction.
Fribourg: Editions Universitaires de Fribourg/Paris: Editions du Cerf.
Barabási, Albert-László, 2002,
Linked: The New Science of Networks.
Boston: Perseus Publishing.
Barber, B. M., and T. Odean, 2001, “The Internet and the Investor.”
Journal of Economic Perspectives,
Winter, Vol. 15, No. 1, 41–54.
Barron, G., and I. Erev, 2003, “Small Feedback-based Decisions and Their Limited Correspondence to Description-based Decisions.”
Journal of Behavioral Decision Making,
16, 215–233.
Bates, Elisabeth, 1994, “Modularity, Domain Specificity, and the Development of Language.” In Gajdusek, D.C., McKhann, G.M., and Bolis, C.L. eds.,
Evolution and Neurology of Language: Discussions in Neuro-science,
10(1–2), 136–149.
Bechara, A., A. R. Damasio, H. Damasio, and S. W. Anderson, 1994, “Insensitivity to Future Consequences Following Damage to Human Prefrontal Cortex.”
Cognition,
50:1–3, 7–15.
Becker, Lawrence C., 1998,
A New Stoicism.
Princeton, N.J.: Princeton University Press.
Bennett, Deborah J., 1998,
Randomness.
Cambridge, Mass.: Harvard University Press.
Bernstein, Peter L., 1996,
Against the Gods: The Remarkable Story of Risk.
New York: Wiley.
Berridge, Kent C., 2003, “Irrational Pursuits: Hyper-incentives from a Visceral Brain.” In Brocas and Carillo.
Bouvier, Alban, ed., 1999,
Pareto aujourd’hui.
Paris: Presses Universitaires de France.
Brent, Joseph, 1993,
Charles Sanders Peirce: A Life.
Bloomington: Indiana University Press.
Brocas, I., and J. Carillo, eds., 2003,
The Psychology of Economic Decisions: Vol. 1: Rationality and Well-being.
Oxford: Oxford University Press.
Brock, W. A., and P.J.F. De Lima, 1995, “Nonlinear Time Series, Complexity Theory, and Finance.” University of Wisconsin, Madison—Working Papers 9523.
Brock, W. A., D. A. Hsieh, and B. LeBaron, 1991,
Nonlinear Dynamics, Chaos, and Instability: Statistical Theory and Economic Evidence,
Cambridge, Mass.: MIT Press.
Brockman, John, 1995,
The Third Culture: Beyond the Scientific Revolution.
New York: Simon & Schuster.
Buchanan, Mark, 2002,
Ubiquity: Why Catastrophes Happen.
New York: Three Rivers Press.
Buehler, R., D. Griffin, and M. Ross, 2002, “Inside the Planning Fallacy: The Causes and Consequences of Optimistic Time Predictions.” In Gilovich, Griffin and Kahneman.
Burnham, Terence C., 1997,
Essays on Genetic Evolution and Economics.
New York:
Dissertation.com.
Burnham, Terence C., 2003, “Caveman Economics.” Harvard Business School.
Burnham, T., and J. Phelan, 2000,
Mean Genes.
Boston: Perseus Publishing.
Camerer, C., G. Loewenstein, and D. Prelec, 2003, “Neuroeconomics: How Neuroscience Can Inform Economics. Caltech Working Paper.
Campbell, Jeremy, 1982,
Grammatical Man: Information, Entropy, Language and Life.
New York: Simon & Schuster.
Carter, Rita, 1999,
Mapping the Mind.
Berkeley: University of California Press.
Carter, Rita, 2002,
Exploring Consciousness.
Berkeley: University of California Press.
Chancellor, Edward, 1999,
Devil Take the Hindmost: A History of Financial Speculation.
New York: Farrar, Straus & Giroux.
Conlan, Roberta, ed., 1999,
States of Mind: New Discoveries About How Our Brains Make Us Who We Are.
New York: Wiley.
Cootner, Paul H., 1964,
The Random Character of Stock Market Prices.
Cambridge, Mass.: The MIT Press.
Cosmides, L., and J. Tooby, 1992, “Cognitive Adaptations for Social Exchange.” In Barkow et al., eds.,
The Adapted Mind.
Oxford: Oxford University Press.
Cover, T. M., and J. A. Thomas, 1991,
Elements of Information Theory.
New York: Wiley.
Csikszentmihalyi, Mihaly, 1993,
Flow: The Psychology of Optimal Experience.
New York: Perennial Press.
Csikszentmihalyi, Mihaly, 1998,
Finding Flow: The Psychology of Engagement with Everyday Life.
New York: Basic Books.
Damasio, Antonio, 1994,
Descartes’ Error: Emotion, Reason, and the Human Brain.
New York: Avon Books.
Damasio, Antonio, 2000,
The Feeling of What Happens: Body and Emotion in the Making of Consciousness.
New York: Harvest Books.
Damasio, Antonio, 2003,
Looking for Spinoza: Joy, Sorrow and the Feeling Brain.
New York: Harcourt.
David, Florence Nightingale, 1962,
Games, Gods, and Gambling: A History of Probability and Statistical Ideas.
Oxford: Oxford University Press.
Dawes, R. M., D. Faust, and P. E. Meehl, 1989, “Clinical Versus Actuarial Judgment.
Science,
243, 1668–1674.
Dawkins, Richard, 1989 (1976),
The Selfish Gene.
2nd ed., Oxford: Oxford University Press.
De Vany, Arthur, 2003,
Hollywood Economics: Chaos in the Movie Industry.
London: Routledge.
Debreu, Gerard, 1959,
Theorie de la valeur,
Dunod, tr.
Theory of Value.
New York: Wiley.
Dennett, Daniel C., 1995,
Darwin’s Dangerous Idea: Evolution and the Meanings of Life.
New York: Simon & Schuster.
Deutsch, David, 1997,
The Fabric of Reality.
New York: Penguin.
DeWitt, B. S., and N. Graham, eds., 1973,
The Many-Worlds Interpretation of Quantum Mechanics.
Princeton, N.J.: Princeton University Press.
Dugatkin, Lee Alan, 2001,
The Imitation Factor: Evolution Beyond the Gene.
New York: Simon & Schuster.
Easterly, William,2001,
The Elusive Quest for Growth: Economists’ Adventures and Misadventures in the Tropics.
Cambridge, Mass.: The MIT Press.
Edmonds, D., and J. Eidinow, 2001,
Wittgenstein’s Poker: The Story of a Ten-Minute Argument Between Two Great Philosophers.
New York: Ecco.
Einstein, A., 1956 (1926),
Investigations on the Theory of the Brownian Movement.
New York: Dover.
Ekman, Paul, 1992,
Telling Lies: Clues to Deceit in the Marketplace, Politics and Marriage.
New York: W. W. Norton.
Elster, Jon, 1998,
Alchemies of the Mind: Rationality and the Emotions.
Cambridge, Eng.: Cambridge University Press.
Evans, Dylan, 2002,
Emotions: The Science of Sentiment.
Oxford: Oxford University Press.
Evans, D., and O. Zarate, 1999,
Introducing Evolutionary Psychology.
London: Totem Books.
Eysenck, M. W., and M. T. Keane, 2000,
Cognitive Psychology,
4th ed.
Finucane, M. L., A. Alhakami, P. Slovic, and S. M. Johnson, 2000, “The Affect Heuristic in Judgments of Risks and Benefits.”
Journal of Behavioral Decision Making,
13, 1–17.
Fischhoff, Baruch, 1982, “For Those Condemned to Study the Past: Heuristics and Biases in Hindsight.” In Kahneman, Slovic and Tversky.
Fodor, Jerry A., 1983,
The Modularity of Mind: An Essay on Faculty Psychology.
Cambridge, Mass.: The MIT Press.
Frank, Robert H., 1985,
Choosing the Right Pond: Human Behavior and the Quest for Status.
Oxford: Oxford University Press.
Frank, Robert H., 1999,
Luxury Fever: Why Money Fails to Satisfy in an Era of Excess.
Princeton, N.J.: Princeton University Press.
Frank, R. H., and P. J. Cook, 1995,
The WinnerTake-All Society: Why the Few at the Top Get So Much More Than the Rest of Us.
New York: Free Press.
Frederick, S., and G. Loewenstein, 1999, “Hedonic Adaptation,” in Kahneman, Diener and Schwartz.
Freedman, D. A., and P. B. Stark, 2003, “What Is the Chance of an Earthquake?” Department of Statistics, University of California, Berkeley, CA 94720-3860. Technical Report 611. September 2001; revised January 2003.
Fukuyama, Francis,1992,
The End of History and the Last Man.
New York: Free Press.
Galbraith, John Kenneth, 1997,
The Great Crash 1929.
New York: Mariner Books.
Gehring, W. J., and A. R. Willoughby, 2002, “The Medial Frontal Cortex and the Rapid Processing of Monetary Gains and Losses.”
Science,
295, March.
Georgescu-Roegen, Nicholas, 1971,
The Entropy Law and the Economic Process.
Cambridge, Mass.: Harvard University Press.
Gigerenzer, Gerd, 1989,
The Empire of Chance: How Probability Changed Science and Everyday Life.
Cambridge, Eng.: Cambridge University Press.
Gigerenzer, Gerd, 1996, “On Narrow Norms and Vague Heuristics: A Reply to Kahneman and Tversky.
Psychological Review,
103,592–596.
Gigerenzer, Gerd, 2003,
Calculated Risks: How to Know When Numbers Deceive You.
New York: Simon & Schuster.
Gigerenzer G., P. M. Todd, and ABC Research Group, 2000,
Simple Heuristics That Make Us Smart.
Oxford: Oxford University Press.
Gigerenzer, G., J. Czerlinski, and L. Martignon, 2002, “How Good Are Fast and Frugal Heuristics?” In Gilovich, Griffin, and Kahneman.
Gilbert, D., E. Pinel, T. D. Wilson, S. Blumberg, and T. Weatley, 2002, “Durability Bias in Affective Forecasting.” In Gilovich, Griffin, and Kahneman.
Gillies, Donald, 2000,
Philosophical Theories of Probability.
London: Routledge.
Gilovich, T., R. P. Vallone, and A. Tversky, 1985, “The Hot Hand in Basketball: On the Misperception of Random Sequences.”
Cognitive Psychology,
17, 295–314.
Gilovich, T., D. Griffin, and D. Kahneman, eds., 2002,
Heuristics and Biases: The Psychology of Intuitive Judgment.
Cambridge, Eng.: Cambridge University Press.
Gladwell, Malcolm, 1996, “The Tipping Point: Why Is the City Suddenly So Much Safer—Could It Be That Crime Really Is an Epidemic?”
The New Yorker,
June 3.
Gladwell, Malcolm, 2000,
The Tipping Point: How Little Things Can Make a Big Difference.
New York: Little, Brown.
———, 2002, “Blowing Up: How Nassim Taleb Turned the Inevitability of Disaster into an Investment Strategy.”
The New Yorker,
April 22 and 29.
Glimcher, Paul, 2002,
Decisions, Uncertainty, and the Brain: The Science of Neuroeconomics.
Cambridge, Mass.: The MIT Press.
Goleman, Daniel, 1995,
Emotional Intelligence: Why It Could Matter More Than IQ.
New York: Bantam Books.
Goleman, Daniel, 2003,
Destructive Emotions, How Can We Overcome Them?: A Scientific Dialogue with the Dalai Lama.
New York: Bantam.
Goodman, Nelson, 1954,
Facts, Fiction and Forecast.
Cambridge, Mass.: Harvard University Press.
Hacking, Ian, 1990,
The Taming of Chance.
Cambridge, Eng.: Cambridge University Press.
Hacohen, Malachi Haim, 2001,
Karl Popper, The Formative Years, 1902–1945: Politics and Philosophy in Interwar Vienna.
Cambridge, Eng.: Cambridge University Press.
Hayek, F. A., 1945, “The Use of Knowledge in Society.”
American Economic Review,
35(4), 519–530.
Hayek, F. A., 1994,
The Road to Serfdom.
Chicago: University of Chicago Press.
Hilton, Denis, 2003, “Psychology and the Financial Markets: Applications to Understanding and Remedying Irrational Decision-making.” In Brocas and Carillo.
Hirshleifer, J., and J. G. Riley, 1992,
The Analytics of Uncertainty and Information.
Cambridge, Eng.: Cambridge University Press.
Horrobin, David, 2002,
Madness of Adam and Eve: How Schizophrenia Shaped Humanity.
New York: Transworld Publishers Limited.
Hosoda, M., G. Coats, E. F. Stone-Romero, and C. A. Backus, 1999, “Who Will Fare Better in Employment-Related Decisions? A Meta-Analytic Review of Physical Attractiveness Research in Work Settings.” Paper presented at the meeting of the Society of Industrial Organizational Psychology, Atlanta, Georgia.
Hsee, C. K., and Y. R. Rottenstreich, 2004, “Music, Pandas and Muggers: On the Affective Psychology of Value.” Forthcoming,
Journal of Experimental Psychology.
Hsieh, David A., 1991, “Chaos and Nonlinear Dynamics: Application to Financial Markets.”
The Journal of Finance,
46(5), 1839–1877.
Huang, C. F., and R. H. Litzenberger, 1988,
Foundations for Financial Economics.
New York/Amsterdam/London: North-Holland.
Hume, David, 1999 (1748),
An Enquiry Concerning Human Understanding.
Oxford: Oxford University Press.
Ingersoll, Jonathan E., Jr., 1987,
The Theory of Financial Decision Making.
Lanham, Md.: Rowman & Littlefield Publishing.
Jaynes, E. T., 2003,
Probability Theory: The Logic of Science.
Cambridge, Eng.: Cambridge University Press.
Kahneman, D., 2003, “Why People Take Risks.” In
Gestire la vulnerabilità e l’incertezza: un incontro internazionale fra studiosi e capi di impresa.
Rome: Italian Institute of Risk Studies.
———, E. Diener, and N. Schwarz, eds., 1999,
Well-being: The Foundations of Hedonic Psychology.
New York: Russell Sage Foundation.
———, and S. Frederick, 2002, “Representativeness Revisited: Attribute Substitution in Intuitive Judgment.” In Gilovich, Griffin, and Kahneman.
———, J. L. Knetsch, and R. H. Thaler, 1986, “Rational Choice and the Framing of Decisions.”
Journal of Business,
Vol. 59 (4), 251–278.
———, J. L. Knetsch, and R. H. Thaler, 1991, “Anomalies: The Endowment Effect, Loss Aversion, and Status Quo Bias.” In Kahneman and Tversky (2000).
———, and D. Lovallo, 1993, “Timid Choices and Bold Forecasts: A Cognitive Perspective on Risk-taking.
Management Science,
39, 17–31.
———, P. Slovic, and A. Tversky, eds., 1982,
Judgment Under Uncertainty: Heuristics and Biases.
Cambridge, Eng.: Cambridge University Press.
———, and A. Tversky, 1972, “Subjective Probability: A Judgment of Representativeness.”
Cognitive Psychology,
3, 430–454.
———, and A. Tversky, 1973, “On the Psychology of Prediction.”
Psychological Review,
80: 237–251.
———, and A. Tversky, 1979, “Prospect Theory: An Analysis of Decision Under Risk.”
Econometrica,
47, 263–291.
———,and A. Tversky,1982,“On the Study of Statistical Intuitions.”
Cognition,
11, 123–141.
———, and A. Tversky, 1996, “On the Reality of Cognitive Illusions.”
Psychological Review,
103, 582–591.
———, and A. Tversky, eds., 2000,
Choices, Values, and Frames.
Cambridge, Eng.: Cambridge University Press.
Kasser, Tim, 2002,
The High Price of Materialism.
Cambridge, Mass.: The MIT Press.
Keynes, John Maynard, 1937, “The General Theory.” In
Quarterly Journal of Economics,
Vol. LI, 209–233.
———, 1989 (1920),
Treatise on Probability.
London: Macmillan.
Kindleberger, Charles P., 2001,
Manias, Panics, and Crashes.
New York: Wiley.
Knight, Frank, 1921 (1965),
Risk, Uncertainty and Profit.
New York: Harper and Row.
Kreps, David M., 1988,
Notes on the Theory of Choice.
Boulder, Colo.: Westview Press.
Kreps, J., and N. B. Davies, 1993,
An Introduction to Behavioral Ecology,
3rd ed. Oxford: Blackwell Scientific Publications.
Kripke, Saul A., 1980,
Naming and Necessity.
Cambridge, Mass.: Harvard University Press.
Kurz, Mordecai, 1997, “Endogenous Uncertainty: A Unified View of Market Volatility,” Working Paper. Stanford, Calif.: Stanford University Press.
Kyburg, Henry E., Jr., 1983,
Epistemology and Inference.
Minneapolis: University of Minnesota Press.
LeDoux, Joseph, 1998,
The Emotional Brain: The Mysterious Underpinnings of Emotional Life.
New York: Simon & Schuster.
LeDoux, Joseph, 2002,
Synaptic Self: How Our Brains Become Who We Are.
New York: Viking.
Levi, Isaac, 1970,
Gambling with Truth.
Boston, Mass.: The MIT Press.
Lewis, T., F. Amini, and R. Lannon, 2000,
A General Theory of Love.
New York: Vintage Books.
Lichtenstein, S., B. Fischhoff, and L. Phillips, 1977, “Calibration of Probabilities: The State of the Art.” In Kahneman, Slovic, and Tversky (1982).
Loewenstein, G. F., E. U. Weber, C. K. Hsee, and E. S. Welch, 2001, “Risk As Feelings.”
Psychological Bulletin,
127, 267–286.
Lowenstein, Roger, 2000,
When Genius Failed: The Rise and Fall of Long-Term Capital Management.
New York: Random House.
Lucas, Robert E., 1978, “Asset Prices in an Exchange Economy.”
Econometrica,
46, 1429–1445.
Luce, R. D., and H. Raiffa, 1957,
Games and Decisions: Introduction and Critical Survey.
New York: Dover.
Machina, M. J., and M. Rothschild, 1987, “Risk.” In Eatwell, J., Milgate, M., and Newman P., eds., 1987,
The New Palgrave: A Dictionary of Economics.
London: Macmillan.
MacKay, Charles, 2002,
Extraordinary Popular Delusions and the Madness of Crowds.
New York: Metro Books.
Magee, Bryan, 1997,
Confessions of a Philosopher.
London: Weidenfeld & Nicholson.
Mandelbrot, Benoit B., 1997,
Fractals and Scaling in Finance.
New York: Springder-Verlag.
Markowitz, Harry, 1959,
Portfolio Selection: Efficient Diversification of Investments,
2nd ed. New York: Wiley.
Meehl, Paul E., 1954,
Clinical Versus Statistical Predictions: A Theoretical Analysis and Revision of the Literature.
Minneapolis: University of Minnesota Press.
Menand, Louis, 2001,
The Metaphysical Club: A Story of Ideas in America.
New York: Farrar, Straus & Giroux.
Merton, Robert C., 1992,
Continuous-Time Finance,
2nd ed. Cambridge, Eng.: Blackwell.
Miller, Geoffrey F., 2000,
The Mating Mind: How Sexual Choice Shaped the Evolution of Human Nature.
New York: Doubleday.
Mumford, David, 1999, “The Dawning of the Age of Stochasticity.”
www.dam.brown.edu/people/mumford/Papers/Dawning.ps.
Myers, David G., 2002,
Intuition: Its Powers and Perils.
New Haven, Conn.: Yale University Press.
Nadeau, Maurice, 1970,
Histoire du surréalisme.
Paris: Seuil.
Niederhoffer, Victor, 1997,
The Education of a Speculator.
New York: Wiley.
Nozick, Robert,1993,
The Nature of Rationality.
Princeton, N.J.: Princeton University Press.
Paulos, John Allen,1988,
Innumeracy.
New York: Hill and Wang, a division of Farrar, Straus, and Giroux.
———,2003,
A Mathematician Plays the Stock Market.
Boston: Basic Books.
Peirce, Charles S., 1998 (1923),
Chance, Love and Logic: Philosophical Essays.
Lincoln: University of Nebraska Press.
Peterson, Ivars, 1998,
The Jungles of Randomness: A Mathematical Safari.
New York: Wiley.
Piattelli-Palmarini, Massimo, 1994,
Inevitable Illusions: How Mistakes of Reason Rule Our Minds.
New York: Wiley.
Pinker, Steven, 1997,
How the Mind Works.
New York: W. W. Norton.
Pinker, Steven, 2002,
The Blank Slate: The Modern Denial of Human Nature.
New York: Viking.
Plotkin, Henry, 1998,
Evolution in Mind: An Introduction to Evolutionary Psychology.
Cambridge, Mass.: Harvard University Press.
Popper, Karl R., 1971,
The Open Society and Its Enemies,
5th ed. Princeton, N.J.: Princeton University Press.
———, 1992,
Conjectures and Refutations: The Growth of Scientific Knowledge,
5th ed. London: Routledge.
———, 1994,
The Myth of the Framework.
London: Routledge.
———, 2002,
The Logic of Scientific Discovery,
15th ed. London: Routledge.
———, 2002,
The Poverty of Historicism.
London: Routledge.
Posner, Richard A., 2002,
Public Intellectuals: A Study in Decline.
Cambridge, Mass.: Harvard University Press.
Rabin, Mathew, 2000, “Inference by Believers in the Law of Small Numbers.” Economics Department, University of California, Berkeley, Working Paper E00-282,
http://repositories.cdlib.org/iber/econ/E00-282
.
Rabin, M., and R. H. Thaler, 2001, “Anomalies: Risk Aversion.”
Journal of Economic Perspectives,
15(1), Winter, 219–232.
Ramachandran, V. S., and S. Blakeslee, 1998,
Phantoms in the Brain.
New York: Morrow.
Ratey, John J., 2001,
A User’s Guide to the Brain: Perception, Attention and the Four Theaters of the Brain.
New York: Pantheon.
Rescher, Nicholas, 1995,
Luck: The Brilliant Randomness of Everyday Life.
New York: Farrar, Straus & Giroux.
Robbe-Grillet, Alain, 1985,
Les gommes.
Paris: Editions de Minuit.
Rozan, Jean-Manuel, 1999,
Le fric.
Paris: Michel Lafon.
Sapolsky, Robert M., 1998,
Why Zebras Don’t Get Ulcers: An Updated Guide to Stress, Stress-Related Diseases, and Coping.
New York: W. H. Freeman & Co.
Sapolsky, Robert M. (and Department of Neurology and Neurological Sciences, Stanford University School of Medicine), 2003, “Glucocorticoids and Hippocampal Atrophy in Neuropsychiatric Disorders.” Stanford University.
Savage, Leonard J., 1972,
The Foundations of Statistics.
New York: Dover.
Schleifer, Andrei, 2000,
Inefficient Markets: An Introduction to Behavioral Finance.
Oxford: Oxford University Press.
Schwartz, Barry, 2003,
The Paradox Of Choice.
New York: Ecco.
Schwartz, B., A. Ward, J. Monterosso, S. Lyubomirsky, K. White, and D. R. Lehman, 2002, “Maximizing Versus Satisficing: Happiness Is a Matter of Choice,”
J Pers Soc Psychol.
Nov., 83 (5):1178–1197.
Searle, John, J., 2001,
Rationality in Action.
Cambridge, Mass.: The MIT Press.
Sen, Amartya, K., 1977, “Rational: A Critique of the Behavioral Foundations of Economic Theory.
Philosophy and Public Affairs,
6, 317–344.
———, 2003,
Rationality and Freedom.
Cambridge, Mass.: The Belknap Press of Harvard University.
Shackle, George L. S., 1973,
Epistemics and Economics: A Critique of Economic Doctrines.
Cambridge, Eng.: Cambridge University Press.
Shahani, C., R. L. Dipboye, and T. M. Gehrlein, 1993, “Attractiveness Bias in the Interview: Exploring the Boundaries of an Effect.”
Basic and Applied Social Psychology,
14 (3), 317–328.
Shefrin, Hersh, 2000,
Beyond Fear and Greed: Understanding Behavioral Finance and the Psychology of Investing.
New York: Oxford University Press.
Shiller, Robert J., 1981, “Do Stock Prices Move Too Much to Be Justified by Subsequent Changes in Dividends?”
American Economic Review,
Vol. 71, 3, 421–436.
———, 1989,
Market Volatility.
Cambridge, Mass.: The MIT Press.
———, 1990. “Market Volatility and Investor Behavior.”
American Economic Review,
Vol. 80, 2, 58–62.
———, 2000,
Irrational Exuberance.
Princeton, N.J.: Princeton University Press.
Shizgal, Peter, 1999, “On the Neural Computation of Utility: Implications from Studies of Brain Simulation Rewards.” In Kahneman, Diener and Schwarz.
Sigelman, C. K., D. B. Thomas, L. Sigelman, and F. D. Ribich, 1986, “Gender, Physical Attractiveness, and Electability: An Experimental Investigation of Voter Biases.”
Journal of Applied Social Psychology,
16 (3), 229–248.
Simon, Herbert A., 1955, “A Behavioral Model of Rational Choice.”
Quarterly Journal of Economics,
69, 99–118.
———, 1956, “Rational Choice and the Structure of the Environment.”
Psychological Review,
63, 129–138.
———, 1957,
Models of Man.
New York: Wiley.
———, 1983,
Reason in Human Affairs.
Stanford, Calif.: Stanford University Press.
———, 1987, “Behavioral Economics.” In Eatwell, J., Milgate, M., and Newman, P.,eds.,1987,
The New Palgrave: A Dictionary of Economics.
London: Macmillan.
———,1987, “Bounded Rationality.”In Eatwell, J., Milgate, M., and Newman, P., eds., 1987,
The New Palgrave: A Dictionary of Economics.
London: Macmillan.
Skinner, B. F., 1948, “Superstition in the Pigeon.”
Journal of Experimental Psychology,
38, 168–172.
Sloman, Steven A., 1996, “The Empirical Case for Two Systems of Reasoning.”
Psychological Bulletin,
119, 3–22.
Sloman, Steven A., 2002, “Two Systems of Reasoning.” In Gilovich, Griffin, and Kahneman.
Slovic, Paul, 1987, “Perception of Risk.”
Science,
236, 280–285.
———, 2000,
The Perception of Risk.
London: Earthscan Publications.
———, M. Finucane, E. Peters, and D. G. MacGregor, 2002, “The Affect Heuristic.” In Gilovich, Griffin and Kahneman.
———, M. Finucane, E. Peters, and D. G. MacGregor, 2003, “Rational Actors or Rational Fools? Implications of the Affect Heuristic for Behavioral Economics.” Working Paper.
www.decisionresearch.com.
———, M. Finucane, E. Peters, and D. G. MacGregor, 2003, “Risk As Analysis, Risk As Feelings: Some Thoughts About Affect, Reason, Risk, and Rationality.” Paper presented at the Annual Meeting of the Society for Risk Analysis, New Orleans, La., December 10, 2002.
Sokal, Alan D., 1996, “Transgressing the Boundaries: Toward a Transformative Hermeneutics of Quantum Gravity.”
Social Text,
46/47, 217–252.
Sornette, Didier, 2003,
Why Stock Markets Crash: Critical Events in Complex Financial Systems.
Princeton, N.J.: Princeton University Press.
Soros, George,1988,
The Alchemy of Finance: Reading the Mind of the Market.
New York: Simon & Schuster.
Sowell, Thomas, 1987,
A Conflict of Visions: Ideological Origins of Political Struggles.
New York: Morrow.
Spencer, B. A., and G. S. Taylor, 1988, “Effects of Facial Attractiveness and Gender on Causal Attributions of Managerial Performance.”
Sex Roles,
19 (5/6), 273–285.
Stanley, T. J., 2000,
The Millionaire Mind.
Kansas City: Andrews McMeel Publishing.
———, and W. D. Danko, 1996,
The Millionaire Next Door: The Surprising Secrets of America’s Wealthy.
Atlanta: Longstreet Press.
Stanovich, K., and R. West, 2000, “Individual Differences in Reasoning: Implications for the Rationality Debate.”
Behavioral and Brain Sciences,
23, 645–665.
Sterelny, Kim,2001,
Dawkins vs Gould: Survival of the Fittest.
Cambridge, Eng.: Totem Books.
Stigler, Stephen M., 1986,
The History of Statistics: The Measurement of Uncertainty Before 1900.
Cambridge, Mass.: The Belknap Press of Harvard University.
———, 2002,
Statistics on the Table: The History of Statistical Concepts and Methods.
Cambridge, Mass.: Harvard University Press.
Sullivan, R., A. Timmermann, and H. White, 1999, “Data-snooping, Technical Trading Rule Performance and the Bootstrap.”
Journal of Finance,
October, 54, 1647–1692.
Taleb, Nassim Nicholas, 1997,
Dynamic Hedging: Managing Vanilla and Exotic Options.
New York: Wiley.
———, 2004, “Bleed or Blowup? Why Do We Prefer Asymmetric Payoffs?”
Journal of Behavioral Finance,
5.
Taszka, T., and P. Zielonka, 2002, “Expert Judgments: Financial Analysts Versus Weather Forecasters.”
The Journal of Psychology and Financial Markets,
Vol 3(3), 152–160.
Thaler, Richard H.,1980,“Towards a Positive Theory of Consumer Choice,”
Journal of Economic Behavior and Organization,
1, 39–60.
———, 1994,
Quasi Rational Economics.
New York: Russell Sage Foundation.
———, 1994,
The Winner’s Curse: Paradoxes and Anomalies of Economic Life.
Princeton, N.J.: Princeton University Press.
Toulmin, Stephen, 1990,
Cosmopolis: The Hidden Agenda of Modernity.
New York: Free Press.
Tversky, A., and D. Kahneman, 1971, “Belief in the Law of Small Numbers.”
Psychology Bulletin,
Aug. 76(2), 105–110.
———, and D. Kahneman, 1973, “Availability: A Heuristic for Judging Frequency and Probability.”
Cognitive Psychology,
5, 207–232.
———, and D. Kahneman, 1982, “Evidential Impact of Base-Rates.” In Kahneman, Slovic, and Tversky, 153–160.
———, and D. Kahneman, 1992, “Advances in Prospect Theory: Cumulative Representation of Uncertainty.
Journal of Risk and Uncertainty,
5, 297–323.
Voit, Johannes, 2001,
The Statistical Mechanics of Financial Markets.
Heidelberg: Springer.
Von Mises, Richard, 1957 (1928),
Probability, Statistics, and Truth.
New York: Dover.
Von Plato, Jan, 1994,
Creating Modern Probability.
Cambridge, Eng.: Cambridge University Press.
Watts, Duncan, 2003,
Six Degrees: The Science of a Connected Age.
New York: W. W. Norton.
Wegner, Daniel M., 2002,
The Illusion of Conscious Will.
Cambridge, Mass.: The MIT Press.
Weinberg, Steven, 2001,
Facing Up: Science and Its Cultural Adversaries.
Working Paper. Harvard University.
Wilson, Timothy D., 2002,
Strangers to Ourselves: Discovering the Adaptive Unconscious.
Cambridge, Mass.: The Belknap Press of Harvard University.
Wilson, Edward O., 2000,
Sociobiology: The New Synthesis.
Cambridge, Mass.: Harvard University Press.
———, 2002,
The Future of Life.
New York: Knopf.
Wilson, T. D., D. B. Centerbar, D. A. Kermer, and D. T. Gilbert, 2005, “The Pleasures of Uncertainty: Prolonging Positive Moods in Ways People Do Not Anticipate,”
J Pers Soc Psychol.
2005 Jan.; 88 (1): 5–21.
———,D. Gilbert, and D.B. Centerbar, 2003,“Making Sense: The Causes of Emotional Evanescence.” In Brocas and Carillo.
———, J. Meyers, and D. Gilbert, 2001, “Lessons from the Past: Do People Learn from Experience That Emotional Reactions Are Short Lived?”
Personality and Social Psychology Bulletin.
Winston, Robert, 2002,
Human Instinct: How Our Primeval Impulses Shape Our Lives.
London: Bantam Press.
Zajdenweber, Daniel, 2000,
L’économie des extrèmes.
Paris: Flammarion.
Zajonc, R.B., 1980, “Feeling and Thinking: Preferences Need No Infderences.”
American Psychologist,
35, 151–175.
———, 1984, “On the Primacy of Affect.”
American Psychologist,
39, 117–123, 114.
Zizzo, D. J., and A. J. Oswald, 2001, “Are People Willing to Pay to Reduce Others’ Incomes?”
Annales d’Economie et de Statistique,
July/December 63/64, 39–62.


================================================================================
CHAPTER/SECTION 325 (Item 334)
================================================================================

Footnotes
To return to the corresponding text, click on the reference number or "Return to text."
Chapter 7
*
What I call empiricism does not simply mean “just look at reality”: it implies the rigorous avoidance of hasty generalizations outside what you saw, your “empiri-cism.” This covers the relation between the past and the future (the past might not be a representative sample of the future, but it also concerns other generalizations we take for granted, in medicine, politics, and science).
Return to text.
*
Popper was not the originator of these ideas on asymmetry: a class of skeptical thinkers such as Sextus Empiricus, Aenesidemus, or al-Ghazälï came up with the ideas before him, as well as Mill and Hume. But Popper rephrased the problem in-dependently and put it in modern terms.
Return to text.


================================================================================
CHAPTER/SECTION 326 (Item 337)
================================================================================

Copyright © 2010, 2015 by Nassim Nicholas Taleb
All rights reserved.
Published in the United States by Random House, an imprint and division of Penguin Random House LLC, New York.
R
ANDOM
H
OUSE
and the H
OUSE
colophon are registered trademarks of Penguin Random House LLC.
Library of Congress Cataloging-in-Publication Data
Taleb, Nassim.
The bed of Procrustes: philosophical and practical aphorisms / by Nassim Nicholas Taleb.
p. cm.
ISBN 978-1-4000-6997-2
eBook ISBN 978-0-679-64368-5
1. Aphorisms and apothegms. 2. Human behavior—Quotations, maxims, etc. I. Title.
PN6271.T35 2011
818’.602—dc22
2010036866
eBook ISBN 9780679643685
randomhousebooks.com
eBook design adapted from printed book design by Simon M. Sullivan
v4.1_r1
a


================================================================================
CHAPTER/SECTION 327 (Item 338)
================================================================================

CONTENTS
Master - Table of Contents
The Bed of Procrustes
Title Page
Copyright
Procrustes
Notice
P
RELUDES
C
OUNTER
N
ARRATIVES
M
ATTERS
O
NTOLOGICAL
T
HE
S
ACRED AND THE
P
ROFANE
C
HANCE
, S
UCCESS
, H
APPINESS, AND
S
TOICISM
C
HARMING AND
L
ESS
C
HARMING
S
UCKER
P
ROBLEMS
T
HESEUS, OR
L
IVING THE
P
ALEO
L
IFE
T
HE
R
EPUBLIC OF
L
ETTERS
T
HE
U
NIVERSAL AND THE
P
ARTICULAR
F
OOLED BY
R
ANDOMNESS
A
ESTHETICS
E
THICS
R
OBUSTNESS AND
A
NTIFRAGILITY
T
HE
L
UDIC
F
ALLACY AND
D
OMAIN
D
EPENDENCE
E
PISTEMOLOGY AND
S
UBTRACTIVE
K
NOWLEDGE
T
HE
S
CANDAL OF
P
REDICTION
B
EING A
P
HILOSOPHER AND
M
ANAGING TO
R
EMAIN
O
NE
E
CONOMIC
L
IFE AND
O
THER
V
ERY
V
ULGAR
S
UBJECTS
T
HE
S
AGE, THE
W
EAK, AND THE
M
AGNIFICENT
T
HE
I
MPLICIT AND THE
E
XPLICIT
O
N THE
V
ARIETIES OF
L
OVE AND
N
ONLOVE
T
HE
E
ND
Postface
Dedication
Acknowledgments


================================================================================
CHAPTER/SECTION 328 (Item 339)
================================================================================

PROCRUSTES
Procrustes, in Greek mythology, was the cruel owner of a small estate in Corydalus in Attica, on the way between Athens and Eleusis, where the mystery rites were performed. Procrustes had a peculiar sense of hospitality: he abducted travelers, provided them with a generous dinner, then invited them to spend the night in a rather special bed. He wanted the bed to fit the traveler to perfection. Those who were too tall had their legs chopped off with a sharp hatchet; those who were too short were stretched (his name was said to be Damastes, or Polyphemon, but he was nicknamed Procrustes, which meant “the stretcher”).
In the purest of poetic justice, Procrustes was hoisted by his own petard. One of the travelers happened to be the fearless Theseus, who slayed the Minotaur later in his heroic career. After the customary dinner, Theseus made Procrustes lie in his own bed. Then, to make him fit in it to the customary perfection, he decapitated him. Theseus thus followed Hercules’s method of paying back in kind.
In more sinister versions (such as the one in Pseudo-Apollodorus’s
Bibliotheca
), Procrustes owned two beds, one
small, one large; he made short victims lie in the large bed, and the tall victims in the short one.
Every aphorism here is about a Procrustean bed of sorts—we humans, facing limits of knowledge, and things we do not observe, the unseen and the unknown, resolve the tension by squeezing life and the world into crisp commoditized ideas, reductive categories, specific vocabularies, and prepackaged narratives, which, on the occasion, has explosive consequences. Further, we seem unaware of this backward fitting, much like tailors who take great pride in delivering the perfectly fitting suit—but do so by surgically altering the limbs of their customers. For instance, few realize that we are changing the brains of schoolchildren through medication in order to make them adjust to the curriculum, rather than the reverse.
Since aphorisms lose their charm whenever explained, I only hint for now at the central theme of this book—I relegate further discussions to the postface. These are stand-alone compressed thoughts revolving around my main idea of
how we deal, and should deal, with what we don’t know
, matters more deeply discussed in my books
The Black Swan
and
Fooled by Randomness
.
*
*
My use of the metaphor of the Procrustes bed isn’t just about putting something in the wrong box; it’s mostly that inverse operation of changing the wrong variable, here the person rather than the bed. Note that every failure of what we call “wisdom” (coupled with technical proficiency) can be reduced to a Procrustean bed situation.


================================================================================
CHAPTER/SECTION 329 (Item 340)
================================================================================

NOTICE
Aphorisms are different from conventional text. The author recommends reading no more than four aphorisms in one sitting. It is also preferable to select these randomly.


================================================================================
CHAPTER/SECTION 330 (Item 341)
================================================================================

PRELUDES
The person you are the most afraid to contradict is yourself.
An idea starts to be interesting when you get scared of taking it to its logical conclusion.
People are much less interested in what you are trying to show them than in what you are trying to hide.
Pharmaceutical companies are better at inventing diseases that match existing drugs, rather than inventing drugs to match existing diseases.
To understand the liberating effect of asceticism, consider that losing all your fortune is much less painful than losing only half of it.
To bankrupt a fool, give him information.
Academia is to knowledge what prostitution is to love; close enough on the surface but, to the nonsucker, not exactly the same thing.
*
1
In science you need to understand the world; in business you need others to misunderstand it.
I suspect that they put Socrates to death because there is something terribly unattractive, alienating, and nonhuman in thinking with too much clarity.
Education makes the wise slightly wiser, but it makes the fool vastly more dangerous.
The test of originality for an idea is not the absence of one single predecessor but the presence of multiple but incompatible ones.
Modernity’s double punishment is to make us both age prematurely and live longer.
An erudite is someone who displays less than he knows; a journalist or consultant, the opposite.
Your brain is most intelligent when you don’t instruct it on what to do—something people who take showers discover on occasion.
If your anger decreases with time, you did injustice; if it increases, you suffered injustice.
I wonder if those who advocate generosity for its rewards notice the inconsistency, or if what they call generosity is an attractive investment strategy.
*
2
Those who think religion is about “belief” don’t understand religion, and don’t understand belief.
Work destroys your soul by stealthily invading your brain during the hours not officially spent working; be selective about professions.
In nature we never repeat the same motion; in captivity (office, gym, commute, sports), life is just repetitive-stress injury. No randomness.
Using, as an excuse, others’ failure of common sense is in itself a failure of common sense.
Compliance with the straitjacket of narrow (Aristotelian) logic and avoidance of fatal inconsistencies are not the same thing.
Economics cannot digest the idea that the collective (and the aggregate) are disproportionately less predictable than individuals.
Don’t talk about “progress” in terms of longevity, safety, or comfort before comparing zoo animals to those in the wilderness.
If you know, in the morning, what your day looks like with any precision, you are a little bit dead—the more precision, the more dead you are.
There is no intermediate state between ice and water but there is one between life and death: employment.
You have a calibrated life when most of what you fear has the titillating prospect of adventure.
Procrastination is the soul rebelling against entrapment.
Nobody wants to be perfectly transparent; not to others, certainly not to himself.
Erudition without bullshit, intellect without cowardice, courage without imprudence, mathematics without nerdiness, scholarship without academia, intelligence without shrewdness, religiosity without intolerance, elegance without softness, sociality without dependence, enjoyment without addiction, religion without tolerance, and, above all, nothing without skin in the game.
*
1
I need a qualifier here. There are exceptions, but there are also many known cases in which a prostitute falls in love with a client.
*
2
A generous act is precisely what should aim at no reward, neither financial nor social nor emotional; deontic (unconditional observance of duties), not utilitarian (aiming at some collective—or even individual—gains in welfare). There is nothing wrong with “generous” acts that elicit a “warm glow” or promise salvation to the giver; these are not to be linguistically conflated with deontic actions, those emanating from pure sense of duty.


================================================================================
CHAPTER/SECTION 331 (Item 342)
================================================================================

COUNTER NARRATIVES
People don’t like it when you ask them for help; they also feel left out when you don’t ask them for help.
The best revenge on a liar is to convince him that you believe what he said.
When we want to do something while unconsciously certain to fail, we seek advice so we can blame someone else for the failure.
France took Algeria hoping for a country to eat cassoulet, and instead France is now eating couscous.
It is harder to say
no
when you really mean it than when you don’t.
Never say
no
twice if you mean it.
We tend to define rudeness less by the words used (what is said) than by the status of the recipient (to whom it is addressed).
Your reputation is harmed the most by what you say to defend it.
The only objective definition of aging is when a person starts to talk about aging.
They will envy you for your success, for your wealth, for your intelligence, for your looks, for your status—but rarely for your wisdom.
Most of what they call humility is successfully disguised arrogance.
Much of the difference between what is work and what is leisure is branding.
If you want people to read a book, tell them it is overrated.
You never win an argument until they attack your person.
The modern hypocrite gives the designation “respect” to what is nothing but fear of the powerful.
Nothing is more permanent than “temporary” arrangements, deficits, truces, and relationships; and nothing is more temporary than “permanent” ones.
The first one who uses “but” has lost the argument.
The most painful moments are not those we spend with uninteresting people; rather, they are those spent with uninteresting people trying hard to be interesting.
Hatred is love with a typo somewhere in the computer code, correctable but very hard to find.
Most mistakes get worse when you try to correct them.
I wonder whether a bitter enemy would be jealous if he discovered that I hated someone else.
The main reason to go to school is to learn how
not
to think like a professor.
The characteristic feature of the loser is to bemoan, in general terms, mankind’s flaws, biases, contradictions, and irrationality—without exploiting them for fun and profit.
The test of whether you really liked a book is if you reread it (and how many times); the test of whether you really liked someone’s company is if you are ready to meet him again and again—the rest is spin, or that variety of sentiment now called self-esteem.
If someone is making an effort to ignore you, he is not ignoring you.
We ask “why is he rich (or poor)?” not “why isn’t he richer (or poorer)?”; “why is the crisis so deep?” not “why isn’t it deeper?”
One of life’s machinations is to make some people both rich and unhappy, that is, jointly fragile and deprived of hope.
Hatred is much harder to fake than love. You hear of fake love; never of fake hate.
Sometimes people ask you a question with their eyes begging you to not tell them the truth.
The opposite of manliness isn’t cowardice; it’s technology.
Usually, what we call a “good listener” is someone with skillfully polished indifference.
In your prayers substitute “Protect us from evil” with “Protect us from those who improve things for a salary.”
It is the appearance of inconsistency, and not its absence, that makes people attractive.
You remember emails you sent that were not answered better than emails that you did not answer.
Never read a book review written by an author whose books you wouldn’t read.
People reserve standard compliments for those who do not threaten their pride; the others they often praise by calling “arrogant.”
The dream of having computers behave like humans is coming true, with the transformation, in a single generation, of humans into computers.
Since Cato the Elder, a certain type of maturity has shown up when one starts blaming the new generation for “shallowness” and praising the previous one for its “values.”
Almost all those caught making a logical fallacy interpret it as a “disagreement.”
It is as difficult to avoid bugging others with advice on how to exercise and other health matters as it is to stick to an exercise schedule.
By praising someone for his lack of defects you are also implying his lack of virtues.
If powerful assholes don’t find you “arrogant,” it means you are doing something wrong.
When she shouts that what you did was unforgivable, she has already started to forgive you.
Being unimaginative is only a problem when you are easily bored.
People feel deep anxiety finding out that someone they thought was stupid is actually more intelligent than they are.
We call narcissistic those individuals who behave as if they were the central residents of the world; those who do exactly the same in a set of two we call lovers or, better, “blessed by love.”
Friendship that ends was never one; there was at least one sucker in it.
Most people fear being without audiovisual stimulation because they are too repetitive when they think and imagine things on their own.
When someone writes “I dislike you but I agree with you,” I read “I dislike you because I agree with you.”
Unrequited hate is vastly more diminishing for the self than unrequited love. You can’t react by reciprocating.
A government stating, “We will not stand idle in front of atrocities committed by [foreign dictator XYZ]” is typically trying to mitigate the guilt for standing idle in front of more atrocities committed by said XYZ.
For the compassionate, sorrow is more easily displaced by another sorrow than by joy.
Wisdom in the young is as unattractive as frivolity in the elderly.
Some people are only funny when they try to be serious.
It is difficult to stop the impulse to reveal secrets in conversation, as if information had the desire to live and the power to multiply.
It is a very powerful manipulation to let others win the small battles.
If you want strangers to help you, smile. For those close to you, cry.


================================================================================
CHAPTER/SECTION 332 (Item 343)
================================================================================

MATTERS ONTOLOGICAL
Life is about execution rather than purpose.
If you get easily bored, it means that your BS detector is functioning properly; if you forget (some) things, it means that your mind knows how to filter; and if you feel sadness, it means that you are human.
It is a very recent disease to mistake the unobserved for the nonexistent; but some are plagued with the worse disease of mistaking the unobserved for the unobservable.
We need to feel a little bit lost somewhere, physically or intellectually, at least once a day.
The ultimate freedom lies in not having to explain why you did something.
Asking science to explain life and vital matters is equivalent to asking a grammarian to explain poetry.
The good life—the
vita beata
—is like reading a Russian novel: It takes two hundred pages of struggling with the characters before one can start enjoying things. Then the agitation starts to make sense.
It is not possible to have fun when you try.
You exist if and only if you are free to do things without a visible objective, with no justification and, above all, outside the dictatorship of someone else’s narrative.
Automation makes otherwise pleasant activities turn into “work.”
Thinking that all individuals pursue “selfish” interests is equivalent to assuming that all random variables have zero covariance.
For life to be really fun, what you fear should line up with what you desire.


================================================================================
CHAPTER/SECTION 333 (Item 344)
================================================================================

THE SACRED AND THE PROFANE
You cannot express the holy in terms made for the profane, but you can discuss the profane in terms made for the holy.
Atheism (materialism) means treating the dead as if they were unborn. I won’t. By accepting the sacred, you reinvent religion.
Paganism is decentralized theology.
If you can’t spontaneously detect (without analyzing) the difference between sacred and profane, you’ll never know what religion means. You will also never figure out what we commonly call art. You will never understand anything.
People used to wear ordinary clothes weekdays and formal attire on Sunday. Today it is the exact reverse.
To mark a separation between holy and profane, I take a ritual bath after any contact, or correspondence (even emails), with consultants, economists, Harvard Business School professors, journalists, and those in similarly depraved pursuits; I then feel and act purified from the profane until the next episode.
Religion isn’t so much about telling man that there is one God as about preventing man from thinking that he is God.
The fewer the gods, the greater the dogma and theological intolerance. So
n
= 0 (“modern” atheists),
n
= 1 (Sunni purists),
n
= 1–2 (Monophysites),
n
= 3–12 (Greek Orthodoxy),
n
flex (Ancient Mediterranean Paganism).
The book is the only medium left that hasn’t been corrupted by the profane: everything else on your eyelids manipulates you with an ad.
*
1
You can replace lies with truth; but myth is only displaced with a narrative.
The sacred is all about unconditionals; the profane is all about conditionals.
*
2
The ancient Mediterranean: before monotheism, people changed and exchanged rites and gods as we do ethnic foods.
The source of the tragic in history is in mistaking someone else’s unconditional for conditional—and the reverse.
Atheists are just modern versions of religious fundamentalists: both take religion too literally.
Restaurants get you in with food to sell you liquor; religions get you in with belief to sell you rules (e.g., avoid debt). People can understand the notion of God, not unexplained rules, interdicts, and categorical heuristics.
One categorical: it is easier to fast than diet. You cannot be “slightly” kosher or halal by only eating a small portion of ham.
To be completely cured of newspapers, spend a year reading the previous week’s newspapers.
*
1
A comment here. After a long diet from the media, I came to realize that there is nothing that’s not (clumsily) trying to sell you something. I only trust my library. There is nothing wrong with the ownership of the physical book as a manifestation of human weakness, desire to show off, peacock tail–style signaling of superiority; it’s the commercial agenda outside the book that corrupts.
*
2
For instance, many people said to be unbribable are just too expensive.


================================================================================
CHAPTER/SECTION 334 (Item 345)
================================================================================

CHANCE, SUCCESS, HAPPINESS, AND STOICISM
Success is becoming in middle adulthood what you dreamed to be in late childhood. The rest comes from loss of control.
The opposite of success isn’t failure; it is name-dropping.
Modernity needs to understand that being rich and becoming rich are not mathematically, personally, socially, and ethically the same thing.
Corollary: if you socialize with someone with a smaller bank account than yours, you are obligated to converse as if you had exactly the same means, eat in the places where he eats, at no point in time show the pictures of your vacation in Provence or anything that hints at the differential in means.
You don’t become completely free by just avoiding to be a slave; you also need to avoid becoming a master.
*
Fortune punishes the greedy by making him poor and the very greedy by making him rich.
Quite revealing of human preferences that more suicides come from shame or loss of financial and social status than medical diagnoses.
Business wars are typically lost by both parties; academic wars are won by both sides.
Studying the work and intellectual habits of a “genius” to learn from him is like studying the garb of a chef to emulate his cooking.
“Wealthy” is meaningless and has no robust absolute measure; use intead the subtractive measure “unwealth,” that is, the difference, at any point in time, between what you have and what you would like to have.
You will never know for sure if someone is an asshole until he becomes rich.
Older people are most beautiful when they have what is lacking in the young: poise, erudition, wisdom, phronesis, and this post-heroic absence of agitation.
I went to a happiness conference; researchers looked very unhappy.
What fools call “wasting time” is most often the best investment.
Decline starts with the replacement of dreams with memories and ends with the replacement of memories with other memories.
There is no clearer sign of failure than a middle-aged man boasting of his performance in college.
You want to avoid being disliked without being envied or admired.
Read nothing from the past one hundred years; eat no fruits from the past one thousand years; drink nothing from the past four thousand years (just wine and water); but talk to no ordinary man over forty. A man without a heroic bent starts dying at the age of thirty.
Some pursuits are much duller from the inside. Even piracy, they say.
Karl Marx, a visionary, figured out that you can control a slave much better by convincing him he is an employee.
I wonder how many people would seek excessive wealth if it did not carry a measure of status with it.
Catholic countries had more serial monogamy than today, but without the need for divorce—life expectancy was short; marriage duration was much, much shorter.
To figure out how well you will do ten years from now relative to someone else, count your enemies, count his, and square the ratio.
The fastest way to become rich is to socialize with the poor; the fastest way to become poor is to socialize with the rich.
The alpha person at a gathering of “high status” persons is often, detectably, the waiter.
You will be civilized on the day you can spend a long period doing nothing, learning nothing, and improving nothing, without feeling the slightest amount of guilt.
Someone who says “I am busy” is either declaring incompetence (and lack of control of his life) or trying to get rid of you.
Success in all endeavors requires the absence of specific qualities. 1) To succeed in crime requires absence of empathy, 2) To succeed in banking you need absence of shame at hiding risks, 3) To succeed in school requires absence of common sense, 4) To succeed in economics requires absence of understanding of probability, risk, second-order effects, or about anything, 5) To succeed in journalism requires an inability to think about matters that have even an infinitesimally small chance of being relevant next January, 6) But to succeed in life requires a total inability to do anything that makes you uncomfortable when you look at yourself in the mirror.
The difference between slaves in Roman and Ottoman days and today’s employees is that slaves did not need to flatter their boss.
The natural benefit of cellphones, laptops, and other indispensable modern items is the joy one gets finding the object after losing it. Lose your wallet full of credit cards and you will have a chance to have a great day.
You are rich if and only if money you refuse tastes better than money you accept.
Do not socialize with people much richer than you; but if you do, do it in your own territory (restaurants you can afford, wine, etc.).
For most, success is the harmful passage from the camp of the hating to the camp of the hated.
To see if you like where you are, without the chains of dependence, check if you are as happy returning as you were leaving.
You can tell how poor someone feels by the number of times he references “money” in his conversation.
The difference between love and happiness is that those who talk about love tend to be in love, but those who talk about happiness tend to be not happy.
Modernity: we created youth without heroism, age without wisdom, and life without grandeur.
You can tell how uninteresting a person is by asking him whom he finds interesting.
The Web is an unhealthy place for someone hungry for attention.
I wonder if anyone ever measured the time it takes, at a party, before a mildly successful stranger who went to Harvard makes others aware of it.
People focus on role models; it is more effective to find antimodels—people you don’t want to resemble when you grow up.
It is a good practice to always apologize, except when you have done something wrong.
Preoccupation with efficacy is the main obstacle to a poetic, noble, elegant, robust, and heroic life.
Some, like most bankers, are so unfit for success that they look like dwarves dressed in giants’ clothes.
Don’t complain too loud about wrongs done you; you may give ideas to your less imaginative enemies.
Most feed their obsessions by trying to get rid of them.
It is as difficult to change someone’s opinions as it is to change his tastes.
What we commonly call “success” (rewards, status, recognition, some new metric) is a consolation prize for those who are both unhappy and not good at what they do.
I have the fondest memories of time spent in places called ugly, the most boring ones of places called scenic.
It is good to not feel envy; but better to neither envy nor be envied.
Fitness is certainly the sign of strength, but outside of natural stimuli the drive to acquire fitness can signal some deep incurable weakness.
Charm is the ability to insult people without offending them; nerdiness the reverse.
Those who do not think that employment is systemic slavery are either blind or employed.
They are born, then put in a box; they go home to live in a box; they study by ticking boxes; they go to what is called “work” in a box, where they sit in their cubicle box; they drive to the grocery store in a box to buy food in a box; they go to the gym in a box to sit in a box; they talk about thinking “outside the box”; and when they die they are put in a box. All boxes, Euclidian, geometrically smooth boxes.
Never hire an A student unless it is to take exams.
Another definition of modernity: conversations can be more and more completely reconstructed with clips from other conversations taking place at the same time on the planet.
The twentieth century was the bankruptcy of the social utopia; the twenty-first will be that of the technological one.
In the days of Suetonius, 60 percent of prominent educators (grammarians) were slaves. Today the ratio is 97.1 percent, and growing.
Efforts at building social, political, and medical utopias have caused nightmares; many cures and techniques came from martial efforts.
The Web’s “connectedness” creates a peculiar form of informational and pseudosocial promiscuity, which makes one feel clean after Web rationing.
In most debates, people seem to be trying to convince one another; but all they can hope for is new arguments to convince themselves.
Did you notice that collecting art is to hobby-painting as watching pornography is to doing the real thing? Only difference is status.
*
Versions of this point have been repeated and rediscovered throughout history—the last convincing one by Montaigne.


================================================================================
CHAPTER/SECTION 335 (Item 346)
================================================================================

CHARMING AND LESS CHARMING SUCKER PROBLEMS
The most depressing aspect of the lives of the couples you watch surreptitiously arguing in restaurants is that they are almost always unaware of the true subject of argument.
It seems that it is the most unsuccessful people who give the most advice, particularly for writing and financial matters.
Never get into a business partnership with a retired lawyer unless he has another hobby.
Rumors are only valuable when they are denied.
The problem with academics is that they really think nonacademics find them more intelligent than themselves.
Over the long term, you are more likely to fool yourself than others.
Universities have been progressing from providing scholarship for a small fee into selling degrees at a large cost.
There are two types of people: those who try to win and those who try to win arguments. They are never the same.
The rational heuristic is to avoid any market commentary from anyone who has to work for a living.
People usually apologize so they can do it again.
Mathematics is to knowledge what an artificial hand is to the real one; some amputate to replace.
Modernity inflicts a sucker narrative on activities; now we “walk for exercise,” not “walk” with no justification; for hidden reasons.
Bureaucracy is a construction designed to maximize the distance between a decision-maker and the risks of the decision.
Social media are severely antisocial, health foods are empirically unhealthy, knowledge workers are very ignorant, and social sciences aren’t scientific at all.
People tend to whisper when they say the truth and raise their voice when they lie.
For so many, instead of looking for “cause of death” when they expire, we should be looking for “cause of life” when they are still around.
Under opacity, incomplete information, and partial understanding, much of what we don’t understand is labeled “irrational.”
It is those who use others who are the most upset when someone uses them.
If someone gives you more than one reason why he wants the job, don’t hire him.
Executive programs allow us to watch people who have never worked lecturing those who have never pondered.
Failure of second-order thinking: he tells you a secret and somehow expects you to keep it, when he just gave you evidence that he can’t keep it himself.
When people say, “I am investing for the long term,” it means they are losing money.
Social networks present information about what people like; more informative if, instead, they described what they don’t like.
The fact that people in countries with cold weather tend to be harder working, richer, less relaxed, less amicable, less tolerant of idleness, more (over) organized and more harried than those in hotter climates should make us wonder whether wealth is mere indemnification, and motivation is just overcompensation for not having a real life.
All rumors about a public figure are to be deemed untrue until he threatens to sue.
People are so prone to overcausation that you can make the reticent turn loquacious by dropping an occasional “why?” in the conversation.
Never show a risk number, even if it is right.
I need to keep reminding myself that a truly independent thinker may look like an accountant.


================================================================================
CHAPTER/SECTION 336 (Item 347)
================================================================================

THESEUS, OR LIVING THE PALEO LIFE
The three most harmful addictions are heroin, carbohydrates, and a monthly salary.
The most important aspect of fasting is that you feel deep, undirected gratitude when you break the fast.
My only measure of success is how much time you have to kill.
I wonder if a lion (or a cannibal) would pay a high premium for free-range humans.
A good book gets better on the second reading. A great book on the third. Any book not worth rereading isn’t worth reading.
If you need to listen to music while walking, don’t walk; and please don’t listen to music.
Men destroy each other during war; themselves during peacetime.
Fasting: every human should learn to read, write, respect the weak, take risks in voicing disrespect for the powerful when warranted, and fast.
Sports feminize men and masculinize women.
Technology can degrade (and endanger) every aspect of a sucker’s life while convincing him that it is becoming more “efficient.”
The difference between technology and slavery is that slaves are fully aware that they are not free.
High Modernity: routine in place of physical effort, physical effort in place of mental expenditure, and mental expenditure in place of mental clarity.
You have a real life if and only if you do not compete with anyone in any of your pursuits.
In real life exams, someone gives you an answer and you have to find the best corresponding questions.
With terminal disease, nature lets you die with abbreviated suffering; medicine lets you suffer with prolonged dying.
We are satisfied with natural (or old) objects like vistas or classical paintings but insatiable with technologies, amplifying small improvements in versions, obsessed about 2.0, caught in a mental treadmill.
Only in recent history has “working hard” signaled pride rather than shame for lack of talent, finesse, and, mostly,
sprezzatura
.
It used to take seven years to figure out if a book is a book or journalism between covers. Now all one needs is to wait two years. Soon, a few months.
In summary, modernity replaced process with result and the relational with the transactional.
Some ideas are born as you write them down, others become dead.
Their idea of the sabbatical is to work six days and rest for one; my idea of the sabbatical is to work for (part of) a day and rest for six.
What they call “play” (gym, travel, sports) looks like work; the harder they try, the more captive they are.
Life is about early detection of the reversal point beyond which your own belongings (say, a house, country house, car, or business) start owning you.
Most modern efficiencies are deferred punishment.
We are hunters; we are only truly alive in those moments when we improvise; no schedule, just small surprises and stimuli from the environment.
For everything, use boredom in place of a clock, as a biological wristwatch, though under constraints of politeness.
A heuristic on whether you have control of your life: can you take naps?
Decomposition, for most, starts when they leave the free, social, and uncorrupted college life for the solitary confinement of professions and nuclear families.
One of the shortest books I’ve ever read had 745 pages.
The longest book I’ve ever read was 205 pages.
For a classicist, a competitive athlete is painful to look at; trying hard to become an animal rather than a man, he will never be as fast as a cheetah or as strong as an ox.
Skills that transfer: street fights, off-path hiking, seduction, broad erudition. Skills that don’t: school, games, sports, laboratory—what’s reduced and organized.
Formal education is credentials plus negative knowledge, so it sort of works out on balance.
You exist in full if and only if your conversation (or writings) cannot be easily reconstructed with clips from other conversations.
The English have random Mediterranean weather; but they go to Spain because their free hours aren’t free.
It is a curse to have ideas that people understand only when it is too late.
For most, work and what comes with it have the eroding effect of chronic injury.
Real life (
vita beata
) is when your choices correspond to your duties.
Technology is at its best when it is invisible.
The difference between true life and modern life equals the one between a conversation and bilateral recitations.
When I look at people on treadmills I wonder how alpha lions, the strongest, expend the least amount of energy, sleeping twenty hours a day; others hunt for them.
Caesar pontem fecit
.
*
Every social association that is not face-to-face is injurious to your health.
I fail to see the difference between extreme wealth and overdose.
*
Literally, “Caesar built a bridge,” but the subtlety is that it can also suggest that “he had a bridge built for him.”


================================================================================
CHAPTER/SECTION 337 (Item 348)
================================================================================

THE REPUBLIC OF LETTERS
Writing is the art of repeating oneself without anyone noticing.
Most people write so they can remember things; I write to forget.
What they call philosophy I call literature; what they call literature I call journalism; what they call journalism I call gossip; and what they call gossip I call (generously) voyeurism.
If the professor is not capable of giving a class without preparation, don’t attend. People should only teach what they have learned organically, through experience and curiosity…or get another job.
Writers are remembered for their best work, politicians for their worst mistakes, and businessmen are almost never remembered.
Critics may appear to blame the author for not writing the book they wanted to read; but in truth they are blaming him for writing the book they wanted, but were unable, to write.
Literature is not about promoting qualities, rather, airbrushing (your) defects.
For pleasure, read one chapter by Nabokov. For punishment, two.
I was told to write medium-sized books. Yet of the two most successful French novels in history, one is very short (
Le Petit Prince
, 80 pages), the other extra long (Proust’s
Recherche
, 3,200 pages), following the statistical arcsine law.
There is a distinction between expressive hypochondria and literature, just as there is one between self-help and philosophy.
You need to keep reminding yourself of the obvious: charm lies in the unsaid, the unwritten, and the undisplayed. It takes mastery to control silence.
No author should be considered as having failed until he starts teaching others about writing.
Hard science gives sensational results with a horribly boring process; philosophy gives boring results with a sensational process; literature gives sensational results with a sensational process; and economics gives boring results with a boring process.
A good maxim allows you to have the last word without even starting a conversation.
A writer told me, “I didn’t get anything done today.” Answer: try to do nothing. The best way to have only good days is to not aim at getting anything done. Actually almost everything I’ve written that has survived was written when I didn’t try to get anything done.
Just as there are authors who enjoy having written and others who enjoy writing, there are books you enjoy reading and others you enjoy having read.
A genius is someone with flaws harder to imitate than his qualities.
With regular books, read the text and skip the footnotes; with those written by academics, read the footnotes and skip the text; and with business books, skip both the text and the footnotes.
Double a man’s erudition; you will halve his citations.
Authors deplete their soul when the marginal contribution of a new book is smaller than that of the previous one.
Losers, when commenting on the works of someone patently more impressive, feel obligated to unnecessarily bring down their subject by expressing what he is not (“he is not a genius, but…”; “while he is no Leonardo…”) instead of expressing what he is.
You are alive in inverse proportion to the density of clichés in your writing.
What we call “business books” is an eliminative category invented by bookstores for writings that have no depth, no style, no empirical rigor, and no linguistic sophistication.
Just like poets and artists, bureaucrats are born, not made; it takes normal humans extraordinary effort to keep attention on such boring tasks.
Mathematicians think in symbols, physicists in objects, philosophers in concepts, geometers in images, jurists in constructs, logicians in operators, writers in impressions, and idiots in words.
Remove all empty words from writings, résumés, conversation, except when they aim at courtesy.
The costs of specialization: architects build to impress other architects; models are thin to impress other models; academics write to impress other academics; filmmakers try to impress other filmmakers; painters impress art dealers; but authors who write to impress book editors tend to fail.
It is a waste of emotions to answer critics; better to stay in print long after they are dead.
I wonder why newssuckers don’t realize that if news had the slightest predictive and nonanecdotal value journalists would be monstrously rich. And if journalists were really not interested in money they would be writing literary essays.
I can predict when an author is about to plagiarize me, and poorly so when he writes that Taleb “popularized” the theory of Black Swan events.
*
Newspaper readers exposed to real prose are like deaf persons at a Puccini opera: they may like a thing or two while wondering, “what’s the point?”
Some books cannot be summarized (real literature, poetry); some can be compressed to about ten pages; the majority to zero pages.
The exponential information age is like a verbally incontinent person: he talks more and more as fewer and fewer people listen.
What we call fiction is, when you look deep, much less fictional than nonfiction; but it is usually less imaginative.
It’s much harder to write a book review for a book you’ve read than for a book you haven’t read.
Most so-called writers keep writing and writing with the hope to, some day, find something to say.
A risk you run when you write a book calling journalists BS vendors is that all your reviewers will be BS vendors.
Today, we mostly face the choice between those who write clearly about a subject they don’t understand and those who write poorly about a subject they don’t understand.
The information-rich Dark Ages: in 2010, 600,000 books were published, just in English, with few memorable quotes. Circa
AD
zero, a handful of books were written. In spite of the few that survived, there are loads of quotes.
In the past, most were ignorant, one in a thousand were refined enough to talk to. Today, literacy is higher, but thanks to progress, the media, and finance, only one in ten thousand.
We are better at (involuntarily) doing out of the box than (voluntarily) thinking out of the box.
I want to write books that only those who read them claim they did.
Half of suckerhood is not realizing that what you don’t like might be loved by someone else (hence by you, later), and the reverse.
It is much less dangerous to think like a man of action than to act like a man of thought.
Literature comes alive when covering up vices, defects, weaknesses, and confusions; it dies with every trace of preaching.
In any subject, if you don’t feel that you don’t know enough, you don’t know enough.
*
It is also an indicator that he will imitate, “me, too” style, my business.


================================================================================
CHAPTER/SECTION 338 (Item 349)
================================================================================

THE UNIVERSAL AND THE PARTICULAR
What I learned on my own I still remember.
Regular minds find similarities in stories (and situations); finer minds detect differences.
To grasp the difference between Universal and Particular, consider that some dress better to impress a single, specific person than an entire crowd.
We unwittingly amplify commonalities with friends, dissimilarities with strangers, and contrasts with enemies.
Many are so unoriginal they study history to find mistakes to repeat.
There is nothing deemed harmful (in general) that cannot be beneficial in some particular instances, and nothing deemed beneficial that cannot harm you in some circumstances. The more complex the system, the weaker the notion of Universal.
The fool generalizes the particular; the nerd particularizes the general; some do both; and the wise does neither.
You want to be yourself, idiosyncratic; the collective (school, rules, jobs, technology) wants you generic to the point of castration.
True love is the complete victory of the particular over the general, and the unconditional over the conditional.
For an honest person, freedom requires having no friends; and, one step above, sainthood requires having no family.


================================================================================
CHAPTER/SECTION 339 (Item 350)
================================================================================

FOOLED BY RANDOMNESS
Unless we manipulate our surroundings, we have as little control over what and whom we think about as we do over the muscles of our hearts.
It is very difficult to argue with salaried people that the simple can be important and the important can be simple.
Corollary to Moore’s Law: every ten years, collective wisdom degrades by half.
*
1
A hotshot is someone temporarily perceived to be of some importance, rather than perceived to be of some temporary importance.
God created Monte Carlo and similar places so extremely rich people would come experience extreme envy.
Never rid anyone of an illusion unless you can replace it in his mind with another illusion. (But don’t work too hard on it; the replacement illusion does not even have to be more convincing than the initial one.)
The tragedy is that much of what you think is random is in your control and, what’s worse, the opposite.
The fool views himself as more unique and others more generic; the wise views himself as more generic and others more unique.
An academic cannot lose his tenure, but a businessman and risk taker, poor or rich, can go bankrupt. That is the infuriating inequality.
What made medicine fool people for so long was that its successes were prominently displayed and its mistakes (literally) buried.
The sucker’s trap is when you focus on what you know and what others don’t know, rather than the reverse.
Journalists cannot grasp that what is interesting is not necessarily important; most cannot even grasp that what is sensational is not necessarily interesting.
Medieval man was a cog in a wheel he did not understand; modern man is a cog in a complicated system he thinks he understands.
If a pilot crashes a plane,
n
= 1 is not anecdote; if he doesn’t crash the plane,
n
= 100 is anecdote.
The calamity of the information age is that the toxicity of data increases much faster than its benefits.
The role of the media is best seen in the journey from Cato the Elder to a modern politician.
*
2
Do some extrapolation if you want to be scared.
Mental clarity is the child of courage, not the other way around.
*
3
Probability is the intersection of the most rigorous mathematics and the messiest of life.
To rephrase, every human should at all times have equality in probability (which we can control), not equality in outcome.
Never rid anyone of an illusion unless you can replace it in his mind with another illusion.
Just as statisticians understand the risks of roulette sequences better than carpenters, probabilists understand systemic ecological risks better than biologists.
Most info-Web-media-newspaper types have a hard time swallowing the idea that knowledge is reached (mostly) by removing junk from people’s heads.
Finer men tolerate others’ small inconsistencies though not the large ones; the weak tolerate others’ large inconsistencies though not small ones.
Polemic is a lucrative form of entertainment, as the media can employ unpaid and fiercely motivated actors.
Randomness is indistinguishable from complicated, undetected, and undetectable order; but order itself is indistinguishable from artful randomness.
*
1
Moore’s Law stipulates that computational power doubles every eighteen months.
*
2
Say, Sarah Palin.
*
3
The biggest error since Socrates has been to believe that lack of clarity is the source of all our ills, not the result of them.


================================================================================
CHAPTER/SECTION 340 (Item 351)
================================================================================

AESTHETICS
Art is a one-sided conversation with the unobserved.
A golden saddle on a sick horse makes the problem feel worse; pomp and slickness in form make absence of substance nauseating.
The genius of Benoît Mandelbrot is in achieving aesthetic simplicity without having recourse to smoothness.
Beauty is enhanced by unashamed irregularities; magnificence by a façade of blunder.
To understand “progress”: all places we call ugly are both man-made and modern (Newark), never natural or historical (Rome).
We love imperfection, the right kind of imperfection; we pay up for original art and typo-laden first editions.
Most people need to wait for another person to say “this is beautiful art” to say “this is beautiful art”; some need to wait for two or more.
Your silence is only informational if you can speak skillfully.
Almutanabbi boasted that he was the greatest of all Arab poets, but he said so in the greatest of all Arab poems.
Wit seduces by signaling intelligence without nerdiness.
In classical renderings of prominent figures, males are lean and females are plump; in modern photographs, the opposite.
Studying neurobiology to understand humans is like studying ink to understand literature.
Just as no monkey is as good-looking as the ugliest of humans, no academic is worthier than the worst of the creators.
If you want to annoy a poet, explain his poetry.


================================================================================
CHAPTER/SECTION 341 (Item 352)
================================================================================

ETHICS
If you find any reason why you and someone are friends, you are not friends.
Soldiers are more loyal to their comrades (and willing to die for them) than to their country. Academics are more loyal to their peers than to truth.
My biggest problem with modernity may lie in the growing separation of the ethical and the legal.
*
1
People reveal much more about themselves while lying than when they tell the truth.
If we are the only animal with a sense of justice, it would clearly be because we also are about the only animal with a sense of cruelty.
Life’s beauty: the kindest act toward you in your life may come from an outsider not interested in reciprocation.
*
2
It is a great compliment for an honest person to be mistaken for a crook by a crook.
We are most motivated to help those who need us the least.
Supposedly, if you are uncompromising or intolerant with BS you lose friends. But you will also make friends, better friends.
To value a person, consider the difference between how impressive he or she was at the first encounter and the most recent one.
Anything people do, write, or say to enhance their status beyond what they give others shows like a mark on their foreheads, visible to others but not to them.
Meditation is a way to be narcissistic without hurting anyone.
Every angel is an asshole somewhere.
Every asshole is an angel somewhere.
True humility is when you can surprise yourself more than others; the rest is either shyness or good marketing.
The difference between the politician and the philosopher is that, in a debate, the politician doesn’t try to convince the other side, only the audience.
We find it to be in extremely bad taste for individuals to boast of their accomplishments; but when countries do so we call it “national pride.”
Another marker for charlatans: they don’t voice opinions that can get them in trouble.
You can only convince people who think they can benefit from being convinced.
Greatness starts with the replacement of hatred with polite disdain.
Never call someone an imbecile (or a fucking idiot) unless he causes harm to others/system; there must be a moral dimension to insults.
Trust people who make a living lying down or standing up more than those who do so sitting down.
Never take advice from a salesman, or any advice that benefits the advice giver.
Your duty is to scream those truths that one should shout but that are merely whispered.
The tragedy of virtue is that the more obvious, boring, unoriginal, and sermonizing the proverb, the harder it is to implement.
It is quite a predicament to be both evil and risk-averse.
Even the cheapest misers can be generous with advice.
If you lie to me, keep lying; don’t hurt me by suddenly telling the truth.
It is easy for others, but not for you, to detect the asymmetry between what you gain and what you give by doing, writing, or saying.
Don’t trust a man who needs an income—except if it is minimum wage.
*
3
You may outlive your strength, never your wisdom.
Something shoddy: citizenship of convenience, holding the passport of a country for ease of travel or tax treatment without committing to its community.
Weak men act to satisfy their needs, stronger men their duties.
Any action one takes with the aim of winning an award, any award, corrupts to the core.
Religions and ethics have evolved from promising heaven if you do good, to promising heaven while you do good, to making you promise to do good.
For social mobility to work, it needs to be a two-way highway, with a large number of pre-rich and an almost as large one of post-rich.
Avoid calling heroes those who had no other choice.
There are those who will thank you for what you gave them and others who will blame you for what you did not give them.
Envy, like thirst for revenge, is the wicked person’s version of our natural sense of injustice.
Ethical man accords his profession to his beliefs, instead of according his beliefs to his profession. This has been rarer and rarer since the Middle Ages.
A prostitute who sells her body (temporarily) is vastly more honorable than someone who sells his opinion for promotion or job tenure.
I trust everyone except those who tell me they are trustworthy.
People often need to suspend their self-promotion, and have someone in their lives they do not need to impress. This explains dog ownership.
Trust those who are greedy for money a thousand times more than those who are greedy for credentials.
Pure generosity is when you help the ingrate. Every other form is self-serving.
*
4
I wonder if crooks can conceive that honest people can be shrewder than they.
Trust those who trust you and distrust those who are suspicious of others.
In Proust there is a character, Morel, who demonizes Nissim Bernard, a Jew who lent him money, and becomes anti-Semitic just so he can escape the feeling of gratitude.
Multiplicative generosity: limit your generosity to those who, in turn, given the circumstances, would be equally generous toward others.
Promising someone good luck as a reward for good deeds sounds like a bribe—perhaps the remnant of an archaic, pre-deontic pre-classical morality.
Virtue is when the income you wish to show the tax agency exceeds what you wish to show your neighbor.
The difference between magnificence and arrogance is in what one does when nobody is looking.
Accept the rationality of time, never its fairness and morality.
The nation-state: apartheid without political incorrectness.
In a crowd of a hundred, 50 percent of the wealth, 90 percent of the imagination, and 100 percent of the intellectual courage will reside in a single person—not necessarily the same one.
The bottom half has typically been screwed by the middle class. That’s the entire story of Rome.
Just as dyed hair makes older men less attractive, it is what you do to hide your weaknesses that makes them repugnant.
Never buy a product that the owner of the company that makes it doesn’t use, or, in the case of, say, medication, wouldn’t contingently use.
For soldiers, we use the term “mercenary,” but we absolve employees of responsibility with “everybody needs to make a living.”
I am rather fed up with those who tell me to be nice and “try to convince” charlatans. The FBI didn’t “try to convince” the Mafia to abandon its activities.
English does not distinguish between arrogant-up (irreverence toward the temporarily powerful) and arrogant-down (directed at the small guy).
Distributive justice isn’t taking from a risk taker who earned honorably, it is keeping his probability of losing back his fortune very high.
Someone from your social class who becomes poor affects you more than thousands of starving ones outside of it.
It takes a lot of skills to be virtuous without being boring.
*
1
Former U.S. Treasury secretary “bankster” Robert Rubin, perhaps the biggest thief in history, broke no law. The difference between legal and ethical increases in a complex system…then blows it up.
*
2
The flip side: the worst pain inflicted on you will come from someone who at some point in your life cared about you.
*
3
Those in corporate captivity would do anything to “feed a family.”
*
4
Kantian ethics.


================================================================================
CHAPTER/SECTION 342 (Item 353)
================================================================================

ROBUSTNESS AND ANTIFRAGILITY
To understand how something works, figure out how to break it.
You are only secure if you can lose your fortune without the additional worse insult of having to become humble.
*
To test someone’s robustness to reputational errors, ask a man in front of an audience if he is “still doing poorly” or if he is “still losing money” and watch his reaction.
General principle: the solutions (on balance) need to be simpler than the problems.
The trick in life (and risk management) is to have as much respect for experience before one acquires said experience as one would after.
Robustness is progress without impatience.
When conflicted between two choices, take neither.
Nation-states like war; city-states like commerce; families like stability; and individuals like entertainment.
The problem with the idea of “learning from one’s mistakes” is that most of what people call mistakes aren’t mistakes.
Robust is when you care more about the few who like your work than the multitude who dislike it (artists); fragile when you care more about the few who dislike your work than the multitude who like it (politicians).
The rationalist imagines an imbecile-free society; the empiricist an imbecile-proof one, or, even better, a rationalist-proof one.
Failure-resistant is achievable; failure-free is not.
Academics are only useful when they try to be useless (say, as in mathematics and philosophy) and dangerous when they try to be useful.
For the robust, an error is information; for the fragile, an error is an error.
The best test of robustness to reputational damage is your emotional state (fear, joy, boredom) when you get an email from a journalist.
The main disadvantage of being a writer, particularly in Britain, is that there is nothing you can do in public or private that would damage your reputation.
The only valid political system is one that can handle an imbecile in power without suffering from it.
Passionate hate (by nations and individuals) ends by rotation to another subject of hate; mediocrity cannot handle more than one enemy. This makes warring statelings with shifting alliances and enmities a robust system.
You can expect blowups and explosive errors in fields where there is a penalty for simplicity.
I find it inconsistent (and corrupt) to dislike big government while favoring big business—but (alas) not the reverse.
Increasingly, people don’t become academics because of intelligence, but rather because of a lower grasp of disorder.
How often have you arrived one, three, or six hours late on a transatlantic flight as opposed to one, three, or six hours early? This explains why deficits tend to be larger, rarely smaller, than planned.
For a free person, the optimal—most opportunistic—route between two points should never be the shortest one.
*
My great-great-great-great-great grandfather’s rule.


================================================================================
CHAPTER/SECTION 343 (Item 354)
================================================================================

THE LUDIC FALLACY AND DOMAIN DEPENDENCE
*
1
I recently had a meal in a fancy restaurant with complicated dishes with fancy names ($125 per person), then enjoyed a pizza afterward, straight out of the oven, $7.95. I wonder why the pizza isn’t twenty times the price of the complicated dish, since I’d rather have the former—at any price—over the latter.
Sports are commoditized and, alas, prostituted randomness.
When you beat up someone physically, you get exercise and stress relief; when you assault him verbally on the Internet, you just harm yourself.
Just as eating cow meat doesn’t turn you into a cow, studying philosophy doesn’t make you wiser.
Just as smooth surfaces, competitive sports, and specialized work fossilize mind and body, competitive academia fossilizes the soul.
They agree that chess training only improves chess skills but disagree that classroom training (almost) only improves classroom skills.
People like to eat fish by the water even if the fish was caught far away and transported by trucks.
Upon arriving at the hotel in Dubai, the businessman had a porter carry his luggage; I later saw him lifting free weights in the gym.
Games were created to give nonheroes the illusion of winning. In real life, you don’t know who really won or lost (except too late), but you can tell who is heroic and who is not.
Mistakes detected by copy editors are not likely to be noticed by readers, and vice versa.
I suspect that IQ, SAT, and school grades are tests designed by nerds so they can get high scores in order to call each other intelligent.
*
2
They read Gibbon’s
Decline and Fall
on an eReader but refuse to drink Château Lynch-Bages in a Styrofoam cup.
Most can’t figure out why one can like rigorous knowledge and despise academics, yet they understand that one can like food and hate canned tuna.
My best example of the domain dependence of our minds, from my recent visit to Paris: at lunch in a French restaurant, my friends ate the salmon and threw away the skin; at dinner, at a sushi bar, the very same friends ate the skin and threw away the salmon.
Fragility: we have been progressively separating human courage from warfare, allowing wimps with computer skills to kill people without the slightest risk to their lives.
Those who can’t do shouldn’t teach.
*
1
Ludic
is Latin for “related to games”; the fallacy prevalent in
The Black Swan
about making life resemble games (or formal setups) with crisp rules rather than the reverse. Domain dependence is when one acts in a certain way in an environment (say, the gym) and a different way in another.
*
2
Smart and wise people who score low on IQ tests, or patently intellectually defective ones, like former U.S. president George W. Bush, who score high on them (130), are testing the test and not the reverse.


================================================================================
CHAPTER/SECTION 344 (Item 355)
================================================================================

EPISTEMOLOGY AND SUBTRACTIVE KNOWLEDGE
Since Plato, Western thought and the theory of knowledge have focused on the notions of True-False; as commendable as it was, it is high time to shift the concern to Robust-Fragile, and social epistemology to the more serious problem of Sucker-Nonsucker.
The problem of knowledge is that there are many more books on birds written by ornithologists than books on birds written by birds and books on ornithologists written by birds.
Change your anchor to what did not happen rather than what did happen.
The perfect sucker understands that pigs can stare at pearls but doesn’t realize he can be in an analog situation.
Those who violate a rule in a logically self-consistent system can only do well if they violate at least one additional logical rule.
It takes extraordinary wisdom and self-control to accept that many things have a logic we do not understand that is smarter than our own.
Knowledge is subtractive, not additive—what we subtract (reduction by what does not work, what
not
to do), not what we add (what to do).
*
They think that intelligence is about noticing things that are relevant (detecting patterns); in a complex world, intelligence consists in ignoring things that are irrelevant (avoiding false patterns).
In a conflict, the middle ground is least likely to be correct.
Happiness: we don’t know what it means, how to measure it, or how to reach it, but we know extremely well how to avoid unhappiness.
In the medical and social domains, treatment should never be equivalent to silencing symptoms.
The imagination of the genius vastly surpasses his intellect; the intellect of the academic vastly surpasses his imagination.
The ideal
trivium
education, and the least harmful one to society and pupils, would be mathematics, logic, and Latin; a double dose of Latin authors to compensate for the severe loss of wisdom that comes from mathematics; just enough mathematics and logic to control verbiage and rhetoric.
The four most influential moderns: Darwin, Marx, Freud, and (the productive) Einstein were scholars but not academics. It has always been hard to do genuine—and nonperishable—work within institutions.
*
The best way to spot a charlatan: someone (like a consultant or a stockbroker) who tells you what to do instead of what
not
to do.


================================================================================
CHAPTER/SECTION 345 (Item 356)
================================================================================

THE SCANDAL OF PREDICTION
A prophet is not someone with special visions, just someone blind to most of what others see.
For the ancients, forecasting historical events was an insult to the God(s); for me, it is an insult to man—that is, for some, to science.
The ancients knew very well that the only way to understand events was to cause them.
Anyone voicing a forecast or expressing an opinion without something at risk has some element of phoniness. Unless he risks going down with the ship this would be like watching an adventure movie.
They would take forecasting more seriously if it were pointed out to them that in Semitic languages the words for “forecast” and “prophecy” are the same.
For Seneca, the Stoic sage should withdraw from public efforts when unheeded and the state is corrupt beyond repair. It is wiser to wait for self-destruction.


================================================================================
CHAPTER/SECTION 346 (Item 357)
================================================================================

BEING A PHILOSOPHER AND MANAGING TO REMAIN ONE
To become a philosopher, start by walking very slowly.
Real mathematicians understand completeness, real philosophers understand incompleteness, the rest don’t formally understand anything.
In twenty-five centuries, no human came along with the brilliance, depth, elegance, wit, and imagination to match Plato—to protect us from his legacy.
A philosopher uses logic without statistics, an economist uses statistics without logic, a physicist uses both.
Why do I have an obsessive Plato problem? Most people need to surpass their predecessors; Plato managed to surpass all his successors.
It is perplexing but amusing to observe people getting extremely excited about things you don’t care about; it is sinister to watch them ignore things you believe are fundamental.
To be a philosopher is to know through long walks, by reasoning, and reasoning only,
a priori
, what others can only potentially learn from their mistakes, crises, accidents, and bankruptcies—that is,
a posteriori
.
Engineers can compute but not define, mathematicians can define but not compute, economists can neither define nor compute.
Something finite but with unknown upper bounds is epistemically equivalent to something infinite. This is epistemic infinity.
Mathematics demands an uncontrolled hunger for abstraction, philosophy a very controlled one.
Conscious ignorance, if you can practice it, expands your world; it can make things infinite.
For the classics, philosophical insight was the product of a life of leisure; for us, a life of leisure can be the product of philosophical insight.
For many people, it takes a lot of preparation to learn to become ordinary.
It takes a lot of intellect and confidence to accept that what makes sense doesn’t really make sense.
A theological Procrustean bed: for the Orthodox since Gregory Palamas and for the Arabs since Algazel, attempts to define God using the language of philosophical universals were a rationalistic mistake. I am still waiting for a modern to take notice.
Let us find what risks we can measure and these are the risks we should be taking.
Saying “the mathematics of uncertainty” is like saying “the chastity of sex”—what is mathematized is no longer uncertain, and vice versa.
If your approach to mathematics is mechanical not mystical, you’re not going to go anywhere.
Sadly, we learn the most from fools, economists, and other reverse role models, yet we pay them back with the worst ingratitude.
Salaried people are just stepparents. They can be good stepparents but never match the biological.
In Plato’s
Protagoras
, Socrates contrasts philosophy as the collaborative search for truth with the sophist’s use of rhetoric to gain the upper hand in argument for fame and money. Twenty-five centuries later, this is exactly the salaried researcher and the modern tenure-loving academic. Progress.


================================================================================
CHAPTER/SECTION 347 (Item 358)
================================================================================

ECONOMIC LIFE AND OTHER VERY VULGAR SUBJECTS
There are designations, like “economist,” “prostitute,” or “consultant,” for which additional characterization doesn’t add information.
A mathematician starts with a problem and creates a solution; a consultant starts by offering a “solution” and creates a problem.
Financial inequalities are ephemeral, one crash away from reallocation; inequalities of status are there to stay.
What they call “risk” I call opportunity; but what they call “low risk” opportunity I call sucker problem.
If you detect a repressed smile on the salesperson’s face, you paid too much for it.
Organizations are like caffeinated dupes unknowingly jogging backward; you only hear of the few who reach their destination.
There are three types of large corporations: those about to go bankrupt, those that are bankrupt and hide it, those that are bankrupt and don’t know it.
The best test of whether someone is extremely stupid (or extremely wise) is whether financial and political news makes sense to him.
The left holds that because markets are stupid models should be smart; the right believes that because models are stupid markets should be smart. Alas, it never hit both sides that both markets and models are very stupid.
When positive, show net; when negative, show gross.
Economics is like a dead star that still seems to produce light; but you know it is dead.
A trader listened to the firm’s “chief” economist’s predictions about gold, then lost a bundle. The trader was asked to leave the firm. He then angrily asked the boss who was firing him, “Why do you fire me alone, not the economist? He too is responsible for the loss.” The boss: “You idiot, we are not firing you for losing money—we are firing you for listening to the economist.”
Suckers think that you cure greed with money, addiction with substances, expert problems with experts, banking with bankers, economics with economists, and debt crises with debt spending.
You can be certain that the head of a corporation has a lot to worry about when he announces publicly that “there is nothing to worry about.”
Economics is about making simple things more complicated, mathematics about making complicated things simpler.
The stock market, in brief: participants are calmly waiting in line to be slaughtered while thinking it is for a Broadway show.
If something (say, a stock price) looks slightly out of line, it is out of line. If it looks way out of line, you are wrong in your method of evaluation.
The main difference between government bailouts and smoking is that in some rare cases the statement “this is my last cigarette” holds true.
It is easier to macrobullshit than to microbullshit.
What makes us fragile is that institutions cannot have the same virtues (honor, truthfulness, courage, loyalty, tenacity) as individuals.
The worst damage has been caused by competent people trying to do good; the best improvements have been brought by incompetent ones
not
trying to do good.
Saying someone is good at making profits but not good at managing risk is like saying someone is a great surgeon except for cases when the patients die.
The difference between banks and the Mafia: banks have better legal-regulatory expertise, but the Mafia understands public opinion.
“It is much easier to scam people for billions than for just millions.”
*
1
Being an entrepreneur is an existential not just a financial thing.
At a panel in Moscow, I watched an economist who got the “Nobel” for writings no one reads, theories no one uses, and lectures no one understands.
Anyone who likes meetings should be banned from attending meetings.
One of the failures of “scientific approximation” in the nonlinear domain comes from the inconvenient fact that the average of expectations is different from the expectation of averages.
*
2
An economist is a mixture of 1) a businessman without common sense, 2) a physicist without brains, and 3) a speculator without balls.
Journalists as reverse aphorists: my statement “you need skills to get a BMW, skills plus luck to become a Warren Buffett” was summarized as “Taleb says Buffett has
no
skills.”
The curious mind embraces science; the gifted and sensitive, the arts; the practical, business; the leftover becomes an economist.
Stiglitz understands everything about economics except for tail risks, which is like knowing everything about flight safety except for crashes.
Public companies, like human cells, are programmed for apoptosis, suicide through debt and hidden risks. Bailouts invest the process with a historical dimension.
Those with brains and no balls become mathematicians, those with balls and no brains join the Mafia, those with no balls and no brains become economists.
In poor countries, officials receive explicit bribes; in D.C. they get the sophisticated implicit, unspoken promise to work for large corporations.
Fate is at its cruelest when a banker ends up in poverty.
Never take investment advice from someone who has to work for a living.
We should make students recompute their GPAs by counting their grades in finance and economics backward.
The agency problem drives every company, thanks to the buildup of hidden risks, to maximal fragility.
Money corrupts those who talk (and write) about it more than those who earn it.
In politics we face the choice between warmongering, nation-state-loving, big-business agents on one hand; and risk-blind, top-down, epistemic arrogant big servants of large employers on the other. But we have a choice.
To have a great day: 1) Smile at a stranger, 2) surprise someone by saying something unexpectedly nice, 3) give some genuine attention to an elderly person, 4) invite someone who doesn’t have many friends for coffee, 5) humiliate an economist, publicly, or create deep anxiety inside a Harvard professor.
Bring the good news in trickles, the bad news in lumps.
Never ask your client for advice.
*
1
Inspired by the Madoff episode.
*
2
Don’t cross a river, because it is on average four feet deep. This is also known as Jensen’s inequality.


================================================================================
CHAPTER/SECTION 348 (Item 359)
================================================================================

THE SAGE, THE WEAK, AND THE MAGNIFICENT
*
1
Mediocre men tend to be outraged by small insults but passive, subdued, and silent in front of very large ones.
*
2
It is a sign of weakness to avoid showing signs of weakness.
The only definition of an alpha male: if you try to be an alpha male, you will never be one.
Risk takers never complain. They do.
Those who have nothing to prove never say that they have nothing to prove.
To be a person of virtue you need to be boringly virtuous in every single small action. To be a person of honor all you need is to be honorable in a few important things (risk your life or career or reputation for a just cause, say, or live up to your word when nobody else has the guts to do so).
The weak shows his strength and hides his weaknesses; the magnificent exhibits his weaknesses like ornaments.
Magnificence is defined by the intersection of reluctant praise by your enemies and criticism by your friends, greatness by their union.
How superb to become wise without being boring; how sad to be boring without being wise.
*
3
If you are only bad-mouthed by people who prefer your company over those of many others, only critiqued by those who scrutinize your work, and only insulted by persons who open your email as soon as they see it, then you are doing the right thing.
The traits I respect are erudition and the courage to stand up when half-men are afraid for their reputation. Any idiot can be intelligent.
The mediocre regret their words more than their silence; finer men regret their silence more than their words; the magnificent has nothing to regret.
It takes some humanity to feel sympathy for those less fortunate than us; but it takes honor to avoid envying those who are much luckier.
Regular men are a certain varying number of meals away from lying, stealing, killing, or even working as forecasters for the Federal Reserve in Washington; never the magnificent.
*
4
Social science means inventing a certain brand of human we can understand.
We viciously accept narcissism in nation-states, while repressing it in individuals: complexity exposes the system’s shaky moral foundations.
When expressing “good luck” to a peer, the weak wishes the opposite; the strong is mildly indifferent; but only the magnificent means it.
Contra the prevailing belief, “success” isn’t being on top of a hierarchy, it is standing outside all hierarchies.
In the past, only some of the males, but all of the females, were able to procreate. Equality is more natural for females.
Someone said, “We need more women in academic philosophy.” But we also need more men in academic philosophy.
The magnificent believes half of what he hears and twice what he says.
It is very easy to be stoic, in failure.
A verbal threat is the most authentic certificate of impotence.
The first, and hardest, step to wisdom: avert the standard assumption that people know what they want.
The two most celebrated acts of courage in history aren’t Homeric fighters but two Eastern Mediterranean fellows who died, even sought death, for their ideas.
The weak cannot be good; or, perhaps, he can only be good within an exhaustive and overreaching legal system.
Virtue is a sequence of small acts of omission. Honor and grandeur can be a single gutsy, momentous, and self-sacrificial act of commission.
By all means, avoid words—threats, complaints, justification, narratives, reframing, attempts to win arguments, supplications; avoid words!
Be polite, courteous, and gentle, but ignore comments, praise, and criticism from people you wouldn’t hire.
According to Lucian of Samosata, the philosopher Demonax stopped a Spartan from beating his servant. “You are making him your equal,” he said.
You are free in inverse proportion to the number of people to whom you can’t say “fuck you.” But you are honorable in proportion to the number of people to whom you can say “fuck you” with impunity but don’t.
The classical man’s worst fear was inglorious death; the modern man’s worst fear is just death.
I never trust a man who doesn’t have enemies.
When you cite some old wisdom-style quote and add “important truth,” “to remember,” or “something to live by,” you are not doing so because it is good, only because it is inapplicable. Had it been both good and applicable you would not have had to cite it. Wisdom that is hard to execute isn’t really wisdom.
*
1
In Aristotle’s
Nicomachean Ethics
, the megalopsychos, which I translate as the magnificent, is the “great-souled” who thinks of himself as worthy of great things and, aware of his own position in life, abides by a certain system of ethics that excludes pettiness. This notion of great soul, though displaced by Christian ethics advocating humility, remains present in Levantine culture, with the literal
Kabir al-nafs
. Among other attributes, the magnificent walks slowly.
*
2
Consider the reaction to the banking and economics establishments.
*
3
Looking at Federal Reserve Chairman Ben Bernanke.
*
4
I had to read Aristotle’s
Nicomachean Ethics
Book IV ten times before realizing what he didn’t say explicitly (but knew): the magnificent (megalopsychos) is all about unconditionals.


================================================================================
CHAPTER/SECTION 349 (Item 360)
================================================================================

THE IMPLICIT AND THE EXPLICIT
You know you have influence when people start noticing your absence more than the presence of others.
The only people who think that real world experience doesn’t matter are those who never had real world experience.
You are guaranteed a repetition when you hear the declaration “never again!”
Some reticent people use silence to conceal their intelligence; but most do so to hide the lack of it.
Complaints don’t deliver complaints, they mostly reveal your weakness.
Swearing on occasion, amid a rich vocabulary, is costly signaling that you are self-owned.
When someone says “I am not that stupid,” it often means that he is more stupid than he thinks.
Bad-mouthing is the only genuine, never faked expression of admiration.
You can only insult a barbarian in his own language.
When a woman says about a man that he is intelligent, she often means handsome; when a man says about a woman that she is dumb, he always means attractive.
What organized dating sites fail to understand is that people are far more interesting in what they don’t say about themselves.
If your beard is gray, produce heuristics but explain the “why.” If your beard is white, skip the why, just say what should be done.
For company, you often prefer those who find
you
interesting over those you find interesting.
The Internet broke the private-public wall; impulsive and inelegant utterances that used to be kept private are now available for literal interpretation.
A happier world is one in which everyone realizes that 1) it is not what you tell people, it is how you say it that makes them feel bad; 2) it is not what you do to them but how you make them look that gets them angry; 3) they should be the ones putting themselves in a specific category.
One of the problems with social networks is that it is getting harder and harder for others to complain about you behind your back.
People laugh out loud and broadcast their laughter when they’re worried about the statement that they purportedly find funny. They would smile—perhaps surreptitiously—otherwise.
You can be certain that a person has the means but not the will to help you when he says “there is nothing else I can do.” And you can be certain that a person has neither means nor will to help you when he says “I am here to help.”
The general principle of antifragility: it is much better to do things you cannot explain than explain things you cannot do.
We expect places and products to be less attractive than in marketing brochures, but we never forgive humans for being worse than their first impressions.
If something looks irrational—and has been so for a long time—odds are you have a wrong definition of rationality.
When someone starts a sentence with “simply,” you should expect to hear something very complicated.
Half the people lie with their lips; the other half with their tears.
The rules you explain are less convincing than the ones you don’t explain—or have to explain.
Knowing stuff others don’t know is most effective when others don’t know you know stuff they don’t know.


================================================================================
CHAPTER/SECTION 350 (Item 361)
================================================================================

ON THE VARIETIES OF LOVE AND NONLOVE
At any stage, humans can thirst for money, knowledge, or love; sometimes for two, never for three.
Love without sacrifice is like theft.
You may eventually forgive and befriend someone who harmed you, never someone who bored you.
Marriage is the institutional process of feminizing men—and feminizing women.
What counts is not what people say about you, it is how much energy they spend in saying it.
There are men who surround themselves with women (and seek wealth) for ostentation; others who do so mostly for consumption; they are rarely the same.
The ones who refer to you repeatedly as “my friend” are most likely to betray you.
Outside of friendship and love, it is very hard to find situations with bilateral, two-way suckers.
An enemy who becomes a friend will stay a friend; a friend turned enemy will never become one.
I attended a symposium, an event named after a fifth-century (
B.C.
) Athenian drinking party in which nonnerds talked about love; alas, there was no drinking and, mercifully, nobody talked about love.
Journalists feel contempt for those who fear them and a deep resentment for those who don’t.
You will get the most attention from those who hate you. No friend, no admirer, and no partner will flatter you with as much curiosity.
Used skillfully, a compliment will be much more offensive than any disparagement.
Humans need to complain just as they need to breathe. Never stop them; just manipulate them by controlling what they complain about and supply them with reasons to complain. They will complain but be thankful.
When a young woman partners with an otherwise uninteresting rich man, she can sincerely believe that she is attracted to some very specific body part (say, his nose, neck, or knee).
Injuries done to us by others tend to be acute; the self-inflicted ones tend to be chronic.
When people call you intelligent it is almost always because they agree with you. Otherwise they just call you arrogant.
A good foe is far more loyal, far more predictable, and, to the clever, far more useful than the most valuable admirer.
We often benefit from harm done to us by others, almost never from self-inflicted injuries.
If my detractors knew me better they would hate me even more.


================================================================================
CHAPTER/SECTION 351 (Item 362)
================================================================================

THE END
Wisdom isn’t about understanding things (and people); it is knowing what they can do to you.
Platonic minds expect life to be like film, with defined terminal endings; a-Platonic ones expect film to be like life and, except for a few irreversible conditions such as death, distrust the terminal nature of all human-declared endings.
The only problem with the last laugh is that the winner has to laugh alone.


================================================================================
CHAPTER/SECTION 352 (Item 363)
================================================================================

POSTFACE
The general theme of my work is the limitations of human knowledge, and the charming and less charming errors and biases when working with matters that lie outside our field of observation, the unobserved and the unobservables—the unknown; what lies on the other side of the veil of opacity.
Because our minds need to reduce information, we are more likely to try to squeeze a phenomenon into the Procrustean bed of a crisp and known category (amputating the unknown), rather than suspend categorization, and make it tangible. Thanks to our detections of false patterns, along with real ones, what is random will appear less random and more certain—our overactive brains are more likely to impose the wrong, simplistic narrative than no narrative at all.
*
1
The mind can be a wonderful tool for self-delusion—it
was not designed to deal with complexity and nonlinear uncertainties.
*
2
Counter to the common discourse,
more information means more delusions:
our detection of false patterns is growing faster and faster as a side effect of modernity and the information age: there is this mismatch between the messy randomness of the information-rich current world, with its complex interactions, and our intuitions of events, derived in a simpler ancestral habitat. Our mental architecture is at an increased mismatch with the world in which we live.
This leads to sucker problems: when the map does not correspond to the territory, there is a certain category of fool—the overeducated, the academic, the journalist, the newspaper reader, the mechanistic “scientist,” the pseudo-empiricist, those endowed with what I call “epistemic arrogance,” this wonderful ability to discount what they did not see, the unobserved—who enter a state of denial, imagining the territory as fitting his map. More generally, the fool here is someone who does the wrong reduction for the sake of reduction, or removes something essential, cutting off the legs, or, better, part of the head of a visitor while insisting that he preserved his persona with 95 percent accuracy. Look around at the Procrustean beds we’ve
created, some beneficial, some more questionable: regulations, top-down governments, academia, gyms, commutes, high-rise office buildings, involuntary human relationships, employment, etc.
Since the Enlightenment, in the great tension between
rationalism
(how we would like things to be so they make sense to us) and
empiricism
(how things are), we have been blaming the world for not fitting the beds of “rational” models, have tried to change humans to fit technology, fudged our ethics to fit our needs for employment, asked economic life to fit the theories of economists, and asked human life to squeeze into some narrative.
We are robust when errors in the representation of the unknown and understanding of random effects do not lead to adverse outcomes—fragile otherwise. The robust benefits from Black Swan events,
*
3
the fragile is severely hit by them. We are more and more fragile to a certain brand of scientific autism making confident claims about the unknown—leading to expert problems, risk, massive dependence on human error. As the reader can see from my aphorisms, I have respect for mother nature’s methods of robustness (billions of years allow most of what is fragile to break); classical thought is more robust (in its respect
for the unknown, the epistemic humility) than the modern post-Enlightenment naïve pseudoscientific autism. Thus my classical values make me advocate the triplet of erudition, elegance, and courage; against modernity’s phoniness, nerdiness, and philistinism.
*
4
Art is robust; science, not always (to put it mildly). Some Procrustean beds make life worth living: art and, the most potent of all, the poetic aphorism.
—
Aphorisms, maxims, proverbs, short sayings, even, to some extent, epigrams are the earliest literary form—often integrated into what we now call poetry. They carry the cognitive compactness of the sound bite (though both more potent and more elegant than today’s down-market version),
*
5
with some show of bravado in the ability of the author to compress powerful ideas in a handful of words—particularly in an oral format. Indeed, it had to be bravado, because the Arabic word for an improvised one-liner is “act of manliness,” though such a notion of “manliness” is
less gender-driven than it sounds and can be equally translated as “the skills of being human” (
virtue
has the same roots in Latin,
vir
, “man”). As if those who could produce powerful thoughts in such a way were invested with talismanic powers.
This mode is at the center of the Levantine soul (and the broader Eastern Mediterranean). When God spoke to the Semites, he spoke in very short poetic sentences, usually through the mouths of prophets. Consider the Scriptures, more particularly the books of Proverbs and Ecclesiastes; Islam’s holy book, the Koran, is a collection of concentrated aphorisms. And the format has been adopted for synthetic literary prophecies: Nietzsche’s
Zarathustra
, or, more recently, my compatriot from a neighboring (and warring) village in northern Lebanon, Kahlil Gibran, author of
The Prophet
.
Outside of what we now call religion, take the aphorisms of Heraclitus and Hippocrates; the works of Publilius Syrus (a Syrian slave who owed his freedom to his eloquence, expressed in his
Sententiae
, potent one-line poems that echo in the maxims of La Rochefoucauld), and the poetry of the poet who is broadly considered the greatest of all Arab poets, Almutanabbi.
Aphorisms as stand-alone sentences have been used for exposition, for religious text, for advice to a grandchild by a Levantine grandmother, for boasting (as I said earlier,
in an aphorism, Almutanabbi used them to tell us, convincingly, that he was the greatest Arab poet), for satires
*
6
(Martial, Aesop, Almaarri), by the
moralistes
(Vaugenargues, La Rochefoucauld, La Bruyère, Chamfort), to expose opaque philosophy (Wittgenstein), relatively clearer ones (Schopenhauer, Nietzsche, Cioran), or crystal-clear ideas (Pascal).
*
7
You never have to explain an aphorism—like poetry, this is something that the reader needs to deal with by himself.
*
8
There are bland aphorisms, the platitudinous ones harboring important truths that you had thought about before (the kind that make intelligent people recoil at Gibran’s
The Prophet
); pleasant ones, those you never thought about but trigger in you the
Aha!
of an important discovery (such as those in La Rochefoucauld); but the best are those you did not think about before, and for which it takes you more than one reading to realize that
they are important truths, particularly when the silent character of the truth in them is so powerful that they are forgotten as soon as read.
Aphorisms require us to change our reading habits and approach them in small doses; each one of them is a complete unit, a complete narrative dissociated from others.
My best definition of a nerd: someone who asks you to explain an aphorism.
—
I have been aware that my style was aphoristic. As a teenager, I was mentored by the poet Georges Schéhadé (his poetry reads like proverbs), who predicted that I would see the light and grow up to make a career in poetry, once I got this ideas business out of my system. More recently, readers have triggered numerous copyright alerts by posting quotes from my books on the Web, but I had never thought of re-expressing my ideas (or, rather, my central idea about the limits of knowledge) in such a way until I realized that these sentences come naturally to me, almost involuntarily, in an eerie way, particularly when walking (slowly) or when freeing up my mind to do nothing, or nothing effortful—I could convince myself that I was hearing voices from the other side of the veil of opacity.
By setting oneself totally free of constraints, free of thoughts, free of this debilitating activity called work, free of efforts, elements hidden in the texture of reality start staring at you; then mysteries that you never thought existed emerge in front of your eyes.
*
1
This discounting of the unseen comes from the human “scorn of the abstract” (our minds are not good at handling the non-anecdotal and tend to be swayed by vivid imagery, making the media distort our view of the world).
*
2
Nor is science capable of dealing effectively with nonlinear and complex matters, those fraught with interdependence (climate, economic life, the human body), in spite of its hyped-up successes in the linear domain (physics and engineering), which give it a prestige that has endangered us.
*
3
A Black Swan (capitalized) is an event (historical, economic, technological, personal) that is both unpredicted by some observer and carries massive consequences. In spite of growth in our knowledge, the role of these Black Swans has been growing.
*
4
Many philistines reduce my ideas to an opposition to technology when in fact I am opposing the naïve blindness to its side effects—the fragility criterion. I’d rather be unconditional about ethics and conditional about technology than the reverse.
*
5
Note the distinction from TV one-liners: the sound bite loses information; the aphorism gains. Somehow, aphorisms obey the Gigerenzer and Goldstein “less is more” effect.
*
6
The best way to measure the loss of intellectual sophistication in the Internet age—this “nerdification,” to put it bluntly—is in the growing disappearance of sarcasm, as mechanistic minds take insults a bit too literally.
*
7
It is not uncommon to find the same maxim repeated by several authors separated by a millennium or a continent.
*
8
The aphorism has been somewhat debased (outside the German language) by its association with witticism, such as the ones by Oscar Wilde, Mark Twain, Ambrose Bierce, or Sacha Guitry—deep thought can be poetic and witty, as with Schopenhauer, Nietzsche, or (sometimes) Wittgenstein; but, abiding by the distinction between Sacred and Profane, philosophy and poetry are not stand-up comedy.


================================================================================
CHAPTER/SECTION 353 (Item 364)
================================================================================

T
O
A
LEXANDER
N. T
ALEB


================================================================================
CHAPTER/SECTION 354 (Item 365)
================================================================================

ACKNOWLEDGMENTS
P. Tanous, L. de Chantal, B. Oppetit, M. Blyth, N. Vardy, B. Appleyard, C. Mihailescu, J. Baz, B. Dupire, Y. Zilber, S. Roberts, A. Pilpel, W. Goodlad, W. Murphy, M. Brockman, J. Brockman, C. Taleb, C. Sandis, J. Kujat, T. Burnham, M. Ghosn (the younger), S. Taleb, D. Riviere, J. Gray, M. Carreira, M.-C. Riachi, P. Bevelin, J. Audi (
pontem fecit
), S. Roberts, B. Flyvberg, E. Boujaoude, P. Boghossian, S. Riley, G. Origgi, S. Ammons, and many more (I sometimes remember names of critically helpful people when it is too late to show gratitude).


================================================================================
CHAPTER/SECTION 355 (Item 366)
================================================================================

B
Y
N
ASSIM
N
ICHOLAS
T
ALEB
Antifragile
The Bed of Procrustes
The Black Swan
Fooled by Randomness


================================================================================
CHAPTER/SECTION 356 (Item 367)
================================================================================

ABOUT THE AUTHOR
NASSIM NICHOLAS TALEB has devoted his life to problems of uncertainty, probability, and knowledge and has led three careers around this focus, as a businessman-trader, a philosophical essayist, and an academic researcher. Although he now spends most of his time either working in intense seclusion in his study, or as a flâneur meditating in cafés across the planet, he is currently Distinguished Professor of Risk Engineering at New York University’s Polytechnic Institute. His main subject matter is “decision making under opacity,” that is, a map and a protocol on how we should live in a world we don’t understand.
His books
Fooled by Randomness
and
The Black Swan
have been published in thirty-three languages.
Taleb believes that prizes, honorary degrees, awards, and ceremonialism debase knowledge by turning it into a spectator sport.


================================================================================
CHAPTER/SECTION 357 (Item 369)
================================================================================

What’s next on
your reading list?
Discover your next
great read!
Get personalized book picks and up-to-date news about this author.
Sign up now.

